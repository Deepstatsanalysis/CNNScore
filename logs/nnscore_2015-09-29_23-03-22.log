I0929 23:03:22.632784 25301 caffe.cpp:184] Using GPUs 0
I0929 23:03:23.204872 25301 solver.cpp:54] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "fixed"
momentum: 0.9
solver_mode: GPU
device_id: 0
net: "model/NNScore/nnscore_model_0.prototxt"
I0929 23:03:23.204902 25301 solver.cpp:97] Creating training net from net file: model/NNScore/nnscore_model_0.prototxt
I0929 23:03:23.205067 25301 net.cpp:339] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_layer
I0929 23:03:23.205112 25301 net.cpp:50] Initializing net from parameters: 
name: "model/NNScore/nnscore_model_0.prototxt"
state {
  phase: TRAIN
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TRAIN
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.0.train"
    batch_size: 20000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I0929 23:03:23.205149 25301 layer_factory.hpp:76] Creating layer data_layer
I0929 23:03:23.218515 25301 net.cpp:110] Creating Layer data_layer
I0929 23:03:23.218544 25301 net.cpp:433] data_layer -> data_blob
I0929 23:03:23.218566 25301 net.cpp:433] data_layer -> label_blob
I0929 23:03:23.219148 25305 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.0.train
I0929 23:03:23.901798 25301 data_layer.cpp:45] output data size: 20000,61,1,1
I0929 23:03:23.906707 25301 net.cpp:155] Setting up data_layer
I0929 23:03:23.906759 25301 net.cpp:163] Top shape: 20000 61 1 1 (1220000)
I0929 23:03:23.906764 25301 net.cpp:163] Top shape: 20000 (20000)
I0929 23:03:23.906780 25301 layer_factory.hpp:76] Creating layer hidden_sum_layer
I0929 23:03:23.906801 25301 net.cpp:110] Creating Layer hidden_sum_layer
I0929 23:03:23.906805 25301 net.cpp:477] hidden_sum_layer <- data_blob
I0929 23:03:23.906813 25301 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I0929 23:03:23.907177 25301 net.cpp:155] Setting up hidden_sum_layer
I0929 23:03:23.907184 25301 net.cpp:163] Top shape: 20000 10 (200000)
I0929 23:03:23.907207 25301 layer_factory.hpp:76] Creating layer hidden_act_layer
I0929 23:03:23.907213 25301 net.cpp:110] Creating Layer hidden_act_layer
I0929 23:03:23.907215 25301 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I0929 23:03:23.907218 25301 net.cpp:433] hidden_act_layer -> hidden_act_blob
I0929 23:03:27.111019 25301 net.cpp:155] Setting up hidden_act_layer
I0929 23:03:27.111042 25301 net.cpp:163] Top shape: 20000 10 (200000)
I0929 23:03:27.111048 25301 layer_factory.hpp:76] Creating layer output_sum_layer
I0929 23:03:27.111057 25301 net.cpp:110] Creating Layer output_sum_layer
I0929 23:03:27.111060 25301 net.cpp:477] output_sum_layer <- hidden_act_blob
I0929 23:03:27.111066 25301 net.cpp:433] output_sum_layer -> output_sum_blob
I0929 23:03:27.111145 25301 net.cpp:155] Setting up output_sum_layer
I0929 23:03:27.111150 25301 net.cpp:163] Top shape: 20000 1 (20000)
I0929 23:03:27.111172 25301 layer_factory.hpp:76] Creating layer output_act_layer
I0929 23:03:27.111177 25301 net.cpp:110] Creating Layer output_act_layer
I0929 23:03:27.111179 25301 net.cpp:477] output_act_layer <- output_sum_blob
I0929 23:03:27.111191 25301 net.cpp:433] output_act_layer -> output_act_blob
I0929 23:03:27.111243 25301 net.cpp:155] Setting up output_act_layer
I0929 23:03:27.111258 25301 net.cpp:163] Top shape: 20000 1 (20000)
I0929 23:03:27.111260 25301 layer_factory.hpp:76] Creating layer error_layer
I0929 23:03:27.111265 25301 net.cpp:110] Creating Layer error_layer
I0929 23:03:27.111268 25301 net.cpp:477] error_layer <- output_act_blob
I0929 23:03:27.111269 25301 net.cpp:477] error_layer <- label_blob
I0929 23:03:27.111273 25301 net.cpp:433] error_layer -> error_blob
I0929 23:03:27.111294 25301 net.cpp:155] Setting up error_layer
I0929 23:03:27.111297 25301 net.cpp:163] Top shape: (1)
I0929 23:03:27.111299 25301 net.cpp:168]     with loss weight 1
I0929 23:03:27.111315 25301 net.cpp:236] error_layer needs backward computation.
I0929 23:03:27.111316 25301 net.cpp:236] output_act_layer needs backward computation.
I0929 23:03:27.111318 25301 net.cpp:236] output_sum_layer needs backward computation.
I0929 23:03:27.111320 25301 net.cpp:236] hidden_act_layer needs backward computation.
I0929 23:03:27.111322 25301 net.cpp:236] hidden_sum_layer needs backward computation.
I0929 23:03:27.111325 25301 net.cpp:240] data_layer does not need backward computation.
I0929 23:03:27.111325 25301 net.cpp:283] This network produces output error_blob
I0929 23:03:27.111330 25301 net.cpp:297] Network initialization done.
I0929 23:03:27.111331 25301 net.cpp:298] Memory required for data: 6720004
I0929 23:03:27.111449 25301 solver.cpp:187] Creating test net (#0) specified by net file: model/NNScore/nnscore_model_0.prototxt
I0929 23:03:27.111480 25301 net.cpp:339] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_layer
I0929 23:03:27.111520 25301 net.cpp:50] Initializing net from parameters: 
name: "model/NNScore/nnscore_model_0.prototxt"
state {
  phase: TEST
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TEST
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.0.test"
    batch_size: 2000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I0929 23:03:27.111538 25301 layer_factory.hpp:76] Creating layer data_layer
I0929 23:03:27.112696 25301 net.cpp:110] Creating Layer data_layer
I0929 23:03:27.112702 25301 net.cpp:433] data_layer -> data_blob
I0929 23:03:27.112725 25301 net.cpp:433] data_layer -> label_blob
I0929 23:03:27.113284 25307 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.0.test
I0929 23:03:27.113365 25301 data_layer.cpp:45] output data size: 2000,61,1,1
I0929 23:03:27.114650 25301 net.cpp:155] Setting up data_layer
I0929 23:03:27.114668 25301 net.cpp:163] Top shape: 2000 61 1 1 (122000)
I0929 23:03:27.114681 25301 net.cpp:163] Top shape: 2000 (2000)
I0929 23:03:27.114684 25301 layer_factory.hpp:76] Creating layer hidden_sum_layer
I0929 23:03:27.114691 25301 net.cpp:110] Creating Layer hidden_sum_layer
I0929 23:03:27.114692 25301 net.cpp:477] hidden_sum_layer <- data_blob
I0929 23:03:27.114696 25301 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I0929 23:03:27.114812 25301 net.cpp:155] Setting up hidden_sum_layer
I0929 23:03:27.114817 25301 net.cpp:163] Top shape: 2000 10 (20000)
I0929 23:03:27.114835 25301 layer_factory.hpp:76] Creating layer hidden_act_layer
I0929 23:03:27.114838 25301 net.cpp:110] Creating Layer hidden_act_layer
I0929 23:03:27.114840 25301 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I0929 23:03:27.114852 25301 net.cpp:433] hidden_act_layer -> hidden_act_blob
I0929 23:03:27.115049 25301 net.cpp:155] Setting up hidden_act_layer
I0929 23:03:27.115056 25301 net.cpp:163] Top shape: 2000 10 (20000)
I0929 23:03:27.115068 25301 layer_factory.hpp:76] Creating layer output_sum_layer
I0929 23:03:27.115072 25301 net.cpp:110] Creating Layer output_sum_layer
I0929 23:03:27.115074 25301 net.cpp:477] output_sum_layer <- hidden_act_blob
I0929 23:03:27.115077 25301 net.cpp:433] output_sum_layer -> output_sum_blob
I0929 23:03:27.115144 25301 net.cpp:155] Setting up output_sum_layer
I0929 23:03:27.115149 25301 net.cpp:163] Top shape: 2000 1 (2000)
I0929 23:03:27.115165 25301 layer_factory.hpp:76] Creating layer output_act_layer
I0929 23:03:27.115169 25301 net.cpp:110] Creating Layer output_act_layer
I0929 23:03:27.115170 25301 net.cpp:477] output_act_layer <- output_sum_blob
I0929 23:03:27.115173 25301 net.cpp:433] output_act_layer -> output_act_blob
I0929 23:03:27.115231 25301 net.cpp:155] Setting up output_act_layer
I0929 23:03:27.115236 25301 net.cpp:163] Top shape: 2000 1 (2000)
I0929 23:03:27.115237 25301 layer_factory.hpp:76] Creating layer error_layer
I0929 23:03:27.115250 25301 net.cpp:110] Creating Layer error_layer
I0929 23:03:27.115252 25301 net.cpp:477] error_layer <- output_act_blob
I0929 23:03:27.115255 25301 net.cpp:477] error_layer <- label_blob
I0929 23:03:27.115258 25301 net.cpp:433] error_layer -> error_blob
I0929 23:03:27.115277 25301 net.cpp:155] Setting up error_layer
I0929 23:03:27.115279 25301 net.cpp:163] Top shape: (1)
I0929 23:03:27.115281 25301 net.cpp:168]     with loss weight 1
I0929 23:03:27.115288 25301 net.cpp:236] error_layer needs backward computation.
I0929 23:03:27.115289 25301 net.cpp:236] output_act_layer needs backward computation.
I0929 23:03:27.115291 25301 net.cpp:236] output_sum_layer needs backward computation.
I0929 23:03:27.115293 25301 net.cpp:236] hidden_act_layer needs backward computation.
I0929 23:03:27.115295 25301 net.cpp:236] hidden_sum_layer needs backward computation.
I0929 23:03:27.115298 25301 net.cpp:240] data_layer does not need backward computation.
I0929 23:03:27.115299 25301 net.cpp:283] This network produces output error_blob
I0929 23:03:27.115303 25301 net.cpp:297] Network initialization done.
I0929 23:03:27.115305 25301 net.cpp:298] Memory required for data: 672004
I0929 23:03:27.115322 25301 solver.cpp:66] Solver scaffolding done.
I0929 23:03:27.115419 25301 caffe.cpp:212] Starting Optimization
I0929 23:03:27.115425 25301 solver.cpp:294] Solving model/NNScore/nnscore_model_0.prototxt
I0929 23:03:27.115437 25301 solver.cpp:295] Learning Rate Policy: fixed
I0929 23:03:27.115597 25301 solver.cpp:347] Iteration 0, Testing net (#0)
I0929 23:03:27.115671 25301 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:03:27.376001 25301 solver.cpp:415]     Test net output #0: error_blob = 0.157134 (* 1 = 0.157134 loss)
I0929 23:03:27.377346 25301 solver.cpp:243] Iteration 0, loss = 0.158523
I0929 23:03:27.377365 25301 solver.cpp:259]     Train net output #0: error_blob = 0.158523 (* 1 = 0.158523 loss)
I0929 23:03:27.377377 25301 solver.cpp:590] Iteration 0, lr = 0.01
I0929 23:03:29.895791 25301 solver.cpp:243] Iteration 100, loss = 0.122459
I0929 23:03:29.895825 25301 solver.cpp:259]     Train net output #0: error_blob = 0.122459 (* 1 = 0.122459 loss)
I0929 23:03:29.895833 25301 solver.cpp:590] Iteration 100, lr = 0.01
I0929 23:03:32.443588 25301 solver.cpp:243] Iteration 200, loss = 0.120713
I0929 23:03:32.443629 25301 solver.cpp:259]     Train net output #0: error_blob = 0.120713 (* 1 = 0.120713 loss)
I0929 23:03:32.443635 25301 solver.cpp:590] Iteration 200, lr = 0.01
I0929 23:03:34.997541 25301 solver.cpp:243] Iteration 300, loss = 0.117902
I0929 23:03:34.997586 25301 solver.cpp:259]     Train net output #0: error_blob = 0.117902 (* 1 = 0.117902 loss)
I0929 23:03:34.997591 25301 solver.cpp:590] Iteration 300, lr = 0.01
I0929 23:03:37.573103 25301 solver.cpp:243] Iteration 400, loss = 0.117102
I0929 23:03:37.573165 25301 solver.cpp:259]     Train net output #0: error_blob = 0.117102 (* 1 = 0.117102 loss)
I0929 23:03:37.573170 25301 solver.cpp:590] Iteration 400, lr = 0.01
I0929 23:03:40.128279 25301 solver.cpp:243] Iteration 500, loss = 0.118842
I0929 23:03:40.128311 25301 solver.cpp:259]     Train net output #0: error_blob = 0.118842 (* 1 = 0.118842 loss)
I0929 23:03:40.128317 25301 solver.cpp:590] Iteration 500, lr = 0.01
I0929 23:03:42.683573 25301 solver.cpp:243] Iteration 600, loss = 0.118349
I0929 23:03:42.683620 25301 solver.cpp:259]     Train net output #0: error_blob = 0.118349 (* 1 = 0.118349 loss)
I0929 23:03:42.683627 25301 solver.cpp:590] Iteration 600, lr = 0.01
I0929 23:03:45.228366 25301 solver.cpp:243] Iteration 700, loss = 0.118852
I0929 23:03:45.228415 25301 solver.cpp:259]     Train net output #0: error_blob = 0.118852 (* 1 = 0.118852 loss)
I0929 23:03:45.228422 25301 solver.cpp:590] Iteration 700, lr = 0.01
I0929 23:03:47.816738 25301 solver.cpp:243] Iteration 800, loss = 0.116366
I0929 23:03:47.816768 25301 solver.cpp:259]     Train net output #0: error_blob = 0.116366 (* 1 = 0.116366 loss)
I0929 23:03:47.816774 25301 solver.cpp:590] Iteration 800, lr = 0.01
I0929 23:03:50.356058 25301 solver.cpp:243] Iteration 900, loss = 0.11488
I0929 23:03:50.356107 25301 solver.cpp:259]     Train net output #0: error_blob = 0.11488 (* 1 = 0.11488 loss)
I0929 23:03:50.356115 25301 solver.cpp:590] Iteration 900, lr = 0.01
I0929 23:03:50.407443 25301 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:03:52.936372 25301 solver.cpp:347] Iteration 1000, Testing net (#0)
I0929 23:03:53.281497 25301 solver.cpp:415]     Test net output #0: error_blob = 0.118563 (* 1 = 0.118563 loss)
I0929 23:03:53.282147 25301 solver.cpp:243] Iteration 1000, loss = 0.117211
I0929 23:03:53.282160 25301 solver.cpp:259]     Train net output #0: error_blob = 0.117211 (* 1 = 0.117211 loss)
I0929 23:03:53.282166 25301 solver.cpp:590] Iteration 1000, lr = 0.01
I0929 23:03:55.843179 25301 solver.cpp:243] Iteration 1100, loss = 0.11828
I0929 23:03:55.843227 25301 solver.cpp:259]     Train net output #0: error_blob = 0.11828 (* 1 = 0.11828 loss)
I0929 23:03:55.843235 25301 solver.cpp:590] Iteration 1100, lr = 0.01
I0929 23:03:58.452574 25301 solver.cpp:243] Iteration 1200, loss = 0.120075
I0929 23:03:58.452605 25301 solver.cpp:259]     Train net output #0: error_blob = 0.120075 (* 1 = 0.120075 loss)
I0929 23:03:58.452610 25301 solver.cpp:590] Iteration 1200, lr = 0.01
I0929 23:04:01.006929 25301 solver.cpp:243] Iteration 1300, loss = 0.116642
I0929 23:04:01.006968 25301 solver.cpp:259]     Train net output #0: error_blob = 0.116642 (* 1 = 0.116642 loss)
I0929 23:04:01.006975 25301 solver.cpp:590] Iteration 1300, lr = 0.01
I0929 23:04:03.590926 25301 solver.cpp:243] Iteration 1400, loss = 0.114349
I0929 23:04:03.590970 25301 solver.cpp:259]     Train net output #0: error_blob = 0.114349 (* 1 = 0.114349 loss)
I0929 23:04:03.590977 25301 solver.cpp:590] Iteration 1400, lr = 0.01
I0929 23:04:06.191818 25301 solver.cpp:243] Iteration 1500, loss = 0.114628
I0929 23:04:06.191855 25301 solver.cpp:259]     Train net output #0: error_blob = 0.114628 (* 1 = 0.114628 loss)
I0929 23:04:06.191864 25301 solver.cpp:590] Iteration 1500, lr = 0.01
I0929 23:04:08.779449 25301 solver.cpp:243] Iteration 1600, loss = 0.116625
I0929 23:04:08.779491 25301 solver.cpp:259]     Train net output #0: error_blob = 0.116625 (* 1 = 0.116625 loss)
I0929 23:04:08.779497 25301 solver.cpp:590] Iteration 1600, lr = 0.01
I0929 23:04:11.337908 25301 solver.cpp:243] Iteration 1700, loss = 0.117712
I0929 23:04:11.337956 25301 solver.cpp:259]     Train net output #0: error_blob = 0.117712 (* 1 = 0.117712 loss)
I0929 23:04:11.337965 25301 solver.cpp:590] Iteration 1700, lr = 0.01
I0929 23:04:13.855361 25301 solver.cpp:243] Iteration 1800, loss = 0.116548
I0929 23:04:13.855403 25301 solver.cpp:259]     Train net output #0: error_blob = 0.116548 (* 1 = 0.116548 loss)
I0929 23:04:13.855409 25301 solver.cpp:590] Iteration 1800, lr = 0.01
I0929 23:04:14.058964 25301 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:04:16.404068 25301 solver.cpp:243] Iteration 1900, loss = 0.116847
I0929 23:04:16.404119 25301 solver.cpp:259]     Train net output #0: error_blob = 0.116847 (* 1 = 0.116847 loss)
I0929 23:04:16.404129 25301 solver.cpp:590] Iteration 1900, lr = 0.01
I0929 23:04:18.949285 25301 solver.cpp:347] Iteration 2000, Testing net (#0)
I0929 23:04:19.236102 25301 solver.cpp:415]     Test net output #0: error_blob = 0.119099 (* 1 = 0.119099 loss)
I0929 23:04:19.236778 25301 solver.cpp:243] Iteration 2000, loss = 0.113547
I0929 23:04:19.236798 25301 solver.cpp:259]     Train net output #0: error_blob = 0.113547 (* 1 = 0.113547 loss)
I0929 23:04:19.236806 25301 solver.cpp:590] Iteration 2000, lr = 0.01
I0929 23:04:21.735162 25301 solver.cpp:243] Iteration 2100, loss = 0.118025
I0929 23:04:21.735210 25301 solver.cpp:259]     Train net output #0: error_blob = 0.118025 (* 1 = 0.118025 loss)
I0929 23:04:21.735219 25301 solver.cpp:590] Iteration 2100, lr = 0.01
I0929 23:04:24.287695 25301 solver.cpp:243] Iteration 2200, loss = 0.117242
I0929 23:04:24.287822 25301 solver.cpp:259]     Train net output #0: error_blob = 0.117242 (* 1 = 0.117242 loss)
I0929 23:04:24.287828 25301 solver.cpp:590] Iteration 2200, lr = 0.01
I0929 23:04:26.831058 25301 solver.cpp:243] Iteration 2300, loss = 0.11827
I0929 23:04:26.831087 25301 solver.cpp:259]     Train net output #0: error_blob = 0.11827 (* 1 = 0.11827 loss)
I0929 23:04:26.831094 25301 solver.cpp:590] Iteration 2300, lr = 0.01
I0929 23:04:29.388633 25301 solver.cpp:243] Iteration 2400, loss = 0.114055
I0929 23:04:29.388679 25301 solver.cpp:259]     Train net output #0: error_blob = 0.114055 (* 1 = 0.114055 loss)
I0929 23:04:29.388687 25301 solver.cpp:590] Iteration 2400, lr = 0.01
I0929 23:04:31.937054 25301 solver.cpp:243] Iteration 2500, loss = 0.11206
I0929 23:04:31.937084 25301 solver.cpp:259]     Train net output #0: error_blob = 0.11206 (* 1 = 0.11206 loss)
I0929 23:04:31.937089 25301 solver.cpp:590] Iteration 2500, lr = 0.01
I0929 23:04:34.493912 25301 solver.cpp:243] Iteration 2600, loss = 0.116061
I0929 23:04:34.493954 25301 solver.cpp:259]     Train net output #0: error_blob = 0.116061 (* 1 = 0.116061 loss)
I0929 23:04:34.493960 25301 solver.cpp:590] Iteration 2600, lr = 0.01
I0929 23:04:37.053298 25301 solver.cpp:243] Iteration 2700, loss = 0.11602
I0929 23:04:37.053329 25301 solver.cpp:259]     Train net output #0: error_blob = 0.11602 (* 1 = 0.11602 loss)
I0929 23:04:37.053334 25301 solver.cpp:590] Iteration 2700, lr = 0.01
I0929 23:04:37.417807 25301 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:04:39.644814 25301 solver.cpp:243] Iteration 2800, loss = 0.118071
I0929 23:04:39.644851 25301 solver.cpp:259]     Train net output #0: error_blob = 0.118071 (* 1 = 0.118071 loss)
I0929 23:04:39.644860 25301 solver.cpp:590] Iteration 2800, lr = 0.01
I0929 23:04:42.223682 25301 solver.cpp:243] Iteration 2900, loss = 0.114486
I0929 23:04:42.223728 25301 solver.cpp:259]     Train net output #0: error_blob = 0.114486 (* 1 = 0.114486 loss)
I0929 23:04:42.223737 25301 solver.cpp:590] Iteration 2900, lr = 0.01
I0929 23:04:44.723681 25301 solver.cpp:347] Iteration 3000, Testing net (#0)
I0929 23:04:45.010279 25301 solver.cpp:415]     Test net output #0: error_blob = 0.118249 (* 1 = 0.118249 loss)
I0929 23:04:45.010946 25301 solver.cpp:243] Iteration 3000, loss = 0.112781
I0929 23:04:45.010963 25301 solver.cpp:259]     Train net output #0: error_blob = 0.112781 (* 1 = 0.112781 loss)
I0929 23:04:45.010972 25301 solver.cpp:590] Iteration 3000, lr = 0.01
I0929 23:04:47.559427 25301 solver.cpp:243] Iteration 3100, loss = 0.11209
I0929 23:04:47.559458 25301 solver.cpp:259]     Train net output #0: error_blob = 0.11209 (* 1 = 0.11209 loss)
I0929 23:04:47.559464 25301 solver.cpp:590] Iteration 3100, lr = 0.01
I0929 23:04:50.115366 25301 solver.cpp:243] Iteration 3200, loss = 0.114963
I0929 23:04:50.115422 25301 solver.cpp:259]     Train net output #0: error_blob = 0.114963 (* 1 = 0.114963 loss)
I0929 23:04:50.115432 25301 solver.cpp:590] Iteration 3200, lr = 0.01
I0929 23:04:52.672313 25301 solver.cpp:243] Iteration 3300, loss = 0.11536
I0929 23:04:52.672343 25301 solver.cpp:259]     Train net output #0: error_blob = 0.11536 (* 1 = 0.11536 loss)
I0929 23:04:52.672350 25301 solver.cpp:590] Iteration 3300, lr = 0.01
I0929 23:04:55.218685 25301 solver.cpp:243] Iteration 3400, loss = 0.116646
I0929 23:04:55.218833 25301 solver.cpp:259]     Train net output #0: error_blob = 0.116646 (* 1 = 0.116646 loss)
I0929 23:04:55.218842 25301 solver.cpp:590] Iteration 3400, lr = 0.01
I0929 23:04:57.772178 25301 solver.cpp:243] Iteration 3500, loss = 0.113298
I0929 23:04:57.772208 25301 solver.cpp:259]     Train net output #0: error_blob = 0.113298 (* 1 = 0.113298 loss)
I0929 23:04:57.772213 25301 solver.cpp:590] Iteration 3500, lr = 0.01
I0929 23:05:00.344254 25301 solver.cpp:243] Iteration 3600, loss = 0.114619
I0929 23:05:00.344310 25301 solver.cpp:259]     Train net output #0: error_blob = 0.114619 (* 1 = 0.114619 loss)
I0929 23:05:00.344317 25301 solver.cpp:590] Iteration 3600, lr = 0.01
I0929 23:05:00.851708 25301 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:05:02.888953 25301 solver.cpp:243] Iteration 3700, loss = 0.11421
I0929 23:05:02.888983 25301 solver.cpp:259]     Train net output #0: error_blob = 0.11421 (* 1 = 0.11421 loss)
I0929 23:05:02.888988 25301 solver.cpp:590] Iteration 3700, lr = 0.01
I0929 23:05:05.400429 25301 solver.cpp:243] Iteration 3800, loss = 0.115354
I0929 23:05:05.400466 25301 solver.cpp:259]     Train net output #0: error_blob = 0.115354 (* 1 = 0.115354 loss)
I0929 23:05:05.400475 25301 solver.cpp:590] Iteration 3800, lr = 0.01
I0929 23:05:07.900729 25301 solver.cpp:243] Iteration 3900, loss = 0.116836
I0929 23:05:07.900759 25301 solver.cpp:259]     Train net output #0: error_blob = 0.116836 (* 1 = 0.116836 loss)
I0929 23:05:07.900765 25301 solver.cpp:590] Iteration 3900, lr = 0.01
I0929 23:05:10.416548 25301 solver.cpp:347] Iteration 4000, Testing net (#0)
I0929 23:05:10.706411 25301 solver.cpp:415]     Test net output #0: error_blob = 0.118454 (* 1 = 0.118454 loss)
I0929 23:05:10.707036 25301 solver.cpp:243] Iteration 4000, loss = 0.113641
I0929 23:05:10.707049 25301 solver.cpp:259]     Train net output #0: error_blob = 0.113641 (* 1 = 0.113641 loss)
I0929 23:05:10.707054 25301 solver.cpp:590] Iteration 4000, lr = 0.01
I0929 23:05:13.256877 25301 solver.cpp:243] Iteration 4100, loss = 0.113507
I0929 23:05:13.256923 25301 solver.cpp:259]     Train net output #0: error_blob = 0.113507 (* 1 = 0.113507 loss)
I0929 23:05:13.256930 25301 solver.cpp:590] Iteration 4100, lr = 0.01
I0929 23:05:15.861199 25301 solver.cpp:243] Iteration 4200, loss = 0.112298
I0929 23:05:15.861237 25301 solver.cpp:259]     Train net output #0: error_blob = 0.112298 (* 1 = 0.112298 loss)
I0929 23:05:15.861244 25301 solver.cpp:590] Iteration 4200, lr = 0.01
I0929 23:05:18.455435 25301 solver.cpp:243] Iteration 4300, loss = 0.115387
I0929 23:05:18.455473 25301 solver.cpp:259]     Train net output #0: error_blob = 0.115387 (* 1 = 0.115387 loss)
I0929 23:05:18.455481 25301 solver.cpp:590] Iteration 4300, lr = 0.01
I0929 23:05:21.042387 25301 solver.cpp:243] Iteration 4400, loss = 0.116668
I0929 23:05:21.042419 25301 solver.cpp:259]     Train net output #0: error_blob = 0.116668 (* 1 = 0.116668 loss)
I0929 23:05:21.042425 25301 solver.cpp:590] Iteration 4400, lr = 0.01
I0929 23:05:23.628691 25301 solver.cpp:243] Iteration 4500, loss = 0.115612
I0929 23:05:23.628720 25301 solver.cpp:259]     Train net output #0: error_blob = 0.115612 (* 1 = 0.115612 loss)
I0929 23:05:23.628726 25301 solver.cpp:590] Iteration 4500, lr = 0.01
I0929 23:05:24.291193 25301 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:05:26.182838 25301 solver.cpp:243] Iteration 4600, loss = 0.114579
I0929 23:05:26.182939 25301 solver.cpp:259]     Train net output #0: error_blob = 0.114579 (* 1 = 0.114579 loss)
I0929 23:05:26.182945 25301 solver.cpp:590] Iteration 4600, lr = 0.01
I0929 23:05:28.743520 25301 solver.cpp:243] Iteration 4700, loss = 0.110907
I0929 23:05:28.743551 25301 solver.cpp:259]     Train net output #0: error_blob = 0.110907 (* 1 = 0.110907 loss)
I0929 23:05:28.743557 25301 solver.cpp:590] Iteration 4700, lr = 0.01
I0929 23:05:31.279745 25301 solver.cpp:243] Iteration 4800, loss = 0.114251
I0929 23:05:31.279793 25301 solver.cpp:259]     Train net output #0: error_blob = 0.114251 (* 1 = 0.114251 loss)
I0929 23:05:31.279800 25301 solver.cpp:590] Iteration 4800, lr = 0.01
I0929 23:05:33.876819 25301 solver.cpp:243] Iteration 4900, loss = 0.115566
I0929 23:05:33.876855 25301 solver.cpp:259]     Train net output #0: error_blob = 0.115566 (* 1 = 0.115566 loss)
I0929 23:05:33.876863 25301 solver.cpp:590] Iteration 4900, lr = 0.01
I0929 23:05:36.435029 25301 solver.cpp:347] Iteration 5000, Testing net (#0)
I0929 23:05:36.730660 25301 solver.cpp:415]     Test net output #0: error_blob = 0.118348 (* 1 = 0.118348 loss)
I0929 23:05:36.731326 25301 solver.cpp:243] Iteration 5000, loss = 0.117372
I0929 23:05:36.731353 25301 solver.cpp:259]     Train net output #0: error_blob = 0.117372 (* 1 = 0.117372 loss)
I0929 23:05:36.731360 25301 solver.cpp:590] Iteration 5000, lr = 0.01
I0929 23:05:39.278929 25301 solver.cpp:243] Iteration 5100, loss = 0.114359
I0929 23:05:39.278977 25301 solver.cpp:259]     Train net output #0: error_blob = 0.114359 (* 1 = 0.114359 loss)
I0929 23:05:39.278985 25301 solver.cpp:590] Iteration 5100, lr = 0.01
I0929 23:05:41.868619 25301 solver.cpp:243] Iteration 5200, loss = 0.110516
I0929 23:05:41.868664 25301 solver.cpp:259]     Train net output #0: error_blob = 0.110516 (* 1 = 0.110516 loss)
I0929 23:05:41.868671 25301 solver.cpp:590] Iteration 5200, lr = 0.01
I0929 23:05:44.469321 25301 solver.cpp:243] Iteration 5300, loss = 0.114496
I0929 23:05:44.469358 25301 solver.cpp:259]     Train net output #0: error_blob = 0.114496 (* 1 = 0.114496 loss)
I0929 23:05:44.469365 25301 solver.cpp:590] Iteration 5300, lr = 0.01
I0929 23:05:47.057862 25301 solver.cpp:243] Iteration 5400, loss = 0.114007
I0929 23:05:47.057904 25301 solver.cpp:259]     Train net output #0: error_blob = 0.114007 (* 1 = 0.114007 loss)
I0929 23:05:47.057910 25301 solver.cpp:590] Iteration 5400, lr = 0.01
I0929 23:05:47.888116 25301 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:05:49.608507 25301 solver.cpp:243] Iteration 5500, loss = 0.116866
I0929 23:05:49.608544 25301 solver.cpp:259]     Train net output #0: error_blob = 0.116866 (* 1 = 0.116866 loss)
I0929 23:05:49.608552 25301 solver.cpp:590] Iteration 5500, lr = 0.01
I0929 23:05:52.133971 25301 solver.cpp:243] Iteration 5600, loss = 0.114027
I0929 23:05:52.134001 25301 solver.cpp:259]     Train net output #0: error_blob = 0.114027 (* 1 = 0.114027 loss)
I0929 23:05:52.134006 25301 solver.cpp:590] Iteration 5600, lr = 0.01
I0929 23:05:54.696776 25301 solver.cpp:243] Iteration 5700, loss = 0.116334
I0929 23:05:54.696807 25301 solver.cpp:259]     Train net output #0: error_blob = 0.116334 (* 1 = 0.116334 loss)
I0929 23:05:54.696812 25301 solver.cpp:590] Iteration 5700, lr = 0.01
I0929 23:05:57.260673 25301 solver.cpp:243] Iteration 5800, loss = 0.112006
I0929 23:05:57.260817 25301 solver.cpp:259]     Train net output #0: error_blob = 0.112006 (* 1 = 0.112006 loss)
I0929 23:05:57.260825 25301 solver.cpp:590] Iteration 5800, lr = 0.01
I0929 23:05:59.771569 25301 solver.cpp:243] Iteration 5900, loss = 0.112782
I0929 23:05:59.771598 25301 solver.cpp:259]     Train net output #0: error_blob = 0.112782 (* 1 = 0.112782 loss)
I0929 23:05:59.771603 25301 solver.cpp:590] Iteration 5900, lr = 0.01
I0929 23:06:02.331333 25301 solver.cpp:347] Iteration 6000, Testing net (#0)
I0929 23:06:02.618690 25301 solver.cpp:415]     Test net output #0: error_blob = 0.120574 (* 1 = 0.120574 loss)
I0929 23:06:02.619303 25301 solver.cpp:243] Iteration 6000, loss = 0.116345
I0929 23:06:02.619320 25301 solver.cpp:259]     Train net output #0: error_blob = 0.116345 (* 1 = 0.116345 loss)
I0929 23:06:02.619328 25301 solver.cpp:590] Iteration 6000, lr = 0.01
I0929 23:06:05.127182 25301 solver.cpp:243] Iteration 6100, loss = 0.11497
I0929 23:06:05.127215 25301 solver.cpp:259]     Train net output #0: error_blob = 0.11497 (* 1 = 0.11497 loss)
I0929 23:06:05.127224 25301 solver.cpp:590] Iteration 6100, lr = 0.01
I0929 23:06:07.696768 25301 solver.cpp:243] Iteration 6200, loss = 0.113
I0929 23:06:07.696801 25301 solver.cpp:259]     Train net output #0: error_blob = 0.113 (* 1 = 0.113 loss)
I0929 23:06:07.696809 25301 solver.cpp:590] Iteration 6200, lr = 0.01
I0929 23:06:10.253099 25301 solver.cpp:243] Iteration 6300, loss = 0.109607
I0929 23:06:10.253149 25301 solver.cpp:259]     Train net output #0: error_blob = 0.109607 (* 1 = 0.109607 loss)
I0929 23:06:10.253159 25301 solver.cpp:590] Iteration 6300, lr = 0.01
I0929 23:06:11.180352 25301 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:06:12.753646 25301 solver.cpp:243] Iteration 6400, loss = 0.113257
I0929 23:06:12.753684 25301 solver.cpp:259]     Train net output #0: error_blob = 0.113257 (* 1 = 0.113257 loss)
I0929 23:06:12.753692 25301 solver.cpp:590] Iteration 6400, lr = 0.01
I0929 23:06:15.343353 25301 solver.cpp:243] Iteration 6500, loss = 0.115023
I0929 23:06:15.343399 25301 solver.cpp:259]     Train net output #0: error_blob = 0.115023 (* 1 = 0.115023 loss)
I0929 23:06:15.343407 25301 solver.cpp:590] Iteration 6500, lr = 0.01
I0929 23:06:17.909459 25301 solver.cpp:243] Iteration 6600, loss = 0.116808
I0929 23:06:17.909500 25301 solver.cpp:259]     Train net output #0: error_blob = 0.116808 (* 1 = 0.116808 loss)
I0929 23:06:17.909507 25301 solver.cpp:590] Iteration 6600, lr = 0.01
I0929 23:06:20.462090 25301 solver.cpp:243] Iteration 6700, loss = 0.112942
I0929 23:06:20.462139 25301 solver.cpp:259]     Train net output #0: error_blob = 0.112942 (* 1 = 0.112942 loss)
I0929 23:06:20.462149 25301 solver.cpp:590] Iteration 6700, lr = 0.01
I0929 23:06:23.014618 25301 solver.cpp:243] Iteration 6800, loss = 0.11081
I0929 23:06:23.014660 25301 solver.cpp:259]     Train net output #0: error_blob = 0.11081 (* 1 = 0.11081 loss)
I0929 23:06:23.014667 25301 solver.cpp:590] Iteration 6800, lr = 0.01
I0929 23:06:25.560185 25301 solver.cpp:243] Iteration 6900, loss = 0.11126
I0929 23:06:25.560215 25301 solver.cpp:259]     Train net output #0: error_blob = 0.11126 (* 1 = 0.11126 loss)
I0929 23:06:25.560221 25301 solver.cpp:590] Iteration 6900, lr = 0.01
I0929 23:06:28.082630 25301 solver.cpp:347] Iteration 7000, Testing net (#0)
I0929 23:06:28.368304 25301 solver.cpp:415]     Test net output #0: error_blob = 0.117647 (* 1 = 0.117647 loss)
I0929 23:06:28.369014 25301 solver.cpp:243] Iteration 7000, loss = 0.113278
I0929 23:06:28.369052 25301 solver.cpp:259]     Train net output #0: error_blob = 0.113278 (* 1 = 0.113278 loss)
I0929 23:06:28.369074 25301 solver.cpp:590] Iteration 7000, lr = 0.01
I0929 23:06:30.878077 25301 solver.cpp:243] Iteration 7100, loss = 0.113964
I0929 23:06:30.878128 25301 solver.cpp:259]     Train net output #0: error_blob = 0.113964 (* 1 = 0.113964 loss)
I0929 23:06:30.878135 25301 solver.cpp:590] Iteration 7100, lr = 0.01
I0929 23:06:33.464566 25301 solver.cpp:243] Iteration 7200, loss = 0.118817
I0929 23:06:33.464601 25301 solver.cpp:259]     Train net output #0: error_blob = 0.118817 (* 1 = 0.118817 loss)
I0929 23:06:33.464608 25301 solver.cpp:590] Iteration 7200, lr = 0.01
I0929 23:06:34.605670 25301 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:06:36.050534 25301 solver.cpp:243] Iteration 7300, loss = 0.112452
I0929 23:06:36.050570 25301 solver.cpp:259]     Train net output #0: error_blob = 0.112452 (* 1 = 0.112452 loss)
I0929 23:06:36.050577 25301 solver.cpp:590] Iteration 7300, lr = 0.01
I0929 23:06:38.655815 25301 solver.cpp:243] Iteration 7400, loss = 0.117199
I0929 23:06:38.655854 25301 solver.cpp:259]     Train net output #0: error_blob = 0.117199 (* 1 = 0.117199 loss)
I0929 23:06:38.655864 25301 solver.cpp:590] Iteration 7400, lr = 0.01
I0929 23:06:41.225915 25301 solver.cpp:243] Iteration 7500, loss = 0.119386
I0929 23:06:41.225958 25301 solver.cpp:259]     Train net output #0: error_blob = 0.119386 (* 1 = 0.119386 loss)
I0929 23:06:41.225965 25301 solver.cpp:590] Iteration 7500, lr = 0.01
I0929 23:06:43.793524 25301 solver.cpp:243] Iteration 7600, loss = 0.116142
I0929 23:06:43.793570 25301 solver.cpp:259]     Train net output #0: error_blob = 0.116142 (* 1 = 0.116142 loss)
I0929 23:06:43.793578 25301 solver.cpp:590] Iteration 7600, lr = 0.01
I0929 23:06:46.368391 25301 solver.cpp:243] Iteration 7700, loss = 0.115024
I0929 23:06:46.368438 25301 solver.cpp:259]     Train net output #0: error_blob = 0.115024 (* 1 = 0.115024 loss)
I0929 23:06:46.368446 25301 solver.cpp:590] Iteration 7700, lr = 0.01
I0929 23:06:48.944743 25301 solver.cpp:243] Iteration 7800, loss = 0.11133
I0929 23:06:48.944782 25301 solver.cpp:259]     Train net output #0: error_blob = 0.11133 (* 1 = 0.11133 loss)
I0929 23:06:48.944792 25301 solver.cpp:590] Iteration 7800, lr = 0.01
I0929 23:06:51.524621 25301 solver.cpp:243] Iteration 7900, loss = 0.112105
I0929 23:06:51.524649 25301 solver.cpp:259]     Train net output #0: error_blob = 0.112105 (* 1 = 0.112105 loss)
I0929 23:06:51.524655 25301 solver.cpp:590] Iteration 7900, lr = 0.01
I0929 23:06:54.050370 25301 solver.cpp:347] Iteration 8000, Testing net (#0)
I0929 23:06:54.333194 25301 solver.cpp:415]     Test net output #0: error_blob = 0.1177 (* 1 = 0.1177 loss)
I0929 23:06:54.333845 25301 solver.cpp:243] Iteration 8000, loss = 0.109535
I0929 23:06:54.333864 25301 solver.cpp:259]     Train net output #0: error_blob = 0.109535 (* 1 = 0.109535 loss)
I0929 23:06:54.333871 25301 solver.cpp:590] Iteration 8000, lr = 0.01
I0929 23:06:56.902441 25301 solver.cpp:243] Iteration 8100, loss = 0.114399
I0929 23:06:56.902478 25301 solver.cpp:259]     Train net output #0: error_blob = 0.114399 (* 1 = 0.114399 loss)
I0929 23:06:56.902487 25301 solver.cpp:590] Iteration 8100, lr = 0.01
I0929 23:06:58.207180 25301 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:06:59.478404 25301 solver.cpp:243] Iteration 8200, loss = 0.114371
I0929 23:06:59.478437 25301 solver.cpp:259]     Train net output #0: error_blob = 0.114371 (* 1 = 0.114371 loss)
I0929 23:06:59.478443 25301 solver.cpp:590] Iteration 8200, lr = 0.01
I0929 23:07:02.019677 25301 solver.cpp:243] Iteration 8300, loss = 0.114176
I0929 23:07:02.019716 25301 solver.cpp:259]     Train net output #0: error_blob = 0.114176 (* 1 = 0.114176 loss)
I0929 23:07:02.019726 25301 solver.cpp:590] Iteration 8300, lr = 0.01
I0929 23:07:04.567314 25301 solver.cpp:243] Iteration 8400, loss = 0.1097
I0929 23:07:04.567355 25301 solver.cpp:259]     Train net output #0: error_blob = 0.1097 (* 1 = 0.1097 loss)
I0929 23:07:04.567361 25301 solver.cpp:590] Iteration 8400, lr = 0.01
I0929 23:07:07.169824 25301 solver.cpp:243] Iteration 8500, loss = 0.108602
I0929 23:07:07.169860 25301 solver.cpp:259]     Train net output #0: error_blob = 0.108602 (* 1 = 0.108602 loss)
I0929 23:07:07.169868 25301 solver.cpp:590] Iteration 8500, lr = 0.01
I0929 23:07:09.713472 25301 solver.cpp:243] Iteration 8600, loss = 0.115707
I0929 23:07:09.713503 25301 solver.cpp:259]     Train net output #0: error_blob = 0.115707 (* 1 = 0.115707 loss)
I0929 23:07:09.713510 25301 solver.cpp:590] Iteration 8600, lr = 0.01
I0929 23:07:12.278535 25301 solver.cpp:243] Iteration 8700, loss = 0.115198
I0929 23:07:12.278566 25301 solver.cpp:259]     Train net output #0: error_blob = 0.115198 (* 1 = 0.115198 loss)
I0929 23:07:12.278571 25301 solver.cpp:590] Iteration 8700, lr = 0.01
I0929 23:07:14.810708 25301 solver.cpp:243] Iteration 8800, loss = 0.116404
I0929 23:07:14.810739 25301 solver.cpp:259]     Train net output #0: error_blob = 0.116404 (* 1 = 0.116404 loss)
I0929 23:07:14.810745 25301 solver.cpp:590] Iteration 8800, lr = 0.01
I0929 23:07:17.409615 25301 solver.cpp:243] Iteration 8900, loss = 0.111886
I0929 23:07:17.409651 25301 solver.cpp:259]     Train net output #0: error_blob = 0.111886 (* 1 = 0.111886 loss)
I0929 23:07:17.409660 25301 solver.cpp:590] Iteration 8900, lr = 0.01
I0929 23:07:19.981250 25301 solver.cpp:347] Iteration 9000, Testing net (#0)
I0929 23:07:20.283166 25301 solver.cpp:415]     Test net output #0: error_blob = 0.122368 (* 1 = 0.122368 loss)
I0929 23:07:20.283831 25301 solver.cpp:243] Iteration 9000, loss = 0.112141
I0929 23:07:20.283854 25301 solver.cpp:259]     Train net output #0: error_blob = 0.112141 (* 1 = 0.112141 loss)
I0929 23:07:20.283862 25301 solver.cpp:590] Iteration 9000, lr = 0.01
I0929 23:07:21.663890 25301 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:07:22.801959 25301 solver.cpp:243] Iteration 9100, loss = 0.112254
I0929 23:07:22.802007 25301 solver.cpp:259]     Train net output #0: error_blob = 0.112254 (* 1 = 0.112254 loss)
I0929 23:07:22.802016 25301 solver.cpp:590] Iteration 9100, lr = 0.01
I0929 23:07:25.377136 25301 solver.cpp:243] Iteration 9200, loss = 0.114088
I0929 23:07:25.377171 25301 solver.cpp:259]     Train net output #0: error_blob = 0.114088 (* 1 = 0.114088 loss)
I0929 23:07:25.377176 25301 solver.cpp:590] Iteration 9200, lr = 0.01
I0929 23:07:27.958917 25301 solver.cpp:243] Iteration 9300, loss = 0.115611
I0929 23:07:27.958956 25301 solver.cpp:259]     Train net output #0: error_blob = 0.115611 (* 1 = 0.115611 loss)
I0929 23:07:27.958966 25301 solver.cpp:590] Iteration 9300, lr = 0.01
I0929 23:07:30.548285 25301 solver.cpp:243] Iteration 9400, loss = 0.113206
I0929 23:07:30.548430 25301 solver.cpp:259]     Train net output #0: error_blob = 0.113206 (* 1 = 0.113206 loss)
I0929 23:07:30.548439 25301 solver.cpp:590] Iteration 9400, lr = 0.01
I0929 23:07:33.133522 25301 solver.cpp:243] Iteration 9500, loss = 0.114323
I0929 23:07:33.133556 25301 solver.cpp:259]     Train net output #0: error_blob = 0.114323 (* 1 = 0.114323 loss)
I0929 23:07:33.133565 25301 solver.cpp:590] Iteration 9500, lr = 0.01
I0929 23:07:35.726100 25301 solver.cpp:243] Iteration 9600, loss = 0.113442
I0929 23:07:35.726140 25301 solver.cpp:259]     Train net output #0: error_blob = 0.113442 (* 1 = 0.113442 loss)
I0929 23:07:35.726146 25301 solver.cpp:590] Iteration 9600, lr = 0.01
I0929 23:07:38.299356 25301 solver.cpp:243] Iteration 9700, loss = 0.113925
I0929 23:07:38.299386 25301 solver.cpp:259]     Train net output #0: error_blob = 0.113925 (* 1 = 0.113925 loss)
I0929 23:07:38.299393 25301 solver.cpp:590] Iteration 9700, lr = 0.01
I0929 23:07:40.836151 25301 solver.cpp:243] Iteration 9800, loss = 0.114423
I0929 23:07:40.836194 25301 solver.cpp:259]     Train net output #0: error_blob = 0.114423 (* 1 = 0.114423 loss)
I0929 23:07:40.836199 25301 solver.cpp:590] Iteration 9800, lr = 0.01
I0929 23:07:43.413864 25301 solver.cpp:243] Iteration 9900, loss = 0.113757
I0929 23:07:43.413908 25301 solver.cpp:259]     Train net output #0: error_blob = 0.113757 (* 1 = 0.113757 loss)
I0929 23:07:43.413913 25301 solver.cpp:590] Iteration 9900, lr = 0.01
I0929 23:07:45.951604 25301 solver.cpp:468] Snapshotting to binary proto file _iter_10000.caffemodel
I0929 23:07:45.952441 25301 solver.cpp:753] Snapshotting solver state to binary proto file _iter_10000.solverstate
I0929 23:07:45.977010 25301 solver.cpp:327] Iteration 10000, loss = 0.110107
I0929 23:07:45.977048 25301 solver.cpp:347] Iteration 10000, Testing net (#0)
I0929 23:07:46.147158 25301 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:07:46.259088 25301 solver.cpp:415]     Test net output #0: error_blob = 0.119442 (* 1 = 0.119442 loss)
I0929 23:07:46.259105 25301 solver.cpp:332] Optimization Done.
I0929 23:07:46.259107 25301 caffe.cpp:215] Optimization Done.
I0929 23:07:46.327008 25310 caffe.cpp:184] Using GPUs 0
I0929 23:07:46.885987 25310 solver.cpp:54] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "fixed"
momentum: 0.9
solver_mode: GPU
device_id: 0
net: "model/NNScore/nnscore_model_1.prototxt"
I0929 23:07:46.886016 25310 solver.cpp:97] Creating training net from net file: model/NNScore/nnscore_model_1.prototxt
I0929 23:07:46.886188 25310 net.cpp:339] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_layer
I0929 23:07:46.886234 25310 net.cpp:50] Initializing net from parameters: 
name: "model/NNScore/nnscore_model_1.prototxt"
state {
  phase: TRAIN
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TRAIN
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.1.train"
    batch_size: 20000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I0929 23:07:46.886312 25310 layer_factory.hpp:76] Creating layer data_layer
I0929 23:07:46.899632 25310 net.cpp:110] Creating Layer data_layer
I0929 23:07:46.899662 25310 net.cpp:433] data_layer -> data_blob
I0929 23:07:46.899696 25310 net.cpp:433] data_layer -> label_blob
I0929 23:07:46.900287 25314 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.1.train
I0929 23:07:47.586284 25310 data_layer.cpp:45] output data size: 20000,61,1,1
I0929 23:07:47.591264 25310 net.cpp:155] Setting up data_layer
I0929 23:07:47.591317 25310 net.cpp:163] Top shape: 20000 61 1 1 (1220000)
I0929 23:07:47.591322 25310 net.cpp:163] Top shape: 20000 (20000)
I0929 23:07:47.591328 25310 layer_factory.hpp:76] Creating layer hidden_sum_layer
I0929 23:07:47.591341 25310 net.cpp:110] Creating Layer hidden_sum_layer
I0929 23:07:47.591344 25310 net.cpp:477] hidden_sum_layer <- data_blob
I0929 23:07:47.591354 25310 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I0929 23:07:47.591738 25310 net.cpp:155] Setting up hidden_sum_layer
I0929 23:07:47.591745 25310 net.cpp:163] Top shape: 20000 10 (200000)
I0929 23:07:47.591766 25310 layer_factory.hpp:76] Creating layer hidden_act_layer
I0929 23:07:47.591774 25310 net.cpp:110] Creating Layer hidden_act_layer
I0929 23:07:47.591776 25310 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I0929 23:07:47.591779 25310 net.cpp:433] hidden_act_layer -> hidden_act_blob
I0929 23:07:50.807073 25310 net.cpp:155] Setting up hidden_act_layer
I0929 23:07:50.807096 25310 net.cpp:163] Top shape: 20000 10 (200000)
I0929 23:07:50.807101 25310 layer_factory.hpp:76] Creating layer output_sum_layer
I0929 23:07:50.807109 25310 net.cpp:110] Creating Layer output_sum_layer
I0929 23:07:50.807113 25310 net.cpp:477] output_sum_layer <- hidden_act_blob
I0929 23:07:50.807118 25310 net.cpp:433] output_sum_layer -> output_sum_blob
I0929 23:07:50.807199 25310 net.cpp:155] Setting up output_sum_layer
I0929 23:07:50.807205 25310 net.cpp:163] Top shape: 20000 1 (20000)
I0929 23:07:50.807212 25310 layer_factory.hpp:76] Creating layer output_act_layer
I0929 23:07:50.807217 25310 net.cpp:110] Creating Layer output_act_layer
I0929 23:07:50.807219 25310 net.cpp:477] output_act_layer <- output_sum_blob
I0929 23:07:50.807222 25310 net.cpp:433] output_act_layer -> output_act_blob
I0929 23:07:50.807277 25310 net.cpp:155] Setting up output_act_layer
I0929 23:07:50.807297 25310 net.cpp:163] Top shape: 20000 1 (20000)
I0929 23:07:50.807301 25310 layer_factory.hpp:76] Creating layer error_layer
I0929 23:07:50.807306 25310 net.cpp:110] Creating Layer error_layer
I0929 23:07:50.807322 25310 net.cpp:477] error_layer <- output_act_blob
I0929 23:07:50.807324 25310 net.cpp:477] error_layer <- label_blob
I0929 23:07:50.807328 25310 net.cpp:433] error_layer -> error_blob
I0929 23:07:50.807351 25310 net.cpp:155] Setting up error_layer
I0929 23:07:50.807364 25310 net.cpp:163] Top shape: (1)
I0929 23:07:50.807366 25310 net.cpp:168]     with loss weight 1
I0929 23:07:50.807391 25310 net.cpp:236] error_layer needs backward computation.
I0929 23:07:50.807394 25310 net.cpp:236] output_act_layer needs backward computation.
I0929 23:07:50.807396 25310 net.cpp:236] output_sum_layer needs backward computation.
I0929 23:07:50.807399 25310 net.cpp:236] hidden_act_layer needs backward computation.
I0929 23:07:50.807400 25310 net.cpp:236] hidden_sum_layer needs backward computation.
I0929 23:07:50.807402 25310 net.cpp:240] data_layer does not need backward computation.
I0929 23:07:50.807404 25310 net.cpp:283] This network produces output error_blob
I0929 23:07:50.807410 25310 net.cpp:297] Network initialization done.
I0929 23:07:50.807410 25310 net.cpp:298] Memory required for data: 6720004
I0929 23:07:50.807553 25310 solver.cpp:187] Creating test net (#0) specified by net file: model/NNScore/nnscore_model_1.prototxt
I0929 23:07:50.807567 25310 net.cpp:339] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_layer
I0929 23:07:50.807608 25310 net.cpp:50] Initializing net from parameters: 
name: "model/NNScore/nnscore_model_1.prototxt"
state {
  phase: TEST
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TEST
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.1.test"
    batch_size: 2000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I0929 23:07:50.807638 25310 layer_factory.hpp:76] Creating layer data_layer
I0929 23:07:50.808857 25310 net.cpp:110] Creating Layer data_layer
I0929 23:07:50.808876 25310 net.cpp:433] data_layer -> data_blob
I0929 23:07:50.808881 25310 net.cpp:433] data_layer -> label_blob
I0929 23:07:50.809422 25316 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.1.test
I0929 23:07:50.809485 25310 data_layer.cpp:45] output data size: 2000,61,1,1
I0929 23:07:50.810878 25310 net.cpp:155] Setting up data_layer
I0929 23:07:50.810889 25310 net.cpp:163] Top shape: 2000 61 1 1 (122000)
I0929 23:07:50.810894 25310 net.cpp:163] Top shape: 2000 (2000)
I0929 23:07:50.810899 25310 layer_factory.hpp:76] Creating layer hidden_sum_layer
I0929 23:07:50.810919 25310 net.cpp:110] Creating Layer hidden_sum_layer
I0929 23:07:50.810924 25310 net.cpp:477] hidden_sum_layer <- data_blob
I0929 23:07:50.810941 25310 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I0929 23:07:50.811074 25310 net.cpp:155] Setting up hidden_sum_layer
I0929 23:07:50.811081 25310 net.cpp:163] Top shape: 2000 10 (20000)
I0929 23:07:50.811091 25310 layer_factory.hpp:76] Creating layer hidden_act_layer
I0929 23:07:50.811100 25310 net.cpp:110] Creating Layer hidden_act_layer
I0929 23:07:50.811105 25310 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I0929 23:07:50.811122 25310 net.cpp:433] hidden_act_layer -> hidden_act_blob
I0929 23:07:50.811312 25310 net.cpp:155] Setting up hidden_act_layer
I0929 23:07:50.811321 25310 net.cpp:163] Top shape: 2000 10 (20000)
I0929 23:07:50.811326 25310 layer_factory.hpp:76] Creating layer output_sum_layer
I0929 23:07:50.811331 25310 net.cpp:110] Creating Layer output_sum_layer
I0929 23:07:50.811336 25310 net.cpp:477] output_sum_layer <- hidden_act_blob
I0929 23:07:50.811342 25310 net.cpp:433] output_sum_layer -> output_sum_blob
I0929 23:07:50.811408 25310 net.cpp:155] Setting up output_sum_layer
I0929 23:07:50.811415 25310 net.cpp:163] Top shape: 2000 1 (2000)
I0929 23:07:50.811424 25310 layer_factory.hpp:76] Creating layer output_act_layer
I0929 23:07:50.811432 25310 net.cpp:110] Creating Layer output_act_layer
I0929 23:07:50.811435 25310 net.cpp:477] output_act_layer <- output_sum_blob
I0929 23:07:50.811440 25310 net.cpp:433] output_act_layer -> output_act_blob
I0929 23:07:50.811496 25310 net.cpp:155] Setting up output_act_layer
I0929 23:07:50.811501 25310 net.cpp:163] Top shape: 2000 1 (2000)
I0929 23:07:50.811506 25310 layer_factory.hpp:76] Creating layer error_layer
I0929 23:07:50.811511 25310 net.cpp:110] Creating Layer error_layer
I0929 23:07:50.811514 25310 net.cpp:477] error_layer <- output_act_blob
I0929 23:07:50.811519 25310 net.cpp:477] error_layer <- label_blob
I0929 23:07:50.811524 25310 net.cpp:433] error_layer -> error_blob
I0929 23:07:50.811550 25310 net.cpp:155] Setting up error_layer
I0929 23:07:50.811556 25310 net.cpp:163] Top shape: (1)
I0929 23:07:50.811560 25310 net.cpp:168]     with loss weight 1
I0929 23:07:50.811571 25310 net.cpp:236] error_layer needs backward computation.
I0929 23:07:50.811575 25310 net.cpp:236] output_act_layer needs backward computation.
I0929 23:07:50.811579 25310 net.cpp:236] output_sum_layer needs backward computation.
I0929 23:07:50.811583 25310 net.cpp:236] hidden_act_layer needs backward computation.
I0929 23:07:50.811586 25310 net.cpp:236] hidden_sum_layer needs backward computation.
I0929 23:07:50.811591 25310 net.cpp:240] data_layer does not need backward computation.
I0929 23:07:50.811595 25310 net.cpp:283] This network produces output error_blob
I0929 23:07:50.811604 25310 net.cpp:297] Network initialization done.
I0929 23:07:50.811607 25310 net.cpp:298] Memory required for data: 672004
I0929 23:07:50.811631 25310 solver.cpp:66] Solver scaffolding done.
I0929 23:07:50.811725 25310 caffe.cpp:212] Starting Optimization
I0929 23:07:50.811733 25310 solver.cpp:294] Solving model/NNScore/nnscore_model_1.prototxt
I0929 23:07:50.811736 25310 solver.cpp:295] Learning Rate Policy: fixed
I0929 23:07:50.811914 25310 solver.cpp:347] Iteration 0, Testing net (#0)
I0929 23:07:50.812016 25310 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:07:51.089014 25310 solver.cpp:415]     Test net output #0: error_blob = 0.120596 (* 1 = 0.120596 loss)
I0929 23:07:51.090481 25310 solver.cpp:243] Iteration 0, loss = 0.124038
I0929 23:07:51.090497 25310 solver.cpp:259]     Train net output #0: error_blob = 0.124038 (* 1 = 0.124038 loss)
I0929 23:07:51.090513 25310 solver.cpp:590] Iteration 0, lr = 0.01
I0929 23:07:53.503967 25310 solver.cpp:243] Iteration 100, loss = 0.117976
I0929 23:07:53.504014 25310 solver.cpp:259]     Train net output #0: error_blob = 0.117976 (* 1 = 0.117976 loss)
I0929 23:07:53.504021 25310 solver.cpp:590] Iteration 100, lr = 0.01
I0929 23:07:55.972309 25310 solver.cpp:243] Iteration 200, loss = 0.12011
I0929 23:07:55.972340 25310 solver.cpp:259]     Train net output #0: error_blob = 0.12011 (* 1 = 0.12011 loss)
I0929 23:07:55.972345 25310 solver.cpp:590] Iteration 200, lr = 0.01
I0929 23:07:58.404079 25310 solver.cpp:243] Iteration 300, loss = 0.116438
I0929 23:07:58.404119 25310 solver.cpp:259]     Train net output #0: error_blob = 0.116438 (* 1 = 0.116438 loss)
I0929 23:07:58.404124 25310 solver.cpp:590] Iteration 300, lr = 0.01
I0929 23:08:00.871594 25310 solver.cpp:243] Iteration 400, loss = 0.118809
I0929 23:08:00.871664 25310 solver.cpp:259]     Train net output #0: error_blob = 0.118809 (* 1 = 0.118809 loss)
I0929 23:08:00.871671 25310 solver.cpp:590] Iteration 400, lr = 0.01
I0929 23:08:03.356644 25310 solver.cpp:243] Iteration 500, loss = 0.116652
I0929 23:08:03.356689 25310 solver.cpp:259]     Train net output #0: error_blob = 0.116652 (* 1 = 0.116652 loss)
I0929 23:08:03.356696 25310 solver.cpp:590] Iteration 500, lr = 0.01
I0929 23:08:05.833237 25310 solver.cpp:243] Iteration 600, loss = 0.121489
I0929 23:08:05.833271 25310 solver.cpp:259]     Train net output #0: error_blob = 0.121489 (* 1 = 0.121489 loss)
I0929 23:08:05.833278 25310 solver.cpp:590] Iteration 600, lr = 0.01
I0929 23:08:08.307153 25310 solver.cpp:243] Iteration 700, loss = 0.116518
I0929 23:08:08.307189 25310 solver.cpp:259]     Train net output #0: error_blob = 0.116518 (* 1 = 0.116518 loss)
I0929 23:08:08.307199 25310 solver.cpp:590] Iteration 700, lr = 0.01
I0929 23:08:10.800165 25310 solver.cpp:243] Iteration 800, loss = 0.117617
I0929 23:08:10.800207 25310 solver.cpp:259]     Train net output #0: error_blob = 0.117617 (* 1 = 0.117617 loss)
I0929 23:08:10.800212 25310 solver.cpp:590] Iteration 800, lr = 0.01
I0929 23:08:13.261791 25310 solver.cpp:243] Iteration 900, loss = 0.116999
I0929 23:08:13.261831 25310 solver.cpp:259]     Train net output #0: error_blob = 0.116999 (* 1 = 0.116999 loss)
I0929 23:08:13.261837 25310 solver.cpp:590] Iteration 900, lr = 0.01
I0929 23:08:13.312119 25310 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:08:15.679509 25310 solver.cpp:347] Iteration 1000, Testing net (#0)
I0929 23:08:16.020949 25310 solver.cpp:415]     Test net output #0: error_blob = 0.117994 (* 1 = 0.117994 loss)
I0929 23:08:16.021559 25310 solver.cpp:243] Iteration 1000, loss = 0.115348
I0929 23:08:16.021572 25310 solver.cpp:259]     Train net output #0: error_blob = 0.115348 (* 1 = 0.115348 loss)
I0929 23:08:16.021579 25310 solver.cpp:590] Iteration 1000, lr = 0.01
I0929 23:08:18.433483 25310 solver.cpp:243] Iteration 1100, loss = 0.119014
I0929 23:08:18.434751 25310 solver.cpp:259]     Train net output #0: error_blob = 0.119014 (* 1 = 0.119014 loss)
I0929 23:08:18.434762 25310 solver.cpp:590] Iteration 1100, lr = 0.01
I0929 23:08:20.925242 25310 solver.cpp:243] Iteration 1200, loss = 0.114234
I0929 23:08:20.925287 25310 solver.cpp:259]     Train net output #0: error_blob = 0.114234 (* 1 = 0.114234 loss)
I0929 23:08:20.925297 25310 solver.cpp:590] Iteration 1200, lr = 0.01
I0929 23:08:23.419312 25310 solver.cpp:243] Iteration 1300, loss = 0.120921
I0929 23:08:23.419353 25310 solver.cpp:259]     Train net output #0: error_blob = 0.120921 (* 1 = 0.120921 loss)
I0929 23:08:23.419358 25310 solver.cpp:590] Iteration 1300, lr = 0.01
I0929 23:08:25.844611 25310 solver.cpp:243] Iteration 1400, loss = 0.115283
I0929 23:08:25.844641 25310 solver.cpp:259]     Train net output #0: error_blob = 0.115283 (* 1 = 0.115283 loss)
I0929 23:08:25.844646 25310 solver.cpp:590] Iteration 1400, lr = 0.01
I0929 23:08:28.326247 25310 solver.cpp:243] Iteration 1500, loss = 0.121912
I0929 23:08:28.326287 25310 solver.cpp:259]     Train net output #0: error_blob = 0.121912 (* 1 = 0.121912 loss)
I0929 23:08:28.326292 25310 solver.cpp:590] Iteration 1500, lr = 0.01
I0929 23:08:30.789623 25310 solver.cpp:243] Iteration 1600, loss = 0.115873
I0929 23:08:30.789651 25310 solver.cpp:259]     Train net output #0: error_blob = 0.115873 (* 1 = 0.115873 loss)
I0929 23:08:30.789655 25310 solver.cpp:590] Iteration 1600, lr = 0.01
I0929 23:08:33.260573 25310 solver.cpp:243] Iteration 1700, loss = 0.118616
I0929 23:08:33.260610 25310 solver.cpp:259]     Train net output #0: error_blob = 0.118616 (* 1 = 0.118616 loss)
I0929 23:08:33.260617 25310 solver.cpp:590] Iteration 1700, lr = 0.01
I0929 23:08:35.731529 25310 solver.cpp:243] Iteration 1800, loss = 0.120218
I0929 23:08:35.731570 25310 solver.cpp:259]     Train net output #0: error_blob = 0.120218 (* 1 = 0.120218 loss)
I0929 23:08:35.731575 25310 solver.cpp:590] Iteration 1800, lr = 0.01
I0929 23:08:35.929121 25310 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:08:38.211359 25310 solver.cpp:243] Iteration 1900, loss = 0.118768
I0929 23:08:38.211400 25310 solver.cpp:259]     Train net output #0: error_blob = 0.118768 (* 1 = 0.118768 loss)
I0929 23:08:38.211405 25310 solver.cpp:590] Iteration 1900, lr = 0.01
I0929 23:08:40.604591 25310 solver.cpp:347] Iteration 2000, Testing net (#0)
I0929 23:08:40.896932 25310 solver.cpp:415]     Test net output #0: error_blob = 0.118457 (* 1 = 0.118457 loss)
I0929 23:08:40.897635 25310 solver.cpp:243] Iteration 2000, loss = 0.11709
I0929 23:08:40.897651 25310 solver.cpp:259]     Train net output #0: error_blob = 0.11709 (* 1 = 0.11709 loss)
I0929 23:08:40.897660 25310 solver.cpp:590] Iteration 2000, lr = 0.01
I0929 23:08:43.357049 25310 solver.cpp:243] Iteration 2100, loss = 0.116076
I0929 23:08:43.357089 25310 solver.cpp:259]     Train net output #0: error_blob = 0.116076 (* 1 = 0.116076 loss)
I0929 23:08:43.357094 25310 solver.cpp:590] Iteration 2100, lr = 0.01
I0929 23:08:45.851172 25310 solver.cpp:243] Iteration 2200, loss = 0.118517
I0929 23:08:45.851218 25310 solver.cpp:259]     Train net output #0: error_blob = 0.118517 (* 1 = 0.118517 loss)
I0929 23:08:45.851225 25310 solver.cpp:590] Iteration 2200, lr = 0.01
I0929 23:08:48.333806 25310 solver.cpp:243] Iteration 2300, loss = 0.115833
I0929 23:08:48.333844 25310 solver.cpp:259]     Train net output #0: error_blob = 0.115833 (* 1 = 0.115833 loss)
I0929 23:08:48.333849 25310 solver.cpp:590] Iteration 2300, lr = 0.01
I0929 23:08:50.799583 25310 solver.cpp:243] Iteration 2400, loss = 0.118927
I0929 23:08:50.800580 25310 solver.cpp:259]     Train net output #0: error_blob = 0.118927 (* 1 = 0.118927 loss)
I0929 23:08:50.800586 25310 solver.cpp:590] Iteration 2400, lr = 0.01
I0929 23:08:53.309687 25310 solver.cpp:243] Iteration 2500, loss = 0.113804
I0929 23:08:53.309725 25310 solver.cpp:259]     Train net output #0: error_blob = 0.113804 (* 1 = 0.113804 loss)
I0929 23:08:53.309732 25310 solver.cpp:590] Iteration 2500, lr = 0.01
I0929 23:08:55.799091 25310 solver.cpp:243] Iteration 2600, loss = 0.119321
I0929 23:08:55.799139 25310 solver.cpp:259]     Train net output #0: error_blob = 0.119321 (* 1 = 0.119321 loss)
I0929 23:08:55.799145 25310 solver.cpp:590] Iteration 2600, lr = 0.01
I0929 23:08:58.260910 25310 solver.cpp:243] Iteration 2700, loss = 0.114325
I0929 23:08:58.260941 25310 solver.cpp:259]     Train net output #0: error_blob = 0.114325 (* 1 = 0.114325 loss)
I0929 23:08:58.260946 25310 solver.cpp:590] Iteration 2700, lr = 0.01
I0929 23:08:58.596246 25310 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:09:00.679015 25310 solver.cpp:243] Iteration 2800, loss = 0.118344
I0929 23:09:00.679056 25310 solver.cpp:259]     Train net output #0: error_blob = 0.118344 (* 1 = 0.118344 loss)
I0929 23:09:00.679061 25310 solver.cpp:590] Iteration 2800, lr = 0.01
I0929 23:09:03.141723 25310 solver.cpp:243] Iteration 2900, loss = 0.115708
I0929 23:09:03.141763 25310 solver.cpp:259]     Train net output #0: error_blob = 0.115708 (* 1 = 0.115708 loss)
I0929 23:09:03.141769 25310 solver.cpp:590] Iteration 2900, lr = 0.01
I0929 23:09:05.610838 25310 solver.cpp:347] Iteration 3000, Testing net (#0)
I0929 23:09:05.891412 25310 solver.cpp:415]     Test net output #0: error_blob = 0.118775 (* 1 = 0.118775 loss)
I0929 23:09:05.892076 25310 solver.cpp:243] Iteration 3000, loss = 0.118155
I0929 23:09:05.892088 25310 solver.cpp:259]     Train net output #0: error_blob = 0.118155 (* 1 = 0.118155 loss)
I0929 23:09:05.892096 25310 solver.cpp:590] Iteration 3000, lr = 0.01
I0929 23:09:08.336280 25310 solver.cpp:243] Iteration 3100, loss = 0.116766
I0929 23:09:08.336309 25310 solver.cpp:259]     Train net output #0: error_blob = 0.116766 (* 1 = 0.116766 loss)
I0929 23:09:08.336313 25310 solver.cpp:590] Iteration 3100, lr = 0.01
I0929 23:09:10.825378 25310 solver.cpp:243] Iteration 3200, loss = 0.114743
I0929 23:09:10.825409 25310 solver.cpp:259]     Train net output #0: error_blob = 0.114743 (* 1 = 0.114743 loss)
I0929 23:09:10.825415 25310 solver.cpp:590] Iteration 3200, lr = 0.01
I0929 23:09:13.300549 25310 solver.cpp:243] Iteration 3300, loss = 0.117594
I0929 23:09:13.300587 25310 solver.cpp:259]     Train net output #0: error_blob = 0.117594 (* 1 = 0.117594 loss)
I0929 23:09:13.300592 25310 solver.cpp:590] Iteration 3300, lr = 0.01
I0929 23:09:15.812468 25310 solver.cpp:243] Iteration 3400, loss = 0.11374
I0929 23:09:15.812515 25310 solver.cpp:259]     Train net output #0: error_blob = 0.11374 (* 1 = 0.11374 loss)
I0929 23:09:15.812520 25310 solver.cpp:590] Iteration 3400, lr = 0.01
I0929 23:09:18.314234 25310 solver.cpp:243] Iteration 3500, loss = 0.118554
I0929 23:09:18.314270 25310 solver.cpp:259]     Train net output #0: error_blob = 0.118554 (* 1 = 0.118554 loss)
I0929 23:09:18.314276 25310 solver.cpp:590] Iteration 3500, lr = 0.01
I0929 23:09:20.822170 25310 solver.cpp:243] Iteration 3600, loss = 0.113856
I0929 23:09:20.822326 25310 solver.cpp:259]     Train net output #0: error_blob = 0.113856 (* 1 = 0.113856 loss)
I0929 23:09:20.822335 25310 solver.cpp:590] Iteration 3600, lr = 0.01
I0929 23:09:21.331362 25310 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:09:23.324717 25310 solver.cpp:243] Iteration 3700, loss = 0.118584
I0929 23:09:23.324745 25310 solver.cpp:259]     Train net output #0: error_blob = 0.118584 (* 1 = 0.118584 loss)
I0929 23:09:23.324749 25310 solver.cpp:590] Iteration 3700, lr = 0.01
I0929 23:09:25.811686 25310 solver.cpp:243] Iteration 3800, loss = 0.114884
I0929 23:09:25.811725 25310 solver.cpp:259]     Train net output #0: error_blob = 0.114884 (* 1 = 0.114884 loss)
I0929 23:09:25.811732 25310 solver.cpp:590] Iteration 3800, lr = 0.01
I0929 23:09:28.336263 25310 solver.cpp:243] Iteration 3900, loss = 0.11775
I0929 23:09:28.336292 25310 solver.cpp:259]     Train net output #0: error_blob = 0.11775 (* 1 = 0.11775 loss)
I0929 23:09:28.336297 25310 solver.cpp:590] Iteration 3900, lr = 0.01
I0929 23:09:30.770527 25310 solver.cpp:347] Iteration 4000, Testing net (#0)
I0929 23:09:31.051774 25310 solver.cpp:415]     Test net output #0: error_blob = 0.117555 (* 1 = 0.117555 loss)
I0929 23:09:31.052440 25310 solver.cpp:243] Iteration 4000, loss = 0.11535
I0929 23:09:31.052455 25310 solver.cpp:259]     Train net output #0: error_blob = 0.11535 (* 1 = 0.11535 loss)
I0929 23:09:31.052464 25310 solver.cpp:590] Iteration 4000, lr = 0.01
I0929 23:09:33.458389 25310 solver.cpp:243] Iteration 4100, loss = 0.115246
I0929 23:09:33.458430 25310 solver.cpp:259]     Train net output #0: error_blob = 0.115246 (* 1 = 0.115246 loss)
I0929 23:09:33.458434 25310 solver.cpp:590] Iteration 4100, lr = 0.01
I0929 23:09:35.908156 25310 solver.cpp:243] Iteration 4200, loss = 0.115551
I0929 23:09:35.908205 25310 solver.cpp:259]     Train net output #0: error_blob = 0.115551 (* 1 = 0.115551 loss)
I0929 23:09:35.908213 25310 solver.cpp:590] Iteration 4200, lr = 0.01
I0929 23:09:38.359153 25310 solver.cpp:243] Iteration 4300, loss = 0.113814
I0929 23:09:38.359182 25310 solver.cpp:259]     Train net output #0: error_blob = 0.113814 (* 1 = 0.113814 loss)
I0929 23:09:38.359186 25310 solver.cpp:590] Iteration 4300, lr = 0.01
I0929 23:09:40.829742 25310 solver.cpp:243] Iteration 4400, loss = 0.117358
I0929 23:09:40.829772 25310 solver.cpp:259]     Train net output #0: error_blob = 0.117358 (* 1 = 0.117358 loss)
I0929 23:09:40.829777 25310 solver.cpp:590] Iteration 4400, lr = 0.01
I0929 23:09:43.281299 25310 solver.cpp:243] Iteration 4500, loss = 0.11253
I0929 23:09:43.281337 25310 solver.cpp:259]     Train net output #0: error_blob = 0.11253 (* 1 = 0.11253 loss)
I0929 23:09:43.281342 25310 solver.cpp:590] Iteration 4500, lr = 0.01
I0929 23:09:43.929245 25310 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:09:45.802692 25310 solver.cpp:243] Iteration 4600, loss = 0.118255
I0929 23:09:45.802721 25310 solver.cpp:259]     Train net output #0: error_blob = 0.118255 (* 1 = 0.118255 loss)
I0929 23:09:45.802726 25310 solver.cpp:590] Iteration 4600, lr = 0.01
I0929 23:09:48.299082 25310 solver.cpp:243] Iteration 4700, loss = 0.112242
I0929 23:09:48.299118 25310 solver.cpp:259]     Train net output #0: error_blob = 0.112242 (* 1 = 0.112242 loss)
I0929 23:09:48.299124 25310 solver.cpp:590] Iteration 4700, lr = 0.01
I0929 23:09:50.787170 25310 solver.cpp:243] Iteration 4800, loss = 0.118692
I0929 23:09:50.787205 25310 solver.cpp:259]     Train net output #0: error_blob = 0.118692 (* 1 = 0.118692 loss)
I0929 23:09:50.787212 25310 solver.cpp:590] Iteration 4800, lr = 0.01
I0929 23:09:53.294940 25310 solver.cpp:243] Iteration 4900, loss = 0.113801
I0929 23:09:53.295071 25310 solver.cpp:259]     Train net output #0: error_blob = 0.113801 (* 1 = 0.113801 loss)
I0929 23:09:53.295079 25310 solver.cpp:590] Iteration 4900, lr = 0.01
I0929 23:09:55.744992 25310 solver.cpp:347] Iteration 5000, Testing net (#0)
I0929 23:09:56.016685 25310 solver.cpp:415]     Test net output #0: error_blob = 0.116981 (* 1 = 0.116981 loss)
I0929 23:09:56.017338 25310 solver.cpp:243] Iteration 5000, loss = 0.117299
I0929 23:09:56.017380 25310 solver.cpp:259]     Train net output #0: error_blob = 0.117299 (* 1 = 0.117299 loss)
I0929 23:09:56.017390 25310 solver.cpp:590] Iteration 5000, lr = 0.01
I0929 23:09:58.444300 25310 solver.cpp:243] Iteration 5100, loss = 0.115112
I0929 23:09:58.444340 25310 solver.cpp:259]     Train net output #0: error_blob = 0.115112 (* 1 = 0.115112 loss)
I0929 23:09:58.444345 25310 solver.cpp:590] Iteration 5100, lr = 0.01
I0929 23:10:00.909457 25310 solver.cpp:243] Iteration 5200, loss = 0.114905
I0929 23:10:00.909495 25310 solver.cpp:259]     Train net output #0: error_blob = 0.114905 (* 1 = 0.114905 loss)
I0929 23:10:00.909499 25310 solver.cpp:590] Iteration 5200, lr = 0.01
I0929 23:10:03.394804 25310 solver.cpp:243] Iteration 5300, loss = 0.118431
I0929 23:10:03.394850 25310 solver.cpp:259]     Train net output #0: error_blob = 0.118431 (* 1 = 0.118431 loss)
I0929 23:10:03.394857 25310 solver.cpp:590] Iteration 5300, lr = 0.01
I0929 23:10:05.873996 25310 solver.cpp:243] Iteration 5400, loss = 0.113582
I0929 23:10:05.874038 25310 solver.cpp:259]     Train net output #0: error_blob = 0.113582 (* 1 = 0.113582 loss)
I0929 23:10:05.874045 25310 solver.cpp:590] Iteration 5400, lr = 0.01
I0929 23:10:06.663825 25310 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:10:08.373914 25310 solver.cpp:243] Iteration 5500, loss = 0.116776
I0929 23:10:08.373953 25310 solver.cpp:259]     Train net output #0: error_blob = 0.116776 (* 1 = 0.116776 loss)
I0929 23:10:08.373958 25310 solver.cpp:590] Iteration 5500, lr = 0.01
I0929 23:10:10.830299 25310 solver.cpp:243] Iteration 5600, loss = 0.111635
I0929 23:10:10.830330 25310 solver.cpp:259]     Train net output #0: error_blob = 0.111635 (* 1 = 0.111635 loss)
I0929 23:10:10.830335 25310 solver.cpp:590] Iteration 5600, lr = 0.01
I0929 23:10:13.297099 25310 solver.cpp:243] Iteration 5700, loss = 0.117502
I0929 23:10:13.297145 25310 solver.cpp:259]     Train net output #0: error_blob = 0.117502 (* 1 = 0.117502 loss)
I0929 23:10:13.297152 25310 solver.cpp:590] Iteration 5700, lr = 0.01
I0929 23:10:15.784057 25310 solver.cpp:243] Iteration 5800, loss = 0.114194
I0929 23:10:15.784088 25310 solver.cpp:259]     Train net output #0: error_blob = 0.114194 (* 1 = 0.114194 loss)
I0929 23:10:15.784092 25310 solver.cpp:590] Iteration 5800, lr = 0.01
I0929 23:10:18.286346 25310 solver.cpp:243] Iteration 5900, loss = 0.117802
I0929 23:10:18.286387 25310 solver.cpp:259]     Train net output #0: error_blob = 0.117802 (* 1 = 0.117802 loss)
I0929 23:10:18.286393 25310 solver.cpp:590] Iteration 5900, lr = 0.01
I0929 23:10:20.729454 25310 solver.cpp:347] Iteration 6000, Testing net (#0)
I0929 23:10:21.010550 25310 solver.cpp:415]     Test net output #0: error_blob = 0.117925 (* 1 = 0.117925 loss)
I0929 23:10:21.011236 25310 solver.cpp:243] Iteration 6000, loss = 0.114287
I0929 23:10:21.011273 25310 solver.cpp:259]     Train net output #0: error_blob = 0.114287 (* 1 = 0.114287 loss)
I0929 23:10:21.011293 25310 solver.cpp:590] Iteration 6000, lr = 0.01
I0929 23:10:23.435214 25310 solver.cpp:243] Iteration 6100, loss = 0.117388
I0929 23:10:23.437021 25310 solver.cpp:259]     Train net output #0: error_blob = 0.117388 (* 1 = 0.117388 loss)
I0929 23:10:23.437031 25310 solver.cpp:590] Iteration 6100, lr = 0.01
I0929 23:10:25.870307 25310 solver.cpp:243] Iteration 6200, loss = 0.114483
I0929 23:10:25.870335 25310 solver.cpp:259]     Train net output #0: error_blob = 0.114483 (* 1 = 0.114483 loss)
I0929 23:10:25.870342 25310 solver.cpp:590] Iteration 6200, lr = 0.01
I0929 23:10:28.357873 25310 solver.cpp:243] Iteration 6300, loss = 0.114168
I0929 23:10:28.357903 25310 solver.cpp:259]     Train net output #0: error_blob = 0.114168 (* 1 = 0.114168 loss)
I0929 23:10:28.357908 25310 solver.cpp:590] Iteration 6300, lr = 0.01
I0929 23:10:29.291229 25310 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:10:30.824506 25310 solver.cpp:243] Iteration 6400, loss = 0.118076
I0929 23:10:30.824534 25310 solver.cpp:259]     Train net output #0: error_blob = 0.118076 (* 1 = 0.118076 loss)
I0929 23:10:30.824538 25310 solver.cpp:590] Iteration 6400, lr = 0.01
I0929 23:10:33.325403 25310 solver.cpp:243] Iteration 6500, loss = 0.112707
I0929 23:10:33.325438 25310 solver.cpp:259]     Train net output #0: error_blob = 0.112707 (* 1 = 0.112707 loss)
I0929 23:10:33.325445 25310 solver.cpp:590] Iteration 6500, lr = 0.01
I0929 23:10:35.792523 25310 solver.cpp:243] Iteration 6600, loss = 0.118126
I0929 23:10:35.792560 25310 solver.cpp:259]     Train net output #0: error_blob = 0.118126 (* 1 = 0.118126 loss)
I0929 23:10:35.792567 25310 solver.cpp:590] Iteration 6600, lr = 0.01
I0929 23:10:38.259114 25310 solver.cpp:243] Iteration 6700, loss = 0.115817
I0929 23:10:38.259145 25310 solver.cpp:259]     Train net output #0: error_blob = 0.115817 (* 1 = 0.115817 loss)
I0929 23:10:38.259150 25310 solver.cpp:590] Iteration 6700, lr = 0.01
I0929 23:10:40.690054 25310 solver.cpp:243] Iteration 6800, loss = 0.116989
I0929 23:10:40.690089 25310 solver.cpp:259]     Train net output #0: error_blob = 0.116989 (* 1 = 0.116989 loss)
I0929 23:10:40.690095 25310 solver.cpp:590] Iteration 6800, lr = 0.01
I0929 23:10:43.219991 25310 solver.cpp:243] Iteration 6900, loss = 0.112226
I0929 23:10:43.220026 25310 solver.cpp:259]     Train net output #0: error_blob = 0.112226 (* 1 = 0.112226 loss)
I0929 23:10:43.220032 25310 solver.cpp:590] Iteration 6900, lr = 0.01
I0929 23:10:45.748648 25310 solver.cpp:347] Iteration 7000, Testing net (#0)
I0929 23:10:46.027230 25310 solver.cpp:415]     Test net output #0: error_blob = 0.114306 (* 1 = 0.114306 loss)
I0929 23:10:46.027940 25310 solver.cpp:243] Iteration 7000, loss = 0.117419
I0929 23:10:46.027953 25310 solver.cpp:259]     Train net output #0: error_blob = 0.117419 (* 1 = 0.117419 loss)
I0929 23:10:46.027959 25310 solver.cpp:590] Iteration 7000, lr = 0.01
I0929 23:10:48.464277 25310 solver.cpp:243] Iteration 7100, loss = 0.112998
I0929 23:10:48.464306 25310 solver.cpp:259]     Train net output #0: error_blob = 0.112998 (* 1 = 0.112998 loss)
I0929 23:10:48.464311 25310 solver.cpp:590] Iteration 7100, lr = 0.01
I0929 23:10:50.915849 25310 solver.cpp:243] Iteration 7200, loss = 0.117938
I0929 23:10:50.915879 25310 solver.cpp:259]     Train net output #0: error_blob = 0.117938 (* 1 = 0.117938 loss)
I0929 23:10:50.915884 25310 solver.cpp:590] Iteration 7200, lr = 0.01
I0929 23:10:51.989506 25310 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:10:53.370941 25310 solver.cpp:243] Iteration 7300, loss = 0.113998
I0929 23:10:53.370982 25310 solver.cpp:259]     Train net output #0: error_blob = 0.113998 (* 1 = 0.113998 loss)
I0929 23:10:53.370987 25310 solver.cpp:590] Iteration 7300, lr = 0.01
I0929 23:10:55.835352 25310 solver.cpp:243] Iteration 7400, loss = 0.116105
I0929 23:10:55.835445 25310 solver.cpp:259]     Train net output #0: error_blob = 0.116105 (* 1 = 0.116105 loss)
I0929 23:10:55.835453 25310 solver.cpp:590] Iteration 7400, lr = 0.01
I0929 23:10:58.315402 25310 solver.cpp:243] Iteration 7500, loss = 0.115514
I0929 23:10:58.315433 25310 solver.cpp:259]     Train net output #0: error_blob = 0.115514 (* 1 = 0.115514 loss)
I0929 23:10:58.315438 25310 solver.cpp:590] Iteration 7500, lr = 0.01
I0929 23:11:00.800940 25310 solver.cpp:243] Iteration 7600, loss = 0.112646
I0929 23:11:00.800969 25310 solver.cpp:259]     Train net output #0: error_blob = 0.112646 (* 1 = 0.112646 loss)
I0929 23:11:00.800973 25310 solver.cpp:590] Iteration 7600, lr = 0.01
I0929 23:11:03.258719 25310 solver.cpp:243] Iteration 7700, loss = 0.116682
I0929 23:11:03.258749 25310 solver.cpp:259]     Train net output #0: error_blob = 0.116682 (* 1 = 0.116682 loss)
I0929 23:11:03.258752 25310 solver.cpp:590] Iteration 7700, lr = 0.01
I0929 23:11:05.699487 25310 solver.cpp:243] Iteration 7800, loss = 0.11258
I0929 23:11:05.699518 25310 solver.cpp:259]     Train net output #0: error_blob = 0.11258 (* 1 = 0.11258 loss)
I0929 23:11:05.699523 25310 solver.cpp:590] Iteration 7800, lr = 0.01
I0929 23:11:08.179261 25310 solver.cpp:243] Iteration 7900, loss = 0.116533
I0929 23:11:08.179299 25310 solver.cpp:259]     Train net output #0: error_blob = 0.116533 (* 1 = 0.116533 loss)
I0929 23:11:08.179306 25310 solver.cpp:590] Iteration 7900, lr = 0.01
I0929 23:11:10.635360 25310 solver.cpp:347] Iteration 8000, Testing net (#0)
I0929 23:11:10.911311 25310 solver.cpp:415]     Test net output #0: error_blob = 0.114279 (* 1 = 0.114279 loss)
I0929 23:11:10.911911 25310 solver.cpp:243] Iteration 8000, loss = 0.110367
I0929 23:11:10.911923 25310 solver.cpp:259]     Train net output #0: error_blob = 0.110367 (* 1 = 0.110367 loss)
I0929 23:11:10.911932 25310 solver.cpp:590] Iteration 8000, lr = 0.01
I0929 23:11:13.310786 25310 solver.cpp:243] Iteration 8100, loss = 0.117037
I0929 23:11:13.310832 25310 solver.cpp:259]     Train net output #0: error_blob = 0.117037 (* 1 = 0.117037 loss)
I0929 23:11:13.310840 25310 solver.cpp:590] Iteration 8100, lr = 0.01
I0929 23:11:14.540877 25310 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:11:15.766572 25310 solver.cpp:243] Iteration 8200, loss = 0.116093
I0929 23:11:15.766602 25310 solver.cpp:259]     Train net output #0: error_blob = 0.116093 (* 1 = 0.116093 loss)
I0929 23:11:15.766607 25310 solver.cpp:590] Iteration 8200, lr = 0.01
I0929 23:11:18.210031 25310 solver.cpp:243] Iteration 8300, loss = 0.116204
I0929 23:11:18.210077 25310 solver.cpp:259]     Train net output #0: error_blob = 0.116204 (* 1 = 0.116204 loss)
I0929 23:11:18.210083 25310 solver.cpp:590] Iteration 8300, lr = 0.01
I0929 23:11:20.696228 25310 solver.cpp:243] Iteration 8400, loss = 0.114977
I0929 23:11:20.696270 25310 solver.cpp:259]     Train net output #0: error_blob = 0.114977 (* 1 = 0.114977 loss)
I0929 23:11:20.696277 25310 solver.cpp:590] Iteration 8400, lr = 0.01
I0929 23:11:23.181146 25310 solver.cpp:243] Iteration 8500, loss = 0.113019
I0929 23:11:23.181179 25310 solver.cpp:259]     Train net output #0: error_blob = 0.113019 (* 1 = 0.113019 loss)
I0929 23:11:23.181182 25310 solver.cpp:590] Iteration 8500, lr = 0.01
I0929 23:11:25.625675 25310 solver.cpp:243] Iteration 8600, loss = 0.114723
I0929 23:11:25.625715 25310 solver.cpp:259]     Train net output #0: error_blob = 0.114723 (* 1 = 0.114723 loss)
I0929 23:11:25.625720 25310 solver.cpp:590] Iteration 8600, lr = 0.01
I0929 23:11:28.039706 25310 solver.cpp:243] Iteration 8700, loss = 0.112347
I0929 23:11:28.039813 25310 solver.cpp:259]     Train net output #0: error_blob = 0.112347 (* 1 = 0.112347 loss)
I0929 23:11:28.039819 25310 solver.cpp:590] Iteration 8700, lr = 0.01
I0929 23:11:30.519316 25310 solver.cpp:243] Iteration 8800, loss = 0.116108
I0929 23:11:30.519347 25310 solver.cpp:259]     Train net output #0: error_blob = 0.116108 (* 1 = 0.116108 loss)
I0929 23:11:30.519352 25310 solver.cpp:590] Iteration 8800, lr = 0.01
I0929 23:11:33.016787 25310 solver.cpp:243] Iteration 8900, loss = 0.114333
I0929 23:11:33.016832 25310 solver.cpp:259]     Train net output #0: error_blob = 0.114333 (* 1 = 0.114333 loss)
I0929 23:11:33.016839 25310 solver.cpp:590] Iteration 8900, lr = 0.01
I0929 23:11:35.516173 25310 solver.cpp:347] Iteration 9000, Testing net (#0)
I0929 23:11:35.793952 25310 solver.cpp:415]     Test net output #0: error_blob = 0.113666 (* 1 = 0.113666 loss)
I0929 23:11:35.794611 25310 solver.cpp:243] Iteration 9000, loss = 0.116372
I0929 23:11:35.794644 25310 solver.cpp:259]     Train net output #0: error_blob = 0.116372 (* 1 = 0.116372 loss)
I0929 23:11:35.794666 25310 solver.cpp:590] Iteration 9000, lr = 0.01
I0929 23:11:37.162943 25310 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:11:38.272953 25310 solver.cpp:243] Iteration 9100, loss = 0.112134
I0929 23:11:38.272987 25310 solver.cpp:259]     Train net output #0: error_blob = 0.112134 (* 1 = 0.112134 loss)
I0929 23:11:38.272994 25310 solver.cpp:590] Iteration 9100, lr = 0.01
I0929 23:11:40.798774 25310 solver.cpp:243] Iteration 9200, loss = 0.11679
I0929 23:11:40.798817 25310 solver.cpp:259]     Train net output #0: error_blob = 0.11679 (* 1 = 0.11679 loss)
I0929 23:11:40.798823 25310 solver.cpp:590] Iteration 9200, lr = 0.01
I0929 23:11:43.302014 25310 solver.cpp:243] Iteration 9300, loss = 0.115335
I0929 23:11:43.302058 25310 solver.cpp:259]     Train net output #0: error_blob = 0.115335 (* 1 = 0.115335 loss)
I0929 23:11:43.302064 25310 solver.cpp:590] Iteration 9300, lr = 0.01
I0929 23:11:45.799945 25310 solver.cpp:243] Iteration 9400, loss = 0.114567
I0929 23:11:45.799990 25310 solver.cpp:259]     Train net output #0: error_blob = 0.114567 (* 1 = 0.114567 loss)
I0929 23:11:45.799996 25310 solver.cpp:590] Iteration 9400, lr = 0.01
I0929 23:11:48.314149 25310 solver.cpp:243] Iteration 9500, loss = 0.115126
I0929 23:11:48.314193 25310 solver.cpp:259]     Train net output #0: error_blob = 0.115126 (* 1 = 0.115126 loss)
I0929 23:11:48.314198 25310 solver.cpp:590] Iteration 9500, lr = 0.01
I0929 23:11:50.827657 25310 solver.cpp:243] Iteration 9600, loss = 0.112297
I0929 23:11:50.827693 25310 solver.cpp:259]     Train net output #0: error_blob = 0.112297 (* 1 = 0.112297 loss)
I0929 23:11:50.827699 25310 solver.cpp:590] Iteration 9600, lr = 0.01
I0929 23:11:53.342762 25310 solver.cpp:243] Iteration 9700, loss = 0.118009
I0929 23:11:53.342799 25310 solver.cpp:259]     Train net output #0: error_blob = 0.118009 (* 1 = 0.118009 loss)
I0929 23:11:53.342805 25310 solver.cpp:590] Iteration 9700, lr = 0.01
I0929 23:11:55.843551 25310 solver.cpp:243] Iteration 9800, loss = 0.117613
I0929 23:11:55.843596 25310 solver.cpp:259]     Train net output #0: error_blob = 0.117613 (* 1 = 0.117613 loss)
I0929 23:11:55.843603 25310 solver.cpp:590] Iteration 9800, lr = 0.01
I0929 23:11:58.353538 25310 solver.cpp:243] Iteration 9900, loss = 0.117594
I0929 23:11:58.353688 25310 solver.cpp:259]     Train net output #0: error_blob = 0.117594 (* 1 = 0.117594 loss)
I0929 23:11:58.353696 25310 solver.cpp:590] Iteration 9900, lr = 0.01
I0929 23:12:00.826736 25310 solver.cpp:468] Snapshotting to binary proto file _iter_10000.caffemodel
I0929 23:12:00.827549 25310 solver.cpp:753] Snapshotting solver state to binary proto file _iter_10000.solverstate
I0929 23:12:00.852082 25310 solver.cpp:327] Iteration 10000, loss = 0.113199
I0929 23:12:00.852108 25310 solver.cpp:347] Iteration 10000, Testing net (#0)
I0929 23:12:01.022713 25310 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:12:01.132319 25310 solver.cpp:415]     Test net output #0: error_blob = 0.115205 (* 1 = 0.115205 loss)
I0929 23:12:01.132343 25310 solver.cpp:332] Optimization Done.
I0929 23:12:01.132346 25310 caffe.cpp:215] Optimization Done.
I0929 23:12:01.195205 25332 caffe.cpp:184] Using GPUs 0
I0929 23:12:01.758584 25332 solver.cpp:54] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "fixed"
momentum: 0.9
solver_mode: GPU
device_id: 0
net: "model/NNScore/nnscore_model_2.prototxt"
I0929 23:12:01.758615 25332 solver.cpp:97] Creating training net from net file: model/NNScore/nnscore_model_2.prototxt
I0929 23:12:01.758788 25332 net.cpp:339] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_layer
I0929 23:12:01.758836 25332 net.cpp:50] Initializing net from parameters: 
name: "model/NNScore/nnscore_model_2.prototxt"
state {
  phase: TRAIN
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TRAIN
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.2.train"
    batch_size: 20000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I0929 23:12:01.758913 25332 layer_factory.hpp:76] Creating layer data_layer
I0929 23:12:01.772171 25332 net.cpp:110] Creating Layer data_layer
I0929 23:12:01.772202 25332 net.cpp:433] data_layer -> data_blob
I0929 23:12:01.772236 25332 net.cpp:433] data_layer -> label_blob
I0929 23:12:01.772833 25337 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.2.train
I0929 23:12:02.463598 25332 data_layer.cpp:45] output data size: 20000,61,1,1
I0929 23:12:02.468544 25332 net.cpp:155] Setting up data_layer
I0929 23:12:02.468590 25332 net.cpp:163] Top shape: 20000 61 1 1 (1220000)
I0929 23:12:02.468603 25332 net.cpp:163] Top shape: 20000 (20000)
I0929 23:12:02.468611 25332 layer_factory.hpp:76] Creating layer hidden_sum_layer
I0929 23:12:02.468621 25332 net.cpp:110] Creating Layer hidden_sum_layer
I0929 23:12:02.468628 25332 net.cpp:477] hidden_sum_layer <- data_blob
I0929 23:12:02.468637 25332 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I0929 23:12:02.468991 25332 net.cpp:155] Setting up hidden_sum_layer
I0929 23:12:02.468998 25332 net.cpp:163] Top shape: 20000 10 (200000)
I0929 23:12:02.469020 25332 layer_factory.hpp:76] Creating layer hidden_act_layer
I0929 23:12:02.469038 25332 net.cpp:110] Creating Layer hidden_act_layer
I0929 23:12:02.469039 25332 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I0929 23:12:02.469043 25332 net.cpp:433] hidden_act_layer -> hidden_act_blob
I0929 23:12:05.748042 25332 net.cpp:155] Setting up hidden_act_layer
I0929 23:12:05.748066 25332 net.cpp:163] Top shape: 20000 10 (200000)
I0929 23:12:05.748072 25332 layer_factory.hpp:76] Creating layer output_sum_layer
I0929 23:12:05.748085 25332 net.cpp:110] Creating Layer output_sum_layer
I0929 23:12:05.748088 25332 net.cpp:477] output_sum_layer <- hidden_act_blob
I0929 23:12:05.748105 25332 net.cpp:433] output_sum_layer -> output_sum_blob
I0929 23:12:05.748208 25332 net.cpp:155] Setting up output_sum_layer
I0929 23:12:05.748213 25332 net.cpp:163] Top shape: 20000 1 (20000)
I0929 23:12:05.748232 25332 layer_factory.hpp:76] Creating layer output_act_layer
I0929 23:12:05.748237 25332 net.cpp:110] Creating Layer output_act_layer
I0929 23:12:05.748248 25332 net.cpp:477] output_act_layer <- output_sum_blob
I0929 23:12:05.748251 25332 net.cpp:433] output_act_layer -> output_act_blob
I0929 23:12:05.748323 25332 net.cpp:155] Setting up output_act_layer
I0929 23:12:05.748352 25332 net.cpp:163] Top shape: 20000 1 (20000)
I0929 23:12:05.748354 25332 layer_factory.hpp:76] Creating layer error_layer
I0929 23:12:05.748359 25332 net.cpp:110] Creating Layer error_layer
I0929 23:12:05.748371 25332 net.cpp:477] error_layer <- output_act_blob
I0929 23:12:05.748374 25332 net.cpp:477] error_layer <- label_blob
I0929 23:12:05.748378 25332 net.cpp:433] error_layer -> error_blob
I0929 23:12:05.748410 25332 net.cpp:155] Setting up error_layer
I0929 23:12:05.748414 25332 net.cpp:163] Top shape: (1)
I0929 23:12:05.748416 25332 net.cpp:168]     with loss weight 1
I0929 23:12:05.748433 25332 net.cpp:236] error_layer needs backward computation.
I0929 23:12:05.748436 25332 net.cpp:236] output_act_layer needs backward computation.
I0929 23:12:05.748438 25332 net.cpp:236] output_sum_layer needs backward computation.
I0929 23:12:05.748440 25332 net.cpp:236] hidden_act_layer needs backward computation.
I0929 23:12:05.748442 25332 net.cpp:236] hidden_sum_layer needs backward computation.
I0929 23:12:05.748445 25332 net.cpp:240] data_layer does not need backward computation.
I0929 23:12:05.748446 25332 net.cpp:283] This network produces output error_blob
I0929 23:12:05.748450 25332 net.cpp:297] Network initialization done.
I0929 23:12:05.748452 25332 net.cpp:298] Memory required for data: 6720004
I0929 23:12:05.748620 25332 solver.cpp:187] Creating test net (#0) specified by net file: model/NNScore/nnscore_model_2.prototxt
I0929 23:12:05.748651 25332 net.cpp:339] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_layer
I0929 23:12:05.748709 25332 net.cpp:50] Initializing net from parameters: 
name: "model/NNScore/nnscore_model_2.prototxt"
state {
  phase: TEST
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TEST
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.2.test"
    batch_size: 2000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I0929 23:12:05.748749 25332 layer_factory.hpp:76] Creating layer data_layer
I0929 23:12:05.749922 25332 net.cpp:110] Creating Layer data_layer
I0929 23:12:05.749927 25332 net.cpp:433] data_layer -> data_blob
I0929 23:12:05.749932 25332 net.cpp:433] data_layer -> label_blob
I0929 23:12:05.750515 25339 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.2.test
I0929 23:12:05.750615 25332 data_layer.cpp:45] output data size: 2000,61,1,1
I0929 23:12:05.751947 25332 net.cpp:155] Setting up data_layer
I0929 23:12:05.751965 25332 net.cpp:163] Top shape: 2000 61 1 1 (122000)
I0929 23:12:05.751970 25332 net.cpp:163] Top shape: 2000 (2000)
I0929 23:12:05.751971 25332 layer_factory.hpp:76] Creating layer hidden_sum_layer
I0929 23:12:05.751989 25332 net.cpp:110] Creating Layer hidden_sum_layer
I0929 23:12:05.751991 25332 net.cpp:477] hidden_sum_layer <- data_blob
I0929 23:12:05.751996 25332 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I0929 23:12:05.752127 25332 net.cpp:155] Setting up hidden_sum_layer
I0929 23:12:05.752131 25332 net.cpp:163] Top shape: 2000 10 (20000)
I0929 23:12:05.752138 25332 layer_factory.hpp:76] Creating layer hidden_act_layer
I0929 23:12:05.752142 25332 net.cpp:110] Creating Layer hidden_act_layer
I0929 23:12:05.752154 25332 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I0929 23:12:05.752166 25332 net.cpp:433] hidden_act_layer -> hidden_act_blob
I0929 23:12:05.752322 25332 net.cpp:155] Setting up hidden_act_layer
I0929 23:12:05.752329 25332 net.cpp:163] Top shape: 2000 10 (20000)
I0929 23:12:05.752331 25332 layer_factory.hpp:76] Creating layer output_sum_layer
I0929 23:12:05.752336 25332 net.cpp:110] Creating Layer output_sum_layer
I0929 23:12:05.752348 25332 net.cpp:477] output_sum_layer <- hidden_act_blob
I0929 23:12:05.752351 25332 net.cpp:433] output_sum_layer -> output_sum_blob
I0929 23:12:05.752419 25332 net.cpp:155] Setting up output_sum_layer
I0929 23:12:05.752424 25332 net.cpp:163] Top shape: 2000 1 (2000)
I0929 23:12:05.752429 25332 layer_factory.hpp:76] Creating layer output_act_layer
I0929 23:12:05.752442 25332 net.cpp:110] Creating Layer output_act_layer
I0929 23:12:05.752444 25332 net.cpp:477] output_act_layer <- output_sum_blob
I0929 23:12:05.752447 25332 net.cpp:433] output_act_layer -> output_act_blob
I0929 23:12:05.752511 25332 net.cpp:155] Setting up output_act_layer
I0929 23:12:05.752516 25332 net.cpp:163] Top shape: 2000 1 (2000)
I0929 23:12:05.752518 25332 layer_factory.hpp:76] Creating layer error_layer
I0929 23:12:05.752521 25332 net.cpp:110] Creating Layer error_layer
I0929 23:12:05.752533 25332 net.cpp:477] error_layer <- output_act_blob
I0929 23:12:05.752537 25332 net.cpp:477] error_layer <- label_blob
I0929 23:12:05.752538 25332 net.cpp:433] error_layer -> error_blob
I0929 23:12:05.752557 25332 net.cpp:155] Setting up error_layer
I0929 23:12:05.752559 25332 net.cpp:163] Top shape: (1)
I0929 23:12:05.752562 25332 net.cpp:168]     with loss weight 1
I0929 23:12:05.752567 25332 net.cpp:236] error_layer needs backward computation.
I0929 23:12:05.752569 25332 net.cpp:236] output_act_layer needs backward computation.
I0929 23:12:05.752570 25332 net.cpp:236] output_sum_layer needs backward computation.
I0929 23:12:05.752573 25332 net.cpp:236] hidden_act_layer needs backward computation.
I0929 23:12:05.752574 25332 net.cpp:236] hidden_sum_layer needs backward computation.
I0929 23:12:05.752576 25332 net.cpp:240] data_layer does not need backward computation.
I0929 23:12:05.752578 25332 net.cpp:283] This network produces output error_blob
I0929 23:12:05.752583 25332 net.cpp:297] Network initialization done.
I0929 23:12:05.752584 25332 net.cpp:298] Memory required for data: 672004
I0929 23:12:05.752599 25332 solver.cpp:66] Solver scaffolding done.
I0929 23:12:05.752689 25332 caffe.cpp:212] Starting Optimization
I0929 23:12:05.752696 25332 solver.cpp:294] Solving model/NNScore/nnscore_model_2.prototxt
I0929 23:12:05.752697 25332 solver.cpp:295] Learning Rate Policy: fixed
I0929 23:12:05.752835 25332 solver.cpp:347] Iteration 0, Testing net (#0)
I0929 23:12:05.752888 25332 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:12:06.020246 25332 solver.cpp:415]     Test net output #0: error_blob = 0.12765 (* 1 = 0.12765 loss)
I0929 23:12:06.021494 25332 solver.cpp:243] Iteration 0, loss = 0.127399
I0929 23:12:06.021507 25332 solver.cpp:259]     Train net output #0: error_blob = 0.127399 (* 1 = 0.127399 loss)
I0929 23:12:06.021517 25332 solver.cpp:590] Iteration 0, lr = 0.01
I0929 23:12:08.480268 25332 solver.cpp:243] Iteration 100, loss = 0.123309
I0929 23:12:08.480312 25332 solver.cpp:259]     Train net output #0: error_blob = 0.123309 (* 1 = 0.123309 loss)
I0929 23:12:08.480319 25332 solver.cpp:590] Iteration 100, lr = 0.01
I0929 23:12:10.943065 25332 solver.cpp:243] Iteration 200, loss = 0.122216
I0929 23:12:10.943105 25332 solver.cpp:259]     Train net output #0: error_blob = 0.122216 (* 1 = 0.122216 loss)
I0929 23:12:10.943112 25332 solver.cpp:590] Iteration 200, lr = 0.01
I0929 23:12:13.406008 25332 solver.cpp:243] Iteration 300, loss = 0.121332
I0929 23:12:13.406046 25332 solver.cpp:259]     Train net output #0: error_blob = 0.121332 (* 1 = 0.121332 loss)
I0929 23:12:13.406051 25332 solver.cpp:590] Iteration 300, lr = 0.01
I0929 23:12:15.877516 25332 solver.cpp:243] Iteration 400, loss = 0.120434
I0929 23:12:15.877568 25332 solver.cpp:259]     Train net output #0: error_blob = 0.120434 (* 1 = 0.120434 loss)
I0929 23:12:15.877573 25332 solver.cpp:590] Iteration 400, lr = 0.01
I0929 23:12:18.364770 25332 solver.cpp:243] Iteration 500, loss = 0.121057
I0929 23:12:18.364807 25332 solver.cpp:259]     Train net output #0: error_blob = 0.121057 (* 1 = 0.121057 loss)
I0929 23:12:18.364816 25332 solver.cpp:590] Iteration 500, lr = 0.01
I0929 23:12:20.945312 25332 solver.cpp:243] Iteration 600, loss = 0.11913
I0929 23:12:20.945341 25332 solver.cpp:259]     Train net output #0: error_blob = 0.11913 (* 1 = 0.11913 loss)
I0929 23:12:20.945346 25332 solver.cpp:590] Iteration 600, lr = 0.01
I0929 23:12:23.472729 25332 solver.cpp:243] Iteration 700, loss = 0.120322
I0929 23:12:23.472775 25332 solver.cpp:259]     Train net output #0: error_blob = 0.120322 (* 1 = 0.120322 loss)
I0929 23:12:23.472784 25332 solver.cpp:590] Iteration 700, lr = 0.01
I0929 23:12:25.996551 25332 solver.cpp:243] Iteration 800, loss = 0.118483
I0929 23:12:25.996589 25332 solver.cpp:259]     Train net output #0: error_blob = 0.118483 (* 1 = 0.118483 loss)
I0929 23:12:25.996597 25332 solver.cpp:590] Iteration 800, lr = 0.01
I0929 23:12:28.485647 25332 solver.cpp:243] Iteration 900, loss = 0.117529
I0929 23:12:28.485677 25332 solver.cpp:259]     Train net output #0: error_blob = 0.117529 (* 1 = 0.117529 loss)
I0929 23:12:28.485682 25332 solver.cpp:590] Iteration 900, lr = 0.01
I0929 23:12:28.536329 25332 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:12:30.961858 25332 solver.cpp:347] Iteration 1000, Testing net (#0)
I0929 23:12:31.244657 25332 solver.cpp:415]     Test net output #0: error_blob = 0.122773 (* 1 = 0.122773 loss)
I0929 23:12:31.245834 25332 solver.cpp:243] Iteration 1000, loss = 0.120766
I0929 23:12:31.245852 25332 solver.cpp:259]     Train net output #0: error_blob = 0.120766 (* 1 = 0.120766 loss)
I0929 23:12:31.245858 25332 solver.cpp:590] Iteration 1000, lr = 0.01
I0929 23:12:33.697367 25332 solver.cpp:243] Iteration 1100, loss = 0.118172
I0929 23:12:33.697399 25332 solver.cpp:259]     Train net output #0: error_blob = 0.118172 (* 1 = 0.118172 loss)
I0929 23:12:33.697404 25332 solver.cpp:590] Iteration 1100, lr = 0.01
I0929 23:12:36.157959 25332 solver.cpp:243] Iteration 1200, loss = 0.11957
I0929 23:12:36.157989 25332 solver.cpp:259]     Train net output #0: error_blob = 0.11957 (* 1 = 0.11957 loss)
I0929 23:12:36.157992 25332 solver.cpp:590] Iteration 1200, lr = 0.01
I0929 23:12:38.626950 25332 solver.cpp:243] Iteration 1300, loss = 0.119208
I0929 23:12:38.626981 25332 solver.cpp:259]     Train net output #0: error_blob = 0.119208 (* 1 = 0.119208 loss)
I0929 23:12:38.626986 25332 solver.cpp:590] Iteration 1300, lr = 0.01
I0929 23:12:41.103427 25332 solver.cpp:243] Iteration 1400, loss = 0.116851
I0929 23:12:41.103458 25332 solver.cpp:259]     Train net output #0: error_blob = 0.116851 (* 1 = 0.116851 loss)
I0929 23:12:41.103463 25332 solver.cpp:590] Iteration 1400, lr = 0.01
I0929 23:12:43.575088 25332 solver.cpp:243] Iteration 1500, loss = 0.11891
I0929 23:12:43.575129 25332 solver.cpp:259]     Train net output #0: error_blob = 0.11891 (* 1 = 0.11891 loss)
I0929 23:12:43.575135 25332 solver.cpp:590] Iteration 1500, lr = 0.01
I0929 23:12:46.050263 25332 solver.cpp:243] Iteration 1600, loss = 0.117542
I0929 23:12:46.050304 25332 solver.cpp:259]     Train net output #0: error_blob = 0.117542 (* 1 = 0.117542 loss)
I0929 23:12:46.050309 25332 solver.cpp:590] Iteration 1600, lr = 0.01
I0929 23:12:48.521224 25332 solver.cpp:243] Iteration 1700, loss = 0.119192
I0929 23:12:48.521257 25332 solver.cpp:259]     Train net output #0: error_blob = 0.119192 (* 1 = 0.119192 loss)
I0929 23:12:48.521262 25332 solver.cpp:590] Iteration 1700, lr = 0.01
I0929 23:12:51.005710 25332 solver.cpp:243] Iteration 1800, loss = 0.11854
I0929 23:12:51.005750 25332 solver.cpp:259]     Train net output #0: error_blob = 0.11854 (* 1 = 0.11854 loss)
I0929 23:12:51.005755 25332 solver.cpp:590] Iteration 1800, lr = 0.01
I0929 23:12:51.199872 25332 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:12:53.452967 25332 solver.cpp:243] Iteration 1900, loss = 0.115139
I0929 23:12:53.452996 25332 solver.cpp:259]     Train net output #0: error_blob = 0.115139 (* 1 = 0.115139 loss)
I0929 23:12:53.453001 25332 solver.cpp:590] Iteration 1900, lr = 0.01
I0929 23:12:55.909121 25332 solver.cpp:347] Iteration 2000, Testing net (#0)
I0929 23:12:56.212255 25332 solver.cpp:415]     Test net output #0: error_blob = 0.121205 (* 1 = 0.121205 loss)
I0929 23:12:56.212972 25332 solver.cpp:243] Iteration 2000, loss = 0.120008
I0929 23:12:56.213014 25332 solver.cpp:259]     Train net output #0: error_blob = 0.120008 (* 1 = 0.120008 loss)
I0929 23:12:56.213023 25332 solver.cpp:590] Iteration 2000, lr = 0.01
I0929 23:12:58.651232 25332 solver.cpp:243] Iteration 2100, loss = 0.116241
I0929 23:12:58.651273 25332 solver.cpp:259]     Train net output #0: error_blob = 0.116241 (* 1 = 0.116241 loss)
I0929 23:12:58.651278 25332 solver.cpp:590] Iteration 2100, lr = 0.01
I0929 23:13:01.138089 25332 solver.cpp:243] Iteration 2200, loss = 0.116667
I0929 23:13:01.138129 25332 solver.cpp:259]     Train net output #0: error_blob = 0.116667 (* 1 = 0.116667 loss)
I0929 23:13:01.138135 25332 solver.cpp:590] Iteration 2200, lr = 0.01
I0929 23:13:03.629750 25332 solver.cpp:243] Iteration 2300, loss = 0.118391
I0929 23:13:03.629884 25332 solver.cpp:259]     Train net output #0: error_blob = 0.118391 (* 1 = 0.118391 loss)
I0929 23:13:03.629900 25332 solver.cpp:590] Iteration 2300, lr = 0.01
I0929 23:13:06.104317 25332 solver.cpp:243] Iteration 2400, loss = 0.114274
I0929 23:13:06.104347 25332 solver.cpp:259]     Train net output #0: error_blob = 0.114274 (* 1 = 0.114274 loss)
I0929 23:13:06.104351 25332 solver.cpp:590] Iteration 2400, lr = 0.01
I0929 23:13:08.559679 25332 solver.cpp:243] Iteration 2500, loss = 0.118372
I0929 23:13:08.559710 25332 solver.cpp:259]     Train net output #0: error_blob = 0.118372 (* 1 = 0.118372 loss)
I0929 23:13:08.559715 25332 solver.cpp:590] Iteration 2500, lr = 0.01
I0929 23:13:11.024704 25332 solver.cpp:243] Iteration 2600, loss = 0.115368
I0929 23:13:11.024735 25332 solver.cpp:259]     Train net output #0: error_blob = 0.115368 (* 1 = 0.115368 loss)
I0929 23:13:11.024741 25332 solver.cpp:590] Iteration 2600, lr = 0.01
I0929 23:13:13.514937 25332 solver.cpp:243] Iteration 2700, loss = 0.115636
I0929 23:13:13.514977 25332 solver.cpp:259]     Train net output #0: error_blob = 0.115636 (* 1 = 0.115636 loss)
I0929 23:13:13.514982 25332 solver.cpp:590] Iteration 2700, lr = 0.01
I0929 23:13:13.857175 25332 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:13:16.005839 25332 solver.cpp:243] Iteration 2800, loss = 0.117982
I0929 23:13:16.005872 25332 solver.cpp:259]     Train net output #0: error_blob = 0.117982 (* 1 = 0.117982 loss)
I0929 23:13:16.005877 25332 solver.cpp:590] Iteration 2800, lr = 0.01
I0929 23:13:18.493952 25332 solver.cpp:243] Iteration 2900, loss = 0.112483
I0929 23:13:18.493983 25332 solver.cpp:259]     Train net output #0: error_blob = 0.112483 (* 1 = 0.112483 loss)
I0929 23:13:18.493988 25332 solver.cpp:590] Iteration 2900, lr = 0.01
I0929 23:13:20.977943 25332 solver.cpp:347] Iteration 3000, Testing net (#0)
I0929 23:13:21.257480 25332 solver.cpp:415]     Test net output #0: error_blob = 0.118034 (* 1 = 0.118034 loss)
I0929 23:13:21.258102 25332 solver.cpp:243] Iteration 3000, loss = 0.117596
I0929 23:13:21.258117 25332 solver.cpp:259]     Train net output #0: error_blob = 0.117596 (* 1 = 0.117596 loss)
I0929 23:13:21.258124 25332 solver.cpp:590] Iteration 3000, lr = 0.01
I0929 23:13:23.729928 25332 solver.cpp:243] Iteration 3100, loss = 0.116906
I0929 23:13:23.729969 25332 solver.cpp:259]     Train net output #0: error_blob = 0.116906 (* 1 = 0.116906 loss)
I0929 23:13:23.729974 25332 solver.cpp:590] Iteration 3100, lr = 0.01
I0929 23:13:26.191491 25332 solver.cpp:243] Iteration 3200, loss = 0.119201
I0929 23:13:26.191522 25332 solver.cpp:259]     Train net output #0: error_blob = 0.119201 (* 1 = 0.119201 loss)
I0929 23:13:26.191527 25332 solver.cpp:590] Iteration 3200, lr = 0.01
I0929 23:13:28.642040 25332 solver.cpp:243] Iteration 3300, loss = 0.117741
I0929 23:13:28.642079 25332 solver.cpp:259]     Train net output #0: error_blob = 0.117741 (* 1 = 0.117741 loss)
I0929 23:13:28.642084 25332 solver.cpp:590] Iteration 3300, lr = 0.01
I0929 23:13:31.114374 25332 solver.cpp:243] Iteration 3400, loss = 0.112449
I0929 23:13:31.114403 25332 solver.cpp:259]     Train net output #0: error_blob = 0.112449 (* 1 = 0.112449 loss)
I0929 23:13:31.114408 25332 solver.cpp:590] Iteration 3400, lr = 0.01
I0929 23:13:33.589792 25332 solver.cpp:243] Iteration 3500, loss = 0.11678
I0929 23:13:33.589823 25332 solver.cpp:259]     Train net output #0: error_blob = 0.11678 (* 1 = 0.11678 loss)
I0929 23:13:33.589828 25332 solver.cpp:590] Iteration 3500, lr = 0.01
I0929 23:13:36.071333 25332 solver.cpp:243] Iteration 3600, loss = 0.116093
I0929 23:13:36.071432 25332 solver.cpp:259]     Train net output #0: error_blob = 0.116093 (* 1 = 0.116093 loss)
I0929 23:13:36.071439 25332 solver.cpp:590] Iteration 3600, lr = 0.01
I0929 23:13:36.570236 25332 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:13:38.548502 25332 solver.cpp:243] Iteration 3700, loss = 0.113737
I0929 23:13:38.548532 25332 solver.cpp:259]     Train net output #0: error_blob = 0.113737 (* 1 = 0.113737 loss)
I0929 23:13:38.548537 25332 solver.cpp:590] Iteration 3700, lr = 0.01
I0929 23:13:40.993113 25332 solver.cpp:243] Iteration 3800, loss = 0.115724
I0929 23:13:40.993139 25332 solver.cpp:259]     Train net output #0: error_blob = 0.115724 (* 1 = 0.115724 loss)
I0929 23:13:40.993144 25332 solver.cpp:590] Iteration 3800, lr = 0.01
I0929 23:13:43.468658 25332 solver.cpp:243] Iteration 3900, loss = 0.118356
I0929 23:13:43.468688 25332 solver.cpp:259]     Train net output #0: error_blob = 0.118356 (* 1 = 0.118356 loss)
I0929 23:13:43.468694 25332 solver.cpp:590] Iteration 3900, lr = 0.01
I0929 23:13:45.940970 25332 solver.cpp:347] Iteration 4000, Testing net (#0)
I0929 23:13:46.284430 25332 solver.cpp:415]     Test net output #0: error_blob = 0.11993 (* 1 = 0.11993 loss)
I0929 23:13:46.285142 25332 solver.cpp:243] Iteration 4000, loss = 0.119656
I0929 23:13:46.285186 25332 solver.cpp:259]     Train net output #0: error_blob = 0.119656 (* 1 = 0.119656 loss)
I0929 23:13:46.285192 25332 solver.cpp:590] Iteration 4000, lr = 0.01
I0929 23:13:48.736721 25332 solver.cpp:243] Iteration 4100, loss = 0.118603
I0929 23:13:48.736752 25332 solver.cpp:259]     Train net output #0: error_blob = 0.118603 (* 1 = 0.118603 loss)
I0929 23:13:48.736757 25332 solver.cpp:590] Iteration 4100, lr = 0.01
I0929 23:13:51.196388 25332 solver.cpp:243] Iteration 4200, loss = 0.116386
I0929 23:13:51.196415 25332 solver.cpp:259]     Train net output #0: error_blob = 0.116386 (* 1 = 0.116386 loss)
I0929 23:13:51.196420 25332 solver.cpp:590] Iteration 4200, lr = 0.01
I0929 23:13:53.656893 25332 solver.cpp:243] Iteration 4300, loss = 0.11913
I0929 23:13:53.656934 25332 solver.cpp:259]     Train net output #0: error_blob = 0.11913 (* 1 = 0.11913 loss)
I0929 23:13:53.656939 25332 solver.cpp:590] Iteration 4300, lr = 0.01
I0929 23:13:56.185111 25332 solver.cpp:243] Iteration 4400, loss = 0.117754
I0929 23:13:56.185142 25332 solver.cpp:259]     Train net output #0: error_blob = 0.117754 (* 1 = 0.117754 loss)
I0929 23:13:56.185147 25332 solver.cpp:590] Iteration 4400, lr = 0.01
I0929 23:13:58.640179 25332 solver.cpp:243] Iteration 4500, loss = 0.119242
I0929 23:13:58.640218 25332 solver.cpp:259]     Train net output #0: error_blob = 0.119242 (* 1 = 0.119242 loss)
I0929 23:13:58.640223 25332 solver.cpp:590] Iteration 4500, lr = 0.01
I0929 23:13:59.282982 25332 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:14:01.129890 25332 solver.cpp:243] Iteration 4600, loss = 0.119623
I0929 23:14:01.129921 25332 solver.cpp:259]     Train net output #0: error_blob = 0.119623 (* 1 = 0.119623 loss)
I0929 23:14:01.129926 25332 solver.cpp:590] Iteration 4600, lr = 0.01
I0929 23:14:03.624197 25332 solver.cpp:243] Iteration 4700, loss = 0.115817
I0929 23:14:03.624228 25332 solver.cpp:259]     Train net output #0: error_blob = 0.115817 (* 1 = 0.115817 loss)
I0929 23:14:03.624234 25332 solver.cpp:590] Iteration 4700, lr = 0.01
I0929 23:14:06.090637 25332 solver.cpp:243] Iteration 4800, loss = 0.118429
I0929 23:14:06.090750 25332 solver.cpp:259]     Train net output #0: error_blob = 0.118429 (* 1 = 0.118429 loss)
I0929 23:14:06.090756 25332 solver.cpp:590] Iteration 4800, lr = 0.01
I0929 23:14:08.576936 25332 solver.cpp:243] Iteration 4900, loss = 0.115492
I0929 23:14:08.576977 25332 solver.cpp:259]     Train net output #0: error_blob = 0.115492 (* 1 = 0.115492 loss)
I0929 23:14:08.576982 25332 solver.cpp:590] Iteration 4900, lr = 0.01
I0929 23:14:11.023257 25332 solver.cpp:347] Iteration 5000, Testing net (#0)
I0929 23:14:11.361775 25332 solver.cpp:415]     Test net output #0: error_blob = 0.120205 (* 1 = 0.120205 loss)
I0929 23:14:11.362390 25332 solver.cpp:243] Iteration 5000, loss = 0.118404
I0929 23:14:11.362406 25332 solver.cpp:259]     Train net output #0: error_blob = 0.118404 (* 1 = 0.118404 loss)
I0929 23:14:11.362411 25332 solver.cpp:590] Iteration 5000, lr = 0.01
I0929 23:14:13.836031 25332 solver.cpp:243] Iteration 5100, loss = 0.117708
I0929 23:14:13.836061 25332 solver.cpp:259]     Train net output #0: error_blob = 0.117708 (* 1 = 0.117708 loss)
I0929 23:14:13.836066 25332 solver.cpp:590] Iteration 5100, lr = 0.01
I0929 23:14:16.306697 25332 solver.cpp:243] Iteration 5200, loss = 0.113288
I0929 23:14:16.306737 25332 solver.cpp:259]     Train net output #0: error_blob = 0.113288 (* 1 = 0.113288 loss)
I0929 23:14:16.306741 25332 solver.cpp:590] Iteration 5200, lr = 0.01
I0929 23:14:18.814270 25332 solver.cpp:243] Iteration 5300, loss = 0.119585
I0929 23:14:18.814297 25332 solver.cpp:259]     Train net output #0: error_blob = 0.119585 (* 1 = 0.119585 loss)
I0929 23:14:18.814302 25332 solver.cpp:590] Iteration 5300, lr = 0.01
I0929 23:14:21.293267 25332 solver.cpp:243] Iteration 5400, loss = 0.116348
I0929 23:14:21.293298 25332 solver.cpp:259]     Train net output #0: error_blob = 0.116348 (* 1 = 0.116348 loss)
I0929 23:14:21.293303 25332 solver.cpp:590] Iteration 5400, lr = 0.01
I0929 23:14:22.080046 25332 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:14:23.737879 25332 solver.cpp:243] Iteration 5500, loss = 0.115605
I0929 23:14:23.737910 25332 solver.cpp:259]     Train net output #0: error_blob = 0.115605 (* 1 = 0.115605 loss)
I0929 23:14:23.737915 25332 solver.cpp:590] Iteration 5500, lr = 0.01
I0929 23:14:26.203207 25332 solver.cpp:243] Iteration 5600, loss = 0.118882
I0929 23:14:26.203236 25332 solver.cpp:259]     Train net output #0: error_blob = 0.118882 (* 1 = 0.118882 loss)
I0929 23:14:26.203241 25332 solver.cpp:590] Iteration 5600, lr = 0.01
I0929 23:14:28.708319 25332 solver.cpp:243] Iteration 5700, loss = 0.114139
I0929 23:14:28.708351 25332 solver.cpp:259]     Train net output #0: error_blob = 0.114139 (* 1 = 0.114139 loss)
I0929 23:14:28.708356 25332 solver.cpp:590] Iteration 5700, lr = 0.01
I0929 23:14:31.165467 25332 solver.cpp:243] Iteration 5800, loss = 0.119476
I0929 23:14:31.165498 25332 solver.cpp:259]     Train net output #0: error_blob = 0.119476 (* 1 = 0.119476 loss)
I0929 23:14:31.165503 25332 solver.cpp:590] Iteration 5800, lr = 0.01
I0929 23:14:33.675292 25332 solver.cpp:243] Iteration 5900, loss = 0.11735
I0929 23:14:33.675323 25332 solver.cpp:259]     Train net output #0: error_blob = 0.11735 (* 1 = 0.11735 loss)
I0929 23:14:33.675328 25332 solver.cpp:590] Iteration 5900, lr = 0.01
I0929 23:14:36.105476 25332 solver.cpp:347] Iteration 6000, Testing net (#0)
I0929 23:14:36.447335 25332 solver.cpp:415]     Test net output #0: error_blob = 0.116177 (* 1 = 0.116177 loss)
I0929 23:14:36.447964 25332 solver.cpp:243] Iteration 6000, loss = 0.115844
I0929 23:14:36.447994 25332 solver.cpp:259]     Train net output #0: error_blob = 0.115844 (* 1 = 0.115844 loss)
I0929 23:14:36.447999 25332 solver.cpp:590] Iteration 6000, lr = 0.01
I0929 23:14:38.889587 25332 solver.cpp:243] Iteration 6100, loss = 0.118978
I0929 23:14:38.889627 25332 solver.cpp:259]     Train net output #0: error_blob = 0.118978 (* 1 = 0.118978 loss)
I0929 23:14:38.889632 25332 solver.cpp:590] Iteration 6100, lr = 0.01
I0929 23:14:41.321588 25332 solver.cpp:243] Iteration 6200, loss = 0.117364
I0929 23:14:41.321630 25332 solver.cpp:259]     Train net output #0: error_blob = 0.117364 (* 1 = 0.117364 loss)
I0929 23:14:41.321635 25332 solver.cpp:590] Iteration 6200, lr = 0.01
I0929 23:14:43.788799 25332 solver.cpp:243] Iteration 6300, loss = 0.120084
I0929 23:14:43.788828 25332 solver.cpp:259]     Train net output #0: error_blob = 0.120084 (* 1 = 0.120084 loss)
I0929 23:14:43.788833 25332 solver.cpp:590] Iteration 6300, lr = 0.01
I0929 23:14:44.730319 25332 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:14:46.258442 25332 solver.cpp:243] Iteration 6400, loss = 0.117397
I0929 23:14:46.258473 25332 solver.cpp:259]     Train net output #0: error_blob = 0.117397 (* 1 = 0.117397 loss)
I0929 23:14:46.258478 25332 solver.cpp:590] Iteration 6400, lr = 0.01
I0929 23:14:48.682571 25332 solver.cpp:243] Iteration 6500, loss = 0.11485
I0929 23:14:48.682613 25332 solver.cpp:259]     Train net output #0: error_blob = 0.11485 (* 1 = 0.11485 loss)
I0929 23:14:48.682618 25332 solver.cpp:590] Iteration 6500, lr = 0.01
I0929 23:14:51.138855 25332 solver.cpp:243] Iteration 6600, loss = 0.118836
I0929 23:14:51.138886 25332 solver.cpp:259]     Train net output #0: error_blob = 0.118836 (* 1 = 0.118836 loss)
I0929 23:14:51.138891 25332 solver.cpp:590] Iteration 6600, lr = 0.01
I0929 23:14:53.634371 25332 solver.cpp:243] Iteration 6700, loss = 0.113465
I0929 23:14:53.634412 25332 solver.cpp:259]     Train net output #0: error_blob = 0.113465 (* 1 = 0.113465 loss)
I0929 23:14:53.634418 25332 solver.cpp:590] Iteration 6700, lr = 0.01
I0929 23:14:56.101770 25332 solver.cpp:243] Iteration 6800, loss = 0.117824
I0929 23:14:56.101800 25332 solver.cpp:259]     Train net output #0: error_blob = 0.117824 (* 1 = 0.117824 loss)
I0929 23:14:56.101805 25332 solver.cpp:590] Iteration 6800, lr = 0.01
I0929 23:14:58.584774 25332 solver.cpp:243] Iteration 6900, loss = 0.11683
I0929 23:14:58.584815 25332 solver.cpp:259]     Train net output #0: error_blob = 0.11683 (* 1 = 0.11683 loss)
I0929 23:14:58.584820 25332 solver.cpp:590] Iteration 6900, lr = 0.01
I0929 23:15:01.054728 25332 solver.cpp:347] Iteration 7000, Testing net (#0)
I0929 23:15:01.374914 25332 solver.cpp:415]     Test net output #0: error_blob = 0.116945 (* 1 = 0.116945 loss)
I0929 23:15:01.375596 25332 solver.cpp:243] Iteration 7000, loss = 0.113776
I0929 23:15:01.375615 25332 solver.cpp:259]     Train net output #0: error_blob = 0.113776 (* 1 = 0.113776 loss)
I0929 23:15:01.375622 25332 solver.cpp:590] Iteration 7000, lr = 0.01
I0929 23:15:03.850716 25332 solver.cpp:243] Iteration 7100, loss = 0.117419
I0929 23:15:03.850761 25332 solver.cpp:259]     Train net output #0: error_blob = 0.117419 (* 1 = 0.117419 loss)
I0929 23:15:03.850769 25332 solver.cpp:590] Iteration 7100, lr = 0.01
I0929 23:15:06.345366 25332 solver.cpp:243] Iteration 7200, loss = 0.11265
I0929 23:15:06.345506 25332 solver.cpp:259]     Train net output #0: error_blob = 0.11265 (* 1 = 0.11265 loss)
I0929 23:15:06.345515 25332 solver.cpp:590] Iteration 7200, lr = 0.01
I0929 23:15:07.456517 25332 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:15:08.867933 25332 solver.cpp:243] Iteration 7300, loss = 0.117695
I0929 23:15:08.867976 25332 solver.cpp:259]     Train net output #0: error_blob = 0.117695 (* 1 = 0.117695 loss)
I0929 23:15:08.867983 25332 solver.cpp:590] Iteration 7300, lr = 0.01
I0929 23:15:11.358011 25332 solver.cpp:243] Iteration 7400, loss = 0.117709
I0929 23:15:11.358047 25332 solver.cpp:259]     Train net output #0: error_blob = 0.117709 (* 1 = 0.117709 loss)
I0929 23:15:11.358053 25332 solver.cpp:590] Iteration 7400, lr = 0.01
I0929 23:15:13.853883 25332 solver.cpp:243] Iteration 7500, loss = 0.112737
I0929 23:15:13.853921 25332 solver.cpp:259]     Train net output #0: error_blob = 0.112737 (* 1 = 0.112737 loss)
I0929 23:15:13.853927 25332 solver.cpp:590] Iteration 7500, lr = 0.01
I0929 23:15:16.340610 25332 solver.cpp:243] Iteration 7600, loss = 0.117715
I0929 23:15:16.340639 25332 solver.cpp:259]     Train net output #0: error_blob = 0.117715 (* 1 = 0.117715 loss)
I0929 23:15:16.340644 25332 solver.cpp:590] Iteration 7600, lr = 0.01
I0929 23:15:18.839488 25332 solver.cpp:243] Iteration 7700, loss = 0.114717
I0929 23:15:18.839516 25332 solver.cpp:259]     Train net output #0: error_blob = 0.114717 (* 1 = 0.114717 loss)
I0929 23:15:18.839521 25332 solver.cpp:590] Iteration 7700, lr = 0.01
I0929 23:15:21.287134 25332 solver.cpp:243] Iteration 7800, loss = 0.115818
I0929 23:15:21.287166 25332 solver.cpp:259]     Train net output #0: error_blob = 0.115818 (* 1 = 0.115818 loss)
I0929 23:15:21.287170 25332 solver.cpp:590] Iteration 7800, lr = 0.01
I0929 23:15:23.735460 25332 solver.cpp:243] Iteration 7900, loss = 0.117981
I0929 23:15:23.735492 25332 solver.cpp:259]     Train net output #0: error_blob = 0.117981 (* 1 = 0.117981 loss)
I0929 23:15:23.735498 25332 solver.cpp:590] Iteration 7900, lr = 0.01
I0929 23:15:26.170157 25332 solver.cpp:347] Iteration 8000, Testing net (#0)
I0929 23:15:26.469467 25332 solver.cpp:415]     Test net output #0: error_blob = 0.122775 (* 1 = 0.122775 loss)
I0929 23:15:26.470190 25332 solver.cpp:243] Iteration 8000, loss = 0.115124
I0929 23:15:26.470235 25332 solver.cpp:259]     Train net output #0: error_blob = 0.115124 (* 1 = 0.115124 loss)
I0929 23:15:26.470255 25332 solver.cpp:590] Iteration 8000, lr = 0.01
I0929 23:15:28.934252 25332 solver.cpp:243] Iteration 8100, loss = 0.11839
I0929 23:15:28.934290 25332 solver.cpp:259]     Train net output #0: error_blob = 0.11839 (* 1 = 0.11839 loss)
I0929 23:15:28.934299 25332 solver.cpp:590] Iteration 8100, lr = 0.01
I0929 23:15:30.165635 25332 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:15:31.422886 25332 solver.cpp:243] Iteration 8200, loss = 0.113401
I0929 23:15:31.422935 25332 solver.cpp:259]     Train net output #0: error_blob = 0.113401 (* 1 = 0.113401 loss)
I0929 23:15:31.422943 25332 solver.cpp:590] Iteration 8200, lr = 0.01
I0929 23:15:33.913655 25332 solver.cpp:243] Iteration 8300, loss = 0.115781
I0929 23:15:33.913696 25332 solver.cpp:259]     Train net output #0: error_blob = 0.115781 (* 1 = 0.115781 loss)
I0929 23:15:33.913702 25332 solver.cpp:590] Iteration 8300, lr = 0.01
I0929 23:15:36.426525 25332 solver.cpp:243] Iteration 8400, loss = 0.117963
I0929 23:15:36.427564 25332 solver.cpp:259]     Train net output #0: error_blob = 0.117963 (* 1 = 0.117963 loss)
I0929 23:15:36.427572 25332 solver.cpp:590] Iteration 8400, lr = 0.01
I0929 23:15:38.927486 25332 solver.cpp:243] Iteration 8500, loss = 0.112436
I0929 23:15:38.927522 25332 solver.cpp:259]     Train net output #0: error_blob = 0.112436 (* 1 = 0.112436 loss)
I0929 23:15:38.927531 25332 solver.cpp:590] Iteration 8500, lr = 0.01
I0929 23:15:41.433344 25332 solver.cpp:243] Iteration 8600, loss = 0.118508
I0929 23:15:41.433393 25332 solver.cpp:259]     Train net output #0: error_blob = 0.118508 (* 1 = 0.118508 loss)
I0929 23:15:41.433400 25332 solver.cpp:590] Iteration 8600, lr = 0.01
I0929 23:15:43.966464 25332 solver.cpp:243] Iteration 8700, loss = 0.114882
I0929 23:15:43.966501 25332 solver.cpp:259]     Train net output #0: error_blob = 0.114882 (* 1 = 0.114882 loss)
I0929 23:15:43.966516 25332 solver.cpp:590] Iteration 8700, lr = 0.01
I0929 23:15:46.501277 25332 solver.cpp:243] Iteration 8800, loss = 0.114329
I0929 23:15:46.501322 25332 solver.cpp:259]     Train net output #0: error_blob = 0.114329 (* 1 = 0.114329 loss)
I0929 23:15:46.501329 25332 solver.cpp:590] Iteration 8800, lr = 0.01
I0929 23:15:49.040307 25332 solver.cpp:243] Iteration 8900, loss = 0.117136
I0929 23:15:49.040350 25332 solver.cpp:259]     Train net output #0: error_blob = 0.117136 (* 1 = 0.117136 loss)
I0929 23:15:49.040357 25332 solver.cpp:590] Iteration 8900, lr = 0.01
I0929 23:15:51.550235 25332 solver.cpp:347] Iteration 9000, Testing net (#0)
I0929 23:15:51.830839 25332 solver.cpp:415]     Test net output #0: error_blob = 0.12107 (* 1 = 0.12107 loss)
I0929 23:15:51.831517 25332 solver.cpp:243] Iteration 9000, loss = 0.112435
I0929 23:15:51.831533 25332 solver.cpp:259]     Train net output #0: error_blob = 0.112435 (* 1 = 0.112435 loss)
I0929 23:15:51.831542 25332 solver.cpp:590] Iteration 9000, lr = 0.01
I0929 23:15:53.146811 25332 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:15:54.246186 25332 solver.cpp:243] Iteration 9100, loss = 0.117535
I0929 23:15:54.246224 25332 solver.cpp:259]     Train net output #0: error_blob = 0.117535 (* 1 = 0.117535 loss)
I0929 23:15:54.246232 25332 solver.cpp:590] Iteration 9100, lr = 0.01
I0929 23:15:56.722669 25332 solver.cpp:243] Iteration 9200, loss = 0.115981
I0929 23:15:56.722702 25332 solver.cpp:259]     Train net output #0: error_blob = 0.115981 (* 1 = 0.115981 loss)
I0929 23:15:56.722705 25332 solver.cpp:590] Iteration 9200, lr = 0.01
I0929 23:15:59.206332 25332 solver.cpp:243] Iteration 9300, loss = 0.113237
I0929 23:15:59.206362 25332 solver.cpp:259]     Train net output #0: error_blob = 0.113237 (* 1 = 0.113237 loss)
I0929 23:15:59.206367 25332 solver.cpp:590] Iteration 9300, lr = 0.01
I0929 23:16:01.696740 25332 solver.cpp:243] Iteration 9400, loss = 0.118416
I0929 23:16:01.696769 25332 solver.cpp:259]     Train net output #0: error_blob = 0.118416 (* 1 = 0.118416 loss)
I0929 23:16:01.696774 25332 solver.cpp:590] Iteration 9400, lr = 0.01
I0929 23:16:04.189273 25332 solver.cpp:243] Iteration 9500, loss = 0.117309
I0929 23:16:04.189304 25332 solver.cpp:259]     Train net output #0: error_blob = 0.117309 (* 1 = 0.117309 loss)
I0929 23:16:04.189309 25332 solver.cpp:590] Iteration 9500, lr = 0.01
I0929 23:16:06.679028 25332 solver.cpp:243] Iteration 9600, loss = 0.118325
I0929 23:16:06.679148 25332 solver.cpp:259]     Train net output #0: error_blob = 0.118325 (* 1 = 0.118325 loss)
I0929 23:16:06.679157 25332 solver.cpp:590] Iteration 9600, lr = 0.01
I0929 23:16:09.161824 25332 solver.cpp:243] Iteration 9700, loss = 0.118592
I0929 23:16:09.161871 25332 solver.cpp:259]     Train net output #0: error_blob = 0.118592 (* 1 = 0.118592 loss)
I0929 23:16:09.161880 25332 solver.cpp:590] Iteration 9700, lr = 0.01
I0929 23:16:11.693835 25332 solver.cpp:243] Iteration 9800, loss = 0.113297
I0929 23:16:11.693871 25332 solver.cpp:259]     Train net output #0: error_blob = 0.113297 (* 1 = 0.113297 loss)
I0929 23:16:11.693877 25332 solver.cpp:590] Iteration 9800, lr = 0.01
I0929 23:16:14.239066 25332 solver.cpp:243] Iteration 9900, loss = 0.118615
I0929 23:16:14.239102 25332 solver.cpp:259]     Train net output #0: error_blob = 0.118615 (* 1 = 0.118615 loss)
I0929 23:16:14.239109 25332 solver.cpp:590] Iteration 9900, lr = 0.01
I0929 23:16:16.748850 25332 solver.cpp:468] Snapshotting to binary proto file _iter_10000.caffemodel
I0929 23:16:16.749727 25332 solver.cpp:753] Snapshotting solver state to binary proto file _iter_10000.solverstate
I0929 23:16:16.774155 25332 solver.cpp:327] Iteration 10000, loss = 0.114611
I0929 23:16:16.774190 25332 solver.cpp:347] Iteration 10000, Testing net (#0)
I0929 23:16:16.963148 25332 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:16:17.073829 25332 solver.cpp:415]     Test net output #0: error_blob = 0.116506 (* 1 = 0.116506 loss)
I0929 23:16:17.073851 25332 solver.cpp:332] Optimization Done.
I0929 23:16:17.073855 25332 caffe.cpp:215] Optimization Done.
I0929 23:16:17.142546 25344 caffe.cpp:184] Using GPUs 0
I0929 23:16:17.699580 25344 solver.cpp:54] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "fixed"
momentum: 0.9
solver_mode: GPU
device_id: 0
net: "model/NNScore/nnscore_model_3.prototxt"
I0929 23:16:17.699611 25344 solver.cpp:97] Creating training net from net file: model/NNScore/nnscore_model_3.prototxt
I0929 23:16:17.699779 25344 net.cpp:339] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_layer
I0929 23:16:17.699826 25344 net.cpp:50] Initializing net from parameters: 
name: "model/NNScore/nnscore_model_3.prototxt"
state {
  phase: TRAIN
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TRAIN
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.3.train"
    batch_size: 20000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I0929 23:16:17.699901 25344 layer_factory.hpp:76] Creating layer data_layer
I0929 23:16:17.713155 25344 net.cpp:110] Creating Layer data_layer
I0929 23:16:17.713186 25344 net.cpp:433] data_layer -> data_blob
I0929 23:16:17.713218 25344 net.cpp:433] data_layer -> label_blob
I0929 23:16:17.713815 25348 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.3.train
I0929 23:16:18.397857 25344 data_layer.cpp:45] output data size: 20000,61,1,1
I0929 23:16:18.402825 25344 net.cpp:155] Setting up data_layer
I0929 23:16:18.402866 25344 net.cpp:163] Top shape: 20000 61 1 1 (1220000)
I0929 23:16:18.402870 25344 net.cpp:163] Top shape: 20000 (20000)
I0929 23:16:18.402876 25344 layer_factory.hpp:76] Creating layer hidden_sum_layer
I0929 23:16:18.402899 25344 net.cpp:110] Creating Layer hidden_sum_layer
I0929 23:16:18.402901 25344 net.cpp:477] hidden_sum_layer <- data_blob
I0929 23:16:18.402911 25344 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I0929 23:16:18.403291 25344 net.cpp:155] Setting up hidden_sum_layer
I0929 23:16:18.403298 25344 net.cpp:163] Top shape: 20000 10 (200000)
I0929 23:16:18.403321 25344 layer_factory.hpp:76] Creating layer hidden_act_layer
I0929 23:16:18.403337 25344 net.cpp:110] Creating Layer hidden_act_layer
I0929 23:16:18.403340 25344 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I0929 23:16:18.403343 25344 net.cpp:433] hidden_act_layer -> hidden_act_blob
I0929 23:16:21.629065 25344 net.cpp:155] Setting up hidden_act_layer
I0929 23:16:21.629101 25344 net.cpp:163] Top shape: 20000 10 (200000)
I0929 23:16:21.629106 25344 layer_factory.hpp:76] Creating layer output_sum_layer
I0929 23:16:21.629119 25344 net.cpp:110] Creating Layer output_sum_layer
I0929 23:16:21.629132 25344 net.cpp:477] output_sum_layer <- hidden_act_blob
I0929 23:16:21.629139 25344 net.cpp:433] output_sum_layer -> output_sum_blob
I0929 23:16:21.629258 25344 net.cpp:155] Setting up output_sum_layer
I0929 23:16:21.629264 25344 net.cpp:163] Top shape: 20000 1 (20000)
I0929 23:16:21.629286 25344 layer_factory.hpp:76] Creating layer output_act_layer
I0929 23:16:21.629299 25344 net.cpp:110] Creating Layer output_act_layer
I0929 23:16:21.629302 25344 net.cpp:477] output_act_layer <- output_sum_blob
I0929 23:16:21.629304 25344 net.cpp:433] output_act_layer -> output_act_blob
I0929 23:16:21.629384 25344 net.cpp:155] Setting up output_act_layer
I0929 23:16:21.629405 25344 net.cpp:163] Top shape: 20000 1 (20000)
I0929 23:16:21.629417 25344 layer_factory.hpp:76] Creating layer error_layer
I0929 23:16:21.629422 25344 net.cpp:110] Creating Layer error_layer
I0929 23:16:21.629425 25344 net.cpp:477] error_layer <- output_act_blob
I0929 23:16:21.629426 25344 net.cpp:477] error_layer <- label_blob
I0929 23:16:21.629441 25344 net.cpp:433] error_layer -> error_blob
I0929 23:16:21.629472 25344 net.cpp:155] Setting up error_layer
I0929 23:16:21.629475 25344 net.cpp:163] Top shape: (1)
I0929 23:16:21.629487 25344 net.cpp:168]     with loss weight 1
I0929 23:16:21.629511 25344 net.cpp:236] error_layer needs backward computation.
I0929 23:16:21.629523 25344 net.cpp:236] output_act_layer needs backward computation.
I0929 23:16:21.629524 25344 net.cpp:236] output_sum_layer needs backward computation.
I0929 23:16:21.629526 25344 net.cpp:236] hidden_act_layer needs backward computation.
I0929 23:16:21.629528 25344 net.cpp:236] hidden_sum_layer needs backward computation.
I0929 23:16:21.629530 25344 net.cpp:240] data_layer does not need backward computation.
I0929 23:16:21.629542 25344 net.cpp:283] This network produces output error_blob
I0929 23:16:21.629546 25344 net.cpp:297] Network initialization done.
I0929 23:16:21.629549 25344 net.cpp:298] Memory required for data: 6720004
I0929 23:16:21.629672 25344 solver.cpp:187] Creating test net (#0) specified by net file: model/NNScore/nnscore_model_3.prototxt
I0929 23:16:21.629701 25344 net.cpp:339] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_layer
I0929 23:16:21.629741 25344 net.cpp:50] Initializing net from parameters: 
name: "model/NNScore/nnscore_model_3.prototxt"
state {
  phase: TEST
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TEST
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.3.test"
    batch_size: 2000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I0929 23:16:21.629771 25344 layer_factory.hpp:76] Creating layer data_layer
I0929 23:16:21.631005 25344 net.cpp:110] Creating Layer data_layer
I0929 23:16:21.631019 25344 net.cpp:433] data_layer -> data_blob
I0929 23:16:21.631023 25344 net.cpp:433] data_layer -> label_blob
I0929 23:16:21.631557 25350 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.3.test
I0929 23:16:21.631619 25344 data_layer.cpp:45] output data size: 2000,61,1,1
I0929 23:16:21.633070 25344 net.cpp:155] Setting up data_layer
I0929 23:16:21.633092 25344 net.cpp:163] Top shape: 2000 61 1 1 (122000)
I0929 23:16:21.633095 25344 net.cpp:163] Top shape: 2000 (2000)
I0929 23:16:21.633098 25344 layer_factory.hpp:76] Creating layer hidden_sum_layer
I0929 23:16:21.633105 25344 net.cpp:110] Creating Layer hidden_sum_layer
I0929 23:16:21.633108 25344 net.cpp:477] hidden_sum_layer <- data_blob
I0929 23:16:21.633112 25344 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I0929 23:16:21.633214 25344 net.cpp:155] Setting up hidden_sum_layer
I0929 23:16:21.633219 25344 net.cpp:163] Top shape: 2000 10 (20000)
I0929 23:16:21.633226 25344 layer_factory.hpp:76] Creating layer hidden_act_layer
I0929 23:16:21.633240 25344 net.cpp:110] Creating Layer hidden_act_layer
I0929 23:16:21.633242 25344 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I0929 23:16:21.633256 25344 net.cpp:433] hidden_act_layer -> hidden_act_blob
I0929 23:16:21.633425 25344 net.cpp:155] Setting up hidden_act_layer
I0929 23:16:21.633431 25344 net.cpp:163] Top shape: 2000 10 (20000)
I0929 23:16:21.633435 25344 layer_factory.hpp:76] Creating layer output_sum_layer
I0929 23:16:21.633448 25344 net.cpp:110] Creating Layer output_sum_layer
I0929 23:16:21.633450 25344 net.cpp:477] output_sum_layer <- hidden_act_blob
I0929 23:16:21.633453 25344 net.cpp:433] output_sum_layer -> output_sum_blob
I0929 23:16:21.633517 25344 net.cpp:155] Setting up output_sum_layer
I0929 23:16:21.633522 25344 net.cpp:163] Top shape: 2000 1 (2000)
I0929 23:16:21.633527 25344 layer_factory.hpp:76] Creating layer output_act_layer
I0929 23:16:21.633540 25344 net.cpp:110] Creating Layer output_act_layer
I0929 23:16:21.633543 25344 net.cpp:477] output_act_layer <- output_sum_blob
I0929 23:16:21.633545 25344 net.cpp:433] output_act_layer -> output_act_blob
I0929 23:16:21.633599 25344 net.cpp:155] Setting up output_act_layer
I0929 23:16:21.633604 25344 net.cpp:163] Top shape: 2000 1 (2000)
I0929 23:16:21.633605 25344 layer_factory.hpp:76] Creating layer error_layer
I0929 23:16:21.633610 25344 net.cpp:110] Creating Layer error_layer
I0929 23:16:21.633620 25344 net.cpp:477] error_layer <- output_act_blob
I0929 23:16:21.633623 25344 net.cpp:477] error_layer <- label_blob
I0929 23:16:21.633625 25344 net.cpp:433] error_layer -> error_blob
I0929 23:16:21.633644 25344 net.cpp:155] Setting up error_layer
I0929 23:16:21.633647 25344 net.cpp:163] Top shape: (1)
I0929 23:16:21.633649 25344 net.cpp:168]     with loss weight 1
I0929 23:16:21.633664 25344 net.cpp:236] error_layer needs backward computation.
I0929 23:16:21.633667 25344 net.cpp:236] output_act_layer needs backward computation.
I0929 23:16:21.633669 25344 net.cpp:236] output_sum_layer needs backward computation.
I0929 23:16:21.633671 25344 net.cpp:236] hidden_act_layer needs backward computation.
I0929 23:16:21.633672 25344 net.cpp:236] hidden_sum_layer needs backward computation.
I0929 23:16:21.633684 25344 net.cpp:240] data_layer does not need backward computation.
I0929 23:16:21.633687 25344 net.cpp:283] This network produces output error_blob
I0929 23:16:21.633690 25344 net.cpp:297] Network initialization done.
I0929 23:16:21.633692 25344 net.cpp:298] Memory required for data: 672004
I0929 23:16:21.633712 25344 solver.cpp:66] Solver scaffolding done.
I0929 23:16:21.633805 25344 caffe.cpp:212] Starting Optimization
I0929 23:16:21.633811 25344 solver.cpp:294] Solving model/NNScore/nnscore_model_3.prototxt
I0929 23:16:21.633812 25344 solver.cpp:295] Learning Rate Policy: fixed
I0929 23:16:21.634011 25344 solver.cpp:347] Iteration 0, Testing net (#0)
I0929 23:16:21.634120 25344 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:16:21.877791 25344 solver.cpp:415]     Test net output #0: error_blob = 0.124442 (* 1 = 0.124442 loss)
I0929 23:16:21.879045 25344 solver.cpp:243] Iteration 0, loss = 0.125455
I0929 23:16:21.879068 25344 solver.cpp:259]     Train net output #0: error_blob = 0.125455 (* 1 = 0.125455 loss)
I0929 23:16:21.879078 25344 solver.cpp:590] Iteration 0, lr = 0.01
I0929 23:16:24.349663 25344 solver.cpp:243] Iteration 100, loss = 0.120152
I0929 23:16:24.349699 25344 solver.cpp:259]     Train net output #0: error_blob = 0.120152 (* 1 = 0.120152 loss)
I0929 23:16:24.349705 25344 solver.cpp:590] Iteration 100, lr = 0.01
I0929 23:16:26.834200 25344 solver.cpp:243] Iteration 200, loss = 0.12043
I0929 23:16:26.834241 25344 solver.cpp:259]     Train net output #0: error_blob = 0.12043 (* 1 = 0.12043 loss)
I0929 23:16:26.834246 25344 solver.cpp:590] Iteration 200, lr = 0.01
I0929 23:16:29.296875 25344 solver.cpp:243] Iteration 300, loss = 0.119851
I0929 23:16:29.296912 25344 solver.cpp:259]     Train net output #0: error_blob = 0.119851 (* 1 = 0.119851 loss)
I0929 23:16:29.296931 25344 solver.cpp:590] Iteration 300, lr = 0.01
I0929 23:16:31.715562 25344 solver.cpp:243] Iteration 400, loss = 0.119042
I0929 23:16:31.715625 25344 solver.cpp:259]     Train net output #0: error_blob = 0.119042 (* 1 = 0.119042 loss)
I0929 23:16:31.715631 25344 solver.cpp:590] Iteration 400, lr = 0.01
I0929 23:16:34.185277 25344 solver.cpp:243] Iteration 500, loss = 0.116933
I0929 23:16:34.185307 25344 solver.cpp:259]     Train net output #0: error_blob = 0.116933 (* 1 = 0.116933 loss)
I0929 23:16:34.185312 25344 solver.cpp:590] Iteration 500, lr = 0.01
I0929 23:16:36.644364 25344 solver.cpp:243] Iteration 600, loss = 0.119438
I0929 23:16:36.644407 25344 solver.cpp:259]     Train net output #0: error_blob = 0.119438 (* 1 = 0.119438 loss)
I0929 23:16:36.644412 25344 solver.cpp:590] Iteration 600, lr = 0.01
I0929 23:16:39.132586 25344 solver.cpp:243] Iteration 700, loss = 0.120095
I0929 23:16:39.132616 25344 solver.cpp:259]     Train net output #0: error_blob = 0.120095 (* 1 = 0.120095 loss)
I0929 23:16:39.132619 25344 solver.cpp:590] Iteration 700, lr = 0.01
I0929 23:16:41.581279 25344 solver.cpp:243] Iteration 800, loss = 0.116487
I0929 23:16:41.581326 25344 solver.cpp:259]     Train net output #0: error_blob = 0.116487 (* 1 = 0.116487 loss)
I0929 23:16:41.581333 25344 solver.cpp:590] Iteration 800, lr = 0.01
I0929 23:16:44.022125 25344 solver.cpp:243] Iteration 900, loss = 0.117814
I0929 23:16:44.022172 25344 solver.cpp:259]     Train net output #0: error_blob = 0.117814 (* 1 = 0.117814 loss)
I0929 23:16:44.022179 25344 solver.cpp:590] Iteration 900, lr = 0.01
I0929 23:16:44.072316 25344 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:16:46.438415 25344 solver.cpp:347] Iteration 1000, Testing net (#0)
I0929 23:16:46.726584 25344 solver.cpp:415]     Test net output #0: error_blob = 0.118596 (* 1 = 0.118596 loss)
I0929 23:16:46.727255 25344 solver.cpp:243] Iteration 1000, loss = 0.119104
I0929 23:16:46.727294 25344 solver.cpp:259]     Train net output #0: error_blob = 0.119104 (* 1 = 0.119104 loss)
I0929 23:16:46.727329 25344 solver.cpp:590] Iteration 1000, lr = 0.01
I0929 23:16:49.149783 25344 solver.cpp:243] Iteration 1100, loss = 0.11701
I0929 23:16:49.149909 25344 solver.cpp:259]     Train net output #0: error_blob = 0.11701 (* 1 = 0.11701 loss)
I0929 23:16:49.149915 25344 solver.cpp:590] Iteration 1100, lr = 0.01
I0929 23:16:51.612813 25344 solver.cpp:243] Iteration 1200, loss = 0.115407
I0929 23:16:51.612859 25344 solver.cpp:259]     Train net output #0: error_blob = 0.115407 (* 1 = 0.115407 loss)
I0929 23:16:51.612869 25344 solver.cpp:590] Iteration 1200, lr = 0.01
I0929 23:16:54.073892 25344 solver.cpp:243] Iteration 1300, loss = 0.118217
I0929 23:16:54.073923 25344 solver.cpp:259]     Train net output #0: error_blob = 0.118217 (* 1 = 0.118217 loss)
I0929 23:16:54.073928 25344 solver.cpp:590] Iteration 1300, lr = 0.01
I0929 23:16:56.564867 25344 solver.cpp:243] Iteration 1400, loss = 0.117754
I0929 23:16:56.564903 25344 solver.cpp:259]     Train net output #0: error_blob = 0.117754 (* 1 = 0.117754 loss)
I0929 23:16:56.564909 25344 solver.cpp:590] Iteration 1400, lr = 0.01
I0929 23:16:59.066289 25344 solver.cpp:243] Iteration 1500, loss = 0.119361
I0929 23:16:59.066329 25344 solver.cpp:259]     Train net output #0: error_blob = 0.119361 (* 1 = 0.119361 loss)
I0929 23:16:59.066337 25344 solver.cpp:590] Iteration 1500, lr = 0.01
I0929 23:17:01.495810 25344 solver.cpp:243] Iteration 1600, loss = 0.119484
I0929 23:17:01.495856 25344 solver.cpp:259]     Train net output #0: error_blob = 0.119484 (* 1 = 0.119484 loss)
I0929 23:17:01.495862 25344 solver.cpp:590] Iteration 1600, lr = 0.01
I0929 23:17:03.938299 25344 solver.cpp:243] Iteration 1700, loss = 0.1182
I0929 23:17:03.938339 25344 solver.cpp:259]     Train net output #0: error_blob = 0.1182 (* 1 = 0.1182 loss)
I0929 23:17:03.938344 25344 solver.cpp:590] Iteration 1700, lr = 0.01
I0929 23:17:06.414690 25344 solver.cpp:243] Iteration 1800, loss = 0.118366
I0929 23:17:06.414729 25344 solver.cpp:259]     Train net output #0: error_blob = 0.118366 (* 1 = 0.118366 loss)
I0929 23:17:06.414734 25344 solver.cpp:590] Iteration 1800, lr = 0.01
I0929 23:17:06.605959 25344 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:17:08.898929 25344 solver.cpp:243] Iteration 1900, loss = 0.115488
I0929 23:17:08.898964 25344 solver.cpp:259]     Train net output #0: error_blob = 0.115488 (* 1 = 0.115488 loss)
I0929 23:17:08.898972 25344 solver.cpp:590] Iteration 1900, lr = 0.01
I0929 23:17:11.372313 25344 solver.cpp:347] Iteration 2000, Testing net (#0)
I0929 23:17:11.644985 25344 solver.cpp:415]     Test net output #0: error_blob = 0.113899 (* 1 = 0.113899 loss)
I0929 23:17:11.645676 25344 solver.cpp:243] Iteration 2000, loss = 0.118447
I0929 23:17:11.645690 25344 solver.cpp:259]     Train net output #0: error_blob = 0.118447 (* 1 = 0.118447 loss)
I0929 23:17:11.645705 25344 solver.cpp:590] Iteration 2000, lr = 0.01
I0929 23:17:14.104589 25344 solver.cpp:243] Iteration 2100, loss = 0.117273
I0929 23:17:14.104619 25344 solver.cpp:259]     Train net output #0: error_blob = 0.117273 (* 1 = 0.117273 loss)
I0929 23:17:14.104624 25344 solver.cpp:590] Iteration 2100, lr = 0.01
I0929 23:17:16.539079 25344 solver.cpp:243] Iteration 2200, loss = 0.117331
I0929 23:17:16.539125 25344 solver.cpp:259]     Train net output #0: error_blob = 0.117331 (* 1 = 0.117331 loss)
I0929 23:17:16.539132 25344 solver.cpp:590] Iteration 2200, lr = 0.01
I0929 23:17:18.982074 25344 solver.cpp:243] Iteration 2300, loss = 0.117656
I0929 23:17:18.982115 25344 solver.cpp:259]     Train net output #0: error_blob = 0.117656 (* 1 = 0.117656 loss)
I0929 23:17:18.982120 25344 solver.cpp:590] Iteration 2300, lr = 0.01
I0929 23:17:21.438756 25344 solver.cpp:243] Iteration 2400, loss = 0.118384
I0929 23:17:21.438858 25344 solver.cpp:259]     Train net output #0: error_blob = 0.118384 (* 1 = 0.118384 loss)
I0929 23:17:21.438863 25344 solver.cpp:590] Iteration 2400, lr = 0.01
I0929 23:17:23.905813 25344 solver.cpp:243] Iteration 2500, loss = 0.115403
I0929 23:17:23.905843 25344 solver.cpp:259]     Train net output #0: error_blob = 0.115403 (* 1 = 0.115403 loss)
I0929 23:17:23.905848 25344 solver.cpp:590] Iteration 2500, lr = 0.01
I0929 23:17:26.363131 25344 solver.cpp:243] Iteration 2600, loss = 0.116772
I0929 23:17:26.363173 25344 solver.cpp:259]     Train net output #0: error_blob = 0.116772 (* 1 = 0.116772 loss)
I0929 23:17:26.363178 25344 solver.cpp:590] Iteration 2600, lr = 0.01
I0929 23:17:28.842628 25344 solver.cpp:243] Iteration 2700, loss = 0.11738
I0929 23:17:28.842658 25344 solver.cpp:259]     Train net output #0: error_blob = 0.11738 (* 1 = 0.11738 loss)
I0929 23:17:28.842663 25344 solver.cpp:590] Iteration 2700, lr = 0.01
I0929 23:17:29.187450 25344 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:17:31.292453 25344 solver.cpp:243] Iteration 2800, loss = 0.115494
I0929 23:17:31.292505 25344 solver.cpp:259]     Train net output #0: error_blob = 0.115494 (* 1 = 0.115494 loss)
I0929 23:17:31.292510 25344 solver.cpp:590] Iteration 2800, lr = 0.01
I0929 23:17:33.747076 25344 solver.cpp:243] Iteration 2900, loss = 0.114335
I0929 23:17:33.747112 25344 solver.cpp:259]     Train net output #0: error_blob = 0.114335 (* 1 = 0.114335 loss)
I0929 23:17:33.747117 25344 solver.cpp:590] Iteration 2900, lr = 0.01
I0929 23:17:36.219949 25344 solver.cpp:347] Iteration 3000, Testing net (#0)
I0929 23:17:36.529793 25344 solver.cpp:415]     Test net output #0: error_blob = 0.110804 (* 1 = 0.110804 loss)
I0929 23:17:36.530405 25344 solver.cpp:243] Iteration 3000, loss = 0.11843
I0929 23:17:36.530416 25344 solver.cpp:259]     Train net output #0: error_blob = 0.11843 (* 1 = 0.11843 loss)
I0929 23:17:36.530421 25344 solver.cpp:590] Iteration 3000, lr = 0.01
I0929 23:17:38.978263 25344 solver.cpp:243] Iteration 3100, loss = 0.118262
I0929 23:17:38.978301 25344 solver.cpp:259]     Train net output #0: error_blob = 0.118262 (* 1 = 0.118262 loss)
I0929 23:17:38.978307 25344 solver.cpp:590] Iteration 3100, lr = 0.01
I0929 23:17:41.434609 25344 solver.cpp:243] Iteration 3200, loss = 0.113726
I0929 23:17:41.434656 25344 solver.cpp:259]     Train net output #0: error_blob = 0.113726 (* 1 = 0.113726 loss)
I0929 23:17:41.434665 25344 solver.cpp:590] Iteration 3200, lr = 0.01
I0929 23:17:43.898377 25344 solver.cpp:243] Iteration 3300, loss = 0.116487
I0929 23:17:43.898408 25344 solver.cpp:259]     Train net output #0: error_blob = 0.116487 (* 1 = 0.116487 loss)
I0929 23:17:43.898412 25344 solver.cpp:590] Iteration 3300, lr = 0.01
I0929 23:17:46.365381 25344 solver.cpp:243] Iteration 3400, loss = 0.117574
I0929 23:17:46.365418 25344 solver.cpp:259]     Train net output #0: error_blob = 0.117574 (* 1 = 0.117574 loss)
I0929 23:17:46.365427 25344 solver.cpp:590] Iteration 3400, lr = 0.01
I0929 23:17:48.827453 25344 solver.cpp:243] Iteration 3500, loss = 0.114789
I0929 23:17:48.827499 25344 solver.cpp:259]     Train net output #0: error_blob = 0.114789 (* 1 = 0.114789 loss)
I0929 23:17:48.827507 25344 solver.cpp:590] Iteration 3500, lr = 0.01
I0929 23:17:51.279661 25344 solver.cpp:243] Iteration 3600, loss = 0.114477
I0929 23:17:51.279708 25344 solver.cpp:259]     Train net output #0: error_blob = 0.114477 (* 1 = 0.114477 loss)
I0929 23:17:51.279716 25344 solver.cpp:590] Iteration 3600, lr = 0.01
I0929 23:17:51.774019 25344 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:17:53.743244 25344 solver.cpp:243] Iteration 3700, loss = 0.118302
I0929 23:17:53.743275 25344 solver.cpp:259]     Train net output #0: error_blob = 0.118302 (* 1 = 0.118302 loss)
I0929 23:17:53.743279 25344 solver.cpp:590] Iteration 3700, lr = 0.01
I0929 23:17:56.200553 25344 solver.cpp:243] Iteration 3800, loss = 0.121476
I0929 23:17:56.200582 25344 solver.cpp:259]     Train net output #0: error_blob = 0.121476 (* 1 = 0.121476 loss)
I0929 23:17:56.200585 25344 solver.cpp:590] Iteration 3800, lr = 0.01
I0929 23:17:58.691426 25344 solver.cpp:243] Iteration 3900, loss = 0.115117
I0929 23:17:58.691454 25344 solver.cpp:259]     Train net output #0: error_blob = 0.115117 (* 1 = 0.115117 loss)
I0929 23:17:58.691458 25344 solver.cpp:590] Iteration 3900, lr = 0.01
I0929 23:18:01.152793 25344 solver.cpp:347] Iteration 4000, Testing net (#0)
I0929 23:18:01.425308 25344 solver.cpp:415]     Test net output #0: error_blob = 0.10971 (* 1 = 0.10971 loss)
I0929 23:18:01.425966 25344 solver.cpp:243] Iteration 4000, loss = 0.118253
I0929 23:18:01.425984 25344 solver.cpp:259]     Train net output #0: error_blob = 0.118253 (* 1 = 0.118253 loss)
I0929 23:18:01.425990 25344 solver.cpp:590] Iteration 4000, lr = 0.01
I0929 23:18:03.875720 25344 solver.cpp:243] Iteration 4100, loss = 0.117972
I0929 23:18:03.875751 25344 solver.cpp:259]     Train net output #0: error_blob = 0.117972 (* 1 = 0.117972 loss)
I0929 23:18:03.875756 25344 solver.cpp:590] Iteration 4100, lr = 0.01
I0929 23:18:06.355612 25344 solver.cpp:243] Iteration 4200, loss = 0.11312
I0929 23:18:06.355641 25344 solver.cpp:259]     Train net output #0: error_blob = 0.11312 (* 1 = 0.11312 loss)
I0929 23:18:06.355646 25344 solver.cpp:590] Iteration 4200, lr = 0.01
I0929 23:18:08.832775 25344 solver.cpp:243] Iteration 4300, loss = 0.113442
I0929 23:18:08.832805 25344 solver.cpp:259]     Train net output #0: error_blob = 0.113442 (* 1 = 0.113442 loss)
I0929 23:18:08.832809 25344 solver.cpp:590] Iteration 4300, lr = 0.01
I0929 23:18:11.303221 25344 solver.cpp:243] Iteration 4400, loss = 0.117338
I0929 23:18:11.303252 25344 solver.cpp:259]     Train net output #0: error_blob = 0.117338 (* 1 = 0.117338 loss)
I0929 23:18:11.303257 25344 solver.cpp:590] Iteration 4400, lr = 0.01
I0929 23:18:13.745484 25344 solver.cpp:243] Iteration 4500, loss = 0.116995
I0929 23:18:13.745514 25344 solver.cpp:259]     Train net output #0: error_blob = 0.116995 (* 1 = 0.116995 loss)
I0929 23:18:13.745519 25344 solver.cpp:590] Iteration 4500, lr = 0.01
I0929 23:18:14.379932 25344 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:18:16.209007 25344 solver.cpp:243] Iteration 4600, loss = 0.114303
I0929 23:18:16.209048 25344 solver.cpp:259]     Train net output #0: error_blob = 0.114303 (* 1 = 0.114303 loss)
I0929 23:18:16.209053 25344 solver.cpp:590] Iteration 4600, lr = 0.01
I0929 23:18:18.667346 25344 solver.cpp:243] Iteration 4700, loss = 0.115794
I0929 23:18:18.667383 25344 solver.cpp:259]     Train net output #0: error_blob = 0.115794 (* 1 = 0.115794 loss)
I0929 23:18:18.667392 25344 solver.cpp:590] Iteration 4700, lr = 0.01
I0929 23:18:21.182242 25344 solver.cpp:243] Iteration 4800, loss = 0.116139
I0929 23:18:21.182279 25344 solver.cpp:259]     Train net output #0: error_blob = 0.116139 (* 1 = 0.116139 loss)
I0929 23:18:21.182286 25344 solver.cpp:590] Iteration 4800, lr = 0.01
I0929 23:18:23.681545 25344 solver.cpp:243] Iteration 4900, loss = 0.118341
I0929 23:18:23.681689 25344 solver.cpp:259]     Train net output #0: error_blob = 0.118341 (* 1 = 0.118341 loss)
I0929 23:18:23.681697 25344 solver.cpp:590] Iteration 4900, lr = 0.01
I0929 23:18:26.108232 25344 solver.cpp:347] Iteration 5000, Testing net (#0)
I0929 23:18:26.384730 25344 solver.cpp:415]     Test net output #0: error_blob = 0.109221 (* 1 = 0.109221 loss)
I0929 23:18:26.385396 25344 solver.cpp:243] Iteration 5000, loss = 0.117314
I0929 23:18:26.385409 25344 solver.cpp:259]     Train net output #0: error_blob = 0.117314 (* 1 = 0.117314 loss)
I0929 23:18:26.385426 25344 solver.cpp:590] Iteration 5000, lr = 0.01
I0929 23:18:28.813019 25344 solver.cpp:243] Iteration 5100, loss = 0.116703
I0929 23:18:28.813060 25344 solver.cpp:259]     Train net output #0: error_blob = 0.116703 (* 1 = 0.116703 loss)
I0929 23:18:28.813065 25344 solver.cpp:590] Iteration 5100, lr = 0.01
I0929 23:18:31.300860 25344 solver.cpp:243] Iteration 5200, loss = 0.11472
I0929 23:18:31.300889 25344 solver.cpp:259]     Train net output #0: error_blob = 0.11472 (* 1 = 0.11472 loss)
I0929 23:18:31.300894 25344 solver.cpp:590] Iteration 5200, lr = 0.01
I0929 23:18:33.790212 25344 solver.cpp:243] Iteration 5300, loss = 0.113952
I0929 23:18:33.790241 25344 solver.cpp:259]     Train net output #0: error_blob = 0.113952 (* 1 = 0.113952 loss)
I0929 23:18:33.790247 25344 solver.cpp:590] Iteration 5300, lr = 0.01
I0929 23:18:36.238324 25344 solver.cpp:243] Iteration 5400, loss = 0.11715
I0929 23:18:36.238365 25344 solver.cpp:259]     Train net output #0: error_blob = 0.11715 (* 1 = 0.11715 loss)
I0929 23:18:36.238371 25344 solver.cpp:590] Iteration 5400, lr = 0.01
I0929 23:18:37.022387 25344 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:18:38.743664 25344 solver.cpp:243] Iteration 5500, loss = 0.116526
I0929 23:18:38.743695 25344 solver.cpp:259]     Train net output #0: error_blob = 0.116526 (* 1 = 0.116526 loss)
I0929 23:18:38.743700 25344 solver.cpp:590] Iteration 5500, lr = 0.01
I0929 23:18:41.220983 25344 solver.cpp:243] Iteration 5600, loss = 0.113529
I0929 23:18:41.221021 25344 solver.cpp:259]     Train net output #0: error_blob = 0.113529 (* 1 = 0.113529 loss)
I0929 23:18:41.221026 25344 solver.cpp:590] Iteration 5600, lr = 0.01
I0929 23:18:43.679436 25344 solver.cpp:243] Iteration 5700, loss = 0.114342
I0929 23:18:43.679467 25344 solver.cpp:259]     Train net output #0: error_blob = 0.114342 (* 1 = 0.114342 loss)
I0929 23:18:43.679472 25344 solver.cpp:590] Iteration 5700, lr = 0.01
I0929 23:18:46.130704 25344 solver.cpp:243] Iteration 5800, loss = 0.117476
I0929 23:18:46.130746 25344 solver.cpp:259]     Train net output #0: error_blob = 0.117476 (* 1 = 0.117476 loss)
I0929 23:18:46.130753 25344 solver.cpp:590] Iteration 5800, lr = 0.01
I0929 23:18:48.606425 25344 solver.cpp:243] Iteration 5900, loss = 0.115238
I0929 23:18:48.606465 25344 solver.cpp:259]     Train net output #0: error_blob = 0.115238 (* 1 = 0.115238 loss)
I0929 23:18:48.606472 25344 solver.cpp:590] Iteration 5900, lr = 0.01
I0929 23:18:51.090257 25344 solver.cpp:347] Iteration 6000, Testing net (#0)
I0929 23:18:51.366376 25344 solver.cpp:415]     Test net output #0: error_blob = 0.111389 (* 1 = 0.111389 loss)
I0929 23:18:51.367058 25344 solver.cpp:243] Iteration 6000, loss = 0.112643
I0929 23:18:51.367095 25344 solver.cpp:259]     Train net output #0: error_blob = 0.112643 (* 1 = 0.112643 loss)
I0929 23:18:51.367113 25344 solver.cpp:590] Iteration 6000, lr = 0.01
I0929 23:18:53.767701 25344 solver.cpp:243] Iteration 6100, loss = 0.11604
I0929 23:18:53.767817 25344 solver.cpp:259]     Train net output #0: error_blob = 0.11604 (* 1 = 0.11604 loss)
I0929 23:18:53.767822 25344 solver.cpp:590] Iteration 6100, lr = 0.01
I0929 23:18:56.245446 25344 solver.cpp:243] Iteration 6200, loss = 0.116572
I0929 23:18:56.245477 25344 solver.cpp:259]     Train net output #0: error_blob = 0.116572 (* 1 = 0.116572 loss)
I0929 23:18:56.245482 25344 solver.cpp:590] Iteration 6200, lr = 0.01
I0929 23:18:58.716063 25344 solver.cpp:243] Iteration 6300, loss = 0.125461
I0929 23:18:58.716114 25344 solver.cpp:259]     Train net output #0: error_blob = 0.125461 (* 1 = 0.125461 loss)
I0929 23:18:58.716120 25344 solver.cpp:590] Iteration 6300, lr = 0.01
I0929 23:18:59.645311 25344 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:19:01.168647 25344 solver.cpp:243] Iteration 6400, loss = 0.115726
I0929 23:19:01.168676 25344 solver.cpp:259]     Train net output #0: error_blob = 0.115726 (* 1 = 0.115726 loss)
I0929 23:19:01.168680 25344 solver.cpp:590] Iteration 6400, lr = 0.01
I0929 23:19:03.633359 25344 solver.cpp:243] Iteration 6500, loss = 0.117633
I0929 23:19:03.633389 25344 solver.cpp:259]     Train net output #0: error_blob = 0.117633 (* 1 = 0.117633 loss)
I0929 23:19:03.633394 25344 solver.cpp:590] Iteration 6500, lr = 0.01
I0929 23:19:06.126869 25344 solver.cpp:243] Iteration 6600, loss = 0.111969
I0929 23:19:06.126899 25344 solver.cpp:259]     Train net output #0: error_blob = 0.111969 (* 1 = 0.111969 loss)
I0929 23:19:06.126904 25344 solver.cpp:590] Iteration 6600, lr = 0.01
I0929 23:19:08.605563 25344 solver.cpp:243] Iteration 6700, loss = 0.115192
I0929 23:19:08.605599 25344 solver.cpp:259]     Train net output #0: error_blob = 0.115192 (* 1 = 0.115192 loss)
I0929 23:19:08.605605 25344 solver.cpp:590] Iteration 6700, lr = 0.01
I0929 23:19:11.058456 25344 solver.cpp:243] Iteration 6800, loss = 0.115561
I0929 23:19:11.058485 25344 solver.cpp:259]     Train net output #0: error_blob = 0.115561 (* 1 = 0.115561 loss)
I0929 23:19:11.058490 25344 solver.cpp:590] Iteration 6800, lr = 0.01
I0929 23:19:13.523988 25344 solver.cpp:243] Iteration 6900, loss = 0.114224
I0929 23:19:13.524025 25344 solver.cpp:259]     Train net output #0: error_blob = 0.114224 (* 1 = 0.114224 loss)
I0929 23:19:13.524032 25344 solver.cpp:590] Iteration 6900, lr = 0.01
I0929 23:19:15.965303 25344 solver.cpp:347] Iteration 7000, Testing net (#0)
I0929 23:19:16.240452 25344 solver.cpp:415]     Test net output #0: error_blob = 0.110956 (* 1 = 0.110956 loss)
I0929 23:19:16.241132 25344 solver.cpp:243] Iteration 7000, loss = 0.111576
I0929 23:19:16.241158 25344 solver.cpp:259]     Train net output #0: error_blob = 0.111576 (* 1 = 0.111576 loss)
I0929 23:19:16.241164 25344 solver.cpp:590] Iteration 7000, lr = 0.01
I0929 23:19:18.657758 25344 solver.cpp:243] Iteration 7100, loss = 0.117426
I0929 23:19:18.657807 25344 solver.cpp:259]     Train net output #0: error_blob = 0.117426 (* 1 = 0.117426 loss)
I0929 23:19:18.657814 25344 solver.cpp:590] Iteration 7100, lr = 0.01
I0929 23:19:21.111428 25344 solver.cpp:243] Iteration 7200, loss = 0.116898
I0929 23:19:21.111464 25344 solver.cpp:259]     Train net output #0: error_blob = 0.116898 (* 1 = 0.116898 loss)
I0929 23:19:21.111471 25344 solver.cpp:590] Iteration 7200, lr = 0.01
I0929 23:19:22.210889 25344 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:19:23.609940 25344 solver.cpp:243] Iteration 7300, loss = 0.112151
I0929 23:19:23.609985 25344 solver.cpp:259]     Train net output #0: error_blob = 0.112151 (* 1 = 0.112151 loss)
I0929 23:19:23.609992 25344 solver.cpp:590] Iteration 7300, lr = 0.01
I0929 23:19:26.101889 25344 solver.cpp:243] Iteration 7400, loss = 0.11871
I0929 23:19:26.101986 25344 solver.cpp:259]     Train net output #0: error_blob = 0.11871 (* 1 = 0.11871 loss)
I0929 23:19:26.102002 25344 solver.cpp:590] Iteration 7400, lr = 0.01
I0929 23:19:28.594200 25344 solver.cpp:243] Iteration 7500, loss = 0.117235
I0929 23:19:28.594234 25344 solver.cpp:259]     Train net output #0: error_blob = 0.117235 (* 1 = 0.117235 loss)
I0929 23:19:28.594240 25344 solver.cpp:590] Iteration 7500, lr = 0.01
I0929 23:19:31.060138 25344 solver.cpp:243] Iteration 7600, loss = 0.112218
I0929 23:19:31.060174 25344 solver.cpp:259]     Train net output #0: error_blob = 0.112218 (* 1 = 0.112218 loss)
I0929 23:19:31.060180 25344 solver.cpp:590] Iteration 7600, lr = 0.01
I0929 23:19:33.559144 25344 solver.cpp:243] Iteration 7700, loss = 0.114128
I0929 23:19:33.559178 25344 solver.cpp:259]     Train net output #0: error_blob = 0.114128 (* 1 = 0.114128 loss)
I0929 23:19:33.559186 25344 solver.cpp:590] Iteration 7700, lr = 0.01
I0929 23:19:36.037122 25344 solver.cpp:243] Iteration 7800, loss = 0.118655
I0929 23:19:36.037155 25344 solver.cpp:259]     Train net output #0: error_blob = 0.118655 (* 1 = 0.118655 loss)
I0929 23:19:36.037163 25344 solver.cpp:590] Iteration 7800, lr = 0.01
I0929 23:19:38.517292 25344 solver.cpp:243] Iteration 7900, loss = 0.115998
I0929 23:19:38.517331 25344 solver.cpp:259]     Train net output #0: error_blob = 0.115998 (* 1 = 0.115998 loss)
I0929 23:19:38.517335 25344 solver.cpp:590] Iteration 7900, lr = 0.01
I0929 23:19:40.947952 25344 solver.cpp:347] Iteration 8000, Testing net (#0)
I0929 23:19:41.223364 25344 solver.cpp:415]     Test net output #0: error_blob = 0.109983 (* 1 = 0.109983 loss)
I0929 23:19:41.224081 25344 solver.cpp:243] Iteration 8000, loss = 0.109819
I0929 23:19:41.224097 25344 solver.cpp:259]     Train net output #0: error_blob = 0.109819 (* 1 = 0.109819 loss)
I0929 23:19:41.224104 25344 solver.cpp:590] Iteration 8000, lr = 0.01
I0929 23:19:43.663429 25344 solver.cpp:243] Iteration 8100, loss = 0.115115
I0929 23:19:43.663460 25344 solver.cpp:259]     Train net output #0: error_blob = 0.115115 (* 1 = 0.115115 loss)
I0929 23:19:43.663465 25344 solver.cpp:590] Iteration 8100, lr = 0.01
I0929 23:19:44.879990 25344 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:19:46.113049 25344 solver.cpp:243] Iteration 8200, loss = 0.116614
I0929 23:19:46.113087 25344 solver.cpp:259]     Train net output #0: error_blob = 0.116614 (* 1 = 0.116614 loss)
I0929 23:19:46.113095 25344 solver.cpp:590] Iteration 8200, lr = 0.01
I0929 23:19:48.588807 25344 solver.cpp:243] Iteration 8300, loss = 0.112755
I0929 23:19:48.588855 25344 solver.cpp:259]     Train net output #0: error_blob = 0.112755 (* 1 = 0.112755 loss)
I0929 23:19:48.588861 25344 solver.cpp:590] Iteration 8300, lr = 0.01
I0929 23:19:51.085255 25344 solver.cpp:243] Iteration 8400, loss = 0.113436
I0929 23:19:51.085295 25344 solver.cpp:259]     Train net output #0: error_blob = 0.113436 (* 1 = 0.113436 loss)
I0929 23:19:51.085301 25344 solver.cpp:590] Iteration 8400, lr = 0.01
I0929 23:19:53.531240 25344 solver.cpp:243] Iteration 8500, loss = 0.116571
I0929 23:19:53.531287 25344 solver.cpp:259]     Train net output #0: error_blob = 0.116571 (* 1 = 0.116571 loss)
I0929 23:19:53.531296 25344 solver.cpp:590] Iteration 8500, lr = 0.01
I0929 23:19:55.984455 25344 solver.cpp:243] Iteration 8600, loss = 0.117218
I0929 23:19:55.984518 25344 solver.cpp:259]     Train net output #0: error_blob = 0.117218 (* 1 = 0.117218 loss)
I0929 23:19:55.984525 25344 solver.cpp:590] Iteration 8600, lr = 0.01
I0929 23:19:58.445333 25344 solver.cpp:243] Iteration 8700, loss = 0.111192
I0929 23:19:58.445458 25344 solver.cpp:259]     Train net output #0: error_blob = 0.111192 (* 1 = 0.111192 loss)
I0929 23:19:58.445477 25344 solver.cpp:590] Iteration 8700, lr = 0.01
I0929 23:20:00.911145 25344 solver.cpp:243] Iteration 8800, loss = 0.115511
I0929 23:20:00.911176 25344 solver.cpp:259]     Train net output #0: error_blob = 0.115511 (* 1 = 0.115511 loss)
I0929 23:20:00.911180 25344 solver.cpp:590] Iteration 8800, lr = 0.01
I0929 23:20:03.380240 25344 solver.cpp:243] Iteration 8900, loss = 0.116518
I0929 23:20:03.380280 25344 solver.cpp:259]     Train net output #0: error_blob = 0.116518 (* 1 = 0.116518 loss)
I0929 23:20:03.380286 25344 solver.cpp:590] Iteration 8900, lr = 0.01
I0929 23:20:05.845052 25344 solver.cpp:347] Iteration 9000, Testing net (#0)
I0929 23:20:06.116597 25344 solver.cpp:415]     Test net output #0: error_blob = 0.109326 (* 1 = 0.109326 loss)
I0929 23:20:06.117281 25344 solver.cpp:243] Iteration 9000, loss = 0.11343
I0929 23:20:06.117295 25344 solver.cpp:259]     Train net output #0: error_blob = 0.11343 (* 1 = 0.11343 loss)
I0929 23:20:06.117313 25344 solver.cpp:590] Iteration 9000, lr = 0.01
I0929 23:20:07.463800 25344 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:20:08.541726 25344 solver.cpp:243] Iteration 9100, loss = 0.114802
I0929 23:20:08.541771 25344 solver.cpp:259]     Train net output #0: error_blob = 0.114802 (* 1 = 0.114802 loss)
I0929 23:20:08.541779 25344 solver.cpp:590] Iteration 9100, lr = 0.01
I0929 23:20:10.995929 25344 solver.cpp:243] Iteration 9200, loss = 0.116374
I0929 23:20:10.995965 25344 solver.cpp:259]     Train net output #0: error_blob = 0.116374 (* 1 = 0.116374 loss)
I0929 23:20:10.995970 25344 solver.cpp:590] Iteration 9200, lr = 0.01
I0929 23:20:13.486078 25344 solver.cpp:243] Iteration 9300, loss = 0.113253
I0929 23:20:13.486114 25344 solver.cpp:259]     Train net output #0: error_blob = 0.113253 (* 1 = 0.113253 loss)
I0929 23:20:13.486119 25344 solver.cpp:590] Iteration 9300, lr = 0.01
I0929 23:20:15.963822 25344 solver.cpp:243] Iteration 9400, loss = 0.111668
I0929 23:20:15.963857 25344 solver.cpp:259]     Train net output #0: error_blob = 0.111668 (* 1 = 0.111668 loss)
I0929 23:20:15.963863 25344 solver.cpp:590] Iteration 9400, lr = 0.01
I0929 23:20:18.449064 25344 solver.cpp:243] Iteration 9500, loss = 0.11828
I0929 23:20:18.449098 25344 solver.cpp:259]     Train net output #0: error_blob = 0.11828 (* 1 = 0.11828 loss)
I0929 23:20:18.449105 25344 solver.cpp:590] Iteration 9500, lr = 0.01
I0929 23:20:20.918383 25344 solver.cpp:243] Iteration 9600, loss = 0.117095
I0929 23:20:20.918423 25344 solver.cpp:259]     Train net output #0: error_blob = 0.117095 (* 1 = 0.117095 loss)
I0929 23:20:20.918431 25344 solver.cpp:590] Iteration 9600, lr = 0.01
I0929 23:20:23.386874 25344 solver.cpp:243] Iteration 9700, loss = 0.110466
I0929 23:20:23.386912 25344 solver.cpp:259]     Train net output #0: error_blob = 0.110466 (* 1 = 0.110466 loss)
I0929 23:20:23.386919 25344 solver.cpp:590] Iteration 9700, lr = 0.01
I0929 23:20:25.868595 25344 solver.cpp:243] Iteration 9800, loss = 0.113551
I0929 23:20:25.868630 25344 solver.cpp:259]     Train net output #0: error_blob = 0.113551 (* 1 = 0.113551 loss)
I0929 23:20:25.868636 25344 solver.cpp:590] Iteration 9800, lr = 0.01
I0929 23:20:28.357863 25344 solver.cpp:243] Iteration 9900, loss = 0.118265
I0929 23:20:28.357894 25344 solver.cpp:259]     Train net output #0: error_blob = 0.118265 (* 1 = 0.118265 loss)
I0929 23:20:28.357899 25344 solver.cpp:590] Iteration 9900, lr = 0.01
I0929 23:20:30.766988 25344 solver.cpp:468] Snapshotting to binary proto file _iter_10000.caffemodel
I0929 23:20:30.768261 25344 solver.cpp:753] Snapshotting solver state to binary proto file _iter_10000.solverstate
I0929 23:20:30.790639 25344 solver.cpp:327] Iteration 10000, loss = 0.112915
I0929 23:20:30.790665 25344 solver.cpp:347] Iteration 10000, Testing net (#0)
I0929 23:20:30.958972 25344 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:20:31.064152 25344 solver.cpp:415]     Test net output #0: error_blob = 0.110809 (* 1 = 0.110809 loss)
I0929 23:20:31.064173 25344 solver.cpp:332] Optimization Done.
I0929 23:20:31.064177 25344 caffe.cpp:215] Optimization Done.
I0929 23:20:31.125075 25357 caffe.cpp:184] Using GPUs 0
I0929 23:20:31.678774 25357 solver.cpp:54] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "fixed"
momentum: 0.9
solver_mode: GPU
device_id: 0
net: "model/NNScore/nnscore_model_4.prototxt"
I0929 23:20:31.678804 25357 solver.cpp:97] Creating training net from net file: model/NNScore/nnscore_model_4.prototxt
I0929 23:20:31.678954 25357 net.cpp:339] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_layer
I0929 23:20:31.678992 25357 net.cpp:50] Initializing net from parameters: 
name: "model/NNScore/nnscore_model_4.prototxt"
state {
  phase: TRAIN
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TRAIN
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.4.train"
    batch_size: 20000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I0929 23:20:31.679038 25357 layer_factory.hpp:76] Creating layer data_layer
I0929 23:20:31.692404 25357 net.cpp:110] Creating Layer data_layer
I0929 23:20:31.692433 25357 net.cpp:433] data_layer -> data_blob
I0929 23:20:31.692456 25357 net.cpp:433] data_layer -> label_blob
I0929 23:20:31.693084 25361 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.4.train
I0929 23:20:32.379873 25357 data_layer.cpp:45] output data size: 20000,61,1,1
I0929 23:20:32.384886 25357 net.cpp:155] Setting up data_layer
I0929 23:20:32.384927 25357 net.cpp:163] Top shape: 20000 61 1 1 (1220000)
I0929 23:20:32.384930 25357 net.cpp:163] Top shape: 20000 (20000)
I0929 23:20:32.384946 25357 layer_factory.hpp:76] Creating layer hidden_sum_layer
I0929 23:20:32.384958 25357 net.cpp:110] Creating Layer hidden_sum_layer
I0929 23:20:32.384961 25357 net.cpp:477] hidden_sum_layer <- data_blob
I0929 23:20:32.384970 25357 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I0929 23:20:32.385337 25357 net.cpp:155] Setting up hidden_sum_layer
I0929 23:20:32.385344 25357 net.cpp:163] Top shape: 20000 10 (200000)
I0929 23:20:32.385365 25357 layer_factory.hpp:76] Creating layer hidden_act_layer
I0929 23:20:32.385383 25357 net.cpp:110] Creating Layer hidden_act_layer
I0929 23:20:32.385385 25357 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I0929 23:20:32.385388 25357 net.cpp:433] hidden_act_layer -> hidden_act_blob
I0929 23:20:35.620865 25357 net.cpp:155] Setting up hidden_act_layer
I0929 23:20:35.620887 25357 net.cpp:163] Top shape: 20000 10 (200000)
I0929 23:20:35.620893 25357 layer_factory.hpp:76] Creating layer output_sum_layer
I0929 23:20:35.620901 25357 net.cpp:110] Creating Layer output_sum_layer
I0929 23:20:35.620904 25357 net.cpp:477] output_sum_layer <- hidden_act_blob
I0929 23:20:35.620910 25357 net.cpp:433] output_sum_layer -> output_sum_blob
I0929 23:20:35.620986 25357 net.cpp:155] Setting up output_sum_layer
I0929 23:20:35.620991 25357 net.cpp:163] Top shape: 20000 1 (20000)
I0929 23:20:35.620998 25357 layer_factory.hpp:76] Creating layer output_act_layer
I0929 23:20:35.621002 25357 net.cpp:110] Creating Layer output_act_layer
I0929 23:20:35.621006 25357 net.cpp:477] output_act_layer <- output_sum_blob
I0929 23:20:35.621008 25357 net.cpp:433] output_act_layer -> output_act_blob
I0929 23:20:35.621059 25357 net.cpp:155] Setting up output_act_layer
I0929 23:20:35.621076 25357 net.cpp:163] Top shape: 20000 1 (20000)
I0929 23:20:35.621079 25357 layer_factory.hpp:76] Creating layer error_layer
I0929 23:20:35.621084 25357 net.cpp:110] Creating Layer error_layer
I0929 23:20:35.621085 25357 net.cpp:477] error_layer <- output_act_blob
I0929 23:20:35.621088 25357 net.cpp:477] error_layer <- label_blob
I0929 23:20:35.621091 25357 net.cpp:433] error_layer -> error_blob
I0929 23:20:35.621114 25357 net.cpp:155] Setting up error_layer
I0929 23:20:35.621117 25357 net.cpp:163] Top shape: (1)
I0929 23:20:35.621119 25357 net.cpp:168]     with loss weight 1
I0929 23:20:35.621134 25357 net.cpp:236] error_layer needs backward computation.
I0929 23:20:35.621136 25357 net.cpp:236] output_act_layer needs backward computation.
I0929 23:20:35.621139 25357 net.cpp:236] output_sum_layer needs backward computation.
I0929 23:20:35.621140 25357 net.cpp:236] hidden_act_layer needs backward computation.
I0929 23:20:35.621142 25357 net.cpp:236] hidden_sum_layer needs backward computation.
I0929 23:20:35.621145 25357 net.cpp:240] data_layer does not need backward computation.
I0929 23:20:35.621145 25357 net.cpp:283] This network produces output error_blob
I0929 23:20:35.621150 25357 net.cpp:297] Network initialization done.
I0929 23:20:35.621152 25357 net.cpp:298] Memory required for data: 6720004
I0929 23:20:35.621268 25357 solver.cpp:187] Creating test net (#0) specified by net file: model/NNScore/nnscore_model_4.prototxt
I0929 23:20:35.621282 25357 net.cpp:339] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_layer
I0929 23:20:35.621312 25357 net.cpp:50] Initializing net from parameters: 
name: "model/NNScore/nnscore_model_4.prototxt"
state {
  phase: TEST
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TEST
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.4.test"
    batch_size: 2000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I0929 23:20:35.621332 25357 layer_factory.hpp:76] Creating layer data_layer
I0929 23:20:35.622486 25357 net.cpp:110] Creating Layer data_layer
I0929 23:20:35.622501 25357 net.cpp:433] data_layer -> data_blob
I0929 23:20:35.622506 25357 net.cpp:433] data_layer -> label_blob
I0929 23:20:35.623073 25363 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.4.test
I0929 23:20:35.623138 25357 data_layer.cpp:45] output data size: 2000,61,1,1
I0929 23:20:35.624449 25357 net.cpp:155] Setting up data_layer
I0929 23:20:35.624469 25357 net.cpp:163] Top shape: 2000 61 1 1 (122000)
I0929 23:20:35.624471 25357 net.cpp:163] Top shape: 2000 (2000)
I0929 23:20:35.624475 25357 layer_factory.hpp:76] Creating layer hidden_sum_layer
I0929 23:20:35.624503 25357 net.cpp:110] Creating Layer hidden_sum_layer
I0929 23:20:35.624516 25357 net.cpp:477] hidden_sum_layer <- data_blob
I0929 23:20:35.624519 25357 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I0929 23:20:35.624637 25357 net.cpp:155] Setting up hidden_sum_layer
I0929 23:20:35.624644 25357 net.cpp:163] Top shape: 2000 10 (20000)
I0929 23:20:35.624650 25357 layer_factory.hpp:76] Creating layer hidden_act_layer
I0929 23:20:35.624655 25357 net.cpp:110] Creating Layer hidden_act_layer
I0929 23:20:35.624656 25357 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I0929 23:20:35.624670 25357 net.cpp:433] hidden_act_layer -> hidden_act_blob
I0929 23:20:35.624871 25357 net.cpp:155] Setting up hidden_act_layer
I0929 23:20:35.624878 25357 net.cpp:163] Top shape: 2000 10 (20000)
I0929 23:20:35.624881 25357 layer_factory.hpp:76] Creating layer output_sum_layer
I0929 23:20:35.624886 25357 net.cpp:110] Creating Layer output_sum_layer
I0929 23:20:35.624887 25357 net.cpp:477] output_sum_layer <- hidden_act_blob
I0929 23:20:35.624891 25357 net.cpp:433] output_sum_layer -> output_sum_blob
I0929 23:20:35.624950 25357 net.cpp:155] Setting up output_sum_layer
I0929 23:20:35.624955 25357 net.cpp:163] Top shape: 2000 1 (2000)
I0929 23:20:35.624960 25357 layer_factory.hpp:76] Creating layer output_act_layer
I0929 23:20:35.624963 25357 net.cpp:110] Creating Layer output_act_layer
I0929 23:20:35.624965 25357 net.cpp:477] output_act_layer <- output_sum_blob
I0929 23:20:35.624969 25357 net.cpp:433] output_act_layer -> output_act_blob
I0929 23:20:35.625017 25357 net.cpp:155] Setting up output_act_layer
I0929 23:20:35.625021 25357 net.cpp:163] Top shape: 2000 1 (2000)
I0929 23:20:35.625025 25357 layer_factory.hpp:76] Creating layer error_layer
I0929 23:20:35.625027 25357 net.cpp:110] Creating Layer error_layer
I0929 23:20:35.625030 25357 net.cpp:477] error_layer <- output_act_blob
I0929 23:20:35.625032 25357 net.cpp:477] error_layer <- label_blob
I0929 23:20:35.625036 25357 net.cpp:433] error_layer -> error_blob
I0929 23:20:35.625054 25357 net.cpp:155] Setting up error_layer
I0929 23:20:35.625057 25357 net.cpp:163] Top shape: (1)
I0929 23:20:35.625059 25357 net.cpp:168]     with loss weight 1
I0929 23:20:35.625066 25357 net.cpp:236] error_layer needs backward computation.
I0929 23:20:35.625067 25357 net.cpp:236] output_act_layer needs backward computation.
I0929 23:20:35.625069 25357 net.cpp:236] output_sum_layer needs backward computation.
I0929 23:20:35.625072 25357 net.cpp:236] hidden_act_layer needs backward computation.
I0929 23:20:35.625073 25357 net.cpp:236] hidden_sum_layer needs backward computation.
I0929 23:20:35.625077 25357 net.cpp:240] data_layer does not need backward computation.
I0929 23:20:35.625078 25357 net.cpp:283] This network produces output error_blob
I0929 23:20:35.625083 25357 net.cpp:297] Network initialization done.
I0929 23:20:35.625084 25357 net.cpp:298] Memory required for data: 672004
I0929 23:20:35.625102 25357 solver.cpp:66] Solver scaffolding done.
I0929 23:20:35.625195 25357 caffe.cpp:212] Starting Optimization
I0929 23:20:35.625201 25357 solver.cpp:294] Solving model/NNScore/nnscore_model_4.prototxt
I0929 23:20:35.625202 25357 solver.cpp:295] Learning Rate Policy: fixed
I0929 23:20:35.625360 25357 solver.cpp:347] Iteration 0, Testing net (#0)
I0929 23:20:35.625432 25357 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:20:35.879129 25357 solver.cpp:415]     Test net output #0: error_blob = 0.124716 (* 1 = 0.124716 loss)
I0929 23:20:35.880478 25357 solver.cpp:243] Iteration 0, loss = 0.128819
I0929 23:20:35.880499 25357 solver.cpp:259]     Train net output #0: error_blob = 0.128819 (* 1 = 0.128819 loss)
I0929 23:20:35.880509 25357 solver.cpp:590] Iteration 0, lr = 0.01
I0929 23:20:38.388257 25357 solver.cpp:243] Iteration 100, loss = 0.122642
I0929 23:20:38.388298 25357 solver.cpp:259]     Train net output #0: error_blob = 0.122642 (* 1 = 0.122642 loss)
I0929 23:20:38.388304 25357 solver.cpp:590] Iteration 100, lr = 0.01
I0929 23:20:40.904556 25357 solver.cpp:243] Iteration 200, loss = 0.119394
I0929 23:20:40.904602 25357 solver.cpp:259]     Train net output #0: error_blob = 0.119394 (* 1 = 0.119394 loss)
I0929 23:20:40.904609 25357 solver.cpp:590] Iteration 200, lr = 0.01
I0929 23:20:43.451573 25357 solver.cpp:243] Iteration 300, loss = 0.121815
I0929 23:20:43.451618 25357 solver.cpp:259]     Train net output #0: error_blob = 0.121815 (* 1 = 0.121815 loss)
I0929 23:20:43.451627 25357 solver.cpp:590] Iteration 300, lr = 0.01
I0929 23:20:46.009981 25357 solver.cpp:243] Iteration 400, loss = 0.121294
I0929 23:20:46.011627 25357 solver.cpp:259]     Train net output #0: error_blob = 0.121294 (* 1 = 0.121294 loss)
I0929 23:20:46.011646 25357 solver.cpp:590] Iteration 400, lr = 0.01
I0929 23:20:48.543284 25357 solver.cpp:243] Iteration 500, loss = 0.120395
I0929 23:20:48.543318 25357 solver.cpp:259]     Train net output #0: error_blob = 0.120395 (* 1 = 0.120395 loss)
I0929 23:20:48.543323 25357 solver.cpp:590] Iteration 500, lr = 0.01
I0929 23:20:51.034979 25357 solver.cpp:243] Iteration 600, loss = 0.119225
I0929 23:20:51.035027 25357 solver.cpp:259]     Train net output #0: error_blob = 0.119225 (* 1 = 0.119225 loss)
I0929 23:20:51.035035 25357 solver.cpp:590] Iteration 600, lr = 0.01
I0929 23:20:53.549765 25357 solver.cpp:243] Iteration 700, loss = 0.119665
I0929 23:20:53.549803 25357 solver.cpp:259]     Train net output #0: error_blob = 0.119665 (* 1 = 0.119665 loss)
I0929 23:20:53.549809 25357 solver.cpp:590] Iteration 700, lr = 0.01
I0929 23:20:56.113710 25357 solver.cpp:243] Iteration 800, loss = 0.119711
I0929 23:20:56.113744 25357 solver.cpp:259]     Train net output #0: error_blob = 0.119711 (* 1 = 0.119711 loss)
I0929 23:20:56.113762 25357 solver.cpp:590] Iteration 800, lr = 0.01
I0929 23:20:58.652235 25357 solver.cpp:243] Iteration 900, loss = 0.120791
I0929 23:20:58.652281 25357 solver.cpp:259]     Train net output #0: error_blob = 0.120791 (* 1 = 0.120791 loss)
I0929 23:20:58.652287 25357 solver.cpp:590] Iteration 900, lr = 0.01
I0929 23:20:58.704190 25357 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:21:01.180765 25357 solver.cpp:347] Iteration 1000, Testing net (#0)
I0929 23:21:01.455904 25357 solver.cpp:415]     Test net output #0: error_blob = 0.116826 (* 1 = 0.116826 loss)
I0929 23:21:01.456558 25357 solver.cpp:243] Iteration 1000, loss = 0.119271
I0929 23:21:01.456571 25357 solver.cpp:259]     Train net output #0: error_blob = 0.119271 (* 1 = 0.119271 loss)
I0929 23:21:01.456578 25357 solver.cpp:590] Iteration 1000, lr = 0.01
I0929 23:21:03.937679 25357 solver.cpp:243] Iteration 1100, loss = 0.115994
I0929 23:21:03.937708 25357 solver.cpp:259]     Train net output #0: error_blob = 0.115994 (* 1 = 0.115994 loss)
I0929 23:21:03.937715 25357 solver.cpp:590] Iteration 1100, lr = 0.01
I0929 23:21:06.476979 25357 solver.cpp:243] Iteration 1200, loss = 0.120226
I0929 23:21:06.477006 25357 solver.cpp:259]     Train net output #0: error_blob = 0.120226 (* 1 = 0.120226 loss)
I0929 23:21:06.477010 25357 solver.cpp:590] Iteration 1200, lr = 0.01
I0929 23:21:09.025074 25357 solver.cpp:243] Iteration 1300, loss = 0.119845
I0929 23:21:09.025120 25357 solver.cpp:259]     Train net output #0: error_blob = 0.119845 (* 1 = 0.119845 loss)
I0929 23:21:09.025126 25357 solver.cpp:590] Iteration 1300, lr = 0.01
I0929 23:21:11.616128 25357 solver.cpp:243] Iteration 1400, loss = 0.118566
I0929 23:21:11.616163 25357 solver.cpp:259]     Train net output #0: error_blob = 0.118566 (* 1 = 0.118566 loss)
I0929 23:21:11.616170 25357 solver.cpp:590] Iteration 1400, lr = 0.01
I0929 23:21:14.182473 25357 solver.cpp:243] Iteration 1500, loss = 0.116811
I0929 23:21:14.182520 25357 solver.cpp:259]     Train net output #0: error_blob = 0.116811 (* 1 = 0.116811 loss)
I0929 23:21:14.182529 25357 solver.cpp:590] Iteration 1500, lr = 0.01
I0929 23:21:16.728899 25357 solver.cpp:243] Iteration 1600, loss = 0.117594
I0929 23:21:16.728938 25357 solver.cpp:259]     Train net output #0: error_blob = 0.117594 (* 1 = 0.117594 loss)
I0929 23:21:16.728943 25357 solver.cpp:590] Iteration 1600, lr = 0.01
I0929 23:21:19.318141 25357 solver.cpp:243] Iteration 1700, loss = 0.118886
I0929 23:21:19.318181 25357 solver.cpp:259]     Train net output #0: error_blob = 0.118886 (* 1 = 0.118886 loss)
I0929 23:21:19.318187 25357 solver.cpp:590] Iteration 1700, lr = 0.01
I0929 23:21:21.857359 25357 solver.cpp:243] Iteration 1800, loss = 0.118924
I0929 23:21:21.857396 25357 solver.cpp:259]     Train net output #0: error_blob = 0.118924 (* 1 = 0.118924 loss)
I0929 23:21:21.857404 25357 solver.cpp:590] Iteration 1800, lr = 0.01
I0929 23:21:22.058203 25357 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:21:24.430820 25357 solver.cpp:243] Iteration 1900, loss = 0.117193
I0929 23:21:24.430851 25357 solver.cpp:259]     Train net output #0: error_blob = 0.117193 (* 1 = 0.117193 loss)
I0929 23:21:24.430855 25357 solver.cpp:590] Iteration 1900, lr = 0.01
I0929 23:21:26.984185 25357 solver.cpp:347] Iteration 2000, Testing net (#0)
I0929 23:21:27.291021 25357 solver.cpp:415]     Test net output #0: error_blob = 0.114617 (* 1 = 0.114617 loss)
I0929 23:21:27.291682 25357 solver.cpp:243] Iteration 2000, loss = 0.114239
I0929 23:21:27.291700 25357 solver.cpp:259]     Train net output #0: error_blob = 0.114239 (* 1 = 0.114239 loss)
I0929 23:21:27.291708 25357 solver.cpp:590] Iteration 2000, lr = 0.01
I0929 23:21:29.782498 25357 solver.cpp:243] Iteration 2100, loss = 0.119517
I0929 23:21:29.782528 25357 solver.cpp:259]     Train net output #0: error_blob = 0.119517 (* 1 = 0.119517 loss)
I0929 23:21:29.782533 25357 solver.cpp:590] Iteration 2100, lr = 0.01
I0929 23:21:32.316124 25357 solver.cpp:243] Iteration 2200, loss = 0.119205
I0929 23:21:32.317725 25357 solver.cpp:259]     Train net output #0: error_blob = 0.119205 (* 1 = 0.119205 loss)
I0929 23:21:32.317734 25357 solver.cpp:590] Iteration 2200, lr = 0.01
I0929 23:21:34.809502 25357 solver.cpp:243] Iteration 2300, loss = 0.119648
I0929 23:21:34.809541 25357 solver.cpp:259]     Train net output #0: error_blob = 0.119648 (* 1 = 0.119648 loss)
I0929 23:21:34.809547 25357 solver.cpp:590] Iteration 2300, lr = 0.01
I0929 23:21:37.281524 25357 solver.cpp:243] Iteration 2400, loss = 0.115367
I0929 23:21:37.281555 25357 solver.cpp:259]     Train net output #0: error_blob = 0.115367 (* 1 = 0.115367 loss)
I0929 23:21:37.281560 25357 solver.cpp:590] Iteration 2400, lr = 0.01
I0929 23:21:39.775862 25357 solver.cpp:243] Iteration 2500, loss = 0.115951
I0929 23:21:39.775909 25357 solver.cpp:259]     Train net output #0: error_blob = 0.115951 (* 1 = 0.115951 loss)
I0929 23:21:39.775915 25357 solver.cpp:590] Iteration 2500, lr = 0.01
I0929 23:21:42.257747 25357 solver.cpp:243] Iteration 2600, loss = 0.118742
I0929 23:21:42.257793 25357 solver.cpp:259]     Train net output #0: error_blob = 0.118742 (* 1 = 0.118742 loss)
I0929 23:21:42.257802 25357 solver.cpp:590] Iteration 2600, lr = 0.01
I0929 23:21:44.762147 25357 solver.cpp:243] Iteration 2700, loss = 0.119128
I0929 23:21:44.762189 25357 solver.cpp:259]     Train net output #0: error_blob = 0.119128 (* 1 = 0.119128 loss)
I0929 23:21:44.762194 25357 solver.cpp:590] Iteration 2700, lr = 0.01
I0929 23:21:45.122232 25357 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:21:47.319010 25357 solver.cpp:243] Iteration 2800, loss = 0.116292
I0929 23:21:47.319056 25357 solver.cpp:259]     Train net output #0: error_blob = 0.116292 (* 1 = 0.116292 loss)
I0929 23:21:47.319063 25357 solver.cpp:590] Iteration 2800, lr = 0.01
I0929 23:21:49.847041 25357 solver.cpp:243] Iteration 2900, loss = 0.113375
I0929 23:21:49.847082 25357 solver.cpp:259]     Train net output #0: error_blob = 0.113375 (* 1 = 0.113375 loss)
I0929 23:21:49.847087 25357 solver.cpp:590] Iteration 2900, lr = 0.01
I0929 23:21:52.357753 25357 solver.cpp:347] Iteration 3000, Testing net (#0)
I0929 23:21:52.627533 25357 solver.cpp:415]     Test net output #0: error_blob = 0.113776 (* 1 = 0.113776 loss)
I0929 23:21:52.628146 25357 solver.cpp:243] Iteration 3000, loss = 0.117625
I0929 23:21:52.628159 25357 solver.cpp:259]     Train net output #0: error_blob = 0.117625 (* 1 = 0.117625 loss)
I0929 23:21:52.628165 25357 solver.cpp:590] Iteration 3000, lr = 0.01
I0929 23:21:55.152968 25357 solver.cpp:243] Iteration 3100, loss = 0.118414
I0929 23:21:55.153003 25357 solver.cpp:259]     Train net output #0: error_blob = 0.118414 (* 1 = 0.118414 loss)
I0929 23:21:55.153012 25357 solver.cpp:590] Iteration 3100, lr = 0.01
I0929 23:21:57.643502 25357 solver.cpp:243] Iteration 3200, loss = 0.116932
I0929 23:21:57.643532 25357 solver.cpp:259]     Train net output #0: error_blob = 0.116932 (* 1 = 0.116932 loss)
I0929 23:21:57.643537 25357 solver.cpp:590] Iteration 3200, lr = 0.01
I0929 23:22:00.115128 25357 solver.cpp:243] Iteration 3300, loss = 0.117977
I0929 23:22:00.115167 25357 solver.cpp:259]     Train net output #0: error_blob = 0.117977 (* 1 = 0.117977 loss)
I0929 23:22:00.115173 25357 solver.cpp:590] Iteration 3300, lr = 0.01
I0929 23:22:02.609488 25357 solver.cpp:243] Iteration 3400, loss = 0.115978
I0929 23:22:02.609601 25357 solver.cpp:259]     Train net output #0: error_blob = 0.115978 (* 1 = 0.115978 loss)
I0929 23:22:02.609607 25357 solver.cpp:590] Iteration 3400, lr = 0.01
I0929 23:22:05.104722 25357 solver.cpp:243] Iteration 3500, loss = 0.117654
I0929 23:22:05.104768 25357 solver.cpp:259]     Train net output #0: error_blob = 0.117654 (* 1 = 0.117654 loss)
I0929 23:22:05.104775 25357 solver.cpp:590] Iteration 3500, lr = 0.01
I0929 23:22:07.659346 25357 solver.cpp:243] Iteration 3600, loss = 0.118286
I0929 23:22:07.659392 25357 solver.cpp:259]     Train net output #0: error_blob = 0.118286 (* 1 = 0.118286 loss)
I0929 23:22:07.659400 25357 solver.cpp:590] Iteration 3600, lr = 0.01
I0929 23:22:08.164543 25357 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:22:10.186276 25357 solver.cpp:243] Iteration 3700, loss = 0.115125
I0929 23:22:10.186321 25357 solver.cpp:259]     Train net output #0: error_blob = 0.115125 (* 1 = 0.115125 loss)
I0929 23:22:10.186328 25357 solver.cpp:590] Iteration 3700, lr = 0.01
I0929 23:22:12.732436 25357 solver.cpp:243] Iteration 3800, loss = 0.114536
I0929 23:22:12.732480 25357 solver.cpp:259]     Train net output #0: error_blob = 0.114536 (* 1 = 0.114536 loss)
I0929 23:22:12.732507 25357 solver.cpp:590] Iteration 3800, lr = 0.01
I0929 23:22:15.286511 25357 solver.cpp:243] Iteration 3900, loss = 0.118961
I0929 23:22:15.286550 25357 solver.cpp:259]     Train net output #0: error_blob = 0.118961 (* 1 = 0.118961 loss)
I0929 23:22:15.286556 25357 solver.cpp:590] Iteration 3900, lr = 0.01
I0929 23:22:17.735687 25357 solver.cpp:347] Iteration 4000, Testing net (#0)
I0929 23:22:18.003701 25357 solver.cpp:415]     Test net output #0: error_blob = 0.113122 (* 1 = 0.113122 loss)
I0929 23:22:18.004323 25357 solver.cpp:243] Iteration 4000, loss = 0.118454
I0929 23:22:18.004343 25357 solver.cpp:259]     Train net output #0: error_blob = 0.118454 (* 1 = 0.118454 loss)
I0929 23:22:18.004349 25357 solver.cpp:590] Iteration 4000, lr = 0.01
I0929 23:22:20.411881 25357 solver.cpp:243] Iteration 4100, loss = 0.115948
I0929 23:22:20.411921 25357 solver.cpp:259]     Train net output #0: error_blob = 0.115948 (* 1 = 0.115948 loss)
I0929 23:22:20.411927 25357 solver.cpp:590] Iteration 4100, lr = 0.01
I0929 23:22:22.890769 25357 solver.cpp:243] Iteration 4200, loss = 0.1141
I0929 23:22:22.890811 25357 solver.cpp:259]     Train net output #0: error_blob = 0.1141 (* 1 = 0.1141 loss)
I0929 23:22:22.890816 25357 solver.cpp:590] Iteration 4200, lr = 0.01
I0929 23:22:25.379416 25357 solver.cpp:243] Iteration 4300, loss = 0.11579
I0929 23:22:25.379443 25357 solver.cpp:259]     Train net output #0: error_blob = 0.11579 (* 1 = 0.11579 loss)
I0929 23:22:25.379449 25357 solver.cpp:590] Iteration 4300, lr = 0.01
I0929 23:22:27.870003 25357 solver.cpp:243] Iteration 4400, loss = 0.11709
I0929 23:22:27.870044 25357 solver.cpp:259]     Train net output #0: error_blob = 0.11709 (* 1 = 0.11709 loss)
I0929 23:22:27.870049 25357 solver.cpp:590] Iteration 4400, lr = 0.01
I0929 23:22:30.369922 25357 solver.cpp:243] Iteration 4500, loss = 0.117941
I0929 23:22:30.369951 25357 solver.cpp:259]     Train net output #0: error_blob = 0.117941 (* 1 = 0.117941 loss)
I0929 23:22:30.369956 25357 solver.cpp:590] Iteration 4500, lr = 0.01
I0929 23:22:31.016290 25357 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:22:32.865326 25357 solver.cpp:243] Iteration 4600, loss = 0.115627
I0929 23:22:32.865407 25357 solver.cpp:259]     Train net output #0: error_blob = 0.115627 (* 1 = 0.115627 loss)
I0929 23:22:32.865413 25357 solver.cpp:590] Iteration 4600, lr = 0.01
I0929 23:22:35.376873 25357 solver.cpp:243] Iteration 4700, loss = 0.112971
I0929 23:22:35.376904 25357 solver.cpp:259]     Train net output #0: error_blob = 0.112971 (* 1 = 0.112971 loss)
I0929 23:22:35.376909 25357 solver.cpp:590] Iteration 4700, lr = 0.01
I0929 23:22:37.873620 25357 solver.cpp:243] Iteration 4800, loss = 0.116717
I0929 23:22:37.873661 25357 solver.cpp:259]     Train net output #0: error_blob = 0.116717 (* 1 = 0.116717 loss)
I0929 23:22:37.873667 25357 solver.cpp:590] Iteration 4800, lr = 0.01
I0929 23:22:40.349002 25357 solver.cpp:243] Iteration 4900, loss = 0.117687
I0929 23:22:40.349030 25357 solver.cpp:259]     Train net output #0: error_blob = 0.117687 (* 1 = 0.117687 loss)
I0929 23:22:40.349035 25357 solver.cpp:590] Iteration 4900, lr = 0.01
I0929 23:22:42.802625 25357 solver.cpp:347] Iteration 5000, Testing net (#0)
I0929 23:22:43.105484 25357 solver.cpp:415]     Test net output #0: error_blob = 0.113551 (* 1 = 0.113551 loss)
I0929 23:22:43.106133 25357 solver.cpp:243] Iteration 5000, loss = 0.118063
I0929 23:22:43.106148 25357 solver.cpp:259]     Train net output #0: error_blob = 0.118063 (* 1 = 0.118063 loss)
I0929 23:22:43.106153 25357 solver.cpp:590] Iteration 5000, lr = 0.01
I0929 23:22:45.691608 25357 solver.cpp:243] Iteration 5100, loss = 0.115135
I0929 23:22:45.691648 25357 solver.cpp:259]     Train net output #0: error_blob = 0.115135 (* 1 = 0.115135 loss)
I0929 23:22:45.691653 25357 solver.cpp:590] Iteration 5100, lr = 0.01
I0929 23:22:48.192077 25357 solver.cpp:243] Iteration 5200, loss = 0.113429
I0929 23:22:48.192108 25357 solver.cpp:259]     Train net output #0: error_blob = 0.113429 (* 1 = 0.113429 loss)
I0929 23:22:48.192113 25357 solver.cpp:590] Iteration 5200, lr = 0.01
I0929 23:22:50.697039 25357 solver.cpp:243] Iteration 5300, loss = 0.116532
I0929 23:22:50.697080 25357 solver.cpp:259]     Train net output #0: error_blob = 0.116532 (* 1 = 0.116532 loss)
I0929 23:22:50.697084 25357 solver.cpp:590] Iteration 5300, lr = 0.01
I0929 23:22:53.233160 25357 solver.cpp:243] Iteration 5400, loss = 0.117235
I0929 23:22:53.233191 25357 solver.cpp:259]     Train net output #0: error_blob = 0.117235 (* 1 = 0.117235 loss)
I0929 23:22:53.233194 25357 solver.cpp:590] Iteration 5400, lr = 0.01
I0929 23:22:54.045274 25357 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:22:55.761363 25357 solver.cpp:243] Iteration 5500, loss = 0.116426
I0929 23:22:55.761392 25357 solver.cpp:259]     Train net output #0: error_blob = 0.116426 (* 1 = 0.116426 loss)
I0929 23:22:55.761397 25357 solver.cpp:590] Iteration 5500, lr = 0.01
I0929 23:22:58.270220 25357 solver.cpp:243] Iteration 5600, loss = 0.111433
I0929 23:22:58.270249 25357 solver.cpp:259]     Train net output #0: error_blob = 0.111433 (* 1 = 0.111433 loss)
I0929 23:22:58.270253 25357 solver.cpp:590] Iteration 5600, lr = 0.01
I0929 23:23:00.752009 25357 solver.cpp:243] Iteration 5700, loss = 0.114974
I0929 23:23:00.752040 25357 solver.cpp:259]     Train net output #0: error_blob = 0.114974 (* 1 = 0.114974 loss)
I0929 23:23:00.752045 25357 solver.cpp:590] Iteration 5700, lr = 0.01
I0929 23:23:03.264799 25357 solver.cpp:243] Iteration 5800, loss = 0.11818
I0929 23:23:03.265807 25357 solver.cpp:259]     Train net output #0: error_blob = 0.11818 (* 1 = 0.11818 loss)
I0929 23:23:03.265815 25357 solver.cpp:590] Iteration 5800, lr = 0.01
I0929 23:23:05.767752 25357 solver.cpp:243] Iteration 5900, loss = 0.117791
I0929 23:23:05.767781 25357 solver.cpp:259]     Train net output #0: error_blob = 0.117791 (* 1 = 0.117791 loss)
I0929 23:23:05.767786 25357 solver.cpp:590] Iteration 5900, lr = 0.01
I0929 23:23:08.260295 25357 solver.cpp:347] Iteration 6000, Testing net (#0)
I0929 23:23:08.618546 25357 solver.cpp:415]     Test net output #0: error_blob = 0.111891 (* 1 = 0.111891 loss)
I0929 23:23:08.619175 25357 solver.cpp:243] Iteration 6000, loss = 0.113539
I0929 23:23:08.619189 25357 solver.cpp:259]     Train net output #0: error_blob = 0.113539 (* 1 = 0.113539 loss)
I0929 23:23:08.619196 25357 solver.cpp:590] Iteration 6000, lr = 0.01
I0929 23:23:11.175873 25357 solver.cpp:243] Iteration 6100, loss = 0.115189
I0929 23:23:11.175904 25357 solver.cpp:259]     Train net output #0: error_blob = 0.115189 (* 1 = 0.115189 loss)
I0929 23:23:11.175911 25357 solver.cpp:590] Iteration 6100, lr = 0.01
I0929 23:23:13.712890 25357 solver.cpp:243] Iteration 6200, loss = 0.115125
I0929 23:23:13.712919 25357 solver.cpp:259]     Train net output #0: error_blob = 0.115125 (* 1 = 0.115125 loss)
I0929 23:23:13.712924 25357 solver.cpp:590] Iteration 6200, lr = 0.01
I0929 23:23:16.206046 25357 solver.cpp:243] Iteration 6300, loss = 0.116645
I0929 23:23:16.206076 25357 solver.cpp:259]     Train net output #0: error_blob = 0.116645 (* 1 = 0.116645 loss)
I0929 23:23:16.206081 25357 solver.cpp:590] Iteration 6300, lr = 0.01
I0929 23:23:17.178331 25357 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:23:18.752261 25357 solver.cpp:243] Iteration 6400, loss = 0.117749
I0929 23:23:18.752291 25357 solver.cpp:259]     Train net output #0: error_blob = 0.117749 (* 1 = 0.117749 loss)
I0929 23:23:18.752296 25357 solver.cpp:590] Iteration 6400, lr = 0.01
I0929 23:23:21.282620 25357 solver.cpp:243] Iteration 6500, loss = 0.112823
I0929 23:23:21.282650 25357 solver.cpp:259]     Train net output #0: error_blob = 0.112823 (* 1 = 0.112823 loss)
I0929 23:23:21.282655 25357 solver.cpp:590] Iteration 6500, lr = 0.01
I0929 23:23:23.827879 25357 solver.cpp:243] Iteration 6600, loss = 0.114665
I0929 23:23:23.827909 25357 solver.cpp:259]     Train net output #0: error_blob = 0.114665 (* 1 = 0.114665 loss)
I0929 23:23:23.827915 25357 solver.cpp:590] Iteration 6600, lr = 0.01
I0929 23:23:26.325778 25357 solver.cpp:243] Iteration 6700, loss = 0.117192
I0929 23:23:26.325809 25357 solver.cpp:259]     Train net output #0: error_blob = 0.117192 (* 1 = 0.117192 loss)
I0929 23:23:26.325814 25357 solver.cpp:590] Iteration 6700, lr = 0.01
I0929 23:23:28.801180 25357 solver.cpp:243] Iteration 6800, loss = 0.116786
I0929 23:23:28.801210 25357 solver.cpp:259]     Train net output #0: error_blob = 0.116786 (* 1 = 0.116786 loss)
I0929 23:23:28.801214 25357 solver.cpp:590] Iteration 6800, lr = 0.01
I0929 23:23:31.310976 25357 solver.cpp:243] Iteration 6900, loss = 0.113375
I0929 23:23:31.311007 25357 solver.cpp:259]     Train net output #0: error_blob = 0.113375 (* 1 = 0.113375 loss)
I0929 23:23:31.311012 25357 solver.cpp:590] Iteration 6900, lr = 0.01
I0929 23:23:33.793148 25357 solver.cpp:347] Iteration 7000, Testing net (#0)
I0929 23:23:34.086580 25357 solver.cpp:415]     Test net output #0: error_blob = 0.112655 (* 1 = 0.112655 loss)
I0929 23:23:34.087208 25357 solver.cpp:243] Iteration 7000, loss = 0.115031
I0929 23:23:34.087223 25357 solver.cpp:259]     Train net output #0: error_blob = 0.115031 (* 1 = 0.115031 loss)
I0929 23:23:34.087227 25357 solver.cpp:590] Iteration 7000, lr = 0.01
I0929 23:23:36.562288 25357 solver.cpp:243] Iteration 7100, loss = 0.120304
I0929 23:23:36.562319 25357 solver.cpp:259]     Train net output #0: error_blob = 0.120304 (* 1 = 0.120304 loss)
I0929 23:23:36.562322 25357 solver.cpp:590] Iteration 7100, lr = 0.01
I0929 23:23:39.031399 25357 solver.cpp:243] Iteration 7200, loss = 0.116481
I0929 23:23:39.031430 25357 solver.cpp:259]     Train net output #0: error_blob = 0.116481 (* 1 = 0.116481 loss)
I0929 23:23:39.031435 25357 solver.cpp:590] Iteration 7200, lr = 0.01
I0929 23:23:40.122458 25357 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:23:41.507340 25357 solver.cpp:243] Iteration 7300, loss = 0.113772
I0929 23:23:41.507370 25357 solver.cpp:259]     Train net output #0: error_blob = 0.113772 (* 1 = 0.113772 loss)
I0929 23:23:41.507375 25357 solver.cpp:590] Iteration 7300, lr = 0.01
I0929 23:23:44.025557 25357 solver.cpp:243] Iteration 7400, loss = 0.111488
I0929 23:23:44.025586 25357 solver.cpp:259]     Train net output #0: error_blob = 0.111488 (* 1 = 0.111488 loss)
I0929 23:23:44.025591 25357 solver.cpp:590] Iteration 7400, lr = 0.01
I0929 23:23:46.570394 25357 solver.cpp:243] Iteration 7500, loss = 0.114275
I0929 23:23:46.570423 25357 solver.cpp:259]     Train net output #0: error_blob = 0.114275 (* 1 = 0.114275 loss)
I0929 23:23:46.570428 25357 solver.cpp:590] Iteration 7500, lr = 0.01
I0929 23:23:49.064118 25357 solver.cpp:243] Iteration 7600, loss = 0.122627
I0929 23:23:49.064147 25357 solver.cpp:259]     Train net output #0: error_blob = 0.122627 (* 1 = 0.122627 loss)
I0929 23:23:49.064152 25357 solver.cpp:590] Iteration 7600, lr = 0.01
I0929 23:23:51.576951 25357 solver.cpp:243] Iteration 7700, loss = 0.119478
I0929 23:23:51.576980 25357 solver.cpp:259]     Train net output #0: error_blob = 0.119478 (* 1 = 0.119478 loss)
I0929 23:23:51.576987 25357 solver.cpp:590] Iteration 7700, lr = 0.01
I0929 23:23:54.076666 25357 solver.cpp:243] Iteration 7800, loss = 0.118345
I0929 23:23:54.076697 25357 solver.cpp:259]     Train net output #0: error_blob = 0.118345 (* 1 = 0.118345 loss)
I0929 23:23:54.076704 25357 solver.cpp:590] Iteration 7800, lr = 0.01
I0929 23:23:56.620651 25357 solver.cpp:243] Iteration 7900, loss = 0.118064
I0929 23:23:56.620679 25357 solver.cpp:259]     Train net output #0: error_blob = 0.118064 (* 1 = 0.118064 loss)
I0929 23:23:56.620684 25357 solver.cpp:590] Iteration 7900, lr = 0.01
I0929 23:23:59.071631 25357 solver.cpp:347] Iteration 8000, Testing net (#0)
I0929 23:23:59.364188 25357 solver.cpp:415]     Test net output #0: error_blob = 0.117932 (* 1 = 0.117932 loss)
I0929 23:23:59.364881 25357 solver.cpp:243] Iteration 8000, loss = 0.118166
I0929 23:23:59.364899 25357 solver.cpp:259]     Train net output #0: error_blob = 0.118166 (* 1 = 0.118166 loss)
I0929 23:23:59.364907 25357 solver.cpp:590] Iteration 8000, lr = 0.01
I0929 23:24:01.851439 25357 solver.cpp:243] Iteration 8100, loss = 0.120552
I0929 23:24:01.851479 25357 solver.cpp:259]     Train net output #0: error_blob = 0.120552 (* 1 = 0.120552 loss)
I0929 23:24:01.851485 25357 solver.cpp:590] Iteration 8100, lr = 0.01
I0929 23:24:03.089651 25357 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:24:04.352977 25357 solver.cpp:243] Iteration 8200, loss = 0.118224
I0929 23:24:04.353082 25357 solver.cpp:259]     Train net output #0: error_blob = 0.118224 (* 1 = 0.118224 loss)
I0929 23:24:04.353090 25357 solver.cpp:590] Iteration 8200, lr = 0.01
I0929 23:24:06.867669 25357 solver.cpp:243] Iteration 8300, loss = 0.115489
I0929 23:24:06.867699 25357 solver.cpp:259]     Train net output #0: error_blob = 0.115489 (* 1 = 0.115489 loss)
I0929 23:24:06.867704 25357 solver.cpp:590] Iteration 8300, lr = 0.01
I0929 23:24:09.397336 25357 solver.cpp:243] Iteration 8400, loss = 0.118349
I0929 23:24:09.397366 25357 solver.cpp:259]     Train net output #0: error_blob = 0.118349 (* 1 = 0.118349 loss)
I0929 23:24:09.397371 25357 solver.cpp:590] Iteration 8400, lr = 0.01
I0929 23:24:11.914154 25357 solver.cpp:243] Iteration 8500, loss = 0.118564
I0929 23:24:11.914183 25357 solver.cpp:259]     Train net output #0: error_blob = 0.118564 (* 1 = 0.118564 loss)
I0929 23:24:11.914188 25357 solver.cpp:590] Iteration 8500, lr = 0.01
I0929 23:24:14.432173 25357 solver.cpp:243] Iteration 8600, loss = 0.118286
I0929 23:24:14.432202 25357 solver.cpp:259]     Train net output #0: error_blob = 0.118286 (* 1 = 0.118286 loss)
I0929 23:24:14.432207 25357 solver.cpp:590] Iteration 8600, lr = 0.01
I0929 23:24:16.940628 25357 solver.cpp:243] Iteration 8700, loss = 0.120236
I0929 23:24:16.940659 25357 solver.cpp:259]     Train net output #0: error_blob = 0.120236 (* 1 = 0.120236 loss)
I0929 23:24:16.940665 25357 solver.cpp:590] Iteration 8700, lr = 0.01
I0929 23:24:19.497907 25357 solver.cpp:243] Iteration 8800, loss = 0.115675
I0929 23:24:19.497937 25357 solver.cpp:259]     Train net output #0: error_blob = 0.115675 (* 1 = 0.115675 loss)
I0929 23:24:19.497943 25357 solver.cpp:590] Iteration 8800, lr = 0.01
I0929 23:24:22.054199 25357 solver.cpp:243] Iteration 8900, loss = 0.117106
I0929 23:24:22.054231 25357 solver.cpp:259]     Train net output #0: error_blob = 0.117106 (* 1 = 0.117106 loss)
I0929 23:24:22.054239 25357 solver.cpp:590] Iteration 8900, lr = 0.01
I0929 23:24:24.600610 25357 solver.cpp:347] Iteration 9000, Testing net (#0)
I0929 23:24:24.996563 25357 solver.cpp:415]     Test net output #0: error_blob = 0.116354 (* 1 = 0.116354 loss)
I0929 23:24:24.997203 25357 solver.cpp:243] Iteration 9000, loss = 0.118474
I0929 23:24:24.997217 25357 solver.cpp:259]     Train net output #0: error_blob = 0.118474 (* 1 = 0.118474 loss)
I0929 23:24:24.997222 25357 solver.cpp:590] Iteration 9000, lr = 0.01
I0929 23:24:26.348634 25357 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:24:27.457262 25357 solver.cpp:243] Iteration 9100, loss = 0.117065
I0929 23:24:27.457293 25357 solver.cpp:259]     Train net output #0: error_blob = 0.117065 (* 1 = 0.117065 loss)
I0929 23:24:27.457298 25357 solver.cpp:590] Iteration 9100, lr = 0.01
I0929 23:24:29.957574 25357 solver.cpp:243] Iteration 9200, loss = 0.113818
I0929 23:24:29.957604 25357 solver.cpp:259]     Train net output #0: error_blob = 0.113818 (* 1 = 0.113818 loss)
I0929 23:24:29.957609 25357 solver.cpp:590] Iteration 9200, lr = 0.01
I0929 23:24:32.463397 25357 solver.cpp:243] Iteration 9300, loss = 0.116473
I0929 23:24:32.463429 25357 solver.cpp:259]     Train net output #0: error_blob = 0.116473 (* 1 = 0.116473 loss)
I0929 23:24:32.463436 25357 solver.cpp:590] Iteration 9300, lr = 0.01
I0929 23:24:34.997717 25357 solver.cpp:243] Iteration 9400, loss = 0.120556
I0929 23:24:34.997817 25357 solver.cpp:259]     Train net output #0: error_blob = 0.120556 (* 1 = 0.120556 loss)
I0929 23:24:34.997825 25357 solver.cpp:590] Iteration 9400, lr = 0.01
I0929 23:24:37.514839 25357 solver.cpp:243] Iteration 9500, loss = 0.119136
I0929 23:24:37.514880 25357 solver.cpp:259]     Train net output #0: error_blob = 0.119136 (* 1 = 0.119136 loss)
I0929 23:24:37.514885 25357 solver.cpp:590] Iteration 9500, lr = 0.01
I0929 23:24:40.009090 25357 solver.cpp:243] Iteration 9600, loss = 0.114859
I0929 23:24:40.009130 25357 solver.cpp:259]     Train net output #0: error_blob = 0.114859 (* 1 = 0.114859 loss)
I0929 23:24:40.009135 25357 solver.cpp:590] Iteration 9600, lr = 0.01
I0929 23:24:42.506007 25357 solver.cpp:243] Iteration 9700, loss = 0.115243
I0929 23:24:42.506047 25357 solver.cpp:259]     Train net output #0: error_blob = 0.115243 (* 1 = 0.115243 loss)
I0929 23:24:42.506053 25357 solver.cpp:590] Iteration 9700, lr = 0.01
I0929 23:24:45.000731 25357 solver.cpp:243] Iteration 9800, loss = 0.116304
I0929 23:24:45.000772 25357 solver.cpp:259]     Train net output #0: error_blob = 0.116304 (* 1 = 0.116304 loss)
I0929 23:24:45.000778 25357 solver.cpp:590] Iteration 9800, lr = 0.01
I0929 23:24:47.485862 25357 solver.cpp:243] Iteration 9900, loss = 0.121415
I0929 23:24:47.485891 25357 solver.cpp:259]     Train net output #0: error_blob = 0.121415 (* 1 = 0.121415 loss)
I0929 23:24:47.485895 25357 solver.cpp:590] Iteration 9900, lr = 0.01
I0929 23:24:49.907951 25357 solver.cpp:468] Snapshotting to binary proto file _iter_10000.caffemodel
I0929 23:24:49.909818 25357 solver.cpp:753] Snapshotting solver state to binary proto file _iter_10000.solverstate
I0929 23:24:49.937105 25357 solver.cpp:327] Iteration 10000, loss = 0.116321
I0929 23:24:49.937130 25357 solver.cpp:347] Iteration 10000, Testing net (#0)
I0929 23:24:50.102764 25357 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:24:50.206130 25357 solver.cpp:415]     Test net output #0: error_blob = 0.114823 (* 1 = 0.114823 loss)
I0929 23:24:50.206161 25357 solver.cpp:332] Optimization Done.
I0929 23:24:50.206163 25357 caffe.cpp:215] Optimization Done.
I0929 23:24:50.282843 25384 caffe.cpp:184] Using GPUs 0
I0929 23:24:50.844130 25384 solver.cpp:54] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "fixed"
momentum: 0.9
solver_mode: GPU
device_id: 0
net: "model/NNScore/nnscore_model_5.prototxt"
I0929 23:24:50.844159 25384 solver.cpp:97] Creating training net from net file: model/NNScore/nnscore_model_5.prototxt
I0929 23:24:50.844347 25384 net.cpp:339] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_layer
I0929 23:24:50.844383 25384 net.cpp:50] Initializing net from parameters: 
name: "model/NNScore/nnscore_model_5.prototxt"
state {
  phase: TRAIN
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TRAIN
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.5.train"
    batch_size: 20000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I0929 23:24:50.844421 25384 layer_factory.hpp:76] Creating layer data_layer
I0929 23:24:50.857790 25384 net.cpp:110] Creating Layer data_layer
I0929 23:24:50.857818 25384 net.cpp:433] data_layer -> data_blob
I0929 23:24:50.857854 25384 net.cpp:433] data_layer -> label_blob
I0929 23:24:50.858446 25388 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.5.train
I0929 23:24:51.541723 25384 data_layer.cpp:45] output data size: 20000,61,1,1
I0929 23:24:51.546687 25384 net.cpp:155] Setting up data_layer
I0929 23:24:51.546743 25384 net.cpp:163] Top shape: 20000 61 1 1 (1220000)
I0929 23:24:51.546747 25384 net.cpp:163] Top shape: 20000 (20000)
I0929 23:24:51.546753 25384 layer_factory.hpp:76] Creating layer hidden_sum_layer
I0929 23:24:51.546764 25384 net.cpp:110] Creating Layer hidden_sum_layer
I0929 23:24:51.546769 25384 net.cpp:477] hidden_sum_layer <- data_blob
I0929 23:24:51.546778 25384 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I0929 23:24:51.547149 25384 net.cpp:155] Setting up hidden_sum_layer
I0929 23:24:51.547157 25384 net.cpp:163] Top shape: 20000 10 (200000)
I0929 23:24:51.547178 25384 layer_factory.hpp:76] Creating layer hidden_act_layer
I0929 23:24:51.547184 25384 net.cpp:110] Creating Layer hidden_act_layer
I0929 23:24:51.547186 25384 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I0929 23:24:51.547189 25384 net.cpp:433] hidden_act_layer -> hidden_act_blob
I0929 23:24:54.768182 25384 net.cpp:155] Setting up hidden_act_layer
I0929 23:24:54.768203 25384 net.cpp:163] Top shape: 20000 10 (200000)
I0929 23:24:54.768208 25384 layer_factory.hpp:76] Creating layer output_sum_layer
I0929 23:24:54.768218 25384 net.cpp:110] Creating Layer output_sum_layer
I0929 23:24:54.768230 25384 net.cpp:477] output_sum_layer <- hidden_act_blob
I0929 23:24:54.768235 25384 net.cpp:433] output_sum_layer -> output_sum_blob
I0929 23:24:54.768332 25384 net.cpp:155] Setting up output_sum_layer
I0929 23:24:54.768337 25384 net.cpp:163] Top shape: 20000 1 (20000)
I0929 23:24:54.768344 25384 layer_factory.hpp:76] Creating layer output_act_layer
I0929 23:24:54.768350 25384 net.cpp:110] Creating Layer output_act_layer
I0929 23:24:54.768352 25384 net.cpp:477] output_act_layer <- output_sum_blob
I0929 23:24:54.768354 25384 net.cpp:433] output_act_layer -> output_act_blob
I0929 23:24:54.768416 25384 net.cpp:155] Setting up output_act_layer
I0929 23:24:54.768445 25384 net.cpp:163] Top shape: 20000 1 (20000)
I0929 23:24:54.768447 25384 layer_factory.hpp:76] Creating layer error_layer
I0929 23:24:54.768461 25384 net.cpp:110] Creating Layer error_layer
I0929 23:24:54.768463 25384 net.cpp:477] error_layer <- output_act_blob
I0929 23:24:54.768466 25384 net.cpp:477] error_layer <- label_blob
I0929 23:24:54.768479 25384 net.cpp:433] error_layer -> error_blob
I0929 23:24:54.768509 25384 net.cpp:155] Setting up error_layer
I0929 23:24:54.768514 25384 net.cpp:163] Top shape: (1)
I0929 23:24:54.768517 25384 net.cpp:168]     with loss weight 1
I0929 23:24:54.768532 25384 net.cpp:236] error_layer needs backward computation.
I0929 23:24:54.768535 25384 net.cpp:236] output_act_layer needs backward computation.
I0929 23:24:54.768537 25384 net.cpp:236] output_sum_layer needs backward computation.
I0929 23:24:54.768538 25384 net.cpp:236] hidden_act_layer needs backward computation.
I0929 23:24:54.768540 25384 net.cpp:236] hidden_sum_layer needs backward computation.
I0929 23:24:54.768543 25384 net.cpp:240] data_layer does not need backward computation.
I0929 23:24:54.768545 25384 net.cpp:283] This network produces output error_blob
I0929 23:24:54.768550 25384 net.cpp:297] Network initialization done.
I0929 23:24:54.768551 25384 net.cpp:298] Memory required for data: 6720004
I0929 23:24:54.768676 25384 solver.cpp:187] Creating test net (#0) specified by net file: model/NNScore/nnscore_model_5.prototxt
I0929 23:24:54.768687 25384 net.cpp:339] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_layer
I0929 23:24:54.768719 25384 net.cpp:50] Initializing net from parameters: 
name: "model/NNScore/nnscore_model_5.prototxt"
state {
  phase: TEST
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TEST
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.5.test"
    batch_size: 2000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I0929 23:24:54.768740 25384 layer_factory.hpp:76] Creating layer data_layer
I0929 23:24:54.769954 25384 net.cpp:110] Creating Layer data_layer
I0929 23:24:54.769959 25384 net.cpp:433] data_layer -> data_blob
I0929 23:24:54.769963 25384 net.cpp:433] data_layer -> label_blob
I0929 23:24:54.770506 25390 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.5.test
I0929 23:24:54.770566 25384 data_layer.cpp:45] output data size: 2000,61,1,1
I0929 23:24:54.771924 25384 net.cpp:155] Setting up data_layer
I0929 23:24:54.771936 25384 net.cpp:163] Top shape: 2000 61 1 1 (122000)
I0929 23:24:54.771939 25384 net.cpp:163] Top shape: 2000 (2000)
I0929 23:24:54.771942 25384 layer_factory.hpp:76] Creating layer hidden_sum_layer
I0929 23:24:54.771950 25384 net.cpp:110] Creating Layer hidden_sum_layer
I0929 23:24:54.771951 25384 net.cpp:477] hidden_sum_layer <- data_blob
I0929 23:24:54.771955 25384 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I0929 23:24:54.772079 25384 net.cpp:155] Setting up hidden_sum_layer
I0929 23:24:54.772086 25384 net.cpp:163] Top shape: 2000 10 (20000)
I0929 23:24:54.772092 25384 layer_factory.hpp:76] Creating layer hidden_act_layer
I0929 23:24:54.772097 25384 net.cpp:110] Creating Layer hidden_act_layer
I0929 23:24:54.772100 25384 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I0929 23:24:54.772114 25384 net.cpp:433] hidden_act_layer -> hidden_act_blob
I0929 23:24:54.772294 25384 net.cpp:155] Setting up hidden_act_layer
I0929 23:24:54.772301 25384 net.cpp:163] Top shape: 2000 10 (20000)
I0929 23:24:54.772303 25384 layer_factory.hpp:76] Creating layer output_sum_layer
I0929 23:24:54.772308 25384 net.cpp:110] Creating Layer output_sum_layer
I0929 23:24:54.772310 25384 net.cpp:477] output_sum_layer <- hidden_act_blob
I0929 23:24:54.772313 25384 net.cpp:433] output_sum_layer -> output_sum_blob
I0929 23:24:54.772371 25384 net.cpp:155] Setting up output_sum_layer
I0929 23:24:54.772375 25384 net.cpp:163] Top shape: 2000 1 (2000)
I0929 23:24:54.772380 25384 layer_factory.hpp:76] Creating layer output_act_layer
I0929 23:24:54.772384 25384 net.cpp:110] Creating Layer output_act_layer
I0929 23:24:54.772387 25384 net.cpp:477] output_act_layer <- output_sum_blob
I0929 23:24:54.772388 25384 net.cpp:433] output_act_layer -> output_act_blob
I0929 23:24:54.772434 25384 net.cpp:155] Setting up output_act_layer
I0929 23:24:54.772439 25384 net.cpp:163] Top shape: 2000 1 (2000)
I0929 23:24:54.772441 25384 layer_factory.hpp:76] Creating layer error_layer
I0929 23:24:54.772444 25384 net.cpp:110] Creating Layer error_layer
I0929 23:24:54.772446 25384 net.cpp:477] error_layer <- output_act_blob
I0929 23:24:54.772449 25384 net.cpp:477] error_layer <- label_blob
I0929 23:24:54.772452 25384 net.cpp:433] error_layer -> error_blob
I0929 23:24:54.772470 25384 net.cpp:155] Setting up error_layer
I0929 23:24:54.772474 25384 net.cpp:163] Top shape: (1)
I0929 23:24:54.772475 25384 net.cpp:168]     with loss weight 1
I0929 23:24:54.772483 25384 net.cpp:236] error_layer needs backward computation.
I0929 23:24:54.772495 25384 net.cpp:236] output_act_layer needs backward computation.
I0929 23:24:54.772497 25384 net.cpp:236] output_sum_layer needs backward computation.
I0929 23:24:54.772500 25384 net.cpp:236] hidden_act_layer needs backward computation.
I0929 23:24:54.772501 25384 net.cpp:236] hidden_sum_layer needs backward computation.
I0929 23:24:54.772505 25384 net.cpp:240] data_layer does not need backward computation.
I0929 23:24:54.772505 25384 net.cpp:283] This network produces output error_blob
I0929 23:24:54.772511 25384 net.cpp:297] Network initialization done.
I0929 23:24:54.772512 25384 net.cpp:298] Memory required for data: 672004
I0929 23:24:54.772531 25384 solver.cpp:66] Solver scaffolding done.
I0929 23:24:54.772620 25384 caffe.cpp:212] Starting Optimization
I0929 23:24:54.772626 25384 solver.cpp:294] Solving model/NNScore/nnscore_model_5.prototxt
I0929 23:24:54.772627 25384 solver.cpp:295] Learning Rate Policy: fixed
I0929 23:24:54.772763 25384 solver.cpp:347] Iteration 0, Testing net (#0)
I0929 23:24:54.772814 25384 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:24:55.059361 25384 solver.cpp:415]     Test net output #0: error_blob = 0.145649 (* 1 = 0.145649 loss)
I0929 23:24:55.060847 25384 solver.cpp:243] Iteration 0, loss = 0.145579
I0929 23:24:55.060865 25384 solver.cpp:259]     Train net output #0: error_blob = 0.145579 (* 1 = 0.145579 loss)
I0929 23:24:55.060886 25384 solver.cpp:590] Iteration 0, lr = 0.01
I0929 23:24:57.600709 25384 solver.cpp:243] Iteration 100, loss = 0.120899
I0929 23:24:57.600749 25384 solver.cpp:259]     Train net output #0: error_blob = 0.120899 (* 1 = 0.120899 loss)
I0929 23:24:57.600754 25384 solver.cpp:590] Iteration 100, lr = 0.01
I0929 23:25:00.135910 25384 solver.cpp:243] Iteration 200, loss = 0.121605
I0929 23:25:00.135946 25384 solver.cpp:259]     Train net output #0: error_blob = 0.121605 (* 1 = 0.121605 loss)
I0929 23:25:00.135954 25384 solver.cpp:590] Iteration 200, lr = 0.01
I0929 23:25:02.725973 25384 solver.cpp:243] Iteration 300, loss = 0.121369
I0929 23:25:02.726013 25384 solver.cpp:259]     Train net output #0: error_blob = 0.121369 (* 1 = 0.121369 loss)
I0929 23:25:02.726019 25384 solver.cpp:590] Iteration 300, lr = 0.01
I0929 23:25:05.286312 25384 solver.cpp:243] Iteration 400, loss = 0.121004
I0929 23:25:05.286372 25384 solver.cpp:259]     Train net output #0: error_blob = 0.121004 (* 1 = 0.121004 loss)
I0929 23:25:05.286377 25384 solver.cpp:590] Iteration 400, lr = 0.01
I0929 23:25:07.861104 25384 solver.cpp:243] Iteration 500, loss = 0.120281
I0929 23:25:07.861142 25384 solver.cpp:259]     Train net output #0: error_blob = 0.120281 (* 1 = 0.120281 loss)
I0929 23:25:07.861148 25384 solver.cpp:590] Iteration 500, lr = 0.01
I0929 23:25:10.423421 25384 solver.cpp:243] Iteration 600, loss = 0.121244
I0929 23:25:10.423457 25384 solver.cpp:259]     Train net output #0: error_blob = 0.121244 (* 1 = 0.121244 loss)
I0929 23:25:10.423465 25384 solver.cpp:590] Iteration 600, lr = 0.01
I0929 23:25:12.974733 25384 solver.cpp:243] Iteration 700, loss = 0.120886
I0929 23:25:12.974772 25384 solver.cpp:259]     Train net output #0: error_blob = 0.120886 (* 1 = 0.120886 loss)
I0929 23:25:12.974776 25384 solver.cpp:590] Iteration 700, lr = 0.01
I0929 23:25:15.490212 25384 solver.cpp:243] Iteration 800, loss = 0.120124
I0929 23:25:15.490241 25384 solver.cpp:259]     Train net output #0: error_blob = 0.120124 (* 1 = 0.120124 loss)
I0929 23:25:15.490245 25384 solver.cpp:590] Iteration 800, lr = 0.01
I0929 23:25:18.048698 25384 solver.cpp:243] Iteration 900, loss = 0.120451
I0929 23:25:18.048728 25384 solver.cpp:259]     Train net output #0: error_blob = 0.120451 (* 1 = 0.120451 loss)
I0929 23:25:18.048733 25384 solver.cpp:590] Iteration 900, lr = 0.01
I0929 23:25:18.097132 25384 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:25:20.588145 25384 solver.cpp:347] Iteration 1000, Testing net (#0)
I0929 23:25:20.862066 25384 solver.cpp:415]     Test net output #0: error_blob = 0.124204 (* 1 = 0.124204 loss)
I0929 23:25:20.862743 25384 solver.cpp:243] Iteration 1000, loss = 0.121885
I0929 23:25:20.862787 25384 solver.cpp:259]     Train net output #0: error_blob = 0.121885 (* 1 = 0.121885 loss)
I0929 23:25:20.862795 25384 solver.cpp:590] Iteration 1000, lr = 0.01
I0929 23:25:23.398732 25384 solver.cpp:243] Iteration 1100, loss = 0.120081
I0929 23:25:23.398766 25384 solver.cpp:259]     Train net output #0: error_blob = 0.120081 (* 1 = 0.120081 loss)
I0929 23:25:23.398773 25384 solver.cpp:590] Iteration 1100, lr = 0.01
I0929 23:25:25.979517 25384 solver.cpp:243] Iteration 1200, loss = 0.119877
I0929 23:25:25.979555 25384 solver.cpp:259]     Train net output #0: error_blob = 0.119877 (* 1 = 0.119877 loss)
I0929 23:25:25.979562 25384 solver.cpp:590] Iteration 1200, lr = 0.01
I0929 23:25:28.549473 25384 solver.cpp:243] Iteration 1300, loss = 0.118118
I0929 23:25:28.549509 25384 solver.cpp:259]     Train net output #0: error_blob = 0.118118 (* 1 = 0.118118 loss)
I0929 23:25:28.549515 25384 solver.cpp:590] Iteration 1300, lr = 0.01
I0929 23:25:31.134446 25384 solver.cpp:243] Iteration 1400, loss = 0.118964
I0929 23:25:31.134486 25384 solver.cpp:259]     Train net output #0: error_blob = 0.118964 (* 1 = 0.118964 loss)
I0929 23:25:31.134492 25384 solver.cpp:590] Iteration 1400, lr = 0.01
I0929 23:25:33.697809 25384 solver.cpp:243] Iteration 1500, loss = 0.120872
I0929 23:25:33.697839 25384 solver.cpp:259]     Train net output #0: error_blob = 0.120872 (* 1 = 0.120872 loss)
I0929 23:25:33.697844 25384 solver.cpp:590] Iteration 1500, lr = 0.01
I0929 23:25:36.264621 25384 solver.cpp:243] Iteration 1600, loss = 0.11985
I0929 23:25:36.264650 25384 solver.cpp:259]     Train net output #0: error_blob = 0.11985 (* 1 = 0.11985 loss)
I0929 23:25:36.264655 25384 solver.cpp:590] Iteration 1600, lr = 0.01
I0929 23:25:38.877737 25384 solver.cpp:243] Iteration 1700, loss = 0.118701
I0929 23:25:38.877763 25384 solver.cpp:259]     Train net output #0: error_blob = 0.118701 (* 1 = 0.118701 loss)
I0929 23:25:38.877768 25384 solver.cpp:590] Iteration 1700, lr = 0.01
I0929 23:25:41.468439 25384 solver.cpp:243] Iteration 1800, loss = 0.119596
I0929 23:25:41.468468 25384 solver.cpp:259]     Train net output #0: error_blob = 0.119596 (* 1 = 0.119596 loss)
I0929 23:25:41.468473 25384 solver.cpp:590] Iteration 1800, lr = 0.01
I0929 23:25:41.674233 25384 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:25:44.013839 25384 solver.cpp:243] Iteration 1900, loss = 0.119871
I0929 23:25:44.013869 25384 solver.cpp:259]     Train net output #0: error_blob = 0.119871 (* 1 = 0.119871 loss)
I0929 23:25:44.013872 25384 solver.cpp:590] Iteration 1900, lr = 0.01
I0929 23:25:46.597235 25384 solver.cpp:347] Iteration 2000, Testing net (#0)
I0929 23:25:46.907212 25384 solver.cpp:415]     Test net output #0: error_blob = 0.123964 (* 1 = 0.123964 loss)
I0929 23:25:46.907901 25384 solver.cpp:243] Iteration 2000, loss = 0.117942
I0929 23:25:46.907938 25384 solver.cpp:259]     Train net output #0: error_blob = 0.117942 (* 1 = 0.117942 loss)
I0929 23:25:46.907960 25384 solver.cpp:590] Iteration 2000, lr = 0.01
I0929 23:25:49.506202 25384 solver.cpp:243] Iteration 2100, loss = 0.118684
I0929 23:25:49.506247 25384 solver.cpp:259]     Train net output #0: error_blob = 0.118684 (* 1 = 0.118684 loss)
I0929 23:25:49.506254 25384 solver.cpp:590] Iteration 2100, lr = 0.01
I0929 23:25:52.080193 25384 solver.cpp:243] Iteration 2200, loss = 0.11902
I0929 23:25:52.081364 25384 solver.cpp:259]     Train net output #0: error_blob = 0.11902 (* 1 = 0.11902 loss)
I0929 23:25:52.081372 25384 solver.cpp:590] Iteration 2200, lr = 0.01
I0929 23:25:54.683848 25384 solver.cpp:243] Iteration 2300, loss = 0.118253
I0929 23:25:54.683888 25384 solver.cpp:259]     Train net output #0: error_blob = 0.118253 (* 1 = 0.118253 loss)
I0929 23:25:54.683893 25384 solver.cpp:590] Iteration 2300, lr = 0.01
I0929 23:25:57.275212 25384 solver.cpp:243] Iteration 2400, loss = 0.117804
I0929 23:25:57.275249 25384 solver.cpp:259]     Train net output #0: error_blob = 0.117804 (* 1 = 0.117804 loss)
I0929 23:25:57.275256 25384 solver.cpp:590] Iteration 2400, lr = 0.01
I0929 23:25:59.851608 25384 solver.cpp:243] Iteration 2500, loss = 0.120476
I0929 23:25:59.851644 25384 solver.cpp:259]     Train net output #0: error_blob = 0.120476 (* 1 = 0.120476 loss)
I0929 23:25:59.851650 25384 solver.cpp:590] Iteration 2500, lr = 0.01
I0929 23:26:02.475575 25384 solver.cpp:243] Iteration 2600, loss = 0.118822
I0929 23:26:02.475613 25384 solver.cpp:259]     Train net output #0: error_blob = 0.118822 (* 1 = 0.118822 loss)
I0929 23:26:02.475620 25384 solver.cpp:590] Iteration 2600, lr = 0.01
I0929 23:26:05.026526 25384 solver.cpp:243] Iteration 2700, loss = 0.117655
I0929 23:26:05.026556 25384 solver.cpp:259]     Train net output #0: error_blob = 0.117655 (* 1 = 0.117655 loss)
I0929 23:26:05.026561 25384 solver.cpp:590] Iteration 2700, lr = 0.01
I0929 23:26:05.381742 25384 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:26:07.637528 25384 solver.cpp:243] Iteration 2800, loss = 0.117623
I0929 23:26:07.637567 25384 solver.cpp:259]     Train net output #0: error_blob = 0.117623 (* 1 = 0.117623 loss)
I0929 23:26:07.637572 25384 solver.cpp:590] Iteration 2800, lr = 0.01
I0929 23:26:10.221635 25384 solver.cpp:243] Iteration 2900, loss = 0.11778
I0929 23:26:10.221674 25384 solver.cpp:259]     Train net output #0: error_blob = 0.11778 (* 1 = 0.11778 loss)
I0929 23:26:10.221679 25384 solver.cpp:590] Iteration 2900, lr = 0.01
I0929 23:26:12.802842 25384 solver.cpp:347] Iteration 3000, Testing net (#0)
I0929 23:26:13.075760 25384 solver.cpp:415]     Test net output #0: error_blob = 0.119156 (* 1 = 0.119156 loss)
I0929 23:26:13.076465 25384 solver.cpp:243] Iteration 3000, loss = 0.119433
I0929 23:26:13.076508 25384 solver.cpp:259]     Train net output #0: error_blob = 0.119433 (* 1 = 0.119433 loss)
I0929 23:26:13.076517 25384 solver.cpp:590] Iteration 3000, lr = 0.01
I0929 23:26:15.639349 25384 solver.cpp:243] Iteration 3100, loss = 0.116886
I0929 23:26:15.639379 25384 solver.cpp:259]     Train net output #0: error_blob = 0.116886 (* 1 = 0.116886 loss)
I0929 23:26:15.639384 25384 solver.cpp:590] Iteration 3100, lr = 0.01
I0929 23:26:18.235038 25384 solver.cpp:243] Iteration 3200, loss = 0.117736
I0929 23:26:18.235083 25384 solver.cpp:259]     Train net output #0: error_blob = 0.117736 (* 1 = 0.117736 loss)
I0929 23:26:18.235090 25384 solver.cpp:590] Iteration 3200, lr = 0.01
I0929 23:26:20.792532 25384 solver.cpp:243] Iteration 3300, loss = 0.119508
I0929 23:26:20.792560 25384 solver.cpp:259]     Train net output #0: error_blob = 0.119508 (* 1 = 0.119508 loss)
I0929 23:26:20.792567 25384 solver.cpp:590] Iteration 3300, lr = 0.01
I0929 23:26:23.427309 25384 solver.cpp:243] Iteration 3400, loss = 0.118151
I0929 23:26:23.427436 25384 solver.cpp:259]     Train net output #0: error_blob = 0.118151 (* 1 = 0.118151 loss)
I0929 23:26:23.427444 25384 solver.cpp:590] Iteration 3400, lr = 0.01
I0929 23:26:26.013031 25384 solver.cpp:243] Iteration 3500, loss = 0.115513
I0929 23:26:26.013059 25384 solver.cpp:259]     Train net output #0: error_blob = 0.115513 (* 1 = 0.115513 loss)
I0929 23:26:26.013064 25384 solver.cpp:590] Iteration 3500, lr = 0.01
I0929 23:26:28.642694 25384 solver.cpp:243] Iteration 3600, loss = 0.122019
I0929 23:26:28.642738 25384 solver.cpp:259]     Train net output #0: error_blob = 0.122019 (* 1 = 0.122019 loss)
I0929 23:26:28.642745 25384 solver.cpp:590] Iteration 3600, lr = 0.01
I0929 23:26:29.156507 25384 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:26:31.266196 25384 solver.cpp:243] Iteration 3700, loss = 0.117683
I0929 23:26:31.266228 25384 solver.cpp:259]     Train net output #0: error_blob = 0.117683 (* 1 = 0.117683 loss)
I0929 23:26:31.266235 25384 solver.cpp:590] Iteration 3700, lr = 0.01
I0929 23:26:33.844362 25384 solver.cpp:243] Iteration 3800, loss = 0.130425
I0929 23:26:33.844408 25384 solver.cpp:259]     Train net output #0: error_blob = 0.130425 (* 1 = 0.130425 loss)
I0929 23:26:33.844415 25384 solver.cpp:590] Iteration 3800, lr = 0.01
I0929 23:26:36.417057 25384 solver.cpp:243] Iteration 3900, loss = 0.116111
I0929 23:26:36.417096 25384 solver.cpp:259]     Train net output #0: error_blob = 0.116111 (* 1 = 0.116111 loss)
I0929 23:26:36.417101 25384 solver.cpp:590] Iteration 3900, lr = 0.01
I0929 23:26:38.989972 25384 solver.cpp:347] Iteration 4000, Testing net (#0)
I0929 23:26:39.274597 25384 solver.cpp:415]     Test net output #0: error_blob = 0.11807 (* 1 = 0.11807 loss)
I0929 23:26:39.275301 25384 solver.cpp:243] Iteration 4000, loss = 0.118598
I0929 23:26:39.275316 25384 solver.cpp:259]     Train net output #0: error_blob = 0.118598 (* 1 = 0.118598 loss)
I0929 23:26:39.275324 25384 solver.cpp:590] Iteration 4000, lr = 0.01
I0929 23:26:41.778695 25384 solver.cpp:243] Iteration 4100, loss = 0.117327
I0929 23:26:41.778743 25384 solver.cpp:259]     Train net output #0: error_blob = 0.117327 (* 1 = 0.117327 loss)
I0929 23:26:41.778753 25384 solver.cpp:590] Iteration 4100, lr = 0.01
I0929 23:26:44.352771 25384 solver.cpp:243] Iteration 4200, loss = 0.120737
I0929 23:26:44.352800 25384 solver.cpp:259]     Train net output #0: error_blob = 0.120737 (* 1 = 0.120737 loss)
I0929 23:26:44.352805 25384 solver.cpp:590] Iteration 4200, lr = 0.01
I0929 23:26:46.936782 25384 solver.cpp:243] Iteration 4300, loss = 0.115184
I0929 23:26:46.936827 25384 solver.cpp:259]     Train net output #0: error_blob = 0.115184 (* 1 = 0.115184 loss)
I0929 23:26:46.936836 25384 solver.cpp:590] Iteration 4300, lr = 0.01
I0929 23:26:49.509013 25384 solver.cpp:243] Iteration 4400, loss = 0.11735
I0929 23:26:49.509049 25384 solver.cpp:259]     Train net output #0: error_blob = 0.11735 (* 1 = 0.11735 loss)
I0929 23:26:49.509057 25384 solver.cpp:590] Iteration 4400, lr = 0.01
I0929 23:26:52.105834 25384 solver.cpp:243] Iteration 4500, loss = 0.117892
I0929 23:26:52.105862 25384 solver.cpp:259]     Train net output #0: error_blob = 0.117892 (* 1 = 0.117892 loss)
I0929 23:26:52.105866 25384 solver.cpp:590] Iteration 4500, lr = 0.01
I0929 23:26:52.773525 25384 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:26:54.709983 25384 solver.cpp:243] Iteration 4600, loss = 0.116125
I0929 23:26:54.710063 25384 solver.cpp:259]     Train net output #0: error_blob = 0.116125 (* 1 = 0.116125 loss)
I0929 23:26:54.710070 25384 solver.cpp:590] Iteration 4600, lr = 0.01
I0929 23:26:57.334990 25384 solver.cpp:243] Iteration 4700, loss = 0.118594
I0929 23:26:57.335018 25384 solver.cpp:259]     Train net output #0: error_blob = 0.118594 (* 1 = 0.118594 loss)
I0929 23:26:57.335023 25384 solver.cpp:590] Iteration 4700, lr = 0.01
I0929 23:26:59.928805 25384 solver.cpp:243] Iteration 4800, loss = 0.11846
I0929 23:26:59.928843 25384 solver.cpp:259]     Train net output #0: error_blob = 0.11846 (* 1 = 0.11846 loss)
I0929 23:26:59.928851 25384 solver.cpp:590] Iteration 4800, lr = 0.01
I0929 23:27:02.535821 25384 solver.cpp:243] Iteration 4900, loss = 0.118998
I0929 23:27:02.535851 25384 solver.cpp:259]     Train net output #0: error_blob = 0.118998 (* 1 = 0.118998 loss)
I0929 23:27:02.535856 25384 solver.cpp:590] Iteration 4900, lr = 0.01
I0929 23:27:05.162207 25384 solver.cpp:347] Iteration 5000, Testing net (#0)
I0929 23:27:05.467988 25384 solver.cpp:415]     Test net output #0: error_blob = 0.116456 (* 1 = 0.116456 loss)
I0929 23:27:05.468607 25384 solver.cpp:243] Iteration 5000, loss = 0.113525
I0929 23:27:05.468623 25384 solver.cpp:259]     Train net output #0: error_blob = 0.113525 (* 1 = 0.113525 loss)
I0929 23:27:05.468628 25384 solver.cpp:590] Iteration 5000, lr = 0.01
I0929 23:27:08.007894 25384 solver.cpp:243] Iteration 5100, loss = 0.116545
I0929 23:27:08.007922 25384 solver.cpp:259]     Train net output #0: error_blob = 0.116545 (* 1 = 0.116545 loss)
I0929 23:27:08.007927 25384 solver.cpp:590] Iteration 5100, lr = 0.01
I0929 23:27:10.598330 25384 solver.cpp:243] Iteration 5200, loss = 0.117364
I0929 23:27:10.598371 25384 solver.cpp:259]     Train net output #0: error_blob = 0.117364 (* 1 = 0.117364 loss)
I0929 23:27:10.598377 25384 solver.cpp:590] Iteration 5200, lr = 0.01
I0929 23:27:13.207715 25384 solver.cpp:243] Iteration 5300, loss = 0.116353
I0929 23:27:13.207753 25384 solver.cpp:259]     Train net output #0: error_blob = 0.116353 (* 1 = 0.116353 loss)
I0929 23:27:13.207761 25384 solver.cpp:590] Iteration 5300, lr = 0.01
I0929 23:27:15.810569 25384 solver.cpp:243] Iteration 5400, loss = 0.116139
I0929 23:27:15.810598 25384 solver.cpp:259]     Train net output #0: error_blob = 0.116139 (* 1 = 0.116139 loss)
I0929 23:27:15.810605 25384 solver.cpp:590] Iteration 5400, lr = 0.01
I0929 23:27:16.637055 25384 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:27:18.411141 25384 solver.cpp:243] Iteration 5500, loss = 0.11561
I0929 23:27:18.411171 25384 solver.cpp:259]     Train net output #0: error_blob = 0.11561 (* 1 = 0.11561 loss)
I0929 23:27:18.411176 25384 solver.cpp:590] Iteration 5500, lr = 0.01
I0929 23:27:20.998412 25384 solver.cpp:243] Iteration 5600, loss = 0.117239
I0929 23:27:20.998450 25384 solver.cpp:259]     Train net output #0: error_blob = 0.117239 (* 1 = 0.117239 loss)
I0929 23:27:20.998456 25384 solver.cpp:590] Iteration 5600, lr = 0.01
I0929 23:27:23.569708 25384 solver.cpp:243] Iteration 5700, loss = 0.115308
I0929 23:27:23.569746 25384 solver.cpp:259]     Train net output #0: error_blob = 0.115308 (* 1 = 0.115308 loss)
I0929 23:27:23.569751 25384 solver.cpp:590] Iteration 5700, lr = 0.01
I0929 23:27:26.145789 25384 solver.cpp:243] Iteration 5800, loss = 0.113125
I0929 23:27:26.147511 25384 solver.cpp:259]     Train net output #0: error_blob = 0.113125 (* 1 = 0.113125 loss)
I0929 23:27:26.147521 25384 solver.cpp:590] Iteration 5800, lr = 0.01
I0929 23:27:28.725530 25384 solver.cpp:243] Iteration 5900, loss = 0.11937
I0929 23:27:28.725561 25384 solver.cpp:259]     Train net output #0: error_blob = 0.11937 (* 1 = 0.11937 loss)
I0929 23:27:28.725566 25384 solver.cpp:590] Iteration 5900, lr = 0.01
I0929 23:27:31.213922 25384 solver.cpp:347] Iteration 6000, Testing net (#0)
I0929 23:27:31.527155 25384 solver.cpp:415]     Test net output #0: error_blob = 0.1168 (* 1 = 0.1168 loss)
I0929 23:27:31.527792 25384 solver.cpp:243] Iteration 6000, loss = 0.117445
I0929 23:27:31.527806 25384 solver.cpp:259]     Train net output #0: error_blob = 0.117445 (* 1 = 0.117445 loss)
I0929 23:27:31.527812 25384 solver.cpp:590] Iteration 6000, lr = 0.01
I0929 23:27:34.074466 25384 solver.cpp:243] Iteration 6100, loss = 0.114528
I0929 23:27:34.074497 25384 solver.cpp:259]     Train net output #0: error_blob = 0.114528 (* 1 = 0.114528 loss)
I0929 23:27:34.074503 25384 solver.cpp:590] Iteration 6100, lr = 0.01
I0929 23:27:36.575348 25384 solver.cpp:243] Iteration 6200, loss = 0.115576
I0929 23:27:36.575379 25384 solver.cpp:259]     Train net output #0: error_blob = 0.115576 (* 1 = 0.115576 loss)
I0929 23:27:36.575387 25384 solver.cpp:590] Iteration 6200, lr = 0.01
I0929 23:27:39.102473 25384 solver.cpp:243] Iteration 6300, loss = 0.118151
I0929 23:27:39.102504 25384 solver.cpp:259]     Train net output #0: error_blob = 0.118151 (* 1 = 0.118151 loss)
I0929 23:27:39.102509 25384 solver.cpp:590] Iteration 6300, lr = 0.01
I0929 23:27:40.079771 25384 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:27:41.643745 25384 solver.cpp:243] Iteration 6400, loss = 0.116841
I0929 23:27:41.643776 25384 solver.cpp:259]     Train net output #0: error_blob = 0.116841 (* 1 = 0.116841 loss)
I0929 23:27:41.643781 25384 solver.cpp:590] Iteration 6400, lr = 0.01
I0929 23:27:44.220703 25384 solver.cpp:243] Iteration 6500, loss = 0.112497
I0929 23:27:44.220742 25384 solver.cpp:259]     Train net output #0: error_blob = 0.112497 (* 1 = 0.112497 loss)
I0929 23:27:44.220747 25384 solver.cpp:590] Iteration 6500, lr = 0.01
I0929 23:27:46.737373 25384 solver.cpp:243] Iteration 6600, loss = 0.115621
I0929 23:27:46.737404 25384 solver.cpp:259]     Train net output #0: error_blob = 0.115621 (* 1 = 0.115621 loss)
I0929 23:27:46.737411 25384 solver.cpp:590] Iteration 6600, lr = 0.01
I0929 23:27:49.293607 25384 solver.cpp:243] Iteration 6700, loss = 0.120102
I0929 23:27:49.293638 25384 solver.cpp:259]     Train net output #0: error_blob = 0.120102 (* 1 = 0.120102 loss)
I0929 23:27:49.293645 25384 solver.cpp:590] Iteration 6700, lr = 0.01
I0929 23:27:51.860388 25384 solver.cpp:243] Iteration 6800, loss = 0.11788
I0929 23:27:51.860419 25384 solver.cpp:259]     Train net output #0: error_blob = 0.11788 (* 1 = 0.11788 loss)
I0929 23:27:51.860424 25384 solver.cpp:590] Iteration 6800, lr = 0.01
I0929 23:27:54.412171 25384 solver.cpp:243] Iteration 6900, loss = 0.113256
I0929 23:27:54.412200 25384 solver.cpp:259]     Train net output #0: error_blob = 0.113256 (* 1 = 0.113256 loss)
I0929 23:27:54.412205 25384 solver.cpp:590] Iteration 6900, lr = 0.01
I0929 23:27:56.889732 25384 solver.cpp:347] Iteration 7000, Testing net (#0)
I0929 23:27:57.176913 25384 solver.cpp:415]     Test net output #0: error_blob = 0.119414 (* 1 = 0.119414 loss)
I0929 23:27:57.177595 25384 solver.cpp:243] Iteration 7000, loss = 0.121545
I0929 23:27:57.177611 25384 solver.cpp:259]     Train net output #0: error_blob = 0.121545 (* 1 = 0.121545 loss)
I0929 23:27:57.177618 25384 solver.cpp:590] Iteration 7000, lr = 0.01
I0929 23:27:59.758534 25384 solver.cpp:243] Iteration 7100, loss = 0.118348
I0929 23:27:59.758564 25384 solver.cpp:259]     Train net output #0: error_blob = 0.118348 (* 1 = 0.118348 loss)
I0929 23:27:59.758569 25384 solver.cpp:590] Iteration 7100, lr = 0.01
I0929 23:28:02.329191 25384 solver.cpp:243] Iteration 7200, loss = 0.114683
I0929 23:28:02.329229 25384 solver.cpp:259]     Train net output #0: error_blob = 0.114683 (* 1 = 0.114683 loss)
I0929 23:28:02.329234 25384 solver.cpp:590] Iteration 7200, lr = 0.01
I0929 23:28:03.453794 25384 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:28:04.886610 25384 solver.cpp:243] Iteration 7300, loss = 0.114265
I0929 23:28:04.886651 25384 solver.cpp:259]     Train net output #0: error_blob = 0.114265 (* 1 = 0.114265 loss)
I0929 23:28:04.886657 25384 solver.cpp:590] Iteration 7300, lr = 0.01
I0929 23:28:07.455087 25384 solver.cpp:243] Iteration 7400, loss = 0.116062
I0929 23:28:07.455116 25384 solver.cpp:259]     Train net output #0: error_blob = 0.116062 (* 1 = 0.116062 loss)
I0929 23:28:07.455121 25384 solver.cpp:590] Iteration 7400, lr = 0.01
I0929 23:28:10.051444 25384 solver.cpp:243] Iteration 7500, loss = 0.118532
I0929 23:28:10.051488 25384 solver.cpp:259]     Train net output #0: error_blob = 0.118532 (* 1 = 0.118532 loss)
I0929 23:28:10.051496 25384 solver.cpp:590] Iteration 7500, lr = 0.01
I0929 23:28:12.635805 25384 solver.cpp:243] Iteration 7600, loss = 0.11397
I0929 23:28:12.635840 25384 solver.cpp:259]     Train net output #0: error_blob = 0.11397 (* 1 = 0.11397 loss)
I0929 23:28:12.635848 25384 solver.cpp:590] Iteration 7600, lr = 0.01
I0929 23:28:15.263496 25384 solver.cpp:243] Iteration 7700, loss = 0.114986
I0929 23:28:15.263528 25384 solver.cpp:259]     Train net output #0: error_blob = 0.114986 (* 1 = 0.114986 loss)
I0929 23:28:15.263535 25384 solver.cpp:590] Iteration 7700, lr = 0.01
I0929 23:28:17.879830 25384 solver.cpp:243] Iteration 7800, loss = 0.117749
I0929 23:28:17.879871 25384 solver.cpp:259]     Train net output #0: error_blob = 0.117749 (* 1 = 0.117749 loss)
I0929 23:28:17.879878 25384 solver.cpp:590] Iteration 7800, lr = 0.01
I0929 23:28:20.399972 25384 solver.cpp:243] Iteration 7900, loss = 0.11643
I0929 23:28:20.400012 25384 solver.cpp:259]     Train net output #0: error_blob = 0.11643 (* 1 = 0.11643 loss)
I0929 23:28:20.400018 25384 solver.cpp:590] Iteration 7900, lr = 0.01
I0929 23:28:22.955507 25384 solver.cpp:347] Iteration 8000, Testing net (#0)
I0929 23:28:23.233919 25384 solver.cpp:415]     Test net output #0: error_blob = 0.113592 (* 1 = 0.113592 loss)
I0929 23:28:23.234583 25384 solver.cpp:243] Iteration 8000, loss = 0.112324
I0929 23:28:23.234618 25384 solver.cpp:259]     Train net output #0: error_blob = 0.112324 (* 1 = 0.112324 loss)
I0929 23:28:23.234638 25384 solver.cpp:590] Iteration 8000, lr = 0.01
I0929 23:28:25.783479 25384 solver.cpp:243] Iteration 8100, loss = 0.1142
I0929 23:28:25.783514 25384 solver.cpp:259]     Train net output #0: error_blob = 0.1142 (* 1 = 0.1142 loss)
I0929 23:28:25.783521 25384 solver.cpp:590] Iteration 8100, lr = 0.01
I0929 23:28:27.100603 25384 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:28:28.385886 25384 solver.cpp:243] Iteration 8200, loss = 0.117983
I0929 23:28:28.385916 25384 solver.cpp:259]     Train net output #0: error_blob = 0.117983 (* 1 = 0.117983 loss)
I0929 23:28:28.385921 25384 solver.cpp:590] Iteration 8200, lr = 0.01
I0929 23:28:30.992238 25384 solver.cpp:243] Iteration 8300, loss = 0.119509
I0929 23:28:30.992275 25384 solver.cpp:259]     Train net output #0: error_blob = 0.119509 (* 1 = 0.119509 loss)
I0929 23:28:30.992281 25384 solver.cpp:590] Iteration 8300, lr = 0.01
I0929 23:28:33.594358 25384 solver.cpp:243] Iteration 8400, loss = 0.113945
I0929 23:28:33.594398 25384 solver.cpp:259]     Train net output #0: error_blob = 0.113945 (* 1 = 0.113945 loss)
I0929 23:28:33.594404 25384 solver.cpp:590] Iteration 8400, lr = 0.01
I0929 23:28:36.105180 25384 solver.cpp:243] Iteration 8500, loss = 0.116495
I0929 23:28:36.105207 25384 solver.cpp:259]     Train net output #0: error_blob = 0.116495 (* 1 = 0.116495 loss)
I0929 23:28:36.105213 25384 solver.cpp:590] Iteration 8500, lr = 0.01
I0929 23:28:38.696949 25384 solver.cpp:243] Iteration 8600, loss = 0.117133
I0929 23:28:38.696979 25384 solver.cpp:259]     Train net output #0: error_blob = 0.117133 (* 1 = 0.117133 loss)
I0929 23:28:38.696985 25384 solver.cpp:590] Iteration 8600, lr = 0.01
I0929 23:28:41.248447 25384 solver.cpp:243] Iteration 8700, loss = 0.116326
I0929 23:28:41.248477 25384 solver.cpp:259]     Train net output #0: error_blob = 0.116326 (* 1 = 0.116326 loss)
I0929 23:28:41.248482 25384 solver.cpp:590] Iteration 8700, lr = 0.01
I0929 23:28:43.857193 25384 solver.cpp:243] Iteration 8800, loss = 0.11439
I0929 23:28:43.857233 25384 solver.cpp:259]     Train net output #0: error_blob = 0.11439 (* 1 = 0.11439 loss)
I0929 23:28:43.857237 25384 solver.cpp:590] Iteration 8800, lr = 0.01
I0929 23:28:46.376763 25384 solver.cpp:243] Iteration 8900, loss = 0.117756
I0929 23:28:46.376793 25384 solver.cpp:259]     Train net output #0: error_blob = 0.117756 (* 1 = 0.117756 loss)
I0929 23:28:46.376799 25384 solver.cpp:590] Iteration 8900, lr = 0.01
I0929 23:28:48.938266 25384 solver.cpp:347] Iteration 9000, Testing net (#0)
I0929 23:28:49.238912 25384 solver.cpp:415]     Test net output #0: error_blob = 0.115858 (* 1 = 0.115858 loss)
I0929 23:28:49.239573 25384 solver.cpp:243] Iteration 9000, loss = 0.117556
I0929 23:28:49.239586 25384 solver.cpp:259]     Train net output #0: error_blob = 0.117556 (* 1 = 0.117556 loss)
I0929 23:28:49.239593 25384 solver.cpp:590] Iteration 9000, lr = 0.01
I0929 23:28:50.668684 25384 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:28:51.834339 25384 solver.cpp:243] Iteration 9100, loss = 0.118585
I0929 23:28:51.834374 25384 solver.cpp:259]     Train net output #0: error_blob = 0.118585 (* 1 = 0.118585 loss)
I0929 23:28:51.834383 25384 solver.cpp:590] Iteration 9100, lr = 0.01
I0929 23:28:54.387507 25384 solver.cpp:243] Iteration 9200, loss = 0.11603
I0929 23:28:54.387548 25384 solver.cpp:259]     Train net output #0: error_blob = 0.11603 (* 1 = 0.11603 loss)
I0929 23:28:54.387554 25384 solver.cpp:590] Iteration 9200, lr = 0.01
I0929 23:28:57.024791 25384 solver.cpp:243] Iteration 9300, loss = 0.117577
I0929 23:28:57.024818 25384 solver.cpp:259]     Train net output #0: error_blob = 0.117577 (* 1 = 0.117577 loss)
I0929 23:28:57.024823 25384 solver.cpp:590] Iteration 9300, lr = 0.01
I0929 23:28:59.600260 25384 solver.cpp:243] Iteration 9400, loss = 0.117342
I0929 23:28:59.600394 25384 solver.cpp:259]     Train net output #0: error_blob = 0.117342 (* 1 = 0.117342 loss)
I0929 23:28:59.600410 25384 solver.cpp:590] Iteration 9400, lr = 0.01
I0929 23:29:02.180645 25384 solver.cpp:243] Iteration 9500, loss = 0.111617
I0929 23:29:02.180675 25384 solver.cpp:259]     Train net output #0: error_blob = 0.111617 (* 1 = 0.111617 loss)
I0929 23:29:02.180680 25384 solver.cpp:590] Iteration 9500, lr = 0.01
I0929 23:29:04.736418 25384 solver.cpp:243] Iteration 9600, loss = 0.117279
I0929 23:29:04.736445 25384 solver.cpp:259]     Train net output #0: error_blob = 0.117279 (* 1 = 0.117279 loss)
I0929 23:29:04.736451 25384 solver.cpp:590] Iteration 9600, lr = 0.01
I0929 23:29:07.283241 25384 solver.cpp:243] Iteration 9700, loss = 0.117813
I0929 23:29:07.283270 25384 solver.cpp:259]     Train net output #0: error_blob = 0.117813 (* 1 = 0.117813 loss)
I0929 23:29:07.283277 25384 solver.cpp:590] Iteration 9700, lr = 0.01
I0929 23:29:09.871230 25384 solver.cpp:243] Iteration 9800, loss = 0.11645
I0929 23:29:09.871263 25384 solver.cpp:259]     Train net output #0: error_blob = 0.11645 (* 1 = 0.11645 loss)
I0929 23:29:09.871269 25384 solver.cpp:590] Iteration 9800, lr = 0.01
I0929 23:29:12.442369 25384 solver.cpp:243] Iteration 9900, loss = 0.112986
I0929 23:29:12.442399 25384 solver.cpp:259]     Train net output #0: error_blob = 0.112986 (* 1 = 0.112986 loss)
I0929 23:29:12.442404 25384 solver.cpp:590] Iteration 9900, lr = 0.01
I0929 23:29:14.999516 25384 solver.cpp:468] Snapshotting to binary proto file _iter_10000.caffemodel
I0929 23:29:15.000638 25384 solver.cpp:753] Snapshotting solver state to binary proto file _iter_10000.solverstate
I0929 23:29:15.025635 25384 solver.cpp:327] Iteration 10000, loss = 0.119659
I0929 23:29:15.025657 25384 solver.cpp:347] Iteration 10000, Testing net (#0)
I0929 23:29:15.254088 25384 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:29:15.358695 25384 solver.cpp:415]     Test net output #0: error_blob = 0.116535 (* 1 = 0.116535 loss)
I0929 23:29:15.358716 25384 solver.cpp:332] Optimization Done.
I0929 23:29:15.358718 25384 caffe.cpp:215] Optimization Done.
I0929 23:29:15.427448 25393 caffe.cpp:184] Using GPUs 0
I0929 23:29:15.986837 25393 solver.cpp:54] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "fixed"
momentum: 0.9
solver_mode: GPU
device_id: 0
net: "model/NNScore/nnscore_model_6.prototxt"
I0929 23:29:15.986872 25393 solver.cpp:97] Creating training net from net file: model/NNScore/nnscore_model_6.prototxt
I0929 23:29:15.987031 25393 net.cpp:339] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_layer
I0929 23:29:15.987074 25393 net.cpp:50] Initializing net from parameters: 
name: "model/NNScore/nnscore_model_6.prototxt"
state {
  phase: TRAIN
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TRAIN
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.6.train"
    batch_size: 20000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I0929 23:29:15.987133 25393 layer_factory.hpp:76] Creating layer data_layer
I0929 23:29:16.000547 25393 net.cpp:110] Creating Layer data_layer
I0929 23:29:16.000569 25393 net.cpp:433] data_layer -> data_blob
I0929 23:29:16.000597 25393 net.cpp:433] data_layer -> label_blob
I0929 23:29:16.001174 25397 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.6.train
I0929 23:29:16.683796 25393 data_layer.cpp:45] output data size: 20000,61,1,1
I0929 23:29:16.688784 25393 net.cpp:155] Setting up data_layer
I0929 23:29:16.688819 25393 net.cpp:163] Top shape: 20000 61 1 1 (1220000)
I0929 23:29:16.688824 25393 net.cpp:163] Top shape: 20000 (20000)
I0929 23:29:16.688832 25393 layer_factory.hpp:76] Creating layer hidden_sum_layer
I0929 23:29:16.688848 25393 net.cpp:110] Creating Layer hidden_sum_layer
I0929 23:29:16.688856 25393 net.cpp:477] hidden_sum_layer <- data_blob
I0929 23:29:16.688869 25393 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I0929 23:29:16.689232 25393 net.cpp:155] Setting up hidden_sum_layer
I0929 23:29:16.689240 25393 net.cpp:163] Top shape: 20000 10 (200000)
I0929 23:29:16.689256 25393 layer_factory.hpp:76] Creating layer hidden_act_layer
I0929 23:29:16.689268 25393 net.cpp:110] Creating Layer hidden_act_layer
I0929 23:29:16.689272 25393 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I0929 23:29:16.689277 25393 net.cpp:433] hidden_act_layer -> hidden_act_blob
I0929 23:29:19.900230 25393 net.cpp:155] Setting up hidden_act_layer
I0929 23:29:19.900257 25393 net.cpp:163] Top shape: 20000 10 (200000)
I0929 23:29:19.900264 25393 layer_factory.hpp:76] Creating layer output_sum_layer
I0929 23:29:19.900286 25393 net.cpp:110] Creating Layer output_sum_layer
I0929 23:29:19.900291 25393 net.cpp:477] output_sum_layer <- hidden_act_blob
I0929 23:29:19.900301 25393 net.cpp:433] output_sum_layer -> output_sum_blob
I0929 23:29:19.900404 25393 net.cpp:155] Setting up output_sum_layer
I0929 23:29:19.900411 25393 net.cpp:163] Top shape: 20000 1 (20000)
I0929 23:29:19.900432 25393 layer_factory.hpp:76] Creating layer output_act_layer
I0929 23:29:19.900441 25393 net.cpp:110] Creating Layer output_act_layer
I0929 23:29:19.900445 25393 net.cpp:477] output_act_layer <- output_sum_blob
I0929 23:29:19.900449 25393 net.cpp:433] output_act_layer -> output_act_blob
I0929 23:29:19.900527 25393 net.cpp:155] Setting up output_act_layer
I0929 23:29:19.900543 25393 net.cpp:163] Top shape: 20000 1 (20000)
I0929 23:29:19.900548 25393 layer_factory.hpp:76] Creating layer error_layer
I0929 23:29:19.900565 25393 net.cpp:110] Creating Layer error_layer
I0929 23:29:19.900569 25393 net.cpp:477] error_layer <- output_act_blob
I0929 23:29:19.900573 25393 net.cpp:477] error_layer <- label_blob
I0929 23:29:19.900579 25393 net.cpp:433] error_layer -> error_blob
I0929 23:29:19.900615 25393 net.cpp:155] Setting up error_layer
I0929 23:29:19.900621 25393 net.cpp:163] Top shape: (1)
I0929 23:29:19.900637 25393 net.cpp:168]     with loss weight 1
I0929 23:29:19.900657 25393 net.cpp:236] error_layer needs backward computation.
I0929 23:29:19.900661 25393 net.cpp:236] output_act_layer needs backward computation.
I0929 23:29:19.900665 25393 net.cpp:236] output_sum_layer needs backward computation.
I0929 23:29:19.900667 25393 net.cpp:236] hidden_act_layer needs backward computation.
I0929 23:29:19.900671 25393 net.cpp:236] hidden_sum_layer needs backward computation.
I0929 23:29:19.900674 25393 net.cpp:240] data_layer does not need backward computation.
I0929 23:29:19.900677 25393 net.cpp:283] This network produces output error_blob
I0929 23:29:19.900686 25393 net.cpp:297] Network initialization done.
I0929 23:29:19.900687 25393 net.cpp:298] Memory required for data: 6720004
I0929 23:29:19.900821 25393 solver.cpp:187] Creating test net (#0) specified by net file: model/NNScore/nnscore_model_6.prototxt
I0929 23:29:19.900848 25393 net.cpp:339] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_layer
I0929 23:29:19.900893 25393 net.cpp:50] Initializing net from parameters: 
name: "model/NNScore/nnscore_model_6.prototxt"
state {
  phase: TEST
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TEST
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.6.test"
    batch_size: 2000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I0929 23:29:19.900933 25393 layer_factory.hpp:76] Creating layer data_layer
I0929 23:29:19.902266 25393 net.cpp:110] Creating Layer data_layer
I0929 23:29:19.902271 25393 net.cpp:433] data_layer -> data_blob
I0929 23:29:19.902278 25393 net.cpp:433] data_layer -> label_blob
I0929 23:29:19.903002 25399 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.6.test
I0929 23:29:19.903087 25393 data_layer.cpp:45] output data size: 2000,61,1,1
I0929 23:29:19.904404 25393 net.cpp:155] Setting up data_layer
I0929 23:29:19.904427 25393 net.cpp:163] Top shape: 2000 61 1 1 (122000)
I0929 23:29:19.904433 25393 net.cpp:163] Top shape: 2000 (2000)
I0929 23:29:19.904438 25393 layer_factory.hpp:76] Creating layer hidden_sum_layer
I0929 23:29:19.904449 25393 net.cpp:110] Creating Layer hidden_sum_layer
I0929 23:29:19.904456 25393 net.cpp:477] hidden_sum_layer <- data_blob
I0929 23:29:19.904463 25393 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I0929 23:29:19.904585 25393 net.cpp:155] Setting up hidden_sum_layer
I0929 23:29:19.904593 25393 net.cpp:163] Top shape: 2000 10 (20000)
I0929 23:29:19.904604 25393 layer_factory.hpp:76] Creating layer hidden_act_layer
I0929 23:29:19.904613 25393 net.cpp:110] Creating Layer hidden_act_layer
I0929 23:29:19.904618 25393 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I0929 23:29:19.904633 25393 net.cpp:433] hidden_act_layer -> hidden_act_blob
I0929 23:29:19.904814 25393 net.cpp:155] Setting up hidden_act_layer
I0929 23:29:19.904824 25393 net.cpp:163] Top shape: 2000 10 (20000)
I0929 23:29:19.904827 25393 layer_factory.hpp:76] Creating layer output_sum_layer
I0929 23:29:19.904834 25393 net.cpp:110] Creating Layer output_sum_layer
I0929 23:29:19.904839 25393 net.cpp:477] output_sum_layer <- hidden_act_blob
I0929 23:29:19.904844 25393 net.cpp:433] output_sum_layer -> output_sum_blob
I0929 23:29:19.904907 25393 net.cpp:155] Setting up output_sum_layer
I0929 23:29:19.904913 25393 net.cpp:163] Top shape: 2000 1 (2000)
I0929 23:29:19.904923 25393 layer_factory.hpp:76] Creating layer output_act_layer
I0929 23:29:19.904932 25393 net.cpp:110] Creating Layer output_act_layer
I0929 23:29:19.904935 25393 net.cpp:477] output_act_layer <- output_sum_blob
I0929 23:29:19.904942 25393 net.cpp:433] output_act_layer -> output_act_blob
I0929 23:29:19.904994 25393 net.cpp:155] Setting up output_act_layer
I0929 23:29:19.905000 25393 net.cpp:163] Top shape: 2000 1 (2000)
I0929 23:29:19.905004 25393 layer_factory.hpp:76] Creating layer error_layer
I0929 23:29:19.905010 25393 net.cpp:110] Creating Layer error_layer
I0929 23:29:19.905014 25393 net.cpp:477] error_layer <- output_act_blob
I0929 23:29:19.905017 25393 net.cpp:477] error_layer <- label_blob
I0929 23:29:19.905025 25393 net.cpp:433] error_layer -> error_blob
I0929 23:29:19.905050 25393 net.cpp:155] Setting up error_layer
I0929 23:29:19.905056 25393 net.cpp:163] Top shape: (1)
I0929 23:29:19.905060 25393 net.cpp:168]     with loss weight 1
I0929 23:29:19.905069 25393 net.cpp:236] error_layer needs backward computation.
I0929 23:29:19.905073 25393 net.cpp:236] output_act_layer needs backward computation.
I0929 23:29:19.905077 25393 net.cpp:236] output_sum_layer needs backward computation.
I0929 23:29:19.905081 25393 net.cpp:236] hidden_act_layer needs backward computation.
I0929 23:29:19.905083 25393 net.cpp:236] hidden_sum_layer needs backward computation.
I0929 23:29:19.905087 25393 net.cpp:240] data_layer does not need backward computation.
I0929 23:29:19.905091 25393 net.cpp:283] This network produces output error_blob
I0929 23:29:19.905097 25393 net.cpp:297] Network initialization done.
I0929 23:29:19.905100 25393 net.cpp:298] Memory required for data: 672004
I0929 23:29:19.905123 25393 solver.cpp:66] Solver scaffolding done.
I0929 23:29:19.905218 25393 caffe.cpp:212] Starting Optimization
I0929 23:29:19.905226 25393 solver.cpp:294] Solving model/NNScore/nnscore_model_6.prototxt
I0929 23:29:19.905231 25393 solver.cpp:295] Learning Rate Policy: fixed
I0929 23:29:19.905436 25393 solver.cpp:347] Iteration 0, Testing net (#0)
I0929 23:29:19.905489 25393 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:29:20.156755 25393 solver.cpp:415]     Test net output #0: error_blob = 0.136548 (* 1 = 0.136548 loss)
I0929 23:29:20.158061 25393 solver.cpp:243] Iteration 0, loss = 0.133931
I0929 23:29:20.158077 25393 solver.cpp:259]     Train net output #0: error_blob = 0.133931 (* 1 = 0.133931 loss)
I0929 23:29:20.158088 25393 solver.cpp:590] Iteration 0, lr = 0.01
I0929 23:29:22.687890 25393 solver.cpp:243] Iteration 100, loss = 0.124909
I0929 23:29:22.687921 25393 solver.cpp:259]     Train net output #0: error_blob = 0.124909 (* 1 = 0.124909 loss)
I0929 23:29:22.687927 25393 solver.cpp:590] Iteration 100, lr = 0.01
I0929 23:29:25.283349 25393 solver.cpp:243] Iteration 200, loss = 0.124888
I0929 23:29:25.283396 25393 solver.cpp:259]     Train net output #0: error_blob = 0.124888 (* 1 = 0.124888 loss)
I0929 23:29:25.283403 25393 solver.cpp:590] Iteration 200, lr = 0.01
I0929 23:29:27.850504 25393 solver.cpp:243] Iteration 300, loss = 0.125068
I0929 23:29:27.850543 25393 solver.cpp:259]     Train net output #0: error_blob = 0.125068 (* 1 = 0.125068 loss)
I0929 23:29:27.850548 25393 solver.cpp:590] Iteration 300, lr = 0.01
I0929 23:29:30.471572 25393 solver.cpp:243] Iteration 400, loss = 0.12499
I0929 23:29:30.471969 25393 solver.cpp:259]     Train net output #0: error_blob = 0.12499 (* 1 = 0.12499 loss)
I0929 23:29:30.471981 25393 solver.cpp:590] Iteration 400, lr = 0.01
I0929 23:29:33.043814 25393 solver.cpp:243] Iteration 500, loss = 0.124906
I0929 23:29:33.043853 25393 solver.cpp:259]     Train net output #0: error_blob = 0.124906 (* 1 = 0.124906 loss)
I0929 23:29:33.043871 25393 solver.cpp:590] Iteration 500, lr = 0.01
I0929 23:29:35.637774 25393 solver.cpp:243] Iteration 600, loss = 0.124899
I0929 23:29:35.637814 25393 solver.cpp:259]     Train net output #0: error_blob = 0.124899 (* 1 = 0.124899 loss)
I0929 23:29:35.637819 25393 solver.cpp:590] Iteration 600, lr = 0.01
I0929 23:29:38.129225 25393 solver.cpp:243] Iteration 700, loss = 0.124859
I0929 23:29:38.129266 25393 solver.cpp:259]     Train net output #0: error_blob = 0.124859 (* 1 = 0.124859 loss)
I0929 23:29:38.129273 25393 solver.cpp:590] Iteration 700, lr = 0.01
I0929 23:29:40.736896 25393 solver.cpp:243] Iteration 800, loss = 0.124983
I0929 23:29:40.736943 25393 solver.cpp:259]     Train net output #0: error_blob = 0.124983 (* 1 = 0.124983 loss)
I0929 23:29:40.736950 25393 solver.cpp:590] Iteration 800, lr = 0.01
I0929 23:29:43.341433 25393 solver.cpp:243] Iteration 900, loss = 0.125006
I0929 23:29:43.341473 25393 solver.cpp:259]     Train net output #0: error_blob = 0.125006 (* 1 = 0.125006 loss)
I0929 23:29:43.341480 25393 solver.cpp:590] Iteration 900, lr = 0.01
I0929 23:29:43.391963 25393 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:29:45.842749 25393 solver.cpp:347] Iteration 1000, Testing net (#0)
I0929 23:29:46.123292 25393 solver.cpp:415]     Test net output #0: error_blob = 0.125056 (* 1 = 0.125056 loss)
I0929 23:29:46.123921 25393 solver.cpp:243] Iteration 1000, loss = 0.124853
I0929 23:29:46.123936 25393 solver.cpp:259]     Train net output #0: error_blob = 0.124853 (* 1 = 0.124853 loss)
I0929 23:29:46.123942 25393 solver.cpp:590] Iteration 1000, lr = 0.01
I0929 23:29:48.702813 25393 solver.cpp:243] Iteration 1100, loss = 0.124855
I0929 23:29:48.702846 25393 solver.cpp:259]     Train net output #0: error_blob = 0.124855 (* 1 = 0.124855 loss)
I0929 23:29:48.702850 25393 solver.cpp:590] Iteration 1100, lr = 0.01
I0929 23:29:51.275454 25393 solver.cpp:243] Iteration 1200, loss = 0.124985
I0929 23:29:51.275493 25393 solver.cpp:259]     Train net output #0: error_blob = 0.124985 (* 1 = 0.124985 loss)
I0929 23:29:51.275499 25393 solver.cpp:590] Iteration 1200, lr = 0.01
I0929 23:29:53.864578 25393 solver.cpp:243] Iteration 1300, loss = 0.125018
I0929 23:29:53.864609 25393 solver.cpp:259]     Train net output #0: error_blob = 0.125018 (* 1 = 0.125018 loss)
I0929 23:29:53.864614 25393 solver.cpp:590] Iteration 1300, lr = 0.01
I0929 23:29:56.463232 25393 solver.cpp:243] Iteration 1400, loss = 0.124884
I0929 23:29:56.463263 25393 solver.cpp:259]     Train net output #0: error_blob = 0.124884 (* 1 = 0.124884 loss)
I0929 23:29:56.463268 25393 solver.cpp:590] Iteration 1400, lr = 0.01
I0929 23:29:59.069591 25393 solver.cpp:243] Iteration 1500, loss = 0.124834
I0929 23:29:59.069622 25393 solver.cpp:259]     Train net output #0: error_blob = 0.124834 (* 1 = 0.124834 loss)
I0929 23:29:59.069628 25393 solver.cpp:590] Iteration 1500, lr = 0.01
I0929 23:30:01.683806 25393 solver.cpp:243] Iteration 1600, loss = 0.124991
I0929 23:30:01.683837 25393 solver.cpp:259]     Train net output #0: error_blob = 0.124991 (* 1 = 0.124991 loss)
I0929 23:30:01.683842 25393 solver.cpp:590] Iteration 1600, lr = 0.01
I0929 23:30:04.272016 25393 solver.cpp:243] Iteration 1700, loss = 0.125005
I0929 23:30:04.272056 25393 solver.cpp:259]     Train net output #0: error_blob = 0.125005 (* 1 = 0.125005 loss)
I0929 23:30:04.272061 25393 solver.cpp:590] Iteration 1700, lr = 0.01
I0929 23:30:06.848181 25393 solver.cpp:243] Iteration 1800, loss = 0.124871
I0929 23:30:06.848214 25393 solver.cpp:259]     Train net output #0: error_blob = 0.124871 (* 1 = 0.124871 loss)
I0929 23:30:06.848220 25393 solver.cpp:590] Iteration 1800, lr = 0.01
I0929 23:30:07.054023 25393 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:30:09.445247 25393 solver.cpp:243] Iteration 1900, loss = 0.124834
I0929 23:30:09.445279 25393 solver.cpp:259]     Train net output #0: error_blob = 0.124834 (* 1 = 0.124834 loss)
I0929 23:30:09.445284 25393 solver.cpp:590] Iteration 1900, lr = 0.01
I0929 23:30:12.017740 25393 solver.cpp:347] Iteration 2000, Testing net (#0)
I0929 23:30:12.303273 25393 solver.cpp:415]     Test net output #0: error_blob = 0.125057 (* 1 = 0.125057 loss)
I0929 23:30:12.303956 25393 solver.cpp:243] Iteration 2000, loss = 0.124985
I0929 23:30:12.303972 25393 solver.cpp:259]     Train net output #0: error_blob = 0.124985 (* 1 = 0.124985 loss)
I0929 23:30:12.303980 25393 solver.cpp:590] Iteration 2000, lr = 0.01
I0929 23:30:14.845733 25393 solver.cpp:243] Iteration 2100, loss = 0.124988
I0929 23:30:14.845767 25393 solver.cpp:259]     Train net output #0: error_blob = 0.124988 (* 1 = 0.124988 loss)
I0929 23:30:14.845773 25393 solver.cpp:590] Iteration 2100, lr = 0.01
I0929 23:30:17.399683 25393 solver.cpp:243] Iteration 2200, loss = 0.124868
I0929 23:30:17.401361 25393 solver.cpp:259]     Train net output #0: error_blob = 0.124868 (* 1 = 0.124868 loss)
I0929 23:30:17.401372 25393 solver.cpp:590] Iteration 2200, lr = 0.01
I0929 23:30:19.951601 25393 solver.cpp:243] Iteration 2300, loss = 0.124838
I0929 23:30:19.951632 25393 solver.cpp:259]     Train net output #0: error_blob = 0.124838 (* 1 = 0.124838 loss)
I0929 23:30:19.951637 25393 solver.cpp:590] Iteration 2300, lr = 0.01
I0929 23:30:22.583343 25393 solver.cpp:243] Iteration 2400, loss = 0.124815
I0929 23:30:22.583381 25393 solver.cpp:259]     Train net output #0: error_blob = 0.124815 (* 1 = 0.124815 loss)
I0929 23:30:22.583386 25393 solver.cpp:590] Iteration 2400, lr = 0.01
I0929 23:30:25.196014 25393 solver.cpp:243] Iteration 2500, loss = 0.124993
I0929 23:30:25.196045 25393 solver.cpp:259]     Train net output #0: error_blob = 0.124993 (* 1 = 0.124993 loss)
I0929 23:30:25.196050 25393 solver.cpp:590] Iteration 2500, lr = 0.01
I0929 23:30:27.795389 25393 solver.cpp:243] Iteration 2600, loss = 0.124993
I0929 23:30:27.795435 25393 solver.cpp:259]     Train net output #0: error_blob = 0.124993 (* 1 = 0.124993 loss)
I0929 23:30:27.795444 25393 solver.cpp:590] Iteration 2600, lr = 0.01
I0929 23:30:30.360895 25393 solver.cpp:243] Iteration 2700, loss = 0.124826
I0929 23:30:30.360944 25393 solver.cpp:259]     Train net output #0: error_blob = 0.124826 (* 1 = 0.124826 loss)
I0929 23:30:30.360952 25393 solver.cpp:590] Iteration 2700, lr = 0.01
I0929 23:30:30.708637 25393 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:30:32.905869 25393 solver.cpp:243] Iteration 2800, loss = 0.124807
I0929 23:30:32.905910 25393 solver.cpp:259]     Train net output #0: error_blob = 0.124807 (* 1 = 0.124807 loss)
I0929 23:30:32.905915 25393 solver.cpp:590] Iteration 2800, lr = 0.01
I0929 23:30:35.472610 25393 solver.cpp:243] Iteration 2900, loss = 0.124984
I0929 23:30:35.472650 25393 solver.cpp:259]     Train net output #0: error_blob = 0.124984 (* 1 = 0.124984 loss)
I0929 23:30:35.472657 25393 solver.cpp:590] Iteration 2900, lr = 0.01
I0929 23:30:38.012115 25393 solver.cpp:347] Iteration 3000, Testing net (#0)
I0929 23:30:38.321696 25393 solver.cpp:415]     Test net output #0: error_blob = 0.125055 (* 1 = 0.125055 loss)
I0929 23:30:38.322391 25393 solver.cpp:243] Iteration 3000, loss = 0.125002
I0929 23:30:38.322407 25393 solver.cpp:259]     Train net output #0: error_blob = 0.125002 (* 1 = 0.125002 loss)
I0929 23:30:38.322412 25393 solver.cpp:590] Iteration 3000, lr = 0.01
I0929 23:30:40.983136 25393 solver.cpp:243] Iteration 3100, loss = 0.124819
I0929 23:30:40.983167 25393 solver.cpp:259]     Train net output #0: error_blob = 0.124819 (* 1 = 0.124819 loss)
I0929 23:30:40.983171 25393 solver.cpp:590] Iteration 3100, lr = 0.01
I0929 23:30:43.589665 25393 solver.cpp:243] Iteration 3200, loss = 0.124772
I0929 23:30:43.589711 25393 solver.cpp:259]     Train net output #0: error_blob = 0.124772 (* 1 = 0.124772 loss)
I0929 23:30:43.589720 25393 solver.cpp:590] Iteration 3200, lr = 0.01
I0929 23:30:46.227815 25393 solver.cpp:243] Iteration 3300, loss = 0.124988
I0929 23:30:46.227856 25393 solver.cpp:259]     Train net output #0: error_blob = 0.124988 (* 1 = 0.124988 loss)
I0929 23:30:46.227862 25393 solver.cpp:590] Iteration 3300, lr = 0.01
I0929 23:30:48.811609 25393 solver.cpp:243] Iteration 3400, loss = 0.125013
I0929 23:30:48.811714 25393 solver.cpp:259]     Train net output #0: error_blob = 0.125013 (* 1 = 0.125013 loss)
I0929 23:30:48.811722 25393 solver.cpp:590] Iteration 3400, lr = 0.01
I0929 23:30:51.422751 25393 solver.cpp:243] Iteration 3500, loss = 0.124808
I0929 23:30:51.422797 25393 solver.cpp:259]     Train net output #0: error_blob = 0.124808 (* 1 = 0.124808 loss)
I0929 23:30:51.422804 25393 solver.cpp:590] Iteration 3500, lr = 0.01
I0929 23:30:54.070492 25393 solver.cpp:243] Iteration 3600, loss = 0.12477
I0929 23:30:54.070536 25393 solver.cpp:259]     Train net output #0: error_blob = 0.12477 (* 1 = 0.12477 loss)
I0929 23:30:54.070544 25393 solver.cpp:590] Iteration 3600, lr = 0.01
I0929 23:30:54.603457 25393 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:30:56.684244 25393 solver.cpp:243] Iteration 3700, loss = 0.124982
I0929 23:30:56.684293 25393 solver.cpp:259]     Train net output #0: error_blob = 0.124982 (* 1 = 0.124982 loss)
I0929 23:30:56.684301 25393 solver.cpp:590] Iteration 3700, lr = 0.01
I0929 23:30:59.245647 25393 solver.cpp:243] Iteration 3800, loss = 0.124989
I0929 23:30:59.245688 25393 solver.cpp:259]     Train net output #0: error_blob = 0.124989 (* 1 = 0.124989 loss)
I0929 23:30:59.245694 25393 solver.cpp:590] Iteration 3800, lr = 0.01
I0929 23:31:01.851909 25393 solver.cpp:243] Iteration 3900, loss = 0.124784
I0929 23:31:01.851940 25393 solver.cpp:259]     Train net output #0: error_blob = 0.124784 (* 1 = 0.124784 loss)
I0929 23:31:01.851945 25393 solver.cpp:590] Iteration 3900, lr = 0.01
I0929 23:31:04.458645 25393 solver.cpp:347] Iteration 4000, Testing net (#0)
I0929 23:31:04.744339 25393 solver.cpp:415]     Test net output #0: error_blob = 0.125053 (* 1 = 0.125053 loss)
I0929 23:31:04.745069 25393 solver.cpp:243] Iteration 4000, loss = 0.124778
I0929 23:31:04.745085 25393 solver.cpp:259]     Train net output #0: error_blob = 0.124778 (* 1 = 0.124778 loss)
I0929 23:31:04.745100 25393 solver.cpp:590] Iteration 4000, lr = 0.01
I0929 23:31:07.334034 25393 solver.cpp:243] Iteration 4100, loss = 0.12475
I0929 23:31:07.334063 25393 solver.cpp:259]     Train net output #0: error_blob = 0.12475 (* 1 = 0.12475 loss)
I0929 23:31:07.334067 25393 solver.cpp:590] Iteration 4100, lr = 0.01
I0929 23:31:09.963650 25393 solver.cpp:243] Iteration 4200, loss = 0.124972
I0929 23:31:09.963692 25393 solver.cpp:259]     Train net output #0: error_blob = 0.124972 (* 1 = 0.124972 loss)
I0929 23:31:09.963698 25393 solver.cpp:590] Iteration 4200, lr = 0.01
I0929 23:31:12.560708 25393 solver.cpp:243] Iteration 4300, loss = 0.125
I0929 23:31:12.560755 25393 solver.cpp:259]     Train net output #0: error_blob = 0.125 (* 1 = 0.125 loss)
I0929 23:31:12.560762 25393 solver.cpp:590] Iteration 4300, lr = 0.01
I0929 23:31:15.209931 25393 solver.cpp:243] Iteration 4400, loss = 0.124772
I0929 23:31:15.209980 25393 solver.cpp:259]     Train net output #0: error_blob = 0.124772 (* 1 = 0.124772 loss)
I0929 23:31:15.209987 25393 solver.cpp:590] Iteration 4400, lr = 0.01
I0929 23:31:17.873287 25393 solver.cpp:243] Iteration 4500, loss = 0.124745
I0929 23:31:17.873337 25393 solver.cpp:259]     Train net output #0: error_blob = 0.124745 (* 1 = 0.124745 loss)
I0929 23:31:17.873343 25393 solver.cpp:590] Iteration 4500, lr = 0.01
I0929 23:31:18.574853 25393 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:31:20.471200 25393 solver.cpp:243] Iteration 4600, loss = 0.124978
I0929 23:31:20.471299 25393 solver.cpp:259]     Train net output #0: error_blob = 0.124978 (* 1 = 0.124978 loss)
I0929 23:31:20.471308 25393 solver.cpp:590] Iteration 4600, lr = 0.01
I0929 23:31:23.059561 25393 solver.cpp:243] Iteration 4700, loss = 0.125011
I0929 23:31:23.059589 25393 solver.cpp:259]     Train net output #0: error_blob = 0.125011 (* 1 = 0.125011 loss)
I0929 23:31:23.059594 25393 solver.cpp:590] Iteration 4700, lr = 0.01
I0929 23:31:25.663368 25393 solver.cpp:243] Iteration 4800, loss = 0.124716
I0929 23:31:25.663414 25393 solver.cpp:259]     Train net output #0: error_blob = 0.124716 (* 1 = 0.124716 loss)
I0929 23:31:25.663424 25393 solver.cpp:590] Iteration 4800, lr = 0.01
I0929 23:31:28.219730 25393 solver.cpp:243] Iteration 4900, loss = 0.12124
I0929 23:31:28.219772 25393 solver.cpp:259]     Train net output #0: error_blob = 0.12124 (* 1 = 0.12124 loss)
I0929 23:31:28.219777 25393 solver.cpp:590] Iteration 4900, lr = 0.01
I0929 23:31:30.808657 25393 solver.cpp:347] Iteration 5000, Testing net (#0)
I0929 23:31:31.091359 25393 solver.cpp:415]     Test net output #0: error_blob = 0.121192 (* 1 = 0.121192 loss)
I0929 23:31:31.092000 25393 solver.cpp:243] Iteration 5000, loss = 0.120839
I0929 23:31:31.092015 25393 solver.cpp:259]     Train net output #0: error_blob = 0.120839 (* 1 = 0.120839 loss)
I0929 23:31:31.092022 25393 solver.cpp:590] Iteration 5000, lr = 0.01
I0929 23:31:33.633016 25393 solver.cpp:243] Iteration 5100, loss = 0.120067
I0929 23:31:33.633054 25393 solver.cpp:259]     Train net output #0: error_blob = 0.120067 (* 1 = 0.120067 loss)
I0929 23:31:33.633060 25393 solver.cpp:590] Iteration 5100, lr = 0.01
I0929 23:31:36.300829 25393 solver.cpp:243] Iteration 5200, loss = 0.118698
I0929 23:31:36.300874 25393 solver.cpp:259]     Train net output #0: error_blob = 0.118698 (* 1 = 0.118698 loss)
I0929 23:31:36.300880 25393 solver.cpp:590] Iteration 5200, lr = 0.01
I0929 23:31:38.903210 25393 solver.cpp:243] Iteration 5300, loss = 0.119109
I0929 23:31:38.903257 25393 solver.cpp:259]     Train net output #0: error_blob = 0.119109 (* 1 = 0.119109 loss)
I0929 23:31:38.903265 25393 solver.cpp:590] Iteration 5300, lr = 0.01
I0929 23:31:41.469120 25393 solver.cpp:243] Iteration 5400, loss = 0.119071
I0929 23:31:41.469169 25393 solver.cpp:259]     Train net output #0: error_blob = 0.119071 (* 1 = 0.119071 loss)
I0929 23:31:41.469177 25393 solver.cpp:590] Iteration 5400, lr = 0.01
I0929 23:31:42.284742 25393 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:31:44.041018 25393 solver.cpp:243] Iteration 5500, loss = 0.119411
I0929 23:31:44.041048 25393 solver.cpp:259]     Train net output #0: error_blob = 0.119411 (* 1 = 0.119411 loss)
I0929 23:31:44.041052 25393 solver.cpp:590] Iteration 5500, lr = 0.01
I0929 23:31:46.612229 25393 solver.cpp:243] Iteration 5600, loss = 0.118891
I0929 23:31:46.612268 25393 solver.cpp:259]     Train net output #0: error_blob = 0.118891 (* 1 = 0.118891 loss)
I0929 23:31:46.612274 25393 solver.cpp:590] Iteration 5600, lr = 0.01
I0929 23:31:49.188868 25393 solver.cpp:243] Iteration 5700, loss = 0.11752
I0929 23:31:49.188909 25393 solver.cpp:259]     Train net output #0: error_blob = 0.11752 (* 1 = 0.11752 loss)
I0929 23:31:49.188915 25393 solver.cpp:590] Iteration 5700, lr = 0.01
I0929 23:31:51.776425 25393 solver.cpp:243] Iteration 5800, loss = 0.11899
I0929 23:31:51.777508 25393 solver.cpp:259]     Train net output #0: error_blob = 0.11899 (* 1 = 0.11899 loss)
I0929 23:31:51.777515 25393 solver.cpp:590] Iteration 5800, lr = 0.01
I0929 23:31:54.358716 25393 solver.cpp:243] Iteration 5900, loss = 0.118899
I0929 23:31:54.358747 25393 solver.cpp:259]     Train net output #0: error_blob = 0.118899 (* 1 = 0.118899 loss)
I0929 23:31:54.358752 25393 solver.cpp:590] Iteration 5900, lr = 0.01
I0929 23:31:56.930311 25393 solver.cpp:347] Iteration 6000, Testing net (#0)
I0929 23:31:57.212529 25393 solver.cpp:415]     Test net output #0: error_blob = 0.118355 (* 1 = 0.118355 loss)
I0929 23:31:57.213210 25393 solver.cpp:243] Iteration 6000, loss = 0.118566
I0929 23:31:57.213258 25393 solver.cpp:259]     Train net output #0: error_blob = 0.118566 (* 1 = 0.118566 loss)
I0929 23:31:57.213277 25393 solver.cpp:590] Iteration 6000, lr = 0.01
I0929 23:31:59.776482 25393 solver.cpp:243] Iteration 6100, loss = 0.117035
I0929 23:31:59.776540 25393 solver.cpp:259]     Train net output #0: error_blob = 0.117035 (* 1 = 0.117035 loss)
I0929 23:31:59.776546 25393 solver.cpp:590] Iteration 6100, lr = 0.01
I0929 23:32:02.344457 25393 solver.cpp:243] Iteration 6200, loss = 0.117271
I0929 23:32:02.344516 25393 solver.cpp:259]     Train net output #0: error_blob = 0.117271 (* 1 = 0.117271 loss)
I0929 23:32:02.344522 25393 solver.cpp:590] Iteration 6200, lr = 0.01
I0929 23:32:04.955476 25393 solver.cpp:243] Iteration 6300, loss = 0.119801
I0929 23:32:04.955507 25393 solver.cpp:259]     Train net output #0: error_blob = 0.119801 (* 1 = 0.119801 loss)
I0929 23:32:04.955512 25393 solver.cpp:590] Iteration 6300, lr = 0.01
I0929 23:32:05.934604 25393 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:32:07.520552 25393 solver.cpp:243] Iteration 6400, loss = 0.11759
I0929 23:32:07.520582 25393 solver.cpp:259]     Train net output #0: error_blob = 0.11759 (* 1 = 0.11759 loss)
I0929 23:32:07.520587 25393 solver.cpp:590] Iteration 6400, lr = 0.01
I0929 23:32:10.060796 25393 solver.cpp:243] Iteration 6500, loss = 0.114763
I0929 23:32:10.060835 25393 solver.cpp:259]     Train net output #0: error_blob = 0.114763 (* 1 = 0.114763 loss)
I0929 23:32:10.060842 25393 solver.cpp:590] Iteration 6500, lr = 0.01
I0929 23:32:12.636477 25393 solver.cpp:243] Iteration 6600, loss = 0.116315
I0929 23:32:12.636523 25393 solver.cpp:259]     Train net output #0: error_blob = 0.116315 (* 1 = 0.116315 loss)
I0929 23:32:12.636529 25393 solver.cpp:590] Iteration 6600, lr = 0.01
I0929 23:32:15.269498 25393 solver.cpp:243] Iteration 6700, loss = 0.118326
I0929 23:32:15.269531 25393 solver.cpp:259]     Train net output #0: error_blob = 0.118326 (* 1 = 0.118326 loss)
I0929 23:32:15.269536 25393 solver.cpp:590] Iteration 6700, lr = 0.01
I0929 23:32:17.825130 25393 solver.cpp:243] Iteration 6800, loss = 0.117972
I0929 23:32:17.825160 25393 solver.cpp:259]     Train net output #0: error_blob = 0.117972 (* 1 = 0.117972 loss)
I0929 23:32:17.825165 25393 solver.cpp:590] Iteration 6800, lr = 0.01
I0929 23:32:20.409209 25393 solver.cpp:243] Iteration 6900, loss = 0.11637
I0929 23:32:20.409242 25393 solver.cpp:259]     Train net output #0: error_blob = 0.11637 (* 1 = 0.11637 loss)
I0929 23:32:20.409247 25393 solver.cpp:590] Iteration 6900, lr = 0.01
I0929 23:32:22.958863 25393 solver.cpp:347] Iteration 7000, Testing net (#0)
I0929 23:32:23.269862 25393 solver.cpp:415]     Test net output #0: error_blob = 0.119019 (* 1 = 0.119019 loss)
I0929 23:32:23.270558 25393 solver.cpp:243] Iteration 7000, loss = 0.114299
I0929 23:32:23.270593 25393 solver.cpp:259]     Train net output #0: error_blob = 0.114299 (* 1 = 0.114299 loss)
I0929 23:32:23.270614 25393 solver.cpp:590] Iteration 7000, lr = 0.01
I0929 23:32:25.798539 25393 solver.cpp:243] Iteration 7100, loss = 0.117728
I0929 23:32:25.798570 25393 solver.cpp:259]     Train net output #0: error_blob = 0.117728 (* 1 = 0.117728 loss)
I0929 23:32:25.798575 25393 solver.cpp:590] Iteration 7100, lr = 0.01
I0929 23:32:28.357048 25393 solver.cpp:243] Iteration 7200, loss = 0.118415
I0929 23:32:28.357079 25393 solver.cpp:259]     Train net output #0: error_blob = 0.118415 (* 1 = 0.118415 loss)
I0929 23:32:28.357084 25393 solver.cpp:590] Iteration 7200, lr = 0.01
I0929 23:32:29.465441 25393 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:32:30.894335 25393 solver.cpp:243] Iteration 7300, loss = 0.115345
I0929 23:32:30.894374 25393 solver.cpp:259]     Train net output #0: error_blob = 0.115345 (* 1 = 0.115345 loss)
I0929 23:32:30.894379 25393 solver.cpp:590] Iteration 7300, lr = 0.01
I0929 23:32:33.405156 25393 solver.cpp:243] Iteration 7400, loss = 0.118232
I0929 23:32:33.405187 25393 solver.cpp:259]     Train net output #0: error_blob = 0.118232 (* 1 = 0.118232 loss)
I0929 23:32:33.405194 25393 solver.cpp:590] Iteration 7400, lr = 0.01
I0929 23:32:35.999418 25393 solver.cpp:243] Iteration 7500, loss = 0.116804
I0929 23:32:35.999459 25393 solver.cpp:259]     Train net output #0: error_blob = 0.116804 (* 1 = 0.116804 loss)
I0929 23:32:35.999465 25393 solver.cpp:590] Iteration 7500, lr = 0.01
I0929 23:32:38.566130 25393 solver.cpp:243] Iteration 7600, loss = 0.119813
I0929 23:32:38.566161 25393 solver.cpp:259]     Train net output #0: error_blob = 0.119813 (* 1 = 0.119813 loss)
I0929 23:32:38.566166 25393 solver.cpp:590] Iteration 7600, lr = 0.01
I0929 23:32:41.143846 25393 solver.cpp:243] Iteration 7700, loss = 0.117664
I0929 23:32:41.143887 25393 solver.cpp:259]     Train net output #0: error_blob = 0.117664 (* 1 = 0.117664 loss)
I0929 23:32:41.143893 25393 solver.cpp:590] Iteration 7700, lr = 0.01
I0929 23:32:43.714283 25393 solver.cpp:243] Iteration 7800, loss = 0.111772
I0929 23:32:43.714311 25393 solver.cpp:259]     Train net output #0: error_blob = 0.111772 (* 1 = 0.111772 loss)
I0929 23:32:43.714316 25393 solver.cpp:590] Iteration 7800, lr = 0.01
I0929 23:32:46.295979 25393 solver.cpp:243] Iteration 7900, loss = 0.115729
I0929 23:32:46.296011 25393 solver.cpp:259]     Train net output #0: error_blob = 0.115729 (* 1 = 0.115729 loss)
I0929 23:32:46.296017 25393 solver.cpp:590] Iteration 7900, lr = 0.01
I0929 23:32:48.822648 25393 solver.cpp:347] Iteration 8000, Testing net (#0)
I0929 23:32:49.198668 25393 solver.cpp:415]     Test net output #0: error_blob = 0.118855 (* 1 = 0.118855 loss)
I0929 23:32:49.199281 25393 solver.cpp:243] Iteration 8000, loss = 0.118665
I0929 23:32:49.199293 25393 solver.cpp:259]     Train net output #0: error_blob = 0.118665 (* 1 = 0.118665 loss)
I0929 23:32:49.199298 25393 solver.cpp:590] Iteration 8000, lr = 0.01
I0929 23:32:51.739054 25393 solver.cpp:243] Iteration 8100, loss = 0.118676
I0929 23:32:51.739085 25393 solver.cpp:259]     Train net output #0: error_blob = 0.118676 (* 1 = 0.118676 loss)
I0929 23:32:51.739094 25393 solver.cpp:590] Iteration 8100, lr = 0.01
I0929 23:32:53.049942 25393 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:32:54.336990 25393 solver.cpp:243] Iteration 8200, loss = 0.113264
I0929 23:32:54.337020 25393 solver.cpp:259]     Train net output #0: error_blob = 0.113264 (* 1 = 0.113264 loss)
I0929 23:32:54.337025 25393 solver.cpp:590] Iteration 8200, lr = 0.01
I0929 23:32:56.873492 25393 solver.cpp:243] Iteration 8300, loss = 0.118629
I0929 23:32:56.873522 25393 solver.cpp:259]     Train net output #0: error_blob = 0.118629 (* 1 = 0.118629 loss)
I0929 23:32:56.873528 25393 solver.cpp:590] Iteration 8300, lr = 0.01
I0929 23:32:59.489272 25393 solver.cpp:243] Iteration 8400, loss = 0.12114
I0929 23:32:59.489305 25393 solver.cpp:259]     Train net output #0: error_blob = 0.12114 (* 1 = 0.12114 loss)
I0929 23:32:59.489312 25393 solver.cpp:590] Iteration 8400, lr = 0.01
I0929 23:33:02.076025 25393 solver.cpp:243] Iteration 8500, loss = 0.119138
I0929 23:33:02.076066 25393 solver.cpp:259]     Train net output #0: error_blob = 0.119138 (* 1 = 0.119138 loss)
I0929 23:33:02.076071 25393 solver.cpp:590] Iteration 8500, lr = 0.01
I0929 23:33:04.607584 25393 solver.cpp:243] Iteration 8600, loss = 0.114921
I0929 23:33:04.607625 25393 solver.cpp:259]     Train net output #0: error_blob = 0.114921 (* 1 = 0.114921 loss)
I0929 23:33:04.607630 25393 solver.cpp:590] Iteration 8600, lr = 0.01
I0929 23:33:07.162595 25393 solver.cpp:243] Iteration 8700, loss = 0.111902
I0929 23:33:07.162626 25393 solver.cpp:259]     Train net output #0: error_blob = 0.111902 (* 1 = 0.111902 loss)
I0929 23:33:07.162631 25393 solver.cpp:590] Iteration 8700, lr = 0.01
I0929 23:33:09.687358 25393 solver.cpp:243] Iteration 8800, loss = 0.116347
I0929 23:33:09.687391 25393 solver.cpp:259]     Train net output #0: error_blob = 0.116347 (* 1 = 0.116347 loss)
I0929 23:33:09.687396 25393 solver.cpp:590] Iteration 8800, lr = 0.01
I0929 23:33:12.288585 25393 solver.cpp:243] Iteration 8900, loss = 0.118143
I0929 23:33:12.288616 25393 solver.cpp:259]     Train net output #0: error_blob = 0.118143 (* 1 = 0.118143 loss)
I0929 23:33:12.288621 25393 solver.cpp:590] Iteration 8900, lr = 0.01
I0929 23:33:14.872766 25393 solver.cpp:347] Iteration 9000, Testing net (#0)
I0929 23:33:15.191812 25393 solver.cpp:415]     Test net output #0: error_blob = 0.119323 (* 1 = 0.119323 loss)
I0929 23:33:15.192420 25393 solver.cpp:243] Iteration 9000, loss = 0.11465
I0929 23:33:15.192430 25393 solver.cpp:259]     Train net output #0: error_blob = 0.11465 (* 1 = 0.11465 loss)
I0929 23:33:15.192435 25393 solver.cpp:590] Iteration 9000, lr = 0.01
I0929 23:33:16.625066 25393 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:33:17.781380 25393 solver.cpp:243] Iteration 9100, loss = 0.111921
I0929 23:33:17.781411 25393 solver.cpp:259]     Train net output #0: error_blob = 0.111921 (* 1 = 0.111921 loss)
I0929 23:33:17.781416 25393 solver.cpp:590] Iteration 9100, lr = 0.01
I0929 23:33:20.350767 25393 solver.cpp:243] Iteration 9200, loss = 0.11498
I0929 23:33:20.350795 25393 solver.cpp:259]     Train net output #0: error_blob = 0.11498 (* 1 = 0.11498 loss)
I0929 23:33:20.350800 25393 solver.cpp:590] Iteration 9200, lr = 0.01
I0929 23:33:22.948129 25393 solver.cpp:243] Iteration 9300, loss = 0.117491
I0929 23:33:22.948170 25393 solver.cpp:259]     Train net output #0: error_blob = 0.117491 (* 1 = 0.117491 loss)
I0929 23:33:22.948174 25393 solver.cpp:590] Iteration 9300, lr = 0.01
I0929 23:33:25.564692 25393 solver.cpp:243] Iteration 9400, loss = 0.116284
I0929 23:33:25.564817 25393 solver.cpp:259]     Train net output #0: error_blob = 0.116284 (* 1 = 0.116284 loss)
I0929 23:33:25.564823 25393 solver.cpp:590] Iteration 9400, lr = 0.01
I0929 23:33:28.186730 25393 solver.cpp:243] Iteration 9500, loss = 0.114893
I0929 23:33:28.186759 25393 solver.cpp:259]     Train net output #0: error_blob = 0.114893 (* 1 = 0.114893 loss)
I0929 23:33:28.186764 25393 solver.cpp:590] Iteration 9500, lr = 0.01
I0929 23:33:30.695574 25393 solver.cpp:243] Iteration 9600, loss = 0.113396
I0929 23:33:30.695605 25393 solver.cpp:259]     Train net output #0: error_blob = 0.113396 (* 1 = 0.113396 loss)
I0929 23:33:30.695611 25393 solver.cpp:590] Iteration 9600, lr = 0.01
I0929 23:33:33.277125 25393 solver.cpp:243] Iteration 9700, loss = 0.11963
I0929 23:33:33.277166 25393 solver.cpp:259]     Train net output #0: error_blob = 0.11963 (* 1 = 0.11963 loss)
I0929 23:33:33.277171 25393 solver.cpp:590] Iteration 9700, lr = 0.01
I0929 23:33:35.779446 25393 solver.cpp:243] Iteration 9800, loss = 0.117403
I0929 23:33:35.779477 25393 solver.cpp:259]     Train net output #0: error_blob = 0.117403 (* 1 = 0.117403 loss)
I0929 23:33:35.779484 25393 solver.cpp:590] Iteration 9800, lr = 0.01
I0929 23:33:38.313974 25393 solver.cpp:243] Iteration 9900, loss = 0.112792
I0929 23:33:38.314003 25393 solver.cpp:259]     Train net output #0: error_blob = 0.112792 (* 1 = 0.112792 loss)
I0929 23:33:38.314008 25393 solver.cpp:590] Iteration 9900, lr = 0.01
I0929 23:33:40.891741 25393 solver.cpp:468] Snapshotting to binary proto file _iter_10000.caffemodel
I0929 23:33:40.892859 25393 solver.cpp:753] Snapshotting solver state to binary proto file _iter_10000.solverstate
I0929 23:33:40.917253 25393 solver.cpp:327] Iteration 10000, loss = 0.113355
I0929 23:33:40.917279 25393 solver.cpp:347] Iteration 10000, Testing net (#0)
I0929 23:33:41.127280 25393 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:33:41.235013 25393 solver.cpp:415]     Test net output #0: error_blob = 0.118366 (* 1 = 0.118366 loss)
I0929 23:33:41.235033 25393 solver.cpp:332] Optimization Done.
I0929 23:33:41.235035 25393 caffe.cpp:215] Optimization Done.
I0929 23:33:41.302943 25404 caffe.cpp:184] Using GPUs 0
I0929 23:33:41.857895 25404 solver.cpp:54] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "fixed"
momentum: 0.9
solver_mode: GPU
device_id: 0
net: "model/NNScore/nnscore_model_7.prototxt"
I0929 23:33:41.857926 25404 solver.cpp:97] Creating training net from net file: model/NNScore/nnscore_model_7.prototxt
I0929 23:33:41.858095 25404 net.cpp:339] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_layer
I0929 23:33:41.858131 25404 net.cpp:50] Initializing net from parameters: 
name: "model/NNScore/nnscore_model_7.prototxt"
state {
  phase: TRAIN
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TRAIN
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.7.train"
    batch_size: 20000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I0929 23:33:41.858189 25404 layer_factory.hpp:76] Creating layer data_layer
I0929 23:33:41.871531 25404 net.cpp:110] Creating Layer data_layer
I0929 23:33:41.871551 25404 net.cpp:433] data_layer -> data_blob
I0929 23:33:41.871583 25404 net.cpp:433] data_layer -> label_blob
I0929 23:33:41.872167 25408 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.7.train
I0929 23:33:42.557572 25404 data_layer.cpp:45] output data size: 20000,61,1,1
I0929 23:33:42.562533 25404 net.cpp:155] Setting up data_layer
I0929 23:33:42.562564 25404 net.cpp:163] Top shape: 20000 61 1 1 (1220000)
I0929 23:33:42.562567 25404 net.cpp:163] Top shape: 20000 (20000)
I0929 23:33:42.562584 25404 layer_factory.hpp:76] Creating layer hidden_sum_layer
I0929 23:33:42.562597 25404 net.cpp:110] Creating Layer hidden_sum_layer
I0929 23:33:42.562600 25404 net.cpp:477] hidden_sum_layer <- data_blob
I0929 23:33:42.562609 25404 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I0929 23:33:42.562990 25404 net.cpp:155] Setting up hidden_sum_layer
I0929 23:33:42.562999 25404 net.cpp:163] Top shape: 20000 10 (200000)
I0929 23:33:42.563019 25404 layer_factory.hpp:76] Creating layer hidden_act_layer
I0929 23:33:42.563025 25404 net.cpp:110] Creating Layer hidden_act_layer
I0929 23:33:42.563029 25404 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I0929 23:33:42.563031 25404 net.cpp:433] hidden_act_layer -> hidden_act_blob
I0929 23:33:45.766381 25404 net.cpp:155] Setting up hidden_act_layer
I0929 23:33:45.766401 25404 net.cpp:163] Top shape: 20000 10 (200000)
I0929 23:33:45.766405 25404 layer_factory.hpp:76] Creating layer output_sum_layer
I0929 23:33:45.766414 25404 net.cpp:110] Creating Layer output_sum_layer
I0929 23:33:45.766417 25404 net.cpp:477] output_sum_layer <- hidden_act_blob
I0929 23:33:45.766423 25404 net.cpp:433] output_sum_layer -> output_sum_blob
I0929 23:33:45.766507 25404 net.cpp:155] Setting up output_sum_layer
I0929 23:33:45.766512 25404 net.cpp:163] Top shape: 20000 1 (20000)
I0929 23:33:45.766520 25404 layer_factory.hpp:76] Creating layer output_act_layer
I0929 23:33:45.766525 25404 net.cpp:110] Creating Layer output_act_layer
I0929 23:33:45.766527 25404 net.cpp:477] output_act_layer <- output_sum_blob
I0929 23:33:45.766530 25404 net.cpp:433] output_act_layer -> output_act_blob
I0929 23:33:45.766587 25404 net.cpp:155] Setting up output_act_layer
I0929 23:33:45.766607 25404 net.cpp:163] Top shape: 20000 1 (20000)
I0929 23:33:45.766609 25404 layer_factory.hpp:76] Creating layer error_layer
I0929 23:33:45.766614 25404 net.cpp:110] Creating Layer error_layer
I0929 23:33:45.766616 25404 net.cpp:477] error_layer <- output_act_blob
I0929 23:33:45.766619 25404 net.cpp:477] error_layer <- label_blob
I0929 23:33:45.766623 25404 net.cpp:433] error_layer -> error_blob
I0929 23:33:45.766647 25404 net.cpp:155] Setting up error_layer
I0929 23:33:45.766651 25404 net.cpp:163] Top shape: (1)
I0929 23:33:45.766654 25404 net.cpp:168]     with loss weight 1
I0929 23:33:45.766670 25404 net.cpp:236] error_layer needs backward computation.
I0929 23:33:45.766672 25404 net.cpp:236] output_act_layer needs backward computation.
I0929 23:33:45.766675 25404 net.cpp:236] output_sum_layer needs backward computation.
I0929 23:33:45.766677 25404 net.cpp:236] hidden_act_layer needs backward computation.
I0929 23:33:45.766680 25404 net.cpp:236] hidden_sum_layer needs backward computation.
I0929 23:33:45.766681 25404 net.cpp:240] data_layer does not need backward computation.
I0929 23:33:45.766683 25404 net.cpp:283] This network produces output error_blob
I0929 23:33:45.766690 25404 net.cpp:297] Network initialization done.
I0929 23:33:45.766690 25404 net.cpp:298] Memory required for data: 6720004
I0929 23:33:45.766820 25404 solver.cpp:187] Creating test net (#0) specified by net file: model/NNScore/nnscore_model_7.prototxt
I0929 23:33:45.766834 25404 net.cpp:339] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_layer
I0929 23:33:45.766866 25404 net.cpp:50] Initializing net from parameters: 
name: "model/NNScore/nnscore_model_7.prototxt"
state {
  phase: TEST
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TEST
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.7.test"
    batch_size: 2000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I0929 23:33:45.766887 25404 layer_factory.hpp:76] Creating layer data_layer
I0929 23:33:45.768138 25404 net.cpp:110] Creating Layer data_layer
I0929 23:33:45.768143 25404 net.cpp:433] data_layer -> data_blob
I0929 23:33:45.768147 25404 net.cpp:433] data_layer -> label_blob
I0929 23:33:45.768702 25410 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.7.test
I0929 23:33:45.768769 25404 data_layer.cpp:45] output data size: 2000,61,1,1
I0929 23:33:45.770130 25404 net.cpp:155] Setting up data_layer
I0929 23:33:45.770141 25404 net.cpp:163] Top shape: 2000 61 1 1 (122000)
I0929 23:33:45.770144 25404 net.cpp:163] Top shape: 2000 (2000)
I0929 23:33:45.770148 25404 layer_factory.hpp:76] Creating layer hidden_sum_layer
I0929 23:33:45.770154 25404 net.cpp:110] Creating Layer hidden_sum_layer
I0929 23:33:45.770156 25404 net.cpp:477] hidden_sum_layer <- data_blob
I0929 23:33:45.770160 25404 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I0929 23:33:45.770269 25404 net.cpp:155] Setting up hidden_sum_layer
I0929 23:33:45.770274 25404 net.cpp:163] Top shape: 2000 10 (20000)
I0929 23:33:45.770282 25404 layer_factory.hpp:76] Creating layer hidden_act_layer
I0929 23:33:45.770287 25404 net.cpp:110] Creating Layer hidden_act_layer
I0929 23:33:45.770288 25404 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I0929 23:33:45.770303 25404 net.cpp:433] hidden_act_layer -> hidden_act_blob
I0929 23:33:45.770472 25404 net.cpp:155] Setting up hidden_act_layer
I0929 23:33:45.770478 25404 net.cpp:163] Top shape: 2000 10 (20000)
I0929 23:33:45.770481 25404 layer_factory.hpp:76] Creating layer output_sum_layer
I0929 23:33:45.770486 25404 net.cpp:110] Creating Layer output_sum_layer
I0929 23:33:45.770488 25404 net.cpp:477] output_sum_layer <- hidden_act_blob
I0929 23:33:45.770493 25404 net.cpp:433] output_sum_layer -> output_sum_blob
I0929 23:33:45.770550 25404 net.cpp:155] Setting up output_sum_layer
I0929 23:33:45.770555 25404 net.cpp:163] Top shape: 2000 1 (2000)
I0929 23:33:45.770560 25404 layer_factory.hpp:76] Creating layer output_act_layer
I0929 23:33:45.770565 25404 net.cpp:110] Creating Layer output_act_layer
I0929 23:33:45.770566 25404 net.cpp:477] output_act_layer <- output_sum_blob
I0929 23:33:45.770570 25404 net.cpp:433] output_act_layer -> output_act_blob
I0929 23:33:45.770615 25404 net.cpp:155] Setting up output_act_layer
I0929 23:33:45.770620 25404 net.cpp:163] Top shape: 2000 1 (2000)
I0929 23:33:45.770622 25404 layer_factory.hpp:76] Creating layer error_layer
I0929 23:33:45.770627 25404 net.cpp:110] Creating Layer error_layer
I0929 23:33:45.770628 25404 net.cpp:477] error_layer <- output_act_blob
I0929 23:33:45.770632 25404 net.cpp:477] error_layer <- label_blob
I0929 23:33:45.770633 25404 net.cpp:433] error_layer -> error_blob
I0929 23:33:45.770653 25404 net.cpp:155] Setting up error_layer
I0929 23:33:45.770656 25404 net.cpp:163] Top shape: (1)
I0929 23:33:45.770658 25404 net.cpp:168]     with loss weight 1
I0929 23:33:45.770665 25404 net.cpp:236] error_layer needs backward computation.
I0929 23:33:45.770668 25404 net.cpp:236] output_act_layer needs backward computation.
I0929 23:33:45.770669 25404 net.cpp:236] output_sum_layer needs backward computation.
I0929 23:33:45.770671 25404 net.cpp:236] hidden_act_layer needs backward computation.
I0929 23:33:45.770673 25404 net.cpp:236] hidden_sum_layer needs backward computation.
I0929 23:33:45.770675 25404 net.cpp:240] data_layer does not need backward computation.
I0929 23:33:45.770678 25404 net.cpp:283] This network produces output error_blob
I0929 23:33:45.770681 25404 net.cpp:297] Network initialization done.
I0929 23:33:45.770684 25404 net.cpp:298] Memory required for data: 672004
I0929 23:33:45.770701 25404 solver.cpp:66] Solver scaffolding done.
I0929 23:33:45.770795 25404 caffe.cpp:212] Starting Optimization
I0929 23:33:45.770800 25404 solver.cpp:294] Solving model/NNScore/nnscore_model_7.prototxt
I0929 23:33:45.770802 25404 solver.cpp:295] Learning Rate Policy: fixed
I0929 23:33:45.770942 25404 solver.cpp:347] Iteration 0, Testing net (#0)
I0929 23:33:45.770998 25404 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:33:46.066967 25404 solver.cpp:415]     Test net output #0: error_blob = 0.17311 (* 1 = 0.17311 loss)
I0929 23:33:46.068276 25404 solver.cpp:243] Iteration 0, loss = 0.166673
I0929 23:33:46.068290 25404 solver.cpp:259]     Train net output #0: error_blob = 0.166673 (* 1 = 0.166673 loss)
I0929 23:33:46.068308 25404 solver.cpp:590] Iteration 0, lr = 0.01
I0929 23:33:48.590126 25404 solver.cpp:243] Iteration 100, loss = 0.125025
I0929 23:33:48.590164 25404 solver.cpp:259]     Train net output #0: error_blob = 0.125025 (* 1 = 0.125025 loss)
I0929 23:33:48.590169 25404 solver.cpp:590] Iteration 100, lr = 0.01
I0929 23:33:51.138739 25404 solver.cpp:243] Iteration 200, loss = 0.125009
I0929 23:33:51.138778 25404 solver.cpp:259]     Train net output #0: error_blob = 0.125009 (* 1 = 0.125009 loss)
I0929 23:33:51.138784 25404 solver.cpp:590] Iteration 200, lr = 0.01
I0929 23:33:53.691325 25404 solver.cpp:243] Iteration 300, loss = 0.125001
I0929 23:33:53.691355 25404 solver.cpp:259]     Train net output #0: error_blob = 0.125001 (* 1 = 0.125001 loss)
I0929 23:33:53.691360 25404 solver.cpp:590] Iteration 300, lr = 0.01
I0929 23:33:56.220897 25404 solver.cpp:243] Iteration 400, loss = 0.124994
I0929 23:33:56.222507 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124994 (* 1 = 0.124994 loss)
I0929 23:33:56.222515 25404 solver.cpp:590] Iteration 400, lr = 0.01
I0929 23:33:58.774042 25404 solver.cpp:243] Iteration 500, loss = 0.124997
I0929 23:33:58.774078 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124997 (* 1 = 0.124997 loss)
I0929 23:33:58.774088 25404 solver.cpp:590] Iteration 500, lr = 0.01
I0929 23:34:01.341639 25404 solver.cpp:243] Iteration 600, loss = 0.12501
I0929 23:34:01.341683 25404 solver.cpp:259]     Train net output #0: error_blob = 0.12501 (* 1 = 0.12501 loss)
I0929 23:34:01.341691 25404 solver.cpp:590] Iteration 600, lr = 0.01
I0929 23:34:03.908800 25404 solver.cpp:243] Iteration 700, loss = 0.125001
I0929 23:34:03.908848 25404 solver.cpp:259]     Train net output #0: error_blob = 0.125001 (* 1 = 0.125001 loss)
I0929 23:34:03.908854 25404 solver.cpp:590] Iteration 700, lr = 0.01
I0929 23:34:06.426826 25404 solver.cpp:243] Iteration 800, loss = 0.124996
I0929 23:34:06.426865 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124996 (* 1 = 0.124996 loss)
I0929 23:34:06.426870 25404 solver.cpp:590] Iteration 800, lr = 0.01
I0929 23:34:08.977111 25404 solver.cpp:243] Iteration 900, loss = 0.124989
I0929 23:34:08.977145 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124989 (* 1 = 0.124989 loss)
I0929 23:34:08.977154 25404 solver.cpp:590] Iteration 900, lr = 0.01
I0929 23:34:09.029922 25404 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:34:11.495502 25404 solver.cpp:347] Iteration 1000, Testing net (#0)
I0929 23:34:11.778568 25404 solver.cpp:415]     Test net output #0: error_blob = 0.125021 (* 1 = 0.125021 loss)
I0929 23:34:11.779263 25404 solver.cpp:243] Iteration 1000, loss = 0.125006
I0929 23:34:11.779305 25404 solver.cpp:259]     Train net output #0: error_blob = 0.125006 (* 1 = 0.125006 loss)
I0929 23:34:11.779325 25404 solver.cpp:590] Iteration 1000, lr = 0.01
I0929 23:34:14.296484 25404 solver.cpp:243] Iteration 1100, loss = 0.125008
I0929 23:34:14.296535 25404 solver.cpp:259]     Train net output #0: error_blob = 0.125008 (* 1 = 0.125008 loss)
I0929 23:34:14.296541 25404 solver.cpp:590] Iteration 1100, lr = 0.01
I0929 23:34:16.844416 25404 solver.cpp:243] Iteration 1200, loss = 0.124998
I0929 23:34:16.844447 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124998 (* 1 = 0.124998 loss)
I0929 23:34:16.844452 25404 solver.cpp:590] Iteration 1200, lr = 0.01
I0929 23:34:19.430837 25404 solver.cpp:243] Iteration 1300, loss = 0.124986
I0929 23:34:19.430878 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124986 (* 1 = 0.124986 loss)
I0929 23:34:19.430883 25404 solver.cpp:590] Iteration 1300, lr = 0.01
I0929 23:34:22.007496 25404 solver.cpp:243] Iteration 1400, loss = 0.125006
I0929 23:34:22.007527 25404 solver.cpp:259]     Train net output #0: error_blob = 0.125006 (* 1 = 0.125006 loss)
I0929 23:34:22.007532 25404 solver.cpp:590] Iteration 1400, lr = 0.01
I0929 23:34:24.464401 25404 solver.cpp:243] Iteration 1500, loss = 0.125009
I0929 23:34:24.464431 25404 solver.cpp:259]     Train net output #0: error_blob = 0.125009 (* 1 = 0.125009 loss)
I0929 23:34:24.464437 25404 solver.cpp:590] Iteration 1500, lr = 0.01
I0929 23:34:26.991139 25404 solver.cpp:243] Iteration 1600, loss = 0.124991
I0929 23:34:26.991183 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124991 (* 1 = 0.124991 loss)
I0929 23:34:26.991189 25404 solver.cpp:590] Iteration 1600, lr = 0.01
I0929 23:34:29.495666 25404 solver.cpp:243] Iteration 1700, loss = 0.124985
I0929 23:34:29.495707 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124985 (* 1 = 0.124985 loss)
I0929 23:34:29.495712 25404 solver.cpp:590] Iteration 1700, lr = 0.01
I0929 23:34:32.016769 25404 solver.cpp:243] Iteration 1800, loss = 0.125
I0929 23:34:32.016799 25404 solver.cpp:259]     Train net output #0: error_blob = 0.125 (* 1 = 0.125 loss)
I0929 23:34:32.016806 25404 solver.cpp:590] Iteration 1800, lr = 0.01
I0929 23:34:32.222686 25404 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:34:34.566654 25404 solver.cpp:243] Iteration 1900, loss = 0.125001
I0929 23:34:34.566702 25404 solver.cpp:259]     Train net output #0: error_blob = 0.125001 (* 1 = 0.125001 loss)
I0929 23:34:34.566709 25404 solver.cpp:590] Iteration 1900, lr = 0.01
I0929 23:34:37.065884 25404 solver.cpp:347] Iteration 2000, Testing net (#0)
I0929 23:34:37.348219 25404 solver.cpp:415]     Test net output #0: error_blob = 0.12502 (* 1 = 0.12502 loss)
I0929 23:34:37.348851 25404 solver.cpp:243] Iteration 2000, loss = 0.124984
I0929 23:34:37.348868 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124984 (* 1 = 0.124984 loss)
I0929 23:34:37.348875 25404 solver.cpp:590] Iteration 2000, lr = 0.01
I0929 23:34:39.853718 25404 solver.cpp:243] Iteration 2100, loss = 0.124985
I0929 23:34:39.853752 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124985 (* 1 = 0.124985 loss)
I0929 23:34:39.853759 25404 solver.cpp:590] Iteration 2100, lr = 0.01
I0929 23:34:42.405859 25404 solver.cpp:243] Iteration 2200, loss = 0.125006
I0929 23:34:42.405966 25404 solver.cpp:259]     Train net output #0: error_blob = 0.125006 (* 1 = 0.125006 loss)
I0929 23:34:42.405974 25404 solver.cpp:590] Iteration 2200, lr = 0.01
I0929 23:34:44.881675 25404 solver.cpp:243] Iteration 2300, loss = 0.124999
I0929 23:34:44.881705 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124999 (* 1 = 0.124999 loss)
I0929 23:34:44.881711 25404 solver.cpp:590] Iteration 2300, lr = 0.01
I0929 23:34:47.362293 25404 solver.cpp:243] Iteration 2400, loss = 0.124983
I0929 23:34:47.362324 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124983 (* 1 = 0.124983 loss)
I0929 23:34:47.362329 25404 solver.cpp:590] Iteration 2400, lr = 0.01
I0929 23:34:49.880151 25404 solver.cpp:243] Iteration 2500, loss = 0.124986
I0929 23:34:49.880192 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124986 (* 1 = 0.124986 loss)
I0929 23:34:49.880197 25404 solver.cpp:590] Iteration 2500, lr = 0.01
I0929 23:34:52.361390 25404 solver.cpp:243] Iteration 2600, loss = 0.125017
I0929 23:34:52.361430 25404 solver.cpp:259]     Train net output #0: error_blob = 0.125017 (* 1 = 0.125017 loss)
I0929 23:34:52.361435 25404 solver.cpp:590] Iteration 2600, lr = 0.01
I0929 23:34:54.927500 25404 solver.cpp:243] Iteration 2700, loss = 0.124996
I0929 23:34:54.927531 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124996 (* 1 = 0.124996 loss)
I0929 23:34:54.927536 25404 solver.cpp:590] Iteration 2700, lr = 0.01
I0929 23:34:55.292920 25404 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:34:57.492920 25404 solver.cpp:243] Iteration 2800, loss = 0.124986
I0929 23:34:57.492951 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124986 (* 1 = 0.124986 loss)
I0929 23:34:57.492956 25404 solver.cpp:590] Iteration 2800, lr = 0.01
I0929 23:35:00.014662 25404 solver.cpp:243] Iteration 2900, loss = 0.124988
I0929 23:35:00.014703 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124988 (* 1 = 0.124988 loss)
I0929 23:35:00.014708 25404 solver.cpp:590] Iteration 2900, lr = 0.01
I0929 23:35:02.491597 25404 solver.cpp:347] Iteration 3000, Testing net (#0)
I0929 23:35:02.776664 25404 solver.cpp:415]     Test net output #0: error_blob = 0.125021 (* 1 = 0.125021 loss)
I0929 23:35:02.777334 25404 solver.cpp:243] Iteration 3000, loss = 0.125018
I0929 23:35:02.777377 25404 solver.cpp:259]     Train net output #0: error_blob = 0.125018 (* 1 = 0.125018 loss)
I0929 23:35:02.777398 25404 solver.cpp:590] Iteration 3000, lr = 0.01
I0929 23:35:05.278898 25404 solver.cpp:243] Iteration 3100, loss = 0.124991
I0929 23:35:05.278929 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124991 (* 1 = 0.124991 loss)
I0929 23:35:05.278934 25404 solver.cpp:590] Iteration 3100, lr = 0.01
I0929 23:35:07.779496 25404 solver.cpp:243] Iteration 3200, loss = 0.124986
I0929 23:35:07.779527 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124986 (* 1 = 0.124986 loss)
I0929 23:35:07.779532 25404 solver.cpp:590] Iteration 3200, lr = 0.01
I0929 23:35:10.274559 25404 solver.cpp:243] Iteration 3300, loss = 0.124991
I0929 23:35:10.274600 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124991 (* 1 = 0.124991 loss)
I0929 23:35:10.274605 25404 solver.cpp:590] Iteration 3300, lr = 0.01
I0929 23:35:12.812583 25404 solver.cpp:243] Iteration 3400, loss = 0.125018
I0929 23:35:12.813578 25404 solver.cpp:259]     Train net output #0: error_blob = 0.125018 (* 1 = 0.125018 loss)
I0929 23:35:12.813586 25404 solver.cpp:590] Iteration 3400, lr = 0.01
I0929 23:35:15.401049 25404 solver.cpp:243] Iteration 3500, loss = 0.124989
I0929 23:35:15.401080 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124989 (* 1 = 0.124989 loss)
I0929 23:35:15.401087 25404 solver.cpp:590] Iteration 3500, lr = 0.01
I0929 23:35:17.945864 25404 solver.cpp:243] Iteration 3600, loss = 0.124989
I0929 23:35:17.945906 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124989 (* 1 = 0.124989 loss)
I0929 23:35:17.945912 25404 solver.cpp:590] Iteration 3600, lr = 0.01
I0929 23:35:18.454509 25404 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:35:20.503612 25404 solver.cpp:243] Iteration 3700, loss = 0.124991
I0929 23:35:20.503653 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124991 (* 1 = 0.124991 loss)
I0929 23:35:20.503657 25404 solver.cpp:590] Iteration 3700, lr = 0.01
I0929 23:35:23.017803 25404 solver.cpp:243] Iteration 3800, loss = 0.125007
I0929 23:35:23.017832 25404 solver.cpp:259]     Train net output #0: error_blob = 0.125007 (* 1 = 0.125007 loss)
I0929 23:35:23.017837 25404 solver.cpp:590] Iteration 3800, lr = 0.01
I0929 23:35:25.530082 25404 solver.cpp:243] Iteration 3900, loss = 0.124986
I0929 23:35:25.530112 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124986 (* 1 = 0.124986 loss)
I0929 23:35:25.530115 25404 solver.cpp:590] Iteration 3900, lr = 0.01
I0929 23:35:28.023972 25404 solver.cpp:347] Iteration 4000, Testing net (#0)
I0929 23:35:28.409498 25404 solver.cpp:415]     Test net output #0: error_blob = 0.125018 (* 1 = 0.125018 loss)
I0929 23:35:28.410171 25404 solver.cpp:243] Iteration 4000, loss = 0.124991
I0929 23:35:28.410181 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124991 (* 1 = 0.124991 loss)
I0929 23:35:28.410186 25404 solver.cpp:590] Iteration 4000, lr = 0.01
I0929 23:35:30.936386 25404 solver.cpp:243] Iteration 4100, loss = 0.124989
I0929 23:35:30.936421 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124989 (* 1 = 0.124989 loss)
I0929 23:35:30.936429 25404 solver.cpp:590] Iteration 4100, lr = 0.01
I0929 23:35:33.509165 25404 solver.cpp:243] Iteration 4200, loss = 0.124997
I0929 23:35:33.509210 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124997 (* 1 = 0.124997 loss)
I0929 23:35:33.509217 25404 solver.cpp:590] Iteration 4200, lr = 0.01
I0929 23:35:36.102284 25404 solver.cpp:243] Iteration 4300, loss = 0.124986
I0929 23:35:36.102315 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124986 (* 1 = 0.124986 loss)
I0929 23:35:36.102320 25404 solver.cpp:590] Iteration 4300, lr = 0.01
I0929 23:35:38.628729 25404 solver.cpp:243] Iteration 4400, loss = 0.124985
I0929 23:35:38.628759 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124985 (* 1 = 0.124985 loss)
I0929 23:35:38.628764 25404 solver.cpp:590] Iteration 4400, lr = 0.01
I0929 23:35:41.188690 25404 solver.cpp:243] Iteration 4500, loss = 0.12498
I0929 23:35:41.188720 25404 solver.cpp:259]     Train net output #0: error_blob = 0.12498 (* 1 = 0.12498 loss)
I0929 23:35:41.188724 25404 solver.cpp:590] Iteration 4500, lr = 0.01
I0929 23:35:41.876457 25404 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:35:43.746500 25404 solver.cpp:243] Iteration 4600, loss = 0.124989
I0929 23:35:43.746587 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124989 (* 1 = 0.124989 loss)
I0929 23:35:43.746598 25404 solver.cpp:590] Iteration 4600, lr = 0.01
I0929 23:35:46.239611 25404 solver.cpp:243] Iteration 4700, loss = 0.124993
I0929 23:35:46.239653 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124993 (* 1 = 0.124993 loss)
I0929 23:35:46.239660 25404 solver.cpp:590] Iteration 4700, lr = 0.01
I0929 23:35:48.750507 25404 solver.cpp:243] Iteration 4800, loss = 0.12498
I0929 23:35:48.750538 25404 solver.cpp:259]     Train net output #0: error_blob = 0.12498 (* 1 = 0.12498 loss)
I0929 23:35:48.750543 25404 solver.cpp:590] Iteration 4800, lr = 0.01
I0929 23:35:51.260311 25404 solver.cpp:243] Iteration 4900, loss = 0.124984
I0929 23:35:51.260350 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124984 (* 1 = 0.124984 loss)
I0929 23:35:51.260357 25404 solver.cpp:590] Iteration 4900, lr = 0.01
I0929 23:35:53.826486 25404 solver.cpp:347] Iteration 5000, Testing net (#0)
I0929 23:35:54.165694 25404 solver.cpp:415]     Test net output #0: error_blob = 0.12502 (* 1 = 0.12502 loss)
I0929 23:35:54.166359 25404 solver.cpp:243] Iteration 5000, loss = 0.124982
I0929 23:35:54.166373 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124982 (* 1 = 0.124982 loss)
I0929 23:35:54.166381 25404 solver.cpp:590] Iteration 5000, lr = 0.01
I0929 23:35:56.628525 25404 solver.cpp:243] Iteration 5100, loss = 0.124994
I0929 23:35:56.628571 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124994 (* 1 = 0.124994 loss)
I0929 23:35:56.628579 25404 solver.cpp:590] Iteration 5100, lr = 0.01
I0929 23:35:59.121600 25404 solver.cpp:243] Iteration 5200, loss = 0.12499
I0929 23:35:59.121630 25404 solver.cpp:259]     Train net output #0: error_blob = 0.12499 (* 1 = 0.12499 loss)
I0929 23:35:59.121636 25404 solver.cpp:590] Iteration 5200, lr = 0.01
I0929 23:36:01.603160 25404 solver.cpp:243] Iteration 5300, loss = 0.124984
I0929 23:36:01.603200 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124984 (* 1 = 0.124984 loss)
I0929 23:36:01.603206 25404 solver.cpp:590] Iteration 5300, lr = 0.01
I0929 23:36:04.146600 25404 solver.cpp:243] Iteration 5400, loss = 0.124975
I0929 23:36:04.146642 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124975 (* 1 = 0.124975 loss)
I0929 23:36:04.146647 25404 solver.cpp:590] Iteration 5400, lr = 0.01
I0929 23:36:04.941525 25404 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:36:06.669623 25404 solver.cpp:243] Iteration 5500, loss = 0.125004
I0929 23:36:06.669670 25404 solver.cpp:259]     Train net output #0: error_blob = 0.125004 (* 1 = 0.125004 loss)
I0929 23:36:06.669677 25404 solver.cpp:590] Iteration 5500, lr = 0.01
I0929 23:36:09.214695 25404 solver.cpp:243] Iteration 5600, loss = 0.12499
I0929 23:36:09.214736 25404 solver.cpp:259]     Train net output #0: error_blob = 0.12499 (* 1 = 0.12499 loss)
I0929 23:36:09.214741 25404 solver.cpp:590] Iteration 5600, lr = 0.01
I0929 23:36:11.744782 25404 solver.cpp:243] Iteration 5700, loss = 0.12498
I0929 23:36:11.744828 25404 solver.cpp:259]     Train net output #0: error_blob = 0.12498 (* 1 = 0.12498 loss)
I0929 23:36:11.744835 25404 solver.cpp:590] Iteration 5700, lr = 0.01
I0929 23:36:14.245311 25404 solver.cpp:243] Iteration 5800, loss = 0.124978
I0929 23:36:14.245434 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124978 (* 1 = 0.124978 loss)
I0929 23:36:14.245443 25404 solver.cpp:590] Iteration 5800, lr = 0.01
I0929 23:36:16.780156 25404 solver.cpp:243] Iteration 5900, loss = 0.124997
I0929 23:36:16.780199 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124997 (* 1 = 0.124997 loss)
I0929 23:36:16.780205 25404 solver.cpp:590] Iteration 5900, lr = 0.01
I0929 23:36:19.311740 25404 solver.cpp:347] Iteration 6000, Testing net (#0)
I0929 23:36:19.593616 25404 solver.cpp:415]     Test net output #0: error_blob = 0.12502 (* 1 = 0.12502 loss)
I0929 23:36:19.594277 25404 solver.cpp:243] Iteration 6000, loss = 0.124984
I0929 23:36:19.594292 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124984 (* 1 = 0.124984 loss)
I0929 23:36:19.594298 25404 solver.cpp:590] Iteration 6000, lr = 0.01
I0929 23:36:22.133872 25404 solver.cpp:243] Iteration 6100, loss = 0.124974
I0929 23:36:22.133906 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124974 (* 1 = 0.124974 loss)
I0929 23:36:22.133913 25404 solver.cpp:590] Iteration 6100, lr = 0.01
I0929 23:36:24.696416 25404 solver.cpp:243] Iteration 6200, loss = 0.124988
I0929 23:36:24.696461 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124988 (* 1 = 0.124988 loss)
I0929 23:36:24.696468 25404 solver.cpp:590] Iteration 6200, lr = 0.01
I0929 23:36:27.218562 25404 solver.cpp:243] Iteration 6300, loss = 0.124994
I0929 23:36:27.218608 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124994 (* 1 = 0.124994 loss)
I0929 23:36:27.218617 25404 solver.cpp:590] Iteration 6300, lr = 0.01
I0929 23:36:28.178546 25404 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:36:29.761745 25404 solver.cpp:243] Iteration 6400, loss = 0.124986
I0929 23:36:29.761775 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124986 (* 1 = 0.124986 loss)
I0929 23:36:29.761782 25404 solver.cpp:590] Iteration 6400, lr = 0.01
I0929 23:36:32.341997 25404 solver.cpp:243] Iteration 6500, loss = 0.124978
I0929 23:36:32.342043 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124978 (* 1 = 0.124978 loss)
I0929 23:36:32.342051 25404 solver.cpp:590] Iteration 6500, lr = 0.01
I0929 23:36:34.981683 25404 solver.cpp:243] Iteration 6600, loss = 0.124993
I0929 23:36:34.981721 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124993 (* 1 = 0.124993 loss)
I0929 23:36:34.981729 25404 solver.cpp:590] Iteration 6600, lr = 0.01
I0929 23:36:37.564815 25404 solver.cpp:243] Iteration 6700, loss = 0.124994
I0929 23:36:37.564849 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124994 (* 1 = 0.124994 loss)
I0929 23:36:37.564857 25404 solver.cpp:590] Iteration 6700, lr = 0.01
I0929 23:36:40.144819 25404 solver.cpp:243] Iteration 6800, loss = 0.124987
I0929 23:36:40.144862 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124987 (* 1 = 0.124987 loss)
I0929 23:36:40.144870 25404 solver.cpp:590] Iteration 6800, lr = 0.01
I0929 23:36:42.736285 25404 solver.cpp:243] Iteration 6900, loss = 0.124981
I0929 23:36:42.736320 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124981 (* 1 = 0.124981 loss)
I0929 23:36:42.736326 25404 solver.cpp:590] Iteration 6900, lr = 0.01
I0929 23:36:45.247851 25404 solver.cpp:347] Iteration 7000, Testing net (#0)
I0929 23:36:45.531862 25404 solver.cpp:415]     Test net output #0: error_blob = 0.125021 (* 1 = 0.125021 loss)
I0929 23:36:45.532541 25404 solver.cpp:243] Iteration 7000, loss = 0.124993
I0929 23:36:45.532557 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124993 (* 1 = 0.124993 loss)
I0929 23:36:45.532564 25404 solver.cpp:590] Iteration 7000, lr = 0.01
I0929 23:36:48.042644 25404 solver.cpp:243] Iteration 7100, loss = 0.124998
I0929 23:36:48.042672 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124998 (* 1 = 0.124998 loss)
I0929 23:36:48.042678 25404 solver.cpp:590] Iteration 7100, lr = 0.01
I0929 23:36:50.530882 25404 solver.cpp:243] Iteration 7200, loss = 0.124988
I0929 23:36:50.530911 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124988 (* 1 = 0.124988 loss)
I0929 23:36:50.530916 25404 solver.cpp:590] Iteration 7200, lr = 0.01
I0929 23:36:51.605093 25404 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:36:53.026625 25404 solver.cpp:243] Iteration 7300, loss = 0.12499
I0929 23:36:53.026664 25404 solver.cpp:259]     Train net output #0: error_blob = 0.12499 (* 1 = 0.12499 loss)
I0929 23:36:53.026671 25404 solver.cpp:590] Iteration 7300, lr = 0.01
I0929 23:36:55.513268 25404 solver.cpp:243] Iteration 7400, loss = 0.124992
I0929 23:36:55.513299 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124992 (* 1 = 0.124992 loss)
I0929 23:36:55.513306 25404 solver.cpp:590] Iteration 7400, lr = 0.01
I0929 23:36:58.042850 25404 solver.cpp:243] Iteration 7500, loss = 0.125003
I0929 23:36:58.042882 25404 solver.cpp:259]     Train net output #0: error_blob = 0.125003 (* 1 = 0.125003 loss)
I0929 23:36:58.042888 25404 solver.cpp:590] Iteration 7500, lr = 0.01
I0929 23:37:00.554111 25404 solver.cpp:243] Iteration 7600, loss = 0.124998
I0929 23:37:00.554147 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124998 (* 1 = 0.124998 loss)
I0929 23:37:00.554154 25404 solver.cpp:590] Iteration 7600, lr = 0.01
I0929 23:37:03.117236 25404 solver.cpp:243] Iteration 7700, loss = 0.124999
I0929 23:37:03.117285 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124999 (* 1 = 0.124999 loss)
I0929 23:37:03.117293 25404 solver.cpp:590] Iteration 7700, lr = 0.01
I0929 23:37:05.654911 25404 solver.cpp:243] Iteration 7800, loss = 0.12499
I0929 23:37:05.654950 25404 solver.cpp:259]     Train net output #0: error_blob = 0.12499 (* 1 = 0.12499 loss)
I0929 23:37:05.654956 25404 solver.cpp:590] Iteration 7800, lr = 0.01
I0929 23:37:08.186123 25404 solver.cpp:243] Iteration 7900, loss = 0.125003
I0929 23:37:08.186152 25404 solver.cpp:259]     Train net output #0: error_blob = 0.125003 (* 1 = 0.125003 loss)
I0929 23:37:08.186157 25404 solver.cpp:590] Iteration 7900, lr = 0.01
I0929 23:37:10.712896 25404 solver.cpp:347] Iteration 8000, Testing net (#0)
I0929 23:37:10.999799 25404 solver.cpp:415]     Test net output #0: error_blob = 0.125023 (* 1 = 0.125023 loss)
I0929 23:37:11.000506 25404 solver.cpp:243] Iteration 8000, loss = 0.124992
I0929 23:37:11.000521 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124992 (* 1 = 0.124992 loss)
I0929 23:37:11.000527 25404 solver.cpp:590] Iteration 8000, lr = 0.01
I0929 23:37:13.520223 25404 solver.cpp:243] Iteration 8100, loss = 0.124999
I0929 23:37:13.520262 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124999 (* 1 = 0.124999 loss)
I0929 23:37:13.520268 25404 solver.cpp:590] Iteration 8100, lr = 0.01
I0929 23:37:14.825800 25404 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:37:16.121431 25404 solver.cpp:243] Iteration 8200, loss = 0.124996
I0929 23:37:16.121580 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124996 (* 1 = 0.124996 loss)
I0929 23:37:16.121600 25404 solver.cpp:590] Iteration 8200, lr = 0.01
I0929 23:37:18.622813 25404 solver.cpp:243] Iteration 8300, loss = 0.125003
I0929 23:37:18.622850 25404 solver.cpp:259]     Train net output #0: error_blob = 0.125003 (* 1 = 0.125003 loss)
I0929 23:37:18.622855 25404 solver.cpp:590] Iteration 8300, lr = 0.01
I0929 23:37:21.155300 25404 solver.cpp:243] Iteration 8400, loss = 0.125002
I0929 23:37:21.155339 25404 solver.cpp:259]     Train net output #0: error_blob = 0.125002 (* 1 = 0.125002 loss)
I0929 23:37:21.155346 25404 solver.cpp:590] Iteration 8400, lr = 0.01
I0929 23:37:23.651253 25404 solver.cpp:243] Iteration 8500, loss = 0.125009
I0929 23:37:23.651290 25404 solver.cpp:259]     Train net output #0: error_blob = 0.125009 (* 1 = 0.125009 loss)
I0929 23:37:23.651298 25404 solver.cpp:590] Iteration 8500, lr = 0.01
I0929 23:37:26.219614 25404 solver.cpp:243] Iteration 8600, loss = 0.124993
I0929 23:37:26.219642 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124993 (* 1 = 0.124993 loss)
I0929 23:37:26.219647 25404 solver.cpp:590] Iteration 8600, lr = 0.01
I0929 23:37:28.811942 25404 solver.cpp:243] Iteration 8700, loss = 0.125
I0929 23:37:28.811977 25404 solver.cpp:259]     Train net output #0: error_blob = 0.125 (* 1 = 0.125 loss)
I0929 23:37:28.811985 25404 solver.cpp:590] Iteration 8700, lr = 0.01
I0929 23:37:31.386539 25404 solver.cpp:243] Iteration 8800, loss = 0.125007
I0929 23:37:31.386574 25404 solver.cpp:259]     Train net output #0: error_blob = 0.125007 (* 1 = 0.125007 loss)
I0929 23:37:31.386584 25404 solver.cpp:590] Iteration 8800, lr = 0.01
I0929 23:37:33.964797 25404 solver.cpp:243] Iteration 8900, loss = 0.125
I0929 23:37:33.964830 25404 solver.cpp:259]     Train net output #0: error_blob = 0.125 (* 1 = 0.125 loss)
I0929 23:37:33.964836 25404 solver.cpp:590] Iteration 8900, lr = 0.01
I0929 23:37:36.484302 25404 solver.cpp:347] Iteration 9000, Testing net (#0)
I0929 23:37:36.767012 25404 solver.cpp:415]     Test net output #0: error_blob = 0.125018 (* 1 = 0.125018 loss)
I0929 23:37:36.767760 25404 solver.cpp:243] Iteration 9000, loss = 0.125
I0929 23:37:36.767788 25404 solver.cpp:259]     Train net output #0: error_blob = 0.125 (* 1 = 0.125 loss)
I0929 23:37:36.767796 25404 solver.cpp:590] Iteration 9000, lr = 0.01
I0929 23:37:38.129914 25404 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:37:39.238617 25404 solver.cpp:243] Iteration 9100, loss = 0.125004
I0929 23:37:39.238658 25404 solver.cpp:259]     Train net output #0: error_blob = 0.125004 (* 1 = 0.125004 loss)
I0929 23:37:39.238664 25404 solver.cpp:590] Iteration 9100, lr = 0.01
I0929 23:37:41.750407 25404 solver.cpp:243] Iteration 9200, loss = 0.125011
I0929 23:37:41.750449 25404 solver.cpp:259]     Train net output #0: error_blob = 0.125011 (* 1 = 0.125011 loss)
I0929 23:37:41.750454 25404 solver.cpp:590] Iteration 9200, lr = 0.01
I0929 23:37:44.292929 25404 solver.cpp:243] Iteration 9300, loss = 0.124997
I0929 23:37:44.292960 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124997 (* 1 = 0.124997 loss)
I0929 23:37:44.292965 25404 solver.cpp:590] Iteration 9300, lr = 0.01
I0929 23:37:46.858105 25404 solver.cpp:243] Iteration 9400, loss = 0.125001
I0929 23:37:46.858222 25404 solver.cpp:259]     Train net output #0: error_blob = 0.125001 (* 1 = 0.125001 loss)
I0929 23:37:46.858229 25404 solver.cpp:590] Iteration 9400, lr = 0.01
I0929 23:37:49.345897 25404 solver.cpp:243] Iteration 9500, loss = 0.124999
I0929 23:37:49.345937 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124999 (* 1 = 0.124999 loss)
I0929 23:37:49.345942 25404 solver.cpp:590] Iteration 9500, lr = 0.01
I0929 23:37:51.908668 25404 solver.cpp:243] Iteration 9600, loss = 0.125017
I0929 23:37:51.908699 25404 solver.cpp:259]     Train net output #0: error_blob = 0.125017 (* 1 = 0.125017 loss)
I0929 23:37:51.908704 25404 solver.cpp:590] Iteration 9600, lr = 0.01
I0929 23:37:54.487017 25404 solver.cpp:243] Iteration 9700, loss = 0.124988
I0929 23:37:54.487048 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124988 (* 1 = 0.124988 loss)
I0929 23:37:54.487054 25404 solver.cpp:590] Iteration 9700, lr = 0.01
I0929 23:37:56.975697 25404 solver.cpp:243] Iteration 9800, loss = 0.124994
I0929 23:37:56.975728 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124994 (* 1 = 0.124994 loss)
I0929 23:37:56.975734 25404 solver.cpp:590] Iteration 9800, lr = 0.01
I0929 23:37:59.434885 25404 solver.cpp:243] Iteration 9900, loss = 0.124998
I0929 23:37:59.434916 25404 solver.cpp:259]     Train net output #0: error_blob = 0.124998 (* 1 = 0.124998 loss)
I0929 23:37:59.434921 25404 solver.cpp:590] Iteration 9900, lr = 0.01
I0929 23:38:01.915518 25404 solver.cpp:468] Snapshotting to binary proto file _iter_10000.caffemodel
I0929 23:38:01.916342 25404 solver.cpp:753] Snapshotting solver state to binary proto file _iter_10000.solverstate
I0929 23:38:01.940253 25404 solver.cpp:327] Iteration 10000, loss = 0.125022
I0929 23:38:01.940279 25404 solver.cpp:347] Iteration 10000, Testing net (#0)
I0929 23:38:02.113736 25404 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:38:02.225533 25404 solver.cpp:415]     Test net output #0: error_blob = 0.125019 (* 1 = 0.125019 loss)
I0929 23:38:02.225550 25404 solver.cpp:332] Optimization Done.
I0929 23:38:02.225554 25404 caffe.cpp:215] Optimization Done.
I0929 23:38:02.286069 25413 caffe.cpp:184] Using GPUs 0
I0929 23:38:02.845268 25413 solver.cpp:54] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "fixed"
momentum: 0.9
solver_mode: GPU
device_id: 0
net: "model/NNScore/nnscore_model_8.prototxt"
I0929 23:38:02.845299 25413 solver.cpp:97] Creating training net from net file: model/NNScore/nnscore_model_8.prototxt
I0929 23:38:02.845470 25413 net.cpp:339] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_layer
I0929 23:38:02.845538 25413 net.cpp:50] Initializing net from parameters: 
name: "model/NNScore/nnscore_model_8.prototxt"
state {
  phase: TRAIN
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TRAIN
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.8.train"
    batch_size: 20000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I0929 23:38:02.845607 25413 layer_factory.hpp:76] Creating layer data_layer
I0929 23:38:02.858845 25413 net.cpp:110] Creating Layer data_layer
I0929 23:38:02.858876 25413 net.cpp:433] data_layer -> data_blob
I0929 23:38:02.858899 25413 net.cpp:433] data_layer -> label_blob
I0929 23:38:02.859490 25417 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.8.train
I0929 23:38:03.548571 25413 data_layer.cpp:45] output data size: 20000,61,1,1
I0929 23:38:03.553611 25413 net.cpp:155] Setting up data_layer
I0929 23:38:03.553653 25413 net.cpp:163] Top shape: 20000 61 1 1 (1220000)
I0929 23:38:03.553656 25413 net.cpp:163] Top shape: 20000 (20000)
I0929 23:38:03.553673 25413 layer_factory.hpp:76] Creating layer hidden_sum_layer
I0929 23:38:03.553685 25413 net.cpp:110] Creating Layer hidden_sum_layer
I0929 23:38:03.553694 25413 net.cpp:477] hidden_sum_layer <- data_blob
I0929 23:38:03.553704 25413 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I0929 23:38:03.554100 25413 net.cpp:155] Setting up hidden_sum_layer
I0929 23:38:03.554107 25413 net.cpp:163] Top shape: 20000 10 (200000)
I0929 23:38:03.554131 25413 layer_factory.hpp:76] Creating layer hidden_act_layer
I0929 23:38:03.554147 25413 net.cpp:110] Creating Layer hidden_act_layer
I0929 23:38:03.554152 25413 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I0929 23:38:03.554155 25413 net.cpp:433] hidden_act_layer -> hidden_act_blob
I0929 23:38:06.787704 25413 net.cpp:155] Setting up hidden_act_layer
I0929 23:38:06.787729 25413 net.cpp:163] Top shape: 20000 10 (200000)
I0929 23:38:06.787732 25413 layer_factory.hpp:76] Creating layer output_sum_layer
I0929 23:38:06.787742 25413 net.cpp:110] Creating Layer output_sum_layer
I0929 23:38:06.787746 25413 net.cpp:477] output_sum_layer <- hidden_act_blob
I0929 23:38:06.787751 25413 net.cpp:433] output_sum_layer -> output_sum_blob
I0929 23:38:06.787837 25413 net.cpp:155] Setting up output_sum_layer
I0929 23:38:06.787842 25413 net.cpp:163] Top shape: 20000 1 (20000)
I0929 23:38:06.787848 25413 layer_factory.hpp:76] Creating layer output_act_layer
I0929 23:38:06.787853 25413 net.cpp:110] Creating Layer output_act_layer
I0929 23:38:06.787856 25413 net.cpp:477] output_act_layer <- output_sum_blob
I0929 23:38:06.787859 25413 net.cpp:433] output_act_layer -> output_act_blob
I0929 23:38:06.787916 25413 net.cpp:155] Setting up output_act_layer
I0929 23:38:06.787937 25413 net.cpp:163] Top shape: 20000 1 (20000)
I0929 23:38:06.787940 25413 layer_factory.hpp:76] Creating layer error_layer
I0929 23:38:06.787945 25413 net.cpp:110] Creating Layer error_layer
I0929 23:38:06.787947 25413 net.cpp:477] error_layer <- output_act_blob
I0929 23:38:06.787950 25413 net.cpp:477] error_layer <- label_blob
I0929 23:38:06.787955 25413 net.cpp:433] error_layer -> error_blob
I0929 23:38:06.787978 25413 net.cpp:155] Setting up error_layer
I0929 23:38:06.787981 25413 net.cpp:163] Top shape: (1)
I0929 23:38:06.787983 25413 net.cpp:168]     with loss weight 1
I0929 23:38:06.787999 25413 net.cpp:236] error_layer needs backward computation.
I0929 23:38:06.788002 25413 net.cpp:236] output_act_layer needs backward computation.
I0929 23:38:06.788004 25413 net.cpp:236] output_sum_layer needs backward computation.
I0929 23:38:06.788007 25413 net.cpp:236] hidden_act_layer needs backward computation.
I0929 23:38:06.788008 25413 net.cpp:236] hidden_sum_layer needs backward computation.
I0929 23:38:06.788010 25413 net.cpp:240] data_layer does not need backward computation.
I0929 23:38:06.788012 25413 net.cpp:283] This network produces output error_blob
I0929 23:38:06.788017 25413 net.cpp:297] Network initialization done.
I0929 23:38:06.788019 25413 net.cpp:298] Memory required for data: 6720004
I0929 23:38:06.788146 25413 solver.cpp:187] Creating test net (#0) specified by net file: model/NNScore/nnscore_model_8.prototxt
I0929 23:38:06.788159 25413 net.cpp:339] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_layer
I0929 23:38:06.788192 25413 net.cpp:50] Initializing net from parameters: 
name: "model/NNScore/nnscore_model_8.prototxt"
state {
  phase: TEST
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TEST
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.8.test"
    batch_size: 2000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I0929 23:38:06.788213 25413 layer_factory.hpp:76] Creating layer data_layer
I0929 23:38:06.789489 25413 net.cpp:110] Creating Layer data_layer
I0929 23:38:06.789497 25413 net.cpp:433] data_layer -> data_blob
I0929 23:38:06.789505 25413 net.cpp:433] data_layer -> label_blob
I0929 23:38:06.790040 25419 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.8.test
I0929 23:38:06.790102 25413 data_layer.cpp:45] output data size: 2000,61,1,1
I0929 23:38:06.791445 25413 net.cpp:155] Setting up data_layer
I0929 23:38:06.791457 25413 net.cpp:163] Top shape: 2000 61 1 1 (122000)
I0929 23:38:06.791462 25413 net.cpp:163] Top shape: 2000 (2000)
I0929 23:38:06.791467 25413 layer_factory.hpp:76] Creating layer hidden_sum_layer
I0929 23:38:06.791477 25413 net.cpp:110] Creating Layer hidden_sum_layer
I0929 23:38:06.791481 25413 net.cpp:477] hidden_sum_layer <- data_blob
I0929 23:38:06.791487 25413 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I0929 23:38:06.791623 25413 net.cpp:155] Setting up hidden_sum_layer
I0929 23:38:06.791630 25413 net.cpp:163] Top shape: 2000 10 (20000)
I0929 23:38:06.791643 25413 layer_factory.hpp:76] Creating layer hidden_act_layer
I0929 23:38:06.791652 25413 net.cpp:110] Creating Layer hidden_act_layer
I0929 23:38:06.791656 25413 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I0929 23:38:06.791674 25413 net.cpp:433] hidden_act_layer -> hidden_act_blob
I0929 23:38:06.791863 25413 net.cpp:155] Setting up hidden_act_layer
I0929 23:38:06.791872 25413 net.cpp:163] Top shape: 2000 10 (20000)
I0929 23:38:06.791875 25413 layer_factory.hpp:76] Creating layer output_sum_layer
I0929 23:38:06.791882 25413 net.cpp:110] Creating Layer output_sum_layer
I0929 23:38:06.791888 25413 net.cpp:477] output_sum_layer <- hidden_act_blob
I0929 23:38:06.791894 25413 net.cpp:433] output_sum_layer -> output_sum_blob
I0929 23:38:06.791961 25413 net.cpp:155] Setting up output_sum_layer
I0929 23:38:06.791968 25413 net.cpp:163] Top shape: 2000 1 (2000)
I0929 23:38:06.791976 25413 layer_factory.hpp:76] Creating layer output_act_layer
I0929 23:38:06.791985 25413 net.cpp:110] Creating Layer output_act_layer
I0929 23:38:06.791990 25413 net.cpp:477] output_act_layer <- output_sum_blob
I0929 23:38:06.791995 25413 net.cpp:433] output_act_layer -> output_act_blob
I0929 23:38:06.792052 25413 net.cpp:155] Setting up output_act_layer
I0929 23:38:06.792058 25413 net.cpp:163] Top shape: 2000 1 (2000)
I0929 23:38:06.792064 25413 layer_factory.hpp:76] Creating layer error_layer
I0929 23:38:06.792070 25413 net.cpp:110] Creating Layer error_layer
I0929 23:38:06.792074 25413 net.cpp:477] error_layer <- output_act_blob
I0929 23:38:06.792078 25413 net.cpp:477] error_layer <- label_blob
I0929 23:38:06.792085 25413 net.cpp:433] error_layer -> error_blob
I0929 23:38:06.792111 25413 net.cpp:155] Setting up error_layer
I0929 23:38:06.792117 25413 net.cpp:163] Top shape: (1)
I0929 23:38:06.792121 25413 net.cpp:168]     with loss weight 1
I0929 23:38:06.792131 25413 net.cpp:236] error_layer needs backward computation.
I0929 23:38:06.792136 25413 net.cpp:236] output_act_layer needs backward computation.
I0929 23:38:06.792140 25413 net.cpp:236] output_sum_layer needs backward computation.
I0929 23:38:06.792142 25413 net.cpp:236] hidden_act_layer needs backward computation.
I0929 23:38:06.792146 25413 net.cpp:236] hidden_sum_layer needs backward computation.
I0929 23:38:06.792150 25413 net.cpp:240] data_layer does not need backward computation.
I0929 23:38:06.792153 25413 net.cpp:283] This network produces output error_blob
I0929 23:38:06.792160 25413 net.cpp:297] Network initialization done.
I0929 23:38:06.792163 25413 net.cpp:298] Memory required for data: 672004
I0929 23:38:06.792188 25413 solver.cpp:66] Solver scaffolding done.
I0929 23:38:06.792287 25413 caffe.cpp:212] Starting Optimization
I0929 23:38:06.792295 25413 solver.cpp:294] Solving model/NNScore/nnscore_model_8.prototxt
I0929 23:38:06.792299 25413 solver.cpp:295] Learning Rate Policy: fixed
I0929 23:38:06.792479 25413 solver.cpp:347] Iteration 0, Testing net (#0)
I0929 23:38:06.792596 25413 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:38:07.078327 25413 solver.cpp:415]     Test net output #0: error_blob = 0.125248 (* 1 = 0.125248 loss)
I0929 23:38:07.079613 25413 solver.cpp:243] Iteration 0, loss = 0.124997
I0929 23:38:07.079627 25413 solver.cpp:259]     Train net output #0: error_blob = 0.124997 (* 1 = 0.124997 loss)
I0929 23:38:07.079643 25413 solver.cpp:590] Iteration 0, lr = 0.01
I0929 23:38:09.562886 25413 solver.cpp:243] Iteration 100, loss = 0.123712
I0929 23:38:09.562917 25413 solver.cpp:259]     Train net output #0: error_blob = 0.123712 (* 1 = 0.123712 loss)
I0929 23:38:09.562922 25413 solver.cpp:590] Iteration 100, lr = 0.01
I0929 23:38:12.073009 25413 solver.cpp:243] Iteration 200, loss = 0.122875
I0929 23:38:12.073055 25413 solver.cpp:259]     Train net output #0: error_blob = 0.122875 (* 1 = 0.122875 loss)
I0929 23:38:12.073063 25413 solver.cpp:590] Iteration 200, lr = 0.01
I0929 23:38:14.567497 25413 solver.cpp:243] Iteration 300, loss = 0.122271
I0929 23:38:14.567528 25413 solver.cpp:259]     Train net output #0: error_blob = 0.122271 (* 1 = 0.122271 loss)
I0929 23:38:14.567533 25413 solver.cpp:590] Iteration 300, lr = 0.01
I0929 23:38:17.077661 25413 solver.cpp:243] Iteration 400, loss = 0.121881
I0929 23:38:17.077713 25413 solver.cpp:259]     Train net output #0: error_blob = 0.121881 (* 1 = 0.121881 loss)
I0929 23:38:17.077719 25413 solver.cpp:590] Iteration 400, lr = 0.01
I0929 23:38:19.578289 25413 solver.cpp:243] Iteration 500, loss = 0.120903
I0929 23:38:19.578325 25413 solver.cpp:259]     Train net output #0: error_blob = 0.120903 (* 1 = 0.120903 loss)
I0929 23:38:19.578331 25413 solver.cpp:590] Iteration 500, lr = 0.01
I0929 23:38:22.104817 25413 solver.cpp:243] Iteration 600, loss = 0.120864
I0929 23:38:22.104846 25413 solver.cpp:259]     Train net output #0: error_blob = 0.120864 (* 1 = 0.120864 loss)
I0929 23:38:22.104851 25413 solver.cpp:590] Iteration 600, lr = 0.01
I0929 23:38:24.616395 25413 solver.cpp:243] Iteration 700, loss = 0.119574
I0929 23:38:24.616428 25413 solver.cpp:259]     Train net output #0: error_blob = 0.119574 (* 1 = 0.119574 loss)
I0929 23:38:24.616436 25413 solver.cpp:590] Iteration 700, lr = 0.01
I0929 23:38:27.130201 25413 solver.cpp:243] Iteration 800, loss = 0.119473
I0929 23:38:27.130234 25413 solver.cpp:259]     Train net output #0: error_blob = 0.119473 (* 1 = 0.119473 loss)
I0929 23:38:27.130239 25413 solver.cpp:590] Iteration 800, lr = 0.01
I0929 23:38:29.643327 25413 solver.cpp:243] Iteration 900, loss = 0.119848
I0929 23:38:29.643373 25413 solver.cpp:259]     Train net output #0: error_blob = 0.119848 (* 1 = 0.119848 loss)
I0929 23:38:29.643379 25413 solver.cpp:590] Iteration 900, lr = 0.01
I0929 23:38:29.694180 25413 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:38:32.151046 25413 solver.cpp:347] Iteration 1000, Testing net (#0)
I0929 23:38:32.457770 25413 solver.cpp:415]     Test net output #0: error_blob = 0.121369 (* 1 = 0.121369 loss)
I0929 23:38:32.458534 25413 solver.cpp:243] Iteration 1000, loss = 0.119014
I0929 23:38:32.458559 25413 solver.cpp:259]     Train net output #0: error_blob = 0.119014 (* 1 = 0.119014 loss)
I0929 23:38:32.458567 25413 solver.cpp:590] Iteration 1000, lr = 0.01
I0929 23:38:34.939807 25413 solver.cpp:243] Iteration 1100, loss = 0.117928
I0929 23:38:34.939841 25413 solver.cpp:259]     Train net output #0: error_blob = 0.117928 (* 1 = 0.117928 loss)
I0929 23:38:34.939847 25413 solver.cpp:590] Iteration 1100, lr = 0.01
I0929 23:38:37.448881 25413 solver.cpp:243] Iteration 1200, loss = 0.118669
I0929 23:38:37.448925 25413 solver.cpp:259]     Train net output #0: error_blob = 0.118669 (* 1 = 0.118669 loss)
I0929 23:38:37.448930 25413 solver.cpp:590] Iteration 1200, lr = 0.01
I0929 23:38:39.964081 25413 solver.cpp:243] Iteration 1300, loss = 0.11748
I0929 23:38:39.964128 25413 solver.cpp:259]     Train net output #0: error_blob = 0.11748 (* 1 = 0.11748 loss)
I0929 23:38:39.964138 25413 solver.cpp:590] Iteration 1300, lr = 0.01
I0929 23:38:42.477725 25413 solver.cpp:243] Iteration 1400, loss = 0.116546
I0929 23:38:42.477764 25413 solver.cpp:259]     Train net output #0: error_blob = 0.116546 (* 1 = 0.116546 loss)
I0929 23:38:42.477771 25413 solver.cpp:590] Iteration 1400, lr = 0.01
I0929 23:38:44.992828 25413 solver.cpp:243] Iteration 1500, loss = 0.118502
I0929 23:38:44.992867 25413 solver.cpp:259]     Train net output #0: error_blob = 0.118502 (* 1 = 0.118502 loss)
I0929 23:38:44.992876 25413 solver.cpp:590] Iteration 1500, lr = 0.01
I0929 23:38:47.505846 25413 solver.cpp:243] Iteration 1600, loss = 0.118984
I0929 23:38:47.505889 25413 solver.cpp:259]     Train net output #0: error_blob = 0.118984 (* 1 = 0.118984 loss)
I0929 23:38:47.505899 25413 solver.cpp:590] Iteration 1600, lr = 0.01
I0929 23:38:50.015977 25413 solver.cpp:243] Iteration 1700, loss = 0.117987
I0929 23:38:50.016011 25413 solver.cpp:259]     Train net output #0: error_blob = 0.117987 (* 1 = 0.117987 loss)
I0929 23:38:50.016018 25413 solver.cpp:590] Iteration 1700, lr = 0.01
I0929 23:38:52.534497 25413 solver.cpp:243] Iteration 1800, loss = 0.117607
I0929 23:38:52.534546 25413 solver.cpp:259]     Train net output #0: error_blob = 0.117607 (* 1 = 0.117607 loss)
I0929 23:38:52.534554 25413 solver.cpp:590] Iteration 1800, lr = 0.01
I0929 23:38:52.731401 25413 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:38:55.044162 25413 solver.cpp:243] Iteration 1900, loss = 0.119724
I0929 23:38:55.044199 25413 solver.cpp:259]     Train net output #0: error_blob = 0.119724 (* 1 = 0.119724 loss)
I0929 23:38:55.044206 25413 solver.cpp:590] Iteration 1900, lr = 0.01
I0929 23:38:57.545656 25413 solver.cpp:347] Iteration 2000, Testing net (#0)
I0929 23:38:57.842499 25413 solver.cpp:415]     Test net output #0: error_blob = 0.120994 (* 1 = 0.120994 loss)
I0929 23:38:57.843205 25413 solver.cpp:243] Iteration 2000, loss = 0.118105
I0929 23:38:57.843219 25413 solver.cpp:259]     Train net output #0: error_blob = 0.118105 (* 1 = 0.118105 loss)
I0929 23:38:57.843226 25413 solver.cpp:590] Iteration 2000, lr = 0.01
I0929 23:39:00.309123 25413 solver.cpp:243] Iteration 2100, loss = 0.115439
I0929 23:39:00.309152 25413 solver.cpp:259]     Train net output #0: error_blob = 0.115439 (* 1 = 0.115439 loss)
I0929 23:39:00.309157 25413 solver.cpp:590] Iteration 2100, lr = 0.01
I0929 23:39:02.813048 25413 solver.cpp:243] Iteration 2200, loss = 0.115649
I0929 23:39:02.813150 25413 solver.cpp:259]     Train net output #0: error_blob = 0.115649 (* 1 = 0.115649 loss)
I0929 23:39:02.813158 25413 solver.cpp:590] Iteration 2200, lr = 0.01
I0929 23:39:05.317778 25413 solver.cpp:243] Iteration 2300, loss = 0.116329
I0929 23:39:05.317816 25413 solver.cpp:259]     Train net output #0: error_blob = 0.116329 (* 1 = 0.116329 loss)
I0929 23:39:05.317823 25413 solver.cpp:590] Iteration 2300, lr = 0.01
I0929 23:39:07.839213 25413 solver.cpp:243] Iteration 2400, loss = 0.114961
I0929 23:39:07.839243 25413 solver.cpp:259]     Train net output #0: error_blob = 0.114961 (* 1 = 0.114961 loss)
I0929 23:39:07.839248 25413 solver.cpp:590] Iteration 2400, lr = 0.01
I0929 23:39:10.323252 25413 solver.cpp:243] Iteration 2500, loss = 0.114175
I0929 23:39:10.323282 25413 solver.cpp:259]     Train net output #0: error_blob = 0.114175 (* 1 = 0.114175 loss)
I0929 23:39:10.323287 25413 solver.cpp:590] Iteration 2500, lr = 0.01
I0929 23:39:12.807343 25413 solver.cpp:243] Iteration 2600, loss = 0.117626
I0929 23:39:12.807381 25413 solver.cpp:259]     Train net output #0: error_blob = 0.117626 (* 1 = 0.117626 loss)
I0929 23:39:12.807389 25413 solver.cpp:590] Iteration 2600, lr = 0.01
I0929 23:39:15.330234 25413 solver.cpp:243] Iteration 2700, loss = 0.116003
I0929 23:39:15.330270 25413 solver.cpp:259]     Train net output #0: error_blob = 0.116003 (* 1 = 0.116003 loss)
I0929 23:39:15.330276 25413 solver.cpp:590] Iteration 2700, lr = 0.01
I0929 23:39:15.682801 25413 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:39:17.820466 25413 solver.cpp:243] Iteration 2800, loss = 0.113961
I0929 23:39:17.820508 25413 solver.cpp:259]     Train net output #0: error_blob = 0.113961 (* 1 = 0.113961 loss)
I0929 23:39:17.820514 25413 solver.cpp:590] Iteration 2800, lr = 0.01
I0929 23:39:20.309226 25413 solver.cpp:243] Iteration 2900, loss = 0.116015
I0929 23:39:20.309273 25413 solver.cpp:259]     Train net output #0: error_blob = 0.116015 (* 1 = 0.116015 loss)
I0929 23:39:20.309281 25413 solver.cpp:590] Iteration 2900, lr = 0.01
I0929 23:39:22.760663 25413 solver.cpp:347] Iteration 3000, Testing net (#0)
I0929 23:39:23.045141 25413 solver.cpp:415]     Test net output #0: error_blob = 0.122925 (* 1 = 0.122925 loss)
I0929 23:39:23.045833 25413 solver.cpp:243] Iteration 3000, loss = 0.116249
I0929 23:39:23.045847 25413 solver.cpp:259]     Train net output #0: error_blob = 0.116249 (* 1 = 0.116249 loss)
I0929 23:39:23.045855 25413 solver.cpp:590] Iteration 3000, lr = 0.01
I0929 23:39:25.479465 25413 solver.cpp:243] Iteration 3100, loss = 0.113038
I0929 23:39:25.479496 25413 solver.cpp:259]     Train net output #0: error_blob = 0.113038 (* 1 = 0.113038 loss)
I0929 23:39:25.479501 25413 solver.cpp:590] Iteration 3100, lr = 0.01
I0929 23:39:28.006836 25413 solver.cpp:243] Iteration 3200, loss = 0.115704
I0929 23:39:28.006873 25413 solver.cpp:259]     Train net output #0: error_blob = 0.115704 (* 1 = 0.115704 loss)
I0929 23:39:28.006880 25413 solver.cpp:590] Iteration 3200, lr = 0.01
I0929 23:39:30.495417 25413 solver.cpp:243] Iteration 3300, loss = 0.116557
I0929 23:39:30.495447 25413 solver.cpp:259]     Train net output #0: error_blob = 0.116557 (* 1 = 0.116557 loss)
I0929 23:39:30.495452 25413 solver.cpp:590] Iteration 3300, lr = 0.01
I0929 23:39:32.995340 25413 solver.cpp:243] Iteration 3400, loss = 0.114438
I0929 23:39:32.996582 25413 solver.cpp:259]     Train net output #0: error_blob = 0.114438 (* 1 = 0.114438 loss)
I0929 23:39:32.996601 25413 solver.cpp:590] Iteration 3400, lr = 0.01
I0929 23:39:35.479799 25413 solver.cpp:243] Iteration 3500, loss = 0.119581
I0929 23:39:35.479830 25413 solver.cpp:259]     Train net output #0: error_blob = 0.119581 (* 1 = 0.119581 loss)
I0929 23:39:35.479835 25413 solver.cpp:590] Iteration 3500, lr = 0.01
I0929 23:39:38.000586 25413 solver.cpp:243] Iteration 3600, loss = 0.119026
I0929 23:39:38.000622 25413 solver.cpp:259]     Train net output #0: error_blob = 0.119026 (* 1 = 0.119026 loss)
I0929 23:39:38.000628 25413 solver.cpp:590] Iteration 3600, lr = 0.01
I0929 23:39:38.506428 25413 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:39:40.520443 25413 solver.cpp:243] Iteration 3700, loss = 0.116699
I0929 23:39:40.520498 25413 solver.cpp:259]     Train net output #0: error_blob = 0.116699 (* 1 = 0.116699 loss)
I0929 23:39:40.520517 25413 solver.cpp:590] Iteration 3700, lr = 0.01
I0929 23:39:43.038889 25413 solver.cpp:243] Iteration 3800, loss = 0.112536
I0929 23:39:43.038919 25413 solver.cpp:259]     Train net output #0: error_blob = 0.112536 (* 1 = 0.112536 loss)
I0929 23:39:43.038925 25413 solver.cpp:590] Iteration 3800, lr = 0.01
I0929 23:39:45.533818 25413 solver.cpp:243] Iteration 3900, loss = 0.120218
I0929 23:39:45.533865 25413 solver.cpp:259]     Train net output #0: error_blob = 0.120218 (* 1 = 0.120218 loss)
I0929 23:39:45.533874 25413 solver.cpp:590] Iteration 3900, lr = 0.01
I0929 23:39:47.992326 25413 solver.cpp:347] Iteration 4000, Testing net (#0)
I0929 23:39:48.274394 25413 solver.cpp:415]     Test net output #0: error_blob = 0.124558 (* 1 = 0.124558 loss)
I0929 23:39:48.275138 25413 solver.cpp:243] Iteration 4000, loss = 0.116253
I0929 23:39:48.275174 25413 solver.cpp:259]     Train net output #0: error_blob = 0.116253 (* 1 = 0.116253 loss)
I0929 23:39:48.275185 25413 solver.cpp:590] Iteration 4000, lr = 0.01
I0929 23:39:50.743186 25413 solver.cpp:243] Iteration 4100, loss = 0.120276
I0929 23:39:50.743217 25413 solver.cpp:259]     Train net output #0: error_blob = 0.120276 (* 1 = 0.120276 loss)
I0929 23:39:50.743223 25413 solver.cpp:590] Iteration 4100, lr = 0.01
I0929 23:39:53.239840 25413 solver.cpp:243] Iteration 4200, loss = 0.11567
I0929 23:39:53.239887 25413 solver.cpp:259]     Train net output #0: error_blob = 0.11567 (* 1 = 0.11567 loss)
I0929 23:39:53.239895 25413 solver.cpp:590] Iteration 4200, lr = 0.01
I0929 23:39:55.755108 25413 solver.cpp:243] Iteration 4300, loss = 0.12135
I0929 23:39:55.755147 25413 solver.cpp:259]     Train net output #0: error_blob = 0.12135 (* 1 = 0.12135 loss)
I0929 23:39:55.755153 25413 solver.cpp:590] Iteration 4300, lr = 0.01
I0929 23:39:58.283118 25413 solver.cpp:243] Iteration 4400, loss = 0.118375
I0929 23:39:58.283149 25413 solver.cpp:259]     Train net output #0: error_blob = 0.118375 (* 1 = 0.118375 loss)
I0929 23:39:58.283154 25413 solver.cpp:590] Iteration 4400, lr = 0.01
I0929 23:40:00.801012 25413 solver.cpp:243] Iteration 4500, loss = 0.11339
I0929 23:40:00.801041 25413 solver.cpp:259]     Train net output #0: error_blob = 0.11339 (* 1 = 0.11339 loss)
I0929 23:40:00.801046 25413 solver.cpp:590] Iteration 4500, lr = 0.01
I0929 23:40:01.448706 25413 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:40:03.312608 25413 solver.cpp:243] Iteration 4600, loss = 0.117334
I0929 23:40:03.312677 25413 solver.cpp:259]     Train net output #0: error_blob = 0.117334 (* 1 = 0.117334 loss)
I0929 23:40:03.312685 25413 solver.cpp:590] Iteration 4600, lr = 0.01
I0929 23:40:05.831648 25413 solver.cpp:243] Iteration 4700, loss = 0.115784
I0929 23:40:05.831681 25413 solver.cpp:259]     Train net output #0: error_blob = 0.115784 (* 1 = 0.115784 loss)
I0929 23:40:05.831686 25413 solver.cpp:590] Iteration 4700, lr = 0.01
I0929 23:40:08.354838 25413 solver.cpp:243] Iteration 4800, loss = 0.115821
I0929 23:40:08.354867 25413 solver.cpp:259]     Train net output #0: error_blob = 0.115821 (* 1 = 0.115821 loss)
I0929 23:40:08.354873 25413 solver.cpp:590] Iteration 4800, lr = 0.01
I0929 23:40:10.865911 25413 solver.cpp:243] Iteration 4900, loss = 0.114849
I0929 23:40:10.865939 25413 solver.cpp:259]     Train net output #0: error_blob = 0.114849 (* 1 = 0.114849 loss)
I0929 23:40:10.865943 25413 solver.cpp:590] Iteration 4900, lr = 0.01
I0929 23:40:13.354980 25413 solver.cpp:347] Iteration 5000, Testing net (#0)
I0929 23:40:13.638991 25413 solver.cpp:415]     Test net output #0: error_blob = 0.123731 (* 1 = 0.123731 loss)
I0929 23:40:13.639708 25413 solver.cpp:243] Iteration 5000, loss = 0.115727
I0929 23:40:13.639725 25413 solver.cpp:259]     Train net output #0: error_blob = 0.115727 (* 1 = 0.115727 loss)
I0929 23:40:13.639734 25413 solver.cpp:590] Iteration 5000, lr = 0.01
I0929 23:40:16.107125 25413 solver.cpp:243] Iteration 5100, loss = 0.119869
I0929 23:40:16.107154 25413 solver.cpp:259]     Train net output #0: error_blob = 0.119869 (* 1 = 0.119869 loss)
I0929 23:40:16.107159 25413 solver.cpp:590] Iteration 5100, lr = 0.01
I0929 23:40:18.620893 25413 solver.cpp:243] Iteration 5200, loss = 0.113591
I0929 23:40:18.620932 25413 solver.cpp:259]     Train net output #0: error_blob = 0.113591 (* 1 = 0.113591 loss)
I0929 23:40:18.620939 25413 solver.cpp:590] Iteration 5200, lr = 0.01
I0929 23:40:21.148942 25413 solver.cpp:243] Iteration 5300, loss = 0.117337
I0929 23:40:21.148982 25413 solver.cpp:259]     Train net output #0: error_blob = 0.117337 (* 1 = 0.117337 loss)
I0929 23:40:21.148988 25413 solver.cpp:590] Iteration 5300, lr = 0.01
I0929 23:40:23.665793 25413 solver.cpp:243] Iteration 5400, loss = 0.114022
I0929 23:40:23.665834 25413 solver.cpp:259]     Train net output #0: error_blob = 0.114022 (* 1 = 0.114022 loss)
I0929 23:40:23.665840 25413 solver.cpp:590] Iteration 5400, lr = 0.01
I0929 23:40:24.463472 25413 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:40:26.146849 25413 solver.cpp:243] Iteration 5500, loss = 0.11631
I0929 23:40:26.146895 25413 solver.cpp:259]     Train net output #0: error_blob = 0.11631 (* 1 = 0.11631 loss)
I0929 23:40:26.146903 25413 solver.cpp:590] Iteration 5500, lr = 0.01
I0929 23:40:28.641742 25413 solver.cpp:243] Iteration 5600, loss = 0.119431
I0929 23:40:28.641789 25413 solver.cpp:259]     Train net output #0: error_blob = 0.119431 (* 1 = 0.119431 loss)
I0929 23:40:28.641796 25413 solver.cpp:590] Iteration 5600, lr = 0.01
I0929 23:40:31.154443 25413 solver.cpp:243] Iteration 5700, loss = 0.11551
I0929 23:40:31.154491 25413 solver.cpp:259]     Train net output #0: error_blob = 0.11551 (* 1 = 0.11551 loss)
I0929 23:40:31.154500 25413 solver.cpp:590] Iteration 5700, lr = 0.01
I0929 23:40:33.665740 25413 solver.cpp:243] Iteration 5800, loss = 0.114505
I0929 23:40:33.665835 25413 solver.cpp:259]     Train net output #0: error_blob = 0.114505 (* 1 = 0.114505 loss)
I0929 23:40:33.665843 25413 solver.cpp:590] Iteration 5800, lr = 0.01
I0929 23:40:36.179496 25413 solver.cpp:243] Iteration 5900, loss = 0.115714
I0929 23:40:36.179535 25413 solver.cpp:259]     Train net output #0: error_blob = 0.115714 (* 1 = 0.115714 loss)
I0929 23:40:36.179541 25413 solver.cpp:590] Iteration 5900, lr = 0.01
I0929 23:40:38.676702 25413 solver.cpp:347] Iteration 6000, Testing net (#0)
I0929 23:40:38.965502 25413 solver.cpp:415]     Test net output #0: error_blob = 0.125865 (* 1 = 0.125865 loss)
I0929 23:40:38.966171 25413 solver.cpp:243] Iteration 6000, loss = 0.116871
I0929 23:40:38.966186 25413 solver.cpp:259]     Train net output #0: error_blob = 0.116871 (* 1 = 0.116871 loss)
I0929 23:40:38.966193 25413 solver.cpp:590] Iteration 6000, lr = 0.01
I0929 23:40:41.431825 25413 solver.cpp:243] Iteration 6100, loss = 0.114212
I0929 23:40:41.431864 25413 solver.cpp:259]     Train net output #0: error_blob = 0.114212 (* 1 = 0.114212 loss)
I0929 23:40:41.431874 25413 solver.cpp:590] Iteration 6100, lr = 0.01
I0929 23:40:43.935600 25413 solver.cpp:243] Iteration 6200, loss = 0.117838
I0929 23:40:43.935639 25413 solver.cpp:259]     Train net output #0: error_blob = 0.117838 (* 1 = 0.117838 loss)
I0929 23:40:43.935645 25413 solver.cpp:590] Iteration 6200, lr = 0.01
I0929 23:40:46.444222 25413 solver.cpp:243] Iteration 6300, loss = 0.116242
I0929 23:40:46.444260 25413 solver.cpp:259]     Train net output #0: error_blob = 0.116242 (* 1 = 0.116242 loss)
I0929 23:40:46.444267 25413 solver.cpp:590] Iteration 6300, lr = 0.01
I0929 23:40:47.400298 25413 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:40:48.944778 25413 solver.cpp:243] Iteration 6400, loss = 0.116535
I0929 23:40:48.944824 25413 solver.cpp:259]     Train net output #0: error_blob = 0.116535 (* 1 = 0.116535 loss)
I0929 23:40:48.944833 25413 solver.cpp:590] Iteration 6400, lr = 0.01
I0929 23:40:51.457088 25413 solver.cpp:243] Iteration 6500, loss = 0.114465
I0929 23:40:51.457128 25413 solver.cpp:259]     Train net output #0: error_blob = 0.114465 (* 1 = 0.114465 loss)
I0929 23:40:51.457134 25413 solver.cpp:590] Iteration 6500, lr = 0.01
I0929 23:40:53.963948 25413 solver.cpp:243] Iteration 6600, loss = 0.116299
I0929 23:40:53.963987 25413 solver.cpp:259]     Train net output #0: error_blob = 0.116299 (* 1 = 0.116299 loss)
I0929 23:40:53.963992 25413 solver.cpp:590] Iteration 6600, lr = 0.01
I0929 23:40:56.473552 25413 solver.cpp:243] Iteration 6700, loss = 0.115767
I0929 23:40:56.473599 25413 solver.cpp:259]     Train net output #0: error_blob = 0.115767 (* 1 = 0.115767 loss)
I0929 23:40:56.473606 25413 solver.cpp:590] Iteration 6700, lr = 0.01
I0929 23:40:58.959625 25413 solver.cpp:243] Iteration 6800, loss = 0.111539
I0929 23:40:58.959663 25413 solver.cpp:259]     Train net output #0: error_blob = 0.111539 (* 1 = 0.111539 loss)
I0929 23:40:58.959672 25413 solver.cpp:590] Iteration 6800, lr = 0.01
I0929 23:41:01.469715 25413 solver.cpp:243] Iteration 6900, loss = 0.114847
I0929 23:41:01.469753 25413 solver.cpp:259]     Train net output #0: error_blob = 0.114847 (* 1 = 0.114847 loss)
I0929 23:41:01.469760 25413 solver.cpp:590] Iteration 6900, lr = 0.01
I0929 23:41:03.956065 25413 solver.cpp:347] Iteration 7000, Testing net (#0)
I0929 23:41:04.279819 25413 solver.cpp:415]     Test net output #0: error_blob = 0.126309 (* 1 = 0.126309 loss)
I0929 23:41:04.280519 25413 solver.cpp:243] Iteration 7000, loss = 0.117303
I0929 23:41:04.280535 25413 solver.cpp:259]     Train net output #0: error_blob = 0.117303 (* 1 = 0.117303 loss)
I0929 23:41:04.280545 25413 solver.cpp:590] Iteration 7000, lr = 0.01
I0929 23:41:06.766363 25413 solver.cpp:243] Iteration 7100, loss = 0.111091
I0929 23:41:06.766396 25413 solver.cpp:259]     Train net output #0: error_blob = 0.111091 (* 1 = 0.111091 loss)
I0929 23:41:06.766403 25413 solver.cpp:590] Iteration 7100, lr = 0.01
I0929 23:41:09.280443 25413 solver.cpp:243] Iteration 7200, loss = 0.114336
I0929 23:41:09.280503 25413 solver.cpp:259]     Train net output #0: error_blob = 0.114336 (* 1 = 0.114336 loss)
I0929 23:41:09.280510 25413 solver.cpp:590] Iteration 7200, lr = 0.01
I0929 23:41:10.386054 25413 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:41:11.804858 25413 solver.cpp:243] Iteration 7300, loss = 0.115836
I0929 23:41:11.804886 25413 solver.cpp:259]     Train net output #0: error_blob = 0.115836 (* 1 = 0.115836 loss)
I0929 23:41:11.804891 25413 solver.cpp:590] Iteration 7300, lr = 0.01
I0929 23:41:14.313825 25413 solver.cpp:243] Iteration 7400, loss = 0.113029
I0929 23:41:14.313868 25413 solver.cpp:259]     Train net output #0: error_blob = 0.113029 (* 1 = 0.113029 loss)
I0929 23:41:14.313874 25413 solver.cpp:590] Iteration 7400, lr = 0.01
I0929 23:41:16.817127 25413 solver.cpp:243] Iteration 7500, loss = 0.114775
I0929 23:41:16.817164 25413 solver.cpp:259]     Train net output #0: error_blob = 0.114775 (* 1 = 0.114775 loss)
I0929 23:41:16.817173 25413 solver.cpp:590] Iteration 7500, lr = 0.01
I0929 23:41:19.328629 25413 solver.cpp:243] Iteration 7600, loss = 0.115986
I0929 23:41:19.328668 25413 solver.cpp:259]     Train net output #0: error_blob = 0.115986 (* 1 = 0.115986 loss)
I0929 23:41:19.328673 25413 solver.cpp:590] Iteration 7600, lr = 0.01
I0929 23:41:21.831219 25413 solver.cpp:243] Iteration 7700, loss = 0.116187
I0929 23:41:21.831250 25413 solver.cpp:259]     Train net output #0: error_blob = 0.116187 (* 1 = 0.116187 loss)
I0929 23:41:21.831256 25413 solver.cpp:590] Iteration 7700, lr = 0.01
I0929 23:41:24.318516 25413 solver.cpp:243] Iteration 7800, loss = 0.116405
I0929 23:41:24.318545 25413 solver.cpp:259]     Train net output #0: error_blob = 0.116405 (* 1 = 0.116405 loss)
I0929 23:41:24.318550 25413 solver.cpp:590] Iteration 7800, lr = 0.01
I0929 23:41:26.818486 25413 solver.cpp:243] Iteration 7900, loss = 0.119629
I0929 23:41:26.818524 25413 solver.cpp:259]     Train net output #0: error_blob = 0.119629 (* 1 = 0.119629 loss)
I0929 23:41:26.818532 25413 solver.cpp:590] Iteration 7900, lr = 0.01
I0929 23:41:29.308390 25413 solver.cpp:347] Iteration 8000, Testing net (#0)
I0929 23:41:29.596312 25413 solver.cpp:415]     Test net output #0: error_blob = 0.123349 (* 1 = 0.123349 loss)
I0929 23:41:29.596940 25413 solver.cpp:243] Iteration 8000, loss = 0.116608
I0929 23:41:29.596953 25413 solver.cpp:259]     Train net output #0: error_blob = 0.116608 (* 1 = 0.116608 loss)
I0929 23:41:29.596958 25413 solver.cpp:590] Iteration 8000, lr = 0.01
I0929 23:41:32.031013 25413 solver.cpp:243] Iteration 8100, loss = 0.114271
I0929 23:41:32.031044 25413 solver.cpp:259]     Train net output #0: error_blob = 0.114271 (* 1 = 0.114271 loss)
I0929 23:41:32.031049 25413 solver.cpp:590] Iteration 8100, lr = 0.01
I0929 23:41:33.280592 25413 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:41:34.518955 25413 solver.cpp:243] Iteration 8200, loss = 0.113999
I0929 23:41:34.519114 25413 solver.cpp:259]     Train net output #0: error_blob = 0.113999 (* 1 = 0.113999 loss)
I0929 23:41:34.519122 25413 solver.cpp:590] Iteration 8200, lr = 0.01
I0929 23:41:37.025521 25413 solver.cpp:243] Iteration 8300, loss = 0.115547
I0929 23:41:37.025553 25413 solver.cpp:259]     Train net output #0: error_blob = 0.115547 (* 1 = 0.115547 loss)
I0929 23:41:37.025560 25413 solver.cpp:590] Iteration 8300, lr = 0.01
I0929 23:41:39.500473 25413 solver.cpp:243] Iteration 8400, loss = 0.112562
I0929 23:41:39.500519 25413 solver.cpp:259]     Train net output #0: error_blob = 0.112562 (* 1 = 0.112562 loss)
I0929 23:41:39.500526 25413 solver.cpp:590] Iteration 8400, lr = 0.01
I0929 23:41:41.981983 25413 solver.cpp:243] Iteration 8500, loss = 0.114917
I0929 23:41:41.982015 25413 solver.cpp:259]     Train net output #0: error_blob = 0.114917 (* 1 = 0.114917 loss)
I0929 23:41:41.982022 25413 solver.cpp:590] Iteration 8500, lr = 0.01
I0929 23:41:44.489748 25413 solver.cpp:243] Iteration 8600, loss = 0.114918
I0929 23:41:44.489779 25413 solver.cpp:259]     Train net output #0: error_blob = 0.114918 (* 1 = 0.114918 loss)
I0929 23:41:44.489786 25413 solver.cpp:590] Iteration 8600, lr = 0.01
I0929 23:41:46.982096 25413 solver.cpp:243] Iteration 8700, loss = 0.115991
I0929 23:41:46.982125 25413 solver.cpp:259]     Train net output #0: error_blob = 0.115991 (* 1 = 0.115991 loss)
I0929 23:41:46.982130 25413 solver.cpp:590] Iteration 8700, lr = 0.01
I0929 23:41:49.481036 25413 solver.cpp:243] Iteration 8800, loss = 0.112086
I0929 23:41:49.481065 25413 solver.cpp:259]     Train net output #0: error_blob = 0.112086 (* 1 = 0.112086 loss)
I0929 23:41:49.481070 25413 solver.cpp:590] Iteration 8800, lr = 0.01
I0929 23:41:51.971460 25413 solver.cpp:243] Iteration 8900, loss = 0.115841
I0929 23:41:51.971492 25413 solver.cpp:259]     Train net output #0: error_blob = 0.115841 (* 1 = 0.115841 loss)
I0929 23:41:51.971496 25413 solver.cpp:590] Iteration 8900, lr = 0.01
I0929 23:41:54.429289 25413 solver.cpp:347] Iteration 9000, Testing net (#0)
I0929 23:41:54.725078 25413 solver.cpp:415]     Test net output #0: error_blob = 0.119512 (* 1 = 0.119512 loss)
I0929 23:41:54.725716 25413 solver.cpp:243] Iteration 9000, loss = 0.11845
I0929 23:41:54.725730 25413 solver.cpp:259]     Train net output #0: error_blob = 0.11845 (* 1 = 0.11845 loss)
I0929 23:41:54.725736 25413 solver.cpp:590] Iteration 9000, lr = 0.01
I0929 23:41:56.165117 25413 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:41:57.250699 25413 solver.cpp:243] Iteration 9100, loss = 0.113106
I0929 23:41:57.250728 25413 solver.cpp:259]     Train net output #0: error_blob = 0.113106 (* 1 = 0.113106 loss)
I0929 23:41:57.250735 25413 solver.cpp:590] Iteration 9100, lr = 0.01
I0929 23:41:59.736925 25413 solver.cpp:243] Iteration 9200, loss = 0.114041
I0929 23:41:59.736965 25413 solver.cpp:259]     Train net output #0: error_blob = 0.114041 (* 1 = 0.114041 loss)
I0929 23:41:59.736971 25413 solver.cpp:590] Iteration 9200, lr = 0.01
I0929 23:42:02.239940 25413 solver.cpp:243] Iteration 9300, loss = 0.115624
I0929 23:42:02.239971 25413 solver.cpp:259]     Train net output #0: error_blob = 0.115624 (* 1 = 0.115624 loss)
I0929 23:42:02.239977 25413 solver.cpp:590] Iteration 9300, lr = 0.01
I0929 23:42:04.742082 25413 solver.cpp:243] Iteration 9400, loss = 0.113524
I0929 23:42:04.742229 25413 solver.cpp:259]     Train net output #0: error_blob = 0.113524 (* 1 = 0.113524 loss)
I0929 23:42:04.742236 25413 solver.cpp:590] Iteration 9400, lr = 0.01
I0929 23:42:07.214323 25413 solver.cpp:243] Iteration 9500, loss = 0.117793
I0929 23:42:07.214352 25413 solver.cpp:259]     Train net output #0: error_blob = 0.117793 (* 1 = 0.117793 loss)
I0929 23:42:07.214361 25413 solver.cpp:590] Iteration 9500, lr = 0.01
I0929 23:42:09.726655 25413 solver.cpp:243] Iteration 9600, loss = 0.114423
I0929 23:42:09.726686 25413 solver.cpp:259]     Train net output #0: error_blob = 0.114423 (* 1 = 0.114423 loss)
I0929 23:42:09.726692 25413 solver.cpp:590] Iteration 9600, lr = 0.01
I0929 23:42:12.210464 25413 solver.cpp:243] Iteration 9700, loss = 0.116453
I0929 23:42:12.210494 25413 solver.cpp:259]     Train net output #0: error_blob = 0.116453 (* 1 = 0.116453 loss)
I0929 23:42:12.210503 25413 solver.cpp:590] Iteration 9700, lr = 0.01
I0929 23:42:14.719995 25413 solver.cpp:243] Iteration 9800, loss = 0.111463
I0929 23:42:14.720026 25413 solver.cpp:259]     Train net output #0: error_blob = 0.111463 (* 1 = 0.111463 loss)
I0929 23:42:14.720033 25413 solver.cpp:590] Iteration 9800, lr = 0.01
I0929 23:42:17.243691 25413 solver.cpp:243] Iteration 9900, loss = 0.117247
I0929 23:42:17.243731 25413 solver.cpp:259]     Train net output #0: error_blob = 0.117247 (* 1 = 0.117247 loss)
I0929 23:42:17.243736 25413 solver.cpp:590] Iteration 9900, lr = 0.01
I0929 23:42:19.691788 25413 solver.cpp:468] Snapshotting to binary proto file _iter_10000.caffemodel
I0929 23:42:19.692633 25413 solver.cpp:753] Snapshotting solver state to binary proto file _iter_10000.solverstate
I0929 23:42:19.716598 25413 solver.cpp:327] Iteration 10000, loss = 0.116318
I0929 23:42:19.716622 25413 solver.cpp:347] Iteration 10000, Testing net (#0)
I0929 23:42:19.953323 25413 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:42:20.059404 25413 solver.cpp:415]     Test net output #0: error_blob = 0.122021 (* 1 = 0.122021 loss)
I0929 23:42:20.059425 25413 solver.cpp:332] Optimization Done.
I0929 23:42:20.059428 25413 caffe.cpp:215] Optimization Done.
I0929 23:42:20.131897 25435 caffe.cpp:184] Using GPUs 0
I0929 23:42:20.688665 25435 solver.cpp:54] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "fixed"
momentum: 0.9
solver_mode: GPU
device_id: 0
net: "model/NNScore/nnscore_model_9.prototxt"
I0929 23:42:20.688696 25435 solver.cpp:97] Creating training net from net file: model/NNScore/nnscore_model_9.prototxt
I0929 23:42:20.688860 25435 net.cpp:339] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_layer
I0929 23:42:20.688897 25435 net.cpp:50] Initializing net from parameters: 
name: "model/NNScore/nnscore_model_9.prototxt"
state {
  phase: TRAIN
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TRAIN
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.9.train"
    batch_size: 20000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I0929 23:42:20.688933 25435 layer_factory.hpp:76] Creating layer data_layer
I0929 23:42:20.702221 25435 net.cpp:110] Creating Layer data_layer
I0929 23:42:20.702252 25435 net.cpp:433] data_layer -> data_blob
I0929 23:42:20.702283 25435 net.cpp:433] data_layer -> label_blob
I0929 23:42:20.702884 25439 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.9.train
I0929 23:42:21.409893 25435 data_layer.cpp:45] output data size: 20000,61,1,1
I0929 23:42:21.414810 25435 net.cpp:155] Setting up data_layer
I0929 23:42:21.414851 25435 net.cpp:163] Top shape: 20000 61 1 1 (1220000)
I0929 23:42:21.414855 25435 net.cpp:163] Top shape: 20000 (20000)
I0929 23:42:21.414871 25435 layer_factory.hpp:76] Creating layer hidden_sum_layer
I0929 23:42:21.414883 25435 net.cpp:110] Creating Layer hidden_sum_layer
I0929 23:42:21.414887 25435 net.cpp:477] hidden_sum_layer <- data_blob
I0929 23:42:21.414897 25435 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I0929 23:42:21.415273 25435 net.cpp:155] Setting up hidden_sum_layer
I0929 23:42:21.415280 25435 net.cpp:163] Top shape: 20000 10 (200000)
I0929 23:42:21.415302 25435 layer_factory.hpp:76] Creating layer hidden_act_layer
I0929 23:42:21.415319 25435 net.cpp:110] Creating Layer hidden_act_layer
I0929 23:42:21.415321 25435 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I0929 23:42:21.415324 25435 net.cpp:433] hidden_act_layer -> hidden_act_blob
I0929 23:42:24.649361 25435 net.cpp:155] Setting up hidden_act_layer
I0929 23:42:24.649384 25435 net.cpp:163] Top shape: 20000 10 (200000)
I0929 23:42:24.649389 25435 layer_factory.hpp:76] Creating layer output_sum_layer
I0929 23:42:24.649399 25435 net.cpp:110] Creating Layer output_sum_layer
I0929 23:42:24.649402 25435 net.cpp:477] output_sum_layer <- hidden_act_blob
I0929 23:42:24.649407 25435 net.cpp:433] output_sum_layer -> output_sum_blob
I0929 23:42:24.649484 25435 net.cpp:155] Setting up output_sum_layer
I0929 23:42:24.649489 25435 net.cpp:163] Top shape: 20000 1 (20000)
I0929 23:42:24.649495 25435 layer_factory.hpp:76] Creating layer output_act_layer
I0929 23:42:24.649500 25435 net.cpp:110] Creating Layer output_act_layer
I0929 23:42:24.649502 25435 net.cpp:477] output_act_layer <- output_sum_blob
I0929 23:42:24.649505 25435 net.cpp:433] output_act_layer -> output_act_blob
I0929 23:42:24.649556 25435 net.cpp:155] Setting up output_act_layer
I0929 23:42:24.649574 25435 net.cpp:163] Top shape: 20000 1 (20000)
I0929 23:42:24.649575 25435 layer_factory.hpp:76] Creating layer error_layer
I0929 23:42:24.649580 25435 net.cpp:110] Creating Layer error_layer
I0929 23:42:24.649582 25435 net.cpp:477] error_layer <- output_act_blob
I0929 23:42:24.649585 25435 net.cpp:477] error_layer <- label_blob
I0929 23:42:24.649588 25435 net.cpp:433] error_layer -> error_blob
I0929 23:42:24.649610 25435 net.cpp:155] Setting up error_layer
I0929 23:42:24.649613 25435 net.cpp:163] Top shape: (1)
I0929 23:42:24.649616 25435 net.cpp:168]     with loss weight 1
I0929 23:42:24.649631 25435 net.cpp:236] error_layer needs backward computation.
I0929 23:42:24.649632 25435 net.cpp:236] output_act_layer needs backward computation.
I0929 23:42:24.649634 25435 net.cpp:236] output_sum_layer needs backward computation.
I0929 23:42:24.649636 25435 net.cpp:236] hidden_act_layer needs backward computation.
I0929 23:42:24.649637 25435 net.cpp:236] hidden_sum_layer needs backward computation.
I0929 23:42:24.649641 25435 net.cpp:240] data_layer does not need backward computation.
I0929 23:42:24.649641 25435 net.cpp:283] This network produces output error_blob
I0929 23:42:24.649646 25435 net.cpp:297] Network initialization done.
I0929 23:42:24.649647 25435 net.cpp:298] Memory required for data: 6720004
I0929 23:42:24.649765 25435 solver.cpp:187] Creating test net (#0) specified by net file: model/NNScore/nnscore_model_9.prototxt
I0929 23:42:24.649794 25435 net.cpp:339] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_layer
I0929 23:42:24.649835 25435 net.cpp:50] Initializing net from parameters: 
name: "model/NNScore/nnscore_model_9.prototxt"
state {
  phase: TEST
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TEST
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.9.test"
    batch_size: 2000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I0929 23:42:24.649855 25435 layer_factory.hpp:76] Creating layer data_layer
I0929 23:42:24.651005 25435 net.cpp:110] Creating Layer data_layer
I0929 23:42:24.651020 25435 net.cpp:433] data_layer -> data_blob
I0929 23:42:24.651023 25435 net.cpp:433] data_layer -> label_blob
I0929 23:42:24.651572 25441 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.9.test
I0929 23:42:24.651659 25435 data_layer.cpp:45] output data size: 2000,61,1,1
I0929 23:42:24.653122 25435 net.cpp:155] Setting up data_layer
I0929 23:42:24.653136 25435 net.cpp:163] Top shape: 2000 61 1 1 (122000)
I0929 23:42:24.653138 25435 net.cpp:163] Top shape: 2000 (2000)
I0929 23:42:24.653141 25435 layer_factory.hpp:76] Creating layer hidden_sum_layer
I0929 23:42:24.653158 25435 net.cpp:110] Creating Layer hidden_sum_layer
I0929 23:42:24.653162 25435 net.cpp:477] hidden_sum_layer <- data_blob
I0929 23:42:24.653165 25435 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I0929 23:42:24.653275 25435 net.cpp:155] Setting up hidden_sum_layer
I0929 23:42:24.653280 25435 net.cpp:163] Top shape: 2000 10 (20000)
I0929 23:42:24.653286 25435 layer_factory.hpp:76] Creating layer hidden_act_layer
I0929 23:42:24.653301 25435 net.cpp:110] Creating Layer hidden_act_layer
I0929 23:42:24.653303 25435 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I0929 23:42:24.653316 25435 net.cpp:433] hidden_act_layer -> hidden_act_blob
I0929 23:42:24.653492 25435 net.cpp:155] Setting up hidden_act_layer
I0929 23:42:24.653498 25435 net.cpp:163] Top shape: 2000 10 (20000)
I0929 23:42:24.653501 25435 layer_factory.hpp:76] Creating layer output_sum_layer
I0929 23:42:24.653506 25435 net.cpp:110] Creating Layer output_sum_layer
I0929 23:42:24.653517 25435 net.cpp:477] output_sum_layer <- hidden_act_blob
I0929 23:42:24.653520 25435 net.cpp:433] output_sum_layer -> output_sum_blob
I0929 23:42:24.653586 25435 net.cpp:155] Setting up output_sum_layer
I0929 23:42:24.653590 25435 net.cpp:163] Top shape: 2000 1 (2000)
I0929 23:42:24.653595 25435 layer_factory.hpp:76] Creating layer output_act_layer
I0929 23:42:24.653609 25435 net.cpp:110] Creating Layer output_act_layer
I0929 23:42:24.653611 25435 net.cpp:477] output_act_layer <- output_sum_blob
I0929 23:42:24.653614 25435 net.cpp:433] output_act_layer -> output_act_blob
I0929 23:42:24.653668 25435 net.cpp:155] Setting up output_act_layer
I0929 23:42:24.653671 25435 net.cpp:163] Top shape: 2000 1 (2000)
I0929 23:42:24.653673 25435 layer_factory.hpp:76] Creating layer error_layer
I0929 23:42:24.653677 25435 net.cpp:110] Creating Layer error_layer
I0929 23:42:24.653689 25435 net.cpp:477] error_layer <- output_act_blob
I0929 23:42:24.653692 25435 net.cpp:477] error_layer <- label_blob
I0929 23:42:24.653694 25435 net.cpp:433] error_layer -> error_blob
I0929 23:42:24.653713 25435 net.cpp:155] Setting up error_layer
I0929 23:42:24.653717 25435 net.cpp:163] Top shape: (1)
I0929 23:42:24.653718 25435 net.cpp:168]     with loss weight 1
I0929 23:42:24.653735 25435 net.cpp:236] error_layer needs backward computation.
I0929 23:42:24.653738 25435 net.cpp:236] output_act_layer needs backward computation.
I0929 23:42:24.653739 25435 net.cpp:236] output_sum_layer needs backward computation.
I0929 23:42:24.653741 25435 net.cpp:236] hidden_act_layer needs backward computation.
I0929 23:42:24.653753 25435 net.cpp:236] hidden_sum_layer needs backward computation.
I0929 23:42:24.653755 25435 net.cpp:240] data_layer does not need backward computation.
I0929 23:42:24.653758 25435 net.cpp:283] This network produces output error_blob
I0929 23:42:24.653761 25435 net.cpp:297] Network initialization done.
I0929 23:42:24.653764 25435 net.cpp:298] Memory required for data: 672004
I0929 23:42:24.653782 25435 solver.cpp:66] Solver scaffolding done.
I0929 23:42:24.653877 25435 caffe.cpp:212] Starting Optimization
I0929 23:42:24.653882 25435 solver.cpp:294] Solving model/NNScore/nnscore_model_9.prototxt
I0929 23:42:24.653883 25435 solver.cpp:295] Learning Rate Policy: fixed
I0929 23:42:24.654067 25435 solver.cpp:347] Iteration 0, Testing net (#0)
I0929 23:42:24.654145 25435 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:42:24.915711 25435 solver.cpp:415]     Test net output #0: error_blob = 0.14173 (* 1 = 0.14173 loss)
I0929 23:42:24.917289 25435 solver.cpp:243] Iteration 0, loss = 0.141007
I0929 23:42:24.917318 25435 solver.cpp:259]     Train net output #0: error_blob = 0.141007 (* 1 = 0.141007 loss)
I0929 23:42:24.917331 25435 solver.cpp:590] Iteration 0, lr = 0.01
I0929 23:42:27.435480 25435 solver.cpp:243] Iteration 100, loss = 0.125007
I0929 23:42:27.435530 25435 solver.cpp:259]     Train net output #0: error_blob = 0.125007 (* 1 = 0.125007 loss)
I0929 23:42:27.435538 25435 solver.cpp:590] Iteration 100, lr = 0.01
I0929 23:42:29.977255 25435 solver.cpp:243] Iteration 200, loss = 0.124982
I0929 23:42:29.977303 25435 solver.cpp:259]     Train net output #0: error_blob = 0.124982 (* 1 = 0.124982 loss)
I0929 23:42:29.977308 25435 solver.cpp:590] Iteration 200, lr = 0.01
I0929 23:42:32.454264 25435 solver.cpp:243] Iteration 300, loss = 0.125001
I0929 23:42:32.454295 25435 solver.cpp:259]     Train net output #0: error_blob = 0.125001 (* 1 = 0.125001 loss)
I0929 23:42:32.454301 25435 solver.cpp:590] Iteration 300, lr = 0.01
I0929 23:42:34.981288 25435 solver.cpp:243] Iteration 400, loss = 0.125001
I0929 23:42:34.981364 25435 solver.cpp:259]     Train net output #0: error_blob = 0.125001 (* 1 = 0.125001 loss)
I0929 23:42:34.981371 25435 solver.cpp:590] Iteration 400, lr = 0.01
I0929 23:42:37.540225 25435 solver.cpp:243] Iteration 500, loss = 0.125001
I0929 23:42:37.540259 25435 solver.cpp:259]     Train net output #0: error_blob = 0.125001 (* 1 = 0.125001 loss)
I0929 23:42:37.540266 25435 solver.cpp:590] Iteration 500, lr = 0.01
I0929 23:42:40.092428 25435 solver.cpp:243] Iteration 600, loss = 0.124998
I0929 23:42:40.092459 25435 solver.cpp:259]     Train net output #0: error_blob = 0.124998 (* 1 = 0.124998 loss)
I0929 23:42:40.092464 25435 solver.cpp:590] Iteration 600, lr = 0.01
I0929 23:42:42.621639 25435 solver.cpp:243] Iteration 700, loss = 0.124996
I0929 23:42:42.621680 25435 solver.cpp:259]     Train net output #0: error_blob = 0.124996 (* 1 = 0.124996 loss)
I0929 23:42:42.621685 25435 solver.cpp:590] Iteration 700, lr = 0.01
I0929 23:42:45.150987 25435 solver.cpp:243] Iteration 800, loss = 0.125
I0929 23:42:45.151016 25435 solver.cpp:259]     Train net output #0: error_blob = 0.125 (* 1 = 0.125 loss)
I0929 23:42:45.151021 25435 solver.cpp:590] Iteration 800, lr = 0.01
I0929 23:42:47.679031 25435 solver.cpp:243] Iteration 900, loss = 0.124998
I0929 23:42:47.679070 25435 solver.cpp:259]     Train net output #0: error_blob = 0.124998 (* 1 = 0.124998 loss)
I0929 23:42:47.679077 25435 solver.cpp:590] Iteration 900, lr = 0.01
I0929 23:42:47.729310 25435 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:42:50.169636 25435 solver.cpp:347] Iteration 1000, Testing net (#0)
I0929 23:42:50.522933 25435 solver.cpp:415]     Test net output #0: error_blob = 0.125001 (* 1 = 0.125001 loss)
I0929 23:42:50.523608 25435 solver.cpp:243] Iteration 1000, loss = 0.124995
I0929 23:42:50.523625 25435 solver.cpp:259]     Train net output #0: error_blob = 0.124995 (* 1 = 0.124995 loss)
I0929 23:42:50.523633 25435 solver.cpp:590] Iteration 1000, lr = 0.01
I0929 23:42:52.998005 25435 solver.cpp:243] Iteration 1100, loss = 0.125001
I0929 23:42:52.998036 25435 solver.cpp:259]     Train net output #0: error_blob = 0.125001 (* 1 = 0.125001 loss)
I0929 23:42:52.998040 25435 solver.cpp:590] Iteration 1100, lr = 0.01
I0929 23:42:55.516999 25435 solver.cpp:243] Iteration 1200, loss = 0.125
I0929 23:42:55.517040 25435 solver.cpp:259]     Train net output #0: error_blob = 0.125 (* 1 = 0.125 loss)
I0929 23:42:55.517045 25435 solver.cpp:590] Iteration 1200, lr = 0.01
I0929 23:42:58.061077 25435 solver.cpp:243] Iteration 1300, loss = 0.124996
I0929 23:42:58.061117 25435 solver.cpp:259]     Train net output #0: error_blob = 0.124996 (* 1 = 0.124996 loss)
I0929 23:42:58.061123 25435 solver.cpp:590] Iteration 1300, lr = 0.01
I0929 23:43:00.608608 25435 solver.cpp:243] Iteration 1400, loss = 0.125001
I0929 23:43:00.608649 25435 solver.cpp:259]     Train net output #0: error_blob = 0.125001 (* 1 = 0.125001 loss)
I0929 23:43:00.608654 25435 solver.cpp:590] Iteration 1400, lr = 0.01
I0929 23:43:03.155288 25435 solver.cpp:243] Iteration 1500, loss = 0.125044
I0929 23:43:03.155335 25435 solver.cpp:259]     Train net output #0: error_blob = 0.125044 (* 1 = 0.125044 loss)
I0929 23:43:03.155342 25435 solver.cpp:590] Iteration 1500, lr = 0.01
I0929 23:43:05.681062 25435 solver.cpp:243] Iteration 1600, loss = 0.124995
I0929 23:43:05.681092 25435 solver.cpp:259]     Train net output #0: error_blob = 0.124995 (* 1 = 0.124995 loss)
I0929 23:43:05.681097 25435 solver.cpp:590] Iteration 1600, lr = 0.01
I0929 23:43:08.228667 25435 solver.cpp:243] Iteration 1700, loss = 0.125001
I0929 23:43:08.228713 25435 solver.cpp:259]     Train net output #0: error_blob = 0.125001 (* 1 = 0.125001 loss)
I0929 23:43:08.228721 25435 solver.cpp:590] Iteration 1700, lr = 0.01
I0929 23:43:10.758158 25435 solver.cpp:243] Iteration 1800, loss = 0.124994
I0929 23:43:10.758188 25435 solver.cpp:259]     Train net output #0: error_blob = 0.124994 (* 1 = 0.124994 loss)
I0929 23:43:10.758193 25435 solver.cpp:590] Iteration 1800, lr = 0.01
I0929 23:43:10.961961 25435 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:43:13.308986 25435 solver.cpp:243] Iteration 1900, loss = 0.124996
I0929 23:43:13.309026 25435 solver.cpp:259]     Train net output #0: error_blob = 0.124996 (* 1 = 0.124996 loss)
I0929 23:43:13.309031 25435 solver.cpp:590] Iteration 1900, lr = 0.01
I0929 23:43:15.817912 25435 solver.cpp:347] Iteration 2000, Testing net (#0)
I0929 23:43:16.101362 25435 solver.cpp:415]     Test net output #0: error_blob = 0.125002 (* 1 = 0.125002 loss)
I0929 23:43:16.102077 25435 solver.cpp:243] Iteration 2000, loss = 0.125001
I0929 23:43:16.102097 25435 solver.cpp:259]     Train net output #0: error_blob = 0.125001 (* 1 = 0.125001 loss)
I0929 23:43:16.102108 25435 solver.cpp:590] Iteration 2000, lr = 0.01
I0929 23:43:18.613160 25435 solver.cpp:243] Iteration 2100, loss = 0.124993
I0929 23:43:18.613209 25435 solver.cpp:259]     Train net output #0: error_blob = 0.124993 (* 1 = 0.124993 loss)
I0929 23:43:18.613215 25435 solver.cpp:590] Iteration 2100, lr = 0.01
I0929 23:43:21.147338 25435 solver.cpp:243] Iteration 2200, loss = 0.124994
I0929 23:43:21.148393 25435 solver.cpp:259]     Train net output #0: error_blob = 0.124994 (* 1 = 0.124994 loss)
I0929 23:43:21.148401 25435 solver.cpp:590] Iteration 2200, lr = 0.01
I0929 23:43:23.687721 25435 solver.cpp:243] Iteration 2300, loss = 0.125001
I0929 23:43:23.687752 25435 solver.cpp:259]     Train net output #0: error_blob = 0.125001 (* 1 = 0.125001 loss)
I0929 23:43:23.687757 25435 solver.cpp:590] Iteration 2300, lr = 0.01
I0929 23:43:26.231451 25435 solver.cpp:243] Iteration 2400, loss = 0.124992
I0929 23:43:26.231487 25435 solver.cpp:259]     Train net output #0: error_blob = 0.124992 (* 1 = 0.124992 loss)
I0929 23:43:26.231494 25435 solver.cpp:590] Iteration 2400, lr = 0.01
I0929 23:43:28.739194 25435 solver.cpp:243] Iteration 2500, loss = 0.124993
I0929 23:43:28.739224 25435 solver.cpp:259]     Train net output #0: error_blob = 0.124993 (* 1 = 0.124993 loss)
I0929 23:43:28.739229 25435 solver.cpp:590] Iteration 2500, lr = 0.01
I0929 23:43:31.286128 25435 solver.cpp:243] Iteration 2600, loss = 0.125
I0929 23:43:31.286167 25435 solver.cpp:259]     Train net output #0: error_blob = 0.125 (* 1 = 0.125 loss)
I0929 23:43:31.286176 25435 solver.cpp:590] Iteration 2600, lr = 0.01
I0929 23:43:33.815590 25435 solver.cpp:243] Iteration 2700, loss = 0.12499
I0929 23:43:33.815630 25435 solver.cpp:259]     Train net output #0: error_blob = 0.12499 (* 1 = 0.12499 loss)
I0929 23:43:33.815636 25435 solver.cpp:590] Iteration 2700, lr = 0.01
I0929 23:43:34.180418 25435 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:43:36.388684 25435 solver.cpp:243] Iteration 2800, loss = 0.12499
I0929 23:43:36.388723 25435 solver.cpp:259]     Train net output #0: error_blob = 0.12499 (* 1 = 0.12499 loss)
I0929 23:43:36.388728 25435 solver.cpp:590] Iteration 2800, lr = 0.01
I0929 23:43:38.918844 25435 solver.cpp:243] Iteration 2900, loss = 0.125001
I0929 23:43:38.918875 25435 solver.cpp:259]     Train net output #0: error_blob = 0.125001 (* 1 = 0.125001 loss)
I0929 23:43:38.918880 25435 solver.cpp:590] Iteration 2900, lr = 0.01
I0929 23:43:41.410274 25435 solver.cpp:347] Iteration 3000, Testing net (#0)
I0929 23:43:41.723644 25435 solver.cpp:415]     Test net output #0: error_blob = 0.125003 (* 1 = 0.125003 loss)
I0929 23:43:41.724285 25435 solver.cpp:243] Iteration 3000, loss = 0.124988
I0929 23:43:41.724300 25435 solver.cpp:259]     Train net output #0: error_blob = 0.124988 (* 1 = 0.124988 loss)
I0929 23:43:41.724305 25435 solver.cpp:590] Iteration 3000, lr = 0.01
I0929 23:43:44.197301 25435 solver.cpp:243] Iteration 3100, loss = 0.124988
I0929 23:43:44.197336 25435 solver.cpp:259]     Train net output #0: error_blob = 0.124988 (* 1 = 0.124988 loss)
I0929 23:43:44.197343 25435 solver.cpp:590] Iteration 3100, lr = 0.01
I0929 23:43:46.762938 25435 solver.cpp:243] Iteration 3200, loss = 0.125
I0929 23:43:46.762984 25435 solver.cpp:259]     Train net output #0: error_blob = 0.125 (* 1 = 0.125 loss)
I0929 23:43:46.762991 25435 solver.cpp:590] Iteration 3200, lr = 0.01
I0929 23:43:49.338660 25435 solver.cpp:243] Iteration 3300, loss = 0.124987
I0929 23:43:49.338696 25435 solver.cpp:259]     Train net output #0: error_blob = 0.124987 (* 1 = 0.124987 loss)
I0929 23:43:49.338703 25435 solver.cpp:590] Iteration 3300, lr = 0.01
I0929 23:43:51.904285 25435 solver.cpp:243] Iteration 3400, loss = 0.124985
I0929 23:43:51.906018 25435 solver.cpp:259]     Train net output #0: error_blob = 0.124985 (* 1 = 0.124985 loss)
I0929 23:43:51.906028 25435 solver.cpp:590] Iteration 3400, lr = 0.01
I0929 23:43:54.396906 25435 solver.cpp:243] Iteration 3500, loss = 0.125
I0929 23:43:54.396936 25435 solver.cpp:259]     Train net output #0: error_blob = 0.125 (* 1 = 0.125 loss)
I0929 23:43:54.396944 25435 solver.cpp:590] Iteration 3500, lr = 0.01
I0929 23:43:56.938386 25435 solver.cpp:243] Iteration 3600, loss = 0.124984
I0929 23:43:56.938436 25435 solver.cpp:259]     Train net output #0: error_blob = 0.124984 (* 1 = 0.124984 loss)
I0929 23:43:56.938444 25435 solver.cpp:590] Iteration 3600, lr = 0.01
I0929 23:43:57.448833 25435 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:43:59.466686 25435 solver.cpp:243] Iteration 3700, loss = 0.124949
I0929 23:43:59.466727 25435 solver.cpp:259]     Train net output #0: error_blob = 0.124949 (* 1 = 0.124949 loss)
I0929 23:43:59.466732 25435 solver.cpp:590] Iteration 3700, lr = 0.01
I0929 23:44:01.974604 25435 solver.cpp:243] Iteration 3800, loss = 0.125
I0929 23:44:01.974633 25435 solver.cpp:259]     Train net output #0: error_blob = 0.125 (* 1 = 0.125 loss)
I0929 23:44:01.974638 25435 solver.cpp:590] Iteration 3800, lr = 0.01
I0929 23:44:04.510784 25435 solver.cpp:243] Iteration 3900, loss = 0.124983
I0929 23:44:04.510831 25435 solver.cpp:259]     Train net output #0: error_blob = 0.124983 (* 1 = 0.124983 loss)
I0929 23:44:04.510839 25435 solver.cpp:590] Iteration 3900, lr = 0.01
I0929 23:44:07.040076 25435 solver.cpp:347] Iteration 4000, Testing net (#0)
I0929 23:44:07.332963 25435 solver.cpp:415]     Test net output #0: error_blob = 0.125006 (* 1 = 0.125006 loss)
I0929 23:44:07.333577 25435 solver.cpp:243] Iteration 4000, loss = 0.124999
I0929 23:44:07.333592 25435 solver.cpp:259]     Train net output #0: error_blob = 0.124999 (* 1 = 0.124999 loss)
I0929 23:44:07.333600 25435 solver.cpp:590] Iteration 4000, lr = 0.01
I0929 23:44:09.986131 25435 solver.cpp:243] Iteration 4100, loss = 0.125001
I0929 23:44:09.986177 25435 solver.cpp:259]     Train net output #0: error_blob = 0.125001 (* 1 = 0.125001 loss)
I0929 23:44:09.986186 25435 solver.cpp:590] Iteration 4100, lr = 0.01
I0929 23:44:12.563189 25435 solver.cpp:243] Iteration 4200, loss = 0.124982
I0929 23:44:12.563218 25435 solver.cpp:259]     Train net output #0: error_blob = 0.124982 (* 1 = 0.124982 loss)
I0929 23:44:12.563222 25435 solver.cpp:590] Iteration 4200, lr = 0.01
I0929 23:44:15.101964 25435 solver.cpp:243] Iteration 4300, loss = 0.125
I0929 23:44:15.102011 25435 solver.cpp:259]     Train net output #0: error_blob = 0.125 (* 1 = 0.125 loss)
I0929 23:44:15.102017 25435 solver.cpp:590] Iteration 4300, lr = 0.01
I0929 23:44:17.622364 25435 solver.cpp:243] Iteration 4400, loss = 0.125001
I0929 23:44:17.622407 25435 solver.cpp:259]     Train net output #0: error_blob = 0.125001 (* 1 = 0.125001 loss)
I0929 23:44:17.622414 25435 solver.cpp:590] Iteration 4400, lr = 0.01
I0929 23:44:20.208009 25435 solver.cpp:243] Iteration 4500, loss = 0.124976
I0929 23:44:20.208055 25435 solver.cpp:259]     Train net output #0: error_blob = 0.124976 (* 1 = 0.124976 loss)
I0929 23:44:20.208060 25435 solver.cpp:590] Iteration 4500, lr = 0.01
I0929 23:44:20.881374 25435 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:44:22.772043 25435 solver.cpp:243] Iteration 4600, loss = 0.125001
I0929 23:44:22.772192 25435 solver.cpp:259]     Train net output #0: error_blob = 0.125001 (* 1 = 0.125001 loss)
I0929 23:44:22.772198 25435 solver.cpp:590] Iteration 4600, lr = 0.01
I0929 23:44:25.255525 25435 solver.cpp:243] Iteration 4700, loss = 0.125019
I0929 23:44:25.255556 25435 solver.cpp:259]     Train net output #0: error_blob = 0.125019 (* 1 = 0.125019 loss)
I0929 23:44:25.255561 25435 solver.cpp:590] Iteration 4700, lr = 0.01
I0929 23:44:27.803900 25435 solver.cpp:243] Iteration 4800, loss = 0.124973
I0929 23:44:27.803930 25435 solver.cpp:259]     Train net output #0: error_blob = 0.124973 (* 1 = 0.124973 loss)
I0929 23:44:27.803938 25435 solver.cpp:590] Iteration 4800, lr = 0.01
I0929 23:44:30.302427 25435 solver.cpp:243] Iteration 4900, loss = 0.125001
I0929 23:44:30.302456 25435 solver.cpp:259]     Train net output #0: error_blob = 0.125001 (* 1 = 0.125001 loss)
I0929 23:44:30.302461 25435 solver.cpp:590] Iteration 4900, lr = 0.01
I0929 23:44:32.732398 25435 solver.cpp:347] Iteration 5000, Testing net (#0)
I0929 23:44:33.039721 25435 solver.cpp:415]     Test net output #0: error_blob = 0.12501 (* 1 = 0.12501 loss)
I0929 23:44:33.040434 25435 solver.cpp:243] Iteration 5000, loss = 0.124976
I0929 23:44:33.040462 25435 solver.cpp:259]     Train net output #0: error_blob = 0.124976 (* 1 = 0.124976 loss)
I0929 23:44:33.040472 25435 solver.cpp:590] Iteration 5000, lr = 0.01
I0929 23:44:35.539443 25435 solver.cpp:243] Iteration 5100, loss = 0.124971
I0929 23:44:35.539490 25435 solver.cpp:259]     Train net output #0: error_blob = 0.124971 (* 1 = 0.124971 loss)
I0929 23:44:35.539499 25435 solver.cpp:590] Iteration 5100, lr = 0.01
I0929 23:44:38.081892 25435 solver.cpp:243] Iteration 5200, loss = 0.125
I0929 23:44:38.081929 25435 solver.cpp:259]     Train net output #0: error_blob = 0.125 (* 1 = 0.125 loss)
I0929 23:44:38.081936 25435 solver.cpp:590] Iteration 5200, lr = 0.01
I0929 23:44:40.616747 25435 solver.cpp:243] Iteration 5300, loss = 0.124974
I0929 23:44:40.616775 25435 solver.cpp:259]     Train net output #0: error_blob = 0.124974 (* 1 = 0.124974 loss)
I0929 23:44:40.616780 25435 solver.cpp:590] Iteration 5300, lr = 0.01
I0929 23:44:43.158041 25435 solver.cpp:243] Iteration 5400, loss = 0.124968
I0929 23:44:43.158089 25435 solver.cpp:259]     Train net output #0: error_blob = 0.124968 (* 1 = 0.124968 loss)
I0929 23:44:43.158095 25435 solver.cpp:590] Iteration 5400, lr = 0.01
I0929 23:44:43.971213 25435 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:44:45.728385 25435 solver.cpp:243] Iteration 5500, loss = 0.124996
I0929 23:44:45.728425 25435 solver.cpp:259]     Train net output #0: error_blob = 0.124996 (* 1 = 0.124996 loss)
I0929 23:44:45.728430 25435 solver.cpp:590] Iteration 5500, lr = 0.01
I0929 23:44:48.277807 25435 solver.cpp:243] Iteration 5600, loss = 0.124972
I0929 23:44:48.277854 25435 solver.cpp:259]     Train net output #0: error_blob = 0.124972 (* 1 = 0.124972 loss)
I0929 23:44:48.277863 25435 solver.cpp:590] Iteration 5600, lr = 0.01
I0929 23:44:50.817787 25435 solver.cpp:243] Iteration 5700, loss = 0.124969
I0929 23:44:50.817834 25435 solver.cpp:259]     Train net output #0: error_blob = 0.124969 (* 1 = 0.124969 loss)
I0929 23:44:50.817842 25435 solver.cpp:590] Iteration 5700, lr = 0.01
I0929 23:44:53.360982 25435 solver.cpp:243] Iteration 5800, loss = 0.125002
I0929 23:44:53.362076 25435 solver.cpp:259]     Train net output #0: error_blob = 0.125002 (* 1 = 0.125002 loss)
I0929 23:44:53.362083 25435 solver.cpp:590] Iteration 5800, lr = 0.01
I0929 23:44:55.866257 25435 solver.cpp:243] Iteration 5900, loss = 0.124972
I0929 23:44:55.866288 25435 solver.cpp:259]     Train net output #0: error_blob = 0.124972 (* 1 = 0.124972 loss)
I0929 23:44:55.866292 25435 solver.cpp:590] Iteration 5900, lr = 0.01
I0929 23:44:58.367898 25435 solver.cpp:347] Iteration 6000, Testing net (#0)
I0929 23:44:58.653997 25435 solver.cpp:415]     Test net output #0: error_blob = 0.125013 (* 1 = 0.125013 loss)
I0929 23:44:58.654639 25435 solver.cpp:243] Iteration 6000, loss = 0.124967
I0929 23:44:58.654651 25435 solver.cpp:259]     Train net output #0: error_blob = 0.124967 (* 1 = 0.124967 loss)
I0929 23:44:58.654666 25435 solver.cpp:590] Iteration 6000, lr = 0.01
I0929 23:45:01.148509 25435 solver.cpp:243] Iteration 6100, loss = 0.125004
I0929 23:45:01.148538 25435 solver.cpp:259]     Train net output #0: error_blob = 0.125004 (* 1 = 0.125004 loss)
I0929 23:45:01.148545 25435 solver.cpp:590] Iteration 6100, lr = 0.01
I0929 23:45:03.689210 25435 solver.cpp:243] Iteration 6200, loss = 0.124969
I0929 23:45:03.689244 25435 solver.cpp:259]     Train net output #0: error_blob = 0.124969 (* 1 = 0.124969 loss)
I0929 23:45:03.689250 25435 solver.cpp:590] Iteration 6200, lr = 0.01
I0929 23:45:06.221858 25435 solver.cpp:243] Iteration 6300, loss = 0.124964
I0929 23:45:06.221899 25435 solver.cpp:259]     Train net output #0: error_blob = 0.124964 (* 1 = 0.124964 loss)
I0929 23:45:06.221904 25435 solver.cpp:590] Iteration 6300, lr = 0.01
I0929 23:45:07.177597 25435 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:45:08.719084 25435 solver.cpp:243] Iteration 6400, loss = 0.124999
I0929 23:45:08.719115 25435 solver.cpp:259]     Train net output #0: error_blob = 0.124999 (* 1 = 0.124999 loss)
I0929 23:45:08.719120 25435 solver.cpp:590] Iteration 6400, lr = 0.01
I0929 23:45:11.226555 25435 solver.cpp:243] Iteration 6500, loss = 0.124967
I0929 23:45:11.226588 25435 solver.cpp:259]     Train net output #0: error_blob = 0.124967 (* 1 = 0.124967 loss)
I0929 23:45:11.226593 25435 solver.cpp:590] Iteration 6500, lr = 0.01
I0929 23:45:13.737149 25435 solver.cpp:243] Iteration 6600, loss = 0.124961
I0929 23:45:13.737179 25435 solver.cpp:259]     Train net output #0: error_blob = 0.124961 (* 1 = 0.124961 loss)
I0929 23:45:13.737186 25435 solver.cpp:590] Iteration 6600, lr = 0.01
I0929 23:45:16.268002 25435 solver.cpp:243] Iteration 6700, loss = 0.125006
I0929 23:45:16.268031 25435 solver.cpp:259]     Train net output #0: error_blob = 0.125006 (* 1 = 0.125006 loss)
I0929 23:45:16.268038 25435 solver.cpp:590] Iteration 6700, lr = 0.01
I0929 23:45:18.772459 25435 solver.cpp:243] Iteration 6800, loss = 0.124964
I0929 23:45:18.772500 25435 solver.cpp:259]     Train net output #0: error_blob = 0.124964 (* 1 = 0.124964 loss)
I0929 23:45:18.772505 25435 solver.cpp:590] Iteration 6800, lr = 0.01
I0929 23:45:21.306273 25435 solver.cpp:243] Iteration 6900, loss = 0.124728
I0929 23:45:21.306305 25435 solver.cpp:259]     Train net output #0: error_blob = 0.124728 (* 1 = 0.124728 loss)
I0929 23:45:21.306310 25435 solver.cpp:590] Iteration 6900, lr = 0.01
I0929 23:45:23.762440 25435 solver.cpp:347] Iteration 7000, Testing net (#0)
I0929 23:45:24.049342 25435 solver.cpp:415]     Test net output #0: error_blob = 0.125015 (* 1 = 0.125015 loss)
I0929 23:45:24.050034 25435 solver.cpp:243] Iteration 7000, loss = 0.125002
I0929 23:45:24.050050 25435 solver.cpp:259]     Train net output #0: error_blob = 0.125002 (* 1 = 0.125002 loss)
I0929 23:45:24.050055 25435 solver.cpp:590] Iteration 7000, lr = 0.01
I0929 23:45:26.526257 25435 solver.cpp:243] Iteration 7100, loss = 0.124967
I0929 23:45:26.526288 25435 solver.cpp:259]     Train net output #0: error_blob = 0.124967 (* 1 = 0.124967 loss)
I0929 23:45:26.526293 25435 solver.cpp:590] Iteration 7100, lr = 0.01
I0929 23:45:29.061012 25435 solver.cpp:243] Iteration 7200, loss = 0.124996
I0929 23:45:29.061043 25435 solver.cpp:259]     Train net output #0: error_blob = 0.124996 (* 1 = 0.124996 loss)
I0929 23:45:29.061048 25435 solver.cpp:590] Iteration 7200, lr = 0.01
I0929 23:45:30.155464 25435 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:45:31.564703 25435 solver.cpp:243] Iteration 7300, loss = 0.125001
I0929 23:45:31.564734 25435 solver.cpp:259]     Train net output #0: error_blob = 0.125001 (* 1 = 0.125001 loss)
I0929 23:45:31.564739 25435 solver.cpp:590] Iteration 7300, lr = 0.01
I0929 23:45:34.089781 25435 solver.cpp:243] Iteration 7400, loss = 0.124962
I0929 23:45:34.089810 25435 solver.cpp:259]     Train net output #0: error_blob = 0.124962 (* 1 = 0.124962 loss)
I0929 23:45:34.089817 25435 solver.cpp:590] Iteration 7400, lr = 0.01
I0929 23:45:36.585780 25435 solver.cpp:243] Iteration 7500, loss = 0.125003
I0929 23:45:36.585811 25435 solver.cpp:259]     Train net output #0: error_blob = 0.125003 (* 1 = 0.125003 loss)
I0929 23:45:36.585816 25435 solver.cpp:590] Iteration 7500, lr = 0.01
I0929 23:45:39.059746 25435 solver.cpp:243] Iteration 7600, loss = 0.125002
I0929 23:45:39.059777 25435 solver.cpp:259]     Train net output #0: error_blob = 0.125002 (* 1 = 0.125002 loss)
I0929 23:45:39.059785 25435 solver.cpp:590] Iteration 7600, lr = 0.01
I0929 23:45:41.572521 25435 solver.cpp:243] Iteration 7700, loss = 0.124955
I0929 23:45:41.572552 25435 solver.cpp:259]     Train net output #0: error_blob = 0.124955 (* 1 = 0.124955 loss)
I0929 23:45:41.572556 25435 solver.cpp:590] Iteration 7700, lr = 0.01
I0929 23:45:44.066228 25435 solver.cpp:243] Iteration 7800, loss = 0.124994
I0929 23:45:44.066257 25435 solver.cpp:259]     Train net output #0: error_blob = 0.124994 (* 1 = 0.124994 loss)
I0929 23:45:44.066262 25435 solver.cpp:590] Iteration 7800, lr = 0.01
I0929 23:45:46.602069 25435 solver.cpp:243] Iteration 7900, loss = 0.124996
I0929 23:45:46.602099 25435 solver.cpp:259]     Train net output #0: error_blob = 0.124996 (* 1 = 0.124996 loss)
I0929 23:45:46.602104 25435 solver.cpp:590] Iteration 7900, lr = 0.01
I0929 23:45:49.058495 25435 solver.cpp:347] Iteration 8000, Testing net (#0)
I0929 23:45:49.339014 25435 solver.cpp:415]     Test net output #0: error_blob = 0.125015 (* 1 = 0.125015 loss)
I0929 23:45:49.339714 25435 solver.cpp:243] Iteration 8000, loss = 0.12495
I0929 23:45:49.339733 25435 solver.cpp:259]     Train net output #0: error_blob = 0.12495 (* 1 = 0.12495 loss)
I0929 23:45:49.339740 25435 solver.cpp:590] Iteration 8000, lr = 0.01
I0929 23:45:51.811588 25435 solver.cpp:243] Iteration 8100, loss = 0.124999
I0929 23:45:51.811627 25435 solver.cpp:259]     Train net output #0: error_blob = 0.124999 (* 1 = 0.124999 loss)
I0929 23:45:51.811632 25435 solver.cpp:590] Iteration 8100, lr = 0.01
I0929 23:45:53.057132 25435 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:45:54.323046 25435 solver.cpp:243] Iteration 8200, loss = 0.125169
I0929 23:45:54.323146 25435 solver.cpp:259]     Train net output #0: error_blob = 0.125169 (* 1 = 0.125169 loss)
I0929 23:45:54.323153 25435 solver.cpp:590] Iteration 8200, lr = 0.01
I0929 23:45:56.819944 25435 solver.cpp:243] Iteration 8300, loss = 0.12495
I0929 23:45:56.819975 25435 solver.cpp:259]     Train net output #0: error_blob = 0.12495 (* 1 = 0.12495 loss)
I0929 23:45:56.819979 25435 solver.cpp:590] Iteration 8300, lr = 0.01
I0929 23:45:59.340333 25435 solver.cpp:243] Iteration 8400, loss = 0.124999
I0929 23:45:59.340364 25435 solver.cpp:259]     Train net output #0: error_blob = 0.124999 (* 1 = 0.124999 loss)
I0929 23:45:59.340369 25435 solver.cpp:590] Iteration 8400, lr = 0.01
I0929 23:46:01.874775 25435 solver.cpp:243] Iteration 8500, loss = 0.12496
I0929 23:46:01.874806 25435 solver.cpp:259]     Train net output #0: error_blob = 0.12496 (* 1 = 0.12496 loss)
I0929 23:46:01.874811 25435 solver.cpp:590] Iteration 8500, lr = 0.01
I0929 23:46:04.416265 25435 solver.cpp:243] Iteration 8600, loss = 0.124951
I0929 23:46:04.416306 25435 solver.cpp:259]     Train net output #0: error_blob = 0.124951 (* 1 = 0.124951 loss)
I0929 23:46:04.416312 25435 solver.cpp:590] Iteration 8600, lr = 0.01
I0929 23:46:06.914517 25435 solver.cpp:243] Iteration 8700, loss = 0.12499
I0929 23:46:06.914559 25435 solver.cpp:259]     Train net output #0: error_blob = 0.12499 (* 1 = 0.12499 loss)
I0929 23:46:06.914564 25435 solver.cpp:590] Iteration 8700, lr = 0.01
I0929 23:46:09.436879 25435 solver.cpp:243] Iteration 8800, loss = 0.124959
I0929 23:46:09.436918 25435 solver.cpp:259]     Train net output #0: error_blob = 0.124959 (* 1 = 0.124959 loss)
I0929 23:46:09.436923 25435 solver.cpp:590] Iteration 8800, lr = 0.01
I0929 23:46:11.958367 25435 solver.cpp:243] Iteration 8900, loss = 0.124951
I0929 23:46:11.958395 25435 solver.cpp:259]     Train net output #0: error_blob = 0.124951 (* 1 = 0.124951 loss)
I0929 23:46:11.958400 25435 solver.cpp:590] Iteration 8900, lr = 0.01
I0929 23:46:14.470643 25435 solver.cpp:347] Iteration 9000, Testing net (#0)
I0929 23:46:14.761093 25435 solver.cpp:415]     Test net output #0: error_blob = 0.125018 (* 1 = 0.125018 loss)
I0929 23:46:14.761788 25435 solver.cpp:243] Iteration 9000, loss = 0.125001
I0929 23:46:14.761824 25435 solver.cpp:259]     Train net output #0: error_blob = 0.125001 (* 1 = 0.125001 loss)
I0929 23:46:14.761847 25435 solver.cpp:590] Iteration 9000, lr = 0.01
I0929 23:46:16.131517 25435 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:46:17.222905 25435 solver.cpp:243] Iteration 9100, loss = 0.124952
I0929 23:46:17.222946 25435 solver.cpp:259]     Train net output #0: error_blob = 0.124952 (* 1 = 0.124952 loss)
I0929 23:46:17.222951 25435 solver.cpp:590] Iteration 9100, lr = 0.01
I0929 23:46:19.724262 25435 solver.cpp:243] Iteration 9200, loss = 0.124948
I0929 23:46:19.724292 25435 solver.cpp:259]     Train net output #0: error_blob = 0.124948 (* 1 = 0.124948 loss)
I0929 23:46:19.724298 25435 solver.cpp:590] Iteration 9200, lr = 0.01
I0929 23:46:22.223620 25435 solver.cpp:243] Iteration 9300, loss = 0.125002
I0929 23:46:22.223661 25435 solver.cpp:259]     Train net output #0: error_blob = 0.125002 (* 1 = 0.125002 loss)
I0929 23:46:22.223665 25435 solver.cpp:590] Iteration 9300, lr = 0.01
I0929 23:46:24.724205 25435 solver.cpp:243] Iteration 9400, loss = 0.124958
I0929 23:46:24.724328 25435 solver.cpp:259]     Train net output #0: error_blob = 0.124958 (* 1 = 0.124958 loss)
I0929 23:46:24.724336 25435 solver.cpp:590] Iteration 9400, lr = 0.01
I0929 23:46:27.223023 25435 solver.cpp:243] Iteration 9500, loss = 0.124953
I0929 23:46:27.223062 25435 solver.cpp:259]     Train net output #0: error_blob = 0.124953 (* 1 = 0.124953 loss)
I0929 23:46:27.223067 25435 solver.cpp:590] Iteration 9500, lr = 0.01
I0929 23:46:29.723299 25435 solver.cpp:243] Iteration 9600, loss = 0.125001
I0929 23:46:29.723337 25435 solver.cpp:259]     Train net output #0: error_blob = 0.125001 (* 1 = 0.125001 loss)
I0929 23:46:29.723342 25435 solver.cpp:590] Iteration 9600, lr = 0.01
I0929 23:46:32.202061 25435 solver.cpp:243] Iteration 9700, loss = 0.124946
I0929 23:46:32.202102 25435 solver.cpp:259]     Train net output #0: error_blob = 0.124946 (* 1 = 0.124946 loss)
I0929 23:46:32.202107 25435 solver.cpp:590] Iteration 9700, lr = 0.01
I0929 23:46:34.680693 25435 solver.cpp:243] Iteration 9800, loss = 0.124947
I0929 23:46:34.680734 25435 solver.cpp:259]     Train net output #0: error_blob = 0.124947 (* 1 = 0.124947 loss)
I0929 23:46:34.680738 25435 solver.cpp:590] Iteration 9800, lr = 0.01
I0929 23:46:37.193294 25435 solver.cpp:243] Iteration 9900, loss = 0.125
I0929 23:46:37.193331 25435 solver.cpp:259]     Train net output #0: error_blob = 0.125 (* 1 = 0.125 loss)
I0929 23:46:37.193337 25435 solver.cpp:590] Iteration 9900, lr = 0.01
I0929 23:46:39.695365 25435 solver.cpp:468] Snapshotting to binary proto file _iter_10000.caffemodel
I0929 23:46:39.696192 25435 solver.cpp:753] Snapshotting solver state to binary proto file _iter_10000.solverstate
I0929 23:46:39.720402 25435 solver.cpp:327] Iteration 10000, loss = 0.124947
I0929 23:46:39.720439 25435 solver.cpp:347] Iteration 10000, Testing net (#0)
I0929 23:46:39.893378 25435 blocking_queue.cpp:50] Data layer prefetch queue empty
I0929 23:46:40.000192 25435 solver.cpp:415]     Test net output #0: error_blob = 0.125028 (* 1 = 0.125028 loss)
I0929 23:46:40.000212 25435 solver.cpp:332] Optimization Done.
I0929 23:46:40.000215 25435 caffe.cpp:215] Optimization Done.
