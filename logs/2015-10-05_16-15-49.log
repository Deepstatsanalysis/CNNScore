I1005 16:15:49.727757 15424 caffe.cpp:184] Using GPUs 0
I1005 16:15:50.303102 15424 solver.cpp:54] Initializing solver from parameters: 
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "fixed"
momentum: 0.9
solver_mode: GPU
device_id: 0
net: "basic/model0_full.prototxt"
I1005 16:15:50.303131 15424 solver.cpp:97] Creating training net from net file: basic/model0_full.prototxt
I1005 16:15:50.303315 15424 net.cpp:50] Initializing net from parameters: 
name: "basic/model0_full.prototxt"
state {
  phase: TRAIN
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.full"
    batch_size: 20000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1005 16:15:50.303354 15424 layer_factory.hpp:76] Creating layer data_layer
I1005 16:15:50.316680 15424 net.cpp:110] Creating Layer data_layer
I1005 16:15:50.316711 15424 net.cpp:433] data_layer -> data_blob
I1005 16:15:50.316745 15424 net.cpp:433] data_layer -> label_blob
I1005 16:15:50.317319 15428 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.full
I1005 16:15:51.001112 15424 data_layer.cpp:45] output data size: 20000,61,1,1
I1005 16:15:51.006044 15424 net.cpp:155] Setting up data_layer
I1005 16:15:51.006085 15424 net.cpp:163] Top shape: 20000 61 1 1 (1220000)
I1005 16:15:51.006089 15424 net.cpp:163] Top shape: 20000 (20000)
I1005 16:15:51.006095 15424 layer_factory.hpp:76] Creating layer hidden_sum_layer
I1005 16:15:51.006119 15424 net.cpp:110] Creating Layer hidden_sum_layer
I1005 16:15:51.006121 15424 net.cpp:477] hidden_sum_layer <- data_blob
I1005 16:15:51.006131 15424 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I1005 16:15:51.006489 15424 net.cpp:155] Setting up hidden_sum_layer
I1005 16:15:51.006496 15424 net.cpp:163] Top shape: 20000 10 (200000)
I1005 16:15:51.006518 15424 layer_factory.hpp:76] Creating layer hidden_act_layer
I1005 16:15:51.006536 15424 net.cpp:110] Creating Layer hidden_act_layer
I1005 16:15:51.006538 15424 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I1005 16:15:51.006541 15424 net.cpp:433] hidden_act_layer -> hidden_act_blob
I1005 16:15:54.218917 15424 net.cpp:155] Setting up hidden_act_layer
I1005 16:15:54.218950 15424 net.cpp:163] Top shape: 20000 10 (200000)
I1005 16:15:54.218955 15424 layer_factory.hpp:76] Creating layer output_sum_layer
I1005 16:15:54.218965 15424 net.cpp:110] Creating Layer output_sum_layer
I1005 16:15:54.218967 15424 net.cpp:477] output_sum_layer <- hidden_act_blob
I1005 16:15:54.218973 15424 net.cpp:433] output_sum_layer -> output_sum_blob
I1005 16:15:54.219063 15424 net.cpp:155] Setting up output_sum_layer
I1005 16:15:54.219069 15424 net.cpp:163] Top shape: 20000 1 (20000)
I1005 16:15:54.219086 15424 layer_factory.hpp:76] Creating layer output_act_layer
I1005 16:15:54.219091 15424 net.cpp:110] Creating Layer output_act_layer
I1005 16:15:54.219094 15424 net.cpp:477] output_act_layer <- output_sum_blob
I1005 16:15:54.219096 15424 net.cpp:433] output_act_layer -> output_act_blob
I1005 16:15:54.219158 15424 net.cpp:155] Setting up output_act_layer
I1005 16:15:54.219162 15424 net.cpp:163] Top shape: 20000 1 (20000)
I1005 16:15:54.219164 15424 layer_factory.hpp:76] Creating layer error_layer
I1005 16:15:54.219180 15424 net.cpp:110] Creating Layer error_layer
I1005 16:15:54.219182 15424 net.cpp:477] error_layer <- output_act_blob
I1005 16:15:54.219200 15424 net.cpp:477] error_layer <- label_blob
I1005 16:15:54.219208 15424 net.cpp:433] error_layer -> error_blob
I1005 16:15:54.219238 15424 net.cpp:155] Setting up error_layer
I1005 16:15:54.219252 15424 net.cpp:163] Top shape: (1)
I1005 16:15:54.219256 15424 net.cpp:168]     with loss weight 1
I1005 16:15:54.219285 15424 net.cpp:236] error_layer needs backward computation.
I1005 16:15:54.219291 15424 net.cpp:236] output_act_layer needs backward computation.
I1005 16:15:54.219311 15424 net.cpp:236] output_sum_layer needs backward computation.
I1005 16:15:54.219316 15424 net.cpp:236] hidden_act_layer needs backward computation.
I1005 16:15:54.219317 15424 net.cpp:236] hidden_sum_layer needs backward computation.
I1005 16:15:54.219319 15424 net.cpp:240] data_layer does not need backward computation.
I1005 16:15:54.219321 15424 net.cpp:283] This network produces output error_blob
I1005 16:15:54.219327 15424 net.cpp:297] Network initialization done.
I1005 16:15:54.219328 15424 net.cpp:298] Memory required for data: 6720004
I1005 16:15:54.219351 15424 solver.cpp:66] Solver scaffolding done.
I1005 16:15:54.219445 15424 caffe.cpp:212] Starting Optimization
I1005 16:15:54.219450 15424 solver.cpp:294] Solving basic/model0_full.prototxt
I1005 16:15:54.219462 15424 solver.cpp:295] Learning Rate Policy: fixed
I1005 16:15:54.220798 15424 solver.cpp:243] Iteration 0, loss = 0.132907
I1005 16:15:54.220823 15424 solver.cpp:259]     Train net output #0: error_blob = 0.132907 (* 1 = 0.132907 loss)
I1005 16:15:54.220829 15424 solver.cpp:590] Iteration 0, lr = 0.01
I1005 16:15:54.221868 15424 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 16:15:56.706032 15424 solver.cpp:243] Iteration 100, loss = 0.117405
I1005 16:15:56.706063 15424 solver.cpp:259]     Train net output #0: error_blob = 0.117405 (* 1 = 0.117405 loss)
I1005 16:15:56.706068 15424 solver.cpp:590] Iteration 100, lr = 0.01
I1005 16:15:59.215427 15424 solver.cpp:243] Iteration 200, loss = 0.114071
I1005 16:15:59.215469 15424 solver.cpp:259]     Train net output #0: error_blob = 0.114071 (* 1 = 0.114071 loss)
I1005 16:15:59.215474 15424 solver.cpp:590] Iteration 200, lr = 0.01
I1005 16:16:01.715181 15424 solver.cpp:243] Iteration 300, loss = 0.110642
I1005 16:16:01.715212 15424 solver.cpp:259]     Train net output #0: error_blob = 0.110642 (* 1 = 0.110642 loss)
I1005 16:16:01.715219 15424 solver.cpp:590] Iteration 300, lr = 0.01
I1005 16:16:04.162257 15424 solver.cpp:243] Iteration 400, loss = 0.108117
I1005 16:16:04.162289 15424 solver.cpp:259]     Train net output #0: error_blob = 0.108117 (* 1 = 0.108117 loss)
I1005 16:16:04.162293 15424 solver.cpp:590] Iteration 400, lr = 0.01
I1005 16:16:06.648877 15424 solver.cpp:243] Iteration 500, loss = 0.106284
I1005 16:16:06.648907 15424 solver.cpp:259]     Train net output #0: error_blob = 0.106284 (* 1 = 0.106284 loss)
I1005 16:16:06.648912 15424 solver.cpp:590] Iteration 500, lr = 0.01
I1005 16:16:09.168611 15424 solver.cpp:243] Iteration 600, loss = 0.105359
I1005 16:16:09.168649 15424 solver.cpp:259]     Train net output #0: error_blob = 0.105359 (* 1 = 0.105359 loss)
I1005 16:16:09.168654 15424 solver.cpp:590] Iteration 600, lr = 0.01
I1005 16:16:11.657119 15424 solver.cpp:243] Iteration 700, loss = 0.103676
I1005 16:16:11.657166 15424 solver.cpp:259]     Train net output #0: error_blob = 0.103676 (* 1 = 0.103676 loss)
I1005 16:16:11.657172 15424 solver.cpp:590] Iteration 700, lr = 0.01
I1005 16:16:14.166098 15424 solver.cpp:243] Iteration 800, loss = 0.103397
I1005 16:16:14.166137 15424 solver.cpp:259]     Train net output #0: error_blob = 0.103397 (* 1 = 0.103397 loss)
I1005 16:16:14.166142 15424 solver.cpp:590] Iteration 800, lr = 0.01
I1005 16:16:16.689543 15424 solver.cpp:243] Iteration 900, loss = 0.10297
I1005 16:16:16.689582 15424 solver.cpp:259]     Train net output #0: error_blob = 0.10297 (* 1 = 0.10297 loss)
I1005 16:16:16.689589 15424 solver.cpp:590] Iteration 900, lr = 0.01
I1005 16:16:19.167743 15424 solver.cpp:243] Iteration 1000, loss = 0.103971
I1005 16:16:19.167809 15424 solver.cpp:259]     Train net output #0: error_blob = 0.103971 (* 1 = 0.103971 loss)
I1005 16:16:19.167814 15424 solver.cpp:590] Iteration 1000, lr = 0.01
I1005 16:16:19.192173 15424 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 16:16:21.630847 15424 solver.cpp:243] Iteration 1100, loss = 0.105238
I1005 16:16:21.631979 15424 solver.cpp:259]     Train net output #0: error_blob = 0.105238 (* 1 = 0.105238 loss)
I1005 16:16:21.631988 15424 solver.cpp:590] Iteration 1100, lr = 0.01
I1005 16:16:24.097055 15424 solver.cpp:243] Iteration 1200, loss = 0.106555
I1005 16:16:24.097085 15424 solver.cpp:259]     Train net output #0: error_blob = 0.106555 (* 1 = 0.106555 loss)
I1005 16:16:24.097090 15424 solver.cpp:590] Iteration 1200, lr = 0.01
I1005 16:16:26.560556 15424 solver.cpp:243] Iteration 1300, loss = 0.105894
I1005 16:16:26.560595 15424 solver.cpp:259]     Train net output #0: error_blob = 0.105894 (* 1 = 0.105894 loss)
I1005 16:16:26.560600 15424 solver.cpp:590] Iteration 1300, lr = 0.01
I1005 16:16:29.024291 15424 solver.cpp:243] Iteration 1400, loss = 0.105544
I1005 16:16:29.024332 15424 solver.cpp:259]     Train net output #0: error_blob = 0.105544 (* 1 = 0.105544 loss)
I1005 16:16:29.024338 15424 solver.cpp:590] Iteration 1400, lr = 0.01
I1005 16:16:31.485455 15424 solver.cpp:243] Iteration 1500, loss = 0.105393
I1005 16:16:31.485486 15424 solver.cpp:259]     Train net output #0: error_blob = 0.105393 (* 1 = 0.105393 loss)
I1005 16:16:31.485491 15424 solver.cpp:590] Iteration 1500, lr = 0.01
I1005 16:16:33.967176 15424 solver.cpp:243] Iteration 1600, loss = 0.102649
I1005 16:16:33.967208 15424 solver.cpp:259]     Train net output #0: error_blob = 0.102649 (* 1 = 0.102649 loss)
I1005 16:16:33.967213 15424 solver.cpp:590] Iteration 1600, lr = 0.01
I1005 16:16:36.452006 15424 solver.cpp:243] Iteration 1700, loss = 0.101159
I1005 16:16:36.452046 15424 solver.cpp:259]     Train net output #0: error_blob = 0.101159 (* 1 = 0.101159 loss)
I1005 16:16:36.452051 15424 solver.cpp:590] Iteration 1700, lr = 0.01
I1005 16:16:38.918745 15424 solver.cpp:243] Iteration 1800, loss = 0.0999125
I1005 16:16:38.918774 15424 solver.cpp:259]     Train net output #0: error_blob = 0.0999125 (* 1 = 0.0999125 loss)
I1005 16:16:38.918779 15424 solver.cpp:590] Iteration 1800, lr = 0.01
I1005 16:16:41.400967 15424 solver.cpp:243] Iteration 1900, loss = 0.0982884
I1005 16:16:41.400996 15424 solver.cpp:259]     Train net output #0: error_blob = 0.0982884 (* 1 = 0.0982884 loss)
I1005 16:16:41.401001 15424 solver.cpp:590] Iteration 1900, lr = 0.01
I1005 16:16:43.879948 15424 solver.cpp:243] Iteration 2000, loss = 0.10116
I1005 16:16:43.879978 15424 solver.cpp:259]     Train net output #0: error_blob = 0.10116 (* 1 = 0.10116 loss)
I1005 16:16:43.879982 15424 solver.cpp:590] Iteration 2000, lr = 0.01
I1005 16:16:43.905174 15424 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 16:16:46.397117 15424 solver.cpp:243] Iteration 2100, loss = 0.0991764
I1005 16:16:46.397158 15424 solver.cpp:259]     Train net output #0: error_blob = 0.0991764 (* 1 = 0.0991764 loss)
I1005 16:16:46.397163 15424 solver.cpp:590] Iteration 2100, lr = 0.01
I1005 16:16:48.877320 15424 solver.cpp:243] Iteration 2200, loss = 0.100168
I1005 16:16:48.877360 15424 solver.cpp:259]     Train net output #0: error_blob = 0.100168 (* 1 = 0.100168 loss)
I1005 16:16:48.877367 15424 solver.cpp:590] Iteration 2200, lr = 0.01
I1005 16:16:51.384346 15424 solver.cpp:243] Iteration 2300, loss = 0.102363
I1005 16:16:51.384385 15424 solver.cpp:259]     Train net output #0: error_blob = 0.102363 (* 1 = 0.102363 loss)
I1005 16:16:51.384392 15424 solver.cpp:590] Iteration 2300, lr = 0.01
I1005 16:16:53.905700 15424 solver.cpp:243] Iteration 2400, loss = 0.104288
I1005 16:16:53.905762 15424 solver.cpp:259]     Train net output #0: error_blob = 0.104288 (* 1 = 0.104288 loss)
I1005 16:16:53.905767 15424 solver.cpp:590] Iteration 2400, lr = 0.01
I1005 16:16:56.410429 15424 solver.cpp:243] Iteration 2500, loss = 0.103989
I1005 16:16:56.410459 15424 solver.cpp:259]     Train net output #0: error_blob = 0.103989 (* 1 = 0.103989 loss)
I1005 16:16:56.410465 15424 solver.cpp:590] Iteration 2500, lr = 0.01
I1005 16:16:58.861424 15424 solver.cpp:243] Iteration 2600, loss = 0.103606
I1005 16:16:58.861464 15424 solver.cpp:259]     Train net output #0: error_blob = 0.103606 (* 1 = 0.103606 loss)
I1005 16:16:58.861469 15424 solver.cpp:590] Iteration 2600, lr = 0.01
I1005 16:17:01.334216 15424 solver.cpp:243] Iteration 2700, loss = 0.10396
I1005 16:17:01.334246 15424 solver.cpp:259]     Train net output #0: error_blob = 0.10396 (* 1 = 0.10396 loss)
I1005 16:17:01.334251 15424 solver.cpp:590] Iteration 2700, lr = 0.01
I1005 16:17:03.785190 15424 solver.cpp:243] Iteration 2800, loss = 0.101936
I1005 16:17:03.785222 15424 solver.cpp:259]     Train net output #0: error_blob = 0.101936 (* 1 = 0.101936 loss)
I1005 16:17:03.785226 15424 solver.cpp:590] Iteration 2800, lr = 0.01
I1005 16:17:06.260076 15424 solver.cpp:243] Iteration 2900, loss = 0.0991425
I1005 16:17:06.260107 15424 solver.cpp:259]     Train net output #0: error_blob = 0.0991425 (* 1 = 0.0991425 loss)
I1005 16:17:06.260113 15424 solver.cpp:590] Iteration 2900, lr = 0.01
I1005 16:17:08.728075 15424 solver.cpp:243] Iteration 3000, loss = 0.0988367
I1005 16:17:08.728108 15424 solver.cpp:259]     Train net output #0: error_blob = 0.0988367 (* 1 = 0.0988367 loss)
I1005 16:17:08.728114 15424 solver.cpp:590] Iteration 3000, lr = 0.01
I1005 16:17:08.754622 15424 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 16:17:11.215174 15424 solver.cpp:243] Iteration 3100, loss = 0.0975029
I1005 16:17:11.215208 15424 solver.cpp:259]     Train net output #0: error_blob = 0.0975029 (* 1 = 0.0975029 loss)
I1005 16:17:11.215212 15424 solver.cpp:590] Iteration 3100, lr = 0.01
I1005 16:17:13.688695 15424 solver.cpp:243] Iteration 3200, loss = 0.0968892
I1005 16:17:13.688736 15424 solver.cpp:259]     Train net output #0: error_blob = 0.0968892 (* 1 = 0.0968892 loss)
I1005 16:17:13.688741 15424 solver.cpp:590] Iteration 3200, lr = 0.01
I1005 16:17:16.165880 15424 solver.cpp:243] Iteration 3300, loss = 0.0996945
I1005 16:17:16.165922 15424 solver.cpp:259]     Train net output #0: error_blob = 0.0996945 (* 1 = 0.0996945 loss)
I1005 16:17:16.165927 15424 solver.cpp:590] Iteration 3300, lr = 0.01
I1005 16:17:18.649822 15424 solver.cpp:243] Iteration 3400, loss = 0.0966886
I1005 16:17:18.649850 15424 solver.cpp:259]     Train net output #0: error_blob = 0.0966886 (* 1 = 0.0966886 loss)
I1005 16:17:18.649855 15424 solver.cpp:590] Iteration 3400, lr = 0.01
I1005 16:17:21.107477 15424 solver.cpp:243] Iteration 3500, loss = 0.100514
I1005 16:17:21.107509 15424 solver.cpp:259]     Train net output #0: error_blob = 0.100514 (* 1 = 0.100514 loss)
I1005 16:17:21.107514 15424 solver.cpp:590] Iteration 3500, lr = 0.01
I1005 16:17:23.571219 15424 solver.cpp:243] Iteration 3600, loss = 0.101413
I1005 16:17:23.571257 15424 solver.cpp:259]     Train net output #0: error_blob = 0.101413 (* 1 = 0.101413 loss)
I1005 16:17:23.571262 15424 solver.cpp:590] Iteration 3600, lr = 0.01
I1005 16:17:26.029981 15424 solver.cpp:243] Iteration 3700, loss = 0.102467
I1005 16:17:26.031057 15424 solver.cpp:259]     Train net output #0: error_blob = 0.102467 (* 1 = 0.102467 loss)
I1005 16:17:26.031077 15424 solver.cpp:590] Iteration 3700, lr = 0.01
I1005 16:17:28.530443 15424 solver.cpp:243] Iteration 3800, loss = 0.10282
I1005 16:17:28.530485 15424 solver.cpp:259]     Train net output #0: error_blob = 0.10282 (* 1 = 0.10282 loss)
I1005 16:17:28.530490 15424 solver.cpp:590] Iteration 3800, lr = 0.01
I1005 16:17:30.984338 15424 solver.cpp:243] Iteration 3900, loss = 0.100619
I1005 16:17:30.984367 15424 solver.cpp:259]     Train net output #0: error_blob = 0.100619 (* 1 = 0.100619 loss)
I1005 16:17:30.984372 15424 solver.cpp:590] Iteration 3900, lr = 0.01
I1005 16:17:33.452688 15424 solver.cpp:243] Iteration 4000, loss = 0.102147
I1005 16:17:33.452718 15424 solver.cpp:259]     Train net output #0: error_blob = 0.102147 (* 1 = 0.102147 loss)
I1005 16:17:33.452723 15424 solver.cpp:590] Iteration 4000, lr = 0.01
I1005 16:17:33.478620 15424 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 16:17:35.955018 15424 solver.cpp:243] Iteration 4100, loss = 0.099748
I1005 16:17:35.955060 15424 solver.cpp:259]     Train net output #0: error_blob = 0.099748 (* 1 = 0.099748 loss)
I1005 16:17:35.955065 15424 solver.cpp:590] Iteration 4100, lr = 0.01
I1005 16:17:38.448076 15424 solver.cpp:243] Iteration 4200, loss = 0.0978569
I1005 16:17:38.448106 15424 solver.cpp:259]     Train net output #0: error_blob = 0.0978569 (* 1 = 0.0978569 loss)
I1005 16:17:38.448109 15424 solver.cpp:590] Iteration 4200, lr = 0.01
I1005 16:17:40.936522 15424 solver.cpp:243] Iteration 4300, loss = 0.0967949
I1005 16:17:40.936561 15424 solver.cpp:259]     Train net output #0: error_blob = 0.0967949 (* 1 = 0.0967949 loss)
I1005 16:17:40.936566 15424 solver.cpp:590] Iteration 4300, lr = 0.01
I1005 16:17:43.412520 15424 solver.cpp:243] Iteration 4400, loss = 0.0961198
I1005 16:17:43.412557 15424 solver.cpp:259]     Train net output #0: error_blob = 0.0961198 (* 1 = 0.0961198 loss)
I1005 16:17:43.412562 15424 solver.cpp:590] Iteration 4400, lr = 0.01
I1005 16:17:45.855146 15424 solver.cpp:243] Iteration 4500, loss = 0.097154
I1005 16:17:45.855175 15424 solver.cpp:259]     Train net output #0: error_blob = 0.097154 (* 1 = 0.097154 loss)
I1005 16:17:45.855180 15424 solver.cpp:590] Iteration 4500, lr = 0.01
I1005 16:17:48.346655 15424 solver.cpp:243] Iteration 4600, loss = 0.0966482
I1005 16:17:48.346685 15424 solver.cpp:259]     Train net output #0: error_blob = 0.0966482 (* 1 = 0.0966482 loss)
I1005 16:17:48.346689 15424 solver.cpp:590] Iteration 4600, lr = 0.01
I1005 16:17:50.772456 15424 solver.cpp:243] Iteration 4700, loss = 0.0980304
I1005 16:17:50.772512 15424 solver.cpp:259]     Train net output #0: error_blob = 0.0980304 (* 1 = 0.0980304 loss)
I1005 16:17:50.772518 15424 solver.cpp:590] Iteration 4700, lr = 0.01
I1005 16:17:53.282996 15424 solver.cpp:243] Iteration 4800, loss = 0.099795
I1005 16:17:53.283028 15424 solver.cpp:259]     Train net output #0: error_blob = 0.099795 (* 1 = 0.099795 loss)
I1005 16:17:53.283033 15424 solver.cpp:590] Iteration 4800, lr = 0.01
I1005 16:17:55.786923 15424 solver.cpp:243] Iteration 4900, loss = 0.100964
I1005 16:17:55.786955 15424 solver.cpp:259]     Train net output #0: error_blob = 0.100964 (* 1 = 0.100964 loss)
I1005 16:17:55.786959 15424 solver.cpp:590] Iteration 4900, lr = 0.01
I1005 16:17:58.314903 15424 solver.cpp:243] Iteration 5000, loss = 0.101262
I1005 16:17:58.315943 15424 solver.cpp:259]     Train net output #0: error_blob = 0.101262 (* 1 = 0.101262 loss)
I1005 16:17:58.315949 15424 solver.cpp:590] Iteration 5000, lr = 0.01
I1005 16:17:58.340276 15424 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 16:18:00.788532 15424 solver.cpp:243] Iteration 5100, loss = 0.102616
I1005 16:18:00.788573 15424 solver.cpp:259]     Train net output #0: error_blob = 0.102616 (* 1 = 0.102616 loss)
I1005 16:18:00.788578 15424 solver.cpp:590] Iteration 5100, lr = 0.01
I1005 16:18:03.319262 15424 solver.cpp:243] Iteration 5200, loss = 0.0994673
I1005 16:18:03.319301 15424 solver.cpp:259]     Train net output #0: error_blob = 0.0994673 (* 1 = 0.0994673 loss)
I1005 16:18:03.319308 15424 solver.cpp:590] Iteration 5200, lr = 0.01
I1005 16:18:05.818771 15424 solver.cpp:243] Iteration 5300, loss = 0.102881
I1005 16:18:05.818812 15424 solver.cpp:259]     Train net output #0: error_blob = 0.102881 (* 1 = 0.102881 loss)
I1005 16:18:05.818819 15424 solver.cpp:590] Iteration 5300, lr = 0.01
I1005 16:18:08.299763 15424 solver.cpp:243] Iteration 5400, loss = 0.0983163
I1005 16:18:08.299796 15424 solver.cpp:259]     Train net output #0: error_blob = 0.0983163 (* 1 = 0.0983163 loss)
I1005 16:18:08.299803 15424 solver.cpp:590] Iteration 5400, lr = 0.01
I1005 16:18:10.805141 15424 solver.cpp:243] Iteration 5500, loss = 0.0955451
I1005 16:18:10.805172 15424 solver.cpp:259]     Train net output #0: error_blob = 0.0955451 (* 1 = 0.0955451 loss)
I1005 16:18:10.805179 15424 solver.cpp:590] Iteration 5500, lr = 0.01
I1005 16:18:13.242277 15424 solver.cpp:243] Iteration 5600, loss = 0.0954376
I1005 16:18:13.242311 15424 solver.cpp:259]     Train net output #0: error_blob = 0.0954376 (* 1 = 0.0954376 loss)
I1005 16:18:13.242316 15424 solver.cpp:590] Iteration 5600, lr = 0.01
I1005 16:18:15.705729 15424 solver.cpp:243] Iteration 5700, loss = 0.0945404
I1005 16:18:15.705770 15424 solver.cpp:259]     Train net output #0: error_blob = 0.0945404 (* 1 = 0.0945404 loss)
I1005 16:18:15.705775 15424 solver.cpp:590] Iteration 5700, lr = 0.01
I1005 16:18:18.187141 15424 solver.cpp:243] Iteration 5800, loss = 0.0972433
I1005 16:18:18.187171 15424 solver.cpp:259]     Train net output #0: error_blob = 0.0972433 (* 1 = 0.0972433 loss)
I1005 16:18:18.187175 15424 solver.cpp:590] Iteration 5800, lr = 0.01
I1005 16:18:20.696411 15424 solver.cpp:243] Iteration 5900, loss = 0.0955944
I1005 16:18:20.696442 15424 solver.cpp:259]     Train net output #0: error_blob = 0.0955944 (* 1 = 0.0955944 loss)
I1005 16:18:20.696447 15424 solver.cpp:590] Iteration 5900, lr = 0.01
I1005 16:18:23.187376 15424 solver.cpp:243] Iteration 6000, loss = 0.0974856
I1005 16:18:23.187415 15424 solver.cpp:259]     Train net output #0: error_blob = 0.0974856 (* 1 = 0.0974856 loss)
I1005 16:18:23.187420 15424 solver.cpp:590] Iteration 6000, lr = 0.01
I1005 16:18:23.212085 15424 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 16:18:25.656810 15424 solver.cpp:243] Iteration 6100, loss = 0.0999833
I1005 16:18:25.656841 15424 solver.cpp:259]     Train net output #0: error_blob = 0.0999833 (* 1 = 0.0999833 loss)
I1005 16:18:25.656847 15424 solver.cpp:590] Iteration 6100, lr = 0.01
I1005 16:18:28.108073 15424 solver.cpp:243] Iteration 6200, loss = 0.101341
I1005 16:18:28.108103 15424 solver.cpp:259]     Train net output #0: error_blob = 0.101341 (* 1 = 0.101341 loss)
I1005 16:18:28.108108 15424 solver.cpp:590] Iteration 6200, lr = 0.01
I1005 16:18:30.581396 15424 solver.cpp:243] Iteration 6300, loss = 0.100074
I1005 16:18:30.581500 15424 solver.cpp:259]     Train net output #0: error_blob = 0.100074 (* 1 = 0.100074 loss)
I1005 16:18:30.581506 15424 solver.cpp:590] Iteration 6300, lr = 0.01
I1005 16:18:33.039295 15424 solver.cpp:243] Iteration 6400, loss = 0.100526
I1005 16:18:33.039326 15424 solver.cpp:259]     Train net output #0: error_blob = 0.100526 (* 1 = 0.100526 loss)
I1005 16:18:33.039330 15424 solver.cpp:590] Iteration 6400, lr = 0.01
I1005 16:18:35.531047 15424 solver.cpp:243] Iteration 6500, loss = 0.100887
I1005 16:18:35.531077 15424 solver.cpp:259]     Train net output #0: error_blob = 0.100887 (* 1 = 0.100887 loss)
I1005 16:18:35.531082 15424 solver.cpp:590] Iteration 6500, lr = 0.01
I1005 16:18:38.001677 15424 solver.cpp:243] Iteration 6600, loss = 0.0990231
I1005 16:18:38.001704 15424 solver.cpp:259]     Train net output #0: error_blob = 0.0990231 (* 1 = 0.0990231 loss)
I1005 16:18:38.001708 15424 solver.cpp:590] Iteration 6600, lr = 0.01
I1005 16:18:40.454747 15424 solver.cpp:243] Iteration 6700, loss = 0.0955171
I1005 16:18:40.454776 15424 solver.cpp:259]     Train net output #0: error_blob = 0.0955171 (* 1 = 0.0955171 loss)
I1005 16:18:40.454779 15424 solver.cpp:590] Iteration 6700, lr = 0.01
I1005 16:18:42.883282 15424 solver.cpp:243] Iteration 6800, loss = 0.0951383
I1005 16:18:42.883312 15424 solver.cpp:259]     Train net output #0: error_blob = 0.0951383 (* 1 = 0.0951383 loss)
I1005 16:18:42.883317 15424 solver.cpp:590] Iteration 6800, lr = 0.01
I1005 16:18:45.350244 15424 solver.cpp:243] Iteration 6900, loss = 0.0940934
I1005 16:18:45.350275 15424 solver.cpp:259]     Train net output #0: error_blob = 0.0940934 (* 1 = 0.0940934 loss)
I1005 16:18:45.350280 15424 solver.cpp:590] Iteration 6900, lr = 0.01
I1005 16:18:47.821223 15424 solver.cpp:243] Iteration 7000, loss = 0.0938048
I1005 16:18:47.821264 15424 solver.cpp:259]     Train net output #0: error_blob = 0.0938048 (* 1 = 0.0938048 loss)
I1005 16:18:47.821269 15424 solver.cpp:590] Iteration 7000, lr = 0.01
I1005 16:18:47.845616 15424 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 16:18:50.310430 15424 solver.cpp:243] Iteration 7100, loss = 0.0968981
I1005 16:18:50.310470 15424 solver.cpp:259]     Train net output #0: error_blob = 0.0968981 (* 1 = 0.0968981 loss)
I1005 16:18:50.310475 15424 solver.cpp:590] Iteration 7100, lr = 0.01
I1005 16:18:52.776469 15424 solver.cpp:243] Iteration 7200, loss = 0.094808
I1005 16:18:52.776510 15424 solver.cpp:259]     Train net output #0: error_blob = 0.094808 (* 1 = 0.094808 loss)
I1005 16:18:52.776515 15424 solver.cpp:590] Iteration 7200, lr = 0.01
I1005 16:18:55.271438 15424 solver.cpp:243] Iteration 7300, loss = 0.0976391
I1005 16:18:55.271468 15424 solver.cpp:259]     Train net output #0: error_blob = 0.0976391 (* 1 = 0.0976391 loss)
I1005 16:18:55.271472 15424 solver.cpp:590] Iteration 7300, lr = 0.01
I1005 16:18:57.738286 15424 solver.cpp:243] Iteration 7400, loss = 0.100384
I1005 16:18:57.738318 15424 solver.cpp:259]     Train net output #0: error_blob = 0.100384 (* 1 = 0.100384 loss)
I1005 16:18:57.738322 15424 solver.cpp:590] Iteration 7400, lr = 0.01
I1005 16:19:00.191294 15424 solver.cpp:243] Iteration 7500, loss = 0.10057
I1005 16:19:00.191324 15424 solver.cpp:259]     Train net output #0: error_blob = 0.10057 (* 1 = 0.10057 loss)
I1005 16:19:00.191329 15424 solver.cpp:590] Iteration 7500, lr = 0.01
I1005 16:19:02.655557 15424 solver.cpp:243] Iteration 7600, loss = 0.100609
I1005 16:19:02.655668 15424 solver.cpp:259]     Train net output #0: error_blob = 0.100609 (* 1 = 0.100609 loss)
I1005 16:19:02.655673 15424 solver.cpp:590] Iteration 7600, lr = 0.01
I1005 16:19:05.137110 15424 solver.cpp:243] Iteration 7700, loss = 0.0995517
I1005 16:19:05.137142 15424 solver.cpp:259]     Train net output #0: error_blob = 0.0995517 (* 1 = 0.0995517 loss)
I1005 16:19:05.137147 15424 solver.cpp:590] Iteration 7700, lr = 0.01
I1005 16:19:07.608913 15424 solver.cpp:243] Iteration 7800, loss = 0.0990928
I1005 16:19:07.608943 15424 solver.cpp:259]     Train net output #0: error_blob = 0.0990928 (* 1 = 0.0990928 loss)
I1005 16:19:07.608949 15424 solver.cpp:590] Iteration 7800, lr = 0.01
I1005 16:19:10.079918 15424 solver.cpp:243] Iteration 7900, loss = 0.0975679
I1005 16:19:10.079946 15424 solver.cpp:259]     Train net output #0: error_blob = 0.0975679 (* 1 = 0.0975679 loss)
I1005 16:19:10.079952 15424 solver.cpp:590] Iteration 7900, lr = 0.01
I1005 16:19:12.554311 15424 solver.cpp:243] Iteration 8000, loss = 0.094725
I1005 16:19:12.554342 15424 solver.cpp:259]     Train net output #0: error_blob = 0.094725 (* 1 = 0.094725 loss)
I1005 16:19:12.554348 15424 solver.cpp:590] Iteration 8000, lr = 0.01
I1005 16:19:12.579816 15424 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 16:19:15.052785 15424 solver.cpp:243] Iteration 8100, loss = 0.0938804
I1005 16:19:15.052815 15424 solver.cpp:259]     Train net output #0: error_blob = 0.0938804 (* 1 = 0.0938804 loss)
I1005 16:19:15.052820 15424 solver.cpp:590] Iteration 8100, lr = 0.01
I1005 16:19:17.545563 15424 solver.cpp:243] Iteration 8200, loss = 0.0934779
I1005 16:19:17.545593 15424 solver.cpp:259]     Train net output #0: error_blob = 0.0934779 (* 1 = 0.0934779 loss)
I1005 16:19:17.545598 15424 solver.cpp:590] Iteration 8200, lr = 0.01
I1005 16:19:20.017825 15424 solver.cpp:243] Iteration 8300, loss = 0.0945627
I1005 16:19:20.017859 15424 solver.cpp:259]     Train net output #0: error_blob = 0.0945627 (* 1 = 0.0945627 loss)
I1005 16:19:20.017865 15424 solver.cpp:590] Iteration 8300, lr = 0.01
I1005 16:19:22.509624 15424 solver.cpp:243] Iteration 8400, loss = 0.09478
I1005 16:19:22.509655 15424 solver.cpp:259]     Train net output #0: error_blob = 0.09478 (* 1 = 0.09478 loss)
I1005 16:19:22.509661 15424 solver.cpp:590] Iteration 8400, lr = 0.01
I1005 16:19:24.993744 15424 solver.cpp:243] Iteration 8500, loss = 0.0950757
I1005 16:19:24.993774 15424 solver.cpp:259]     Train net output #0: error_blob = 0.0950757 (* 1 = 0.0950757 loss)
I1005 16:19:24.993780 15424 solver.cpp:590] Iteration 8500, lr = 0.01
I1005 16:19:27.480473 15424 solver.cpp:243] Iteration 8600, loss = 0.0986265
I1005 16:19:27.480516 15424 solver.cpp:259]     Train net output #0: error_blob = 0.0986265 (* 1 = 0.0986265 loss)
I1005 16:19:27.480522 15424 solver.cpp:590] Iteration 8600, lr = 0.01
I1005 16:19:29.969893 15424 solver.cpp:243] Iteration 8700, loss = 0.0990657
I1005 16:19:29.969923 15424 solver.cpp:259]     Train net output #0: error_blob = 0.0990657 (* 1 = 0.0990657 loss)
I1005 16:19:29.969928 15424 solver.cpp:590] Iteration 8700, lr = 0.01
I1005 16:19:32.460674 15424 solver.cpp:243] Iteration 8800, loss = 0.0987604
I1005 16:19:32.460701 15424 solver.cpp:259]     Train net output #0: error_blob = 0.0987604 (* 1 = 0.0987604 loss)
I1005 16:19:32.460706 15424 solver.cpp:590] Iteration 8800, lr = 0.01
I1005 16:19:34.943922 15424 solver.cpp:243] Iteration 8900, loss = 0.100972
I1005 16:19:34.944098 15424 solver.cpp:259]     Train net output #0: error_blob = 0.100972 (* 1 = 0.100972 loss)
I1005 16:19:34.944106 15424 solver.cpp:590] Iteration 8900, lr = 0.01
I1005 16:19:37.436898 15424 solver.cpp:243] Iteration 9000, loss = 0.096611
I1005 16:19:37.436926 15424 solver.cpp:259]     Train net output #0: error_blob = 0.096611 (* 1 = 0.096611 loss)
I1005 16:19:37.436931 15424 solver.cpp:590] Iteration 9000, lr = 0.01
I1005 16:19:37.462373 15424 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 16:19:39.913105 15424 solver.cpp:243] Iteration 9100, loss = 0.0999619
I1005 16:19:39.913136 15424 solver.cpp:259]     Train net output #0: error_blob = 0.0999619 (* 1 = 0.0999619 loss)
I1005 16:19:39.913139 15424 solver.cpp:590] Iteration 9100, lr = 0.01
I1005 16:19:42.406990 15424 solver.cpp:243] Iteration 9200, loss = 0.09614
I1005 16:19:42.407021 15424 solver.cpp:259]     Train net output #0: error_blob = 0.09614 (* 1 = 0.09614 loss)
I1005 16:19:42.407026 15424 solver.cpp:590] Iteration 9200, lr = 0.01
I1005 16:19:44.903937 15424 solver.cpp:243] Iteration 9300, loss = 0.0933588
I1005 16:19:44.903978 15424 solver.cpp:259]     Train net output #0: error_blob = 0.0933588 (* 1 = 0.0933588 loss)
I1005 16:19:44.903983 15424 solver.cpp:590] Iteration 9300, lr = 0.01
I1005 16:19:47.384554 15424 solver.cpp:243] Iteration 9400, loss = 0.0931224
I1005 16:19:47.384584 15424 solver.cpp:259]     Train net output #0: error_blob = 0.0931224 (* 1 = 0.0931224 loss)
I1005 16:19:47.384590 15424 solver.cpp:590] Iteration 9400, lr = 0.01
I1005 16:19:49.873479 15424 solver.cpp:243] Iteration 9500, loss = 0.0934659
I1005 16:19:49.873512 15424 solver.cpp:259]     Train net output #0: error_blob = 0.0934659 (* 1 = 0.0934659 loss)
I1005 16:19:49.873517 15424 solver.cpp:590] Iteration 9500, lr = 0.01
I1005 16:19:52.349596 15424 solver.cpp:243] Iteration 9600, loss = 0.0946457
I1005 16:19:52.349627 15424 solver.cpp:259]     Train net output #0: error_blob = 0.0946457 (* 1 = 0.0946457 loss)
I1005 16:19:52.349633 15424 solver.cpp:590] Iteration 9600, lr = 0.01
I1005 16:19:54.856884 15424 solver.cpp:243] Iteration 9700, loss = 0.0937965
I1005 16:19:54.856914 15424 solver.cpp:259]     Train net output #0: error_blob = 0.0937965 (* 1 = 0.0937965 loss)
I1005 16:19:54.856921 15424 solver.cpp:590] Iteration 9700, lr = 0.01
I1005 16:19:57.370239 15424 solver.cpp:243] Iteration 9800, loss = 0.0957542
I1005 16:19:57.370272 15424 solver.cpp:259]     Train net output #0: error_blob = 0.0957542 (* 1 = 0.0957542 loss)
I1005 16:19:57.370280 15424 solver.cpp:590] Iteration 9800, lr = 0.01
I1005 16:19:59.869915 15424 solver.cpp:243] Iteration 9900, loss = 0.0988089
I1005 16:19:59.869946 15424 solver.cpp:259]     Train net output #0: error_blob = 0.0988089 (* 1 = 0.0988089 loss)
I1005 16:19:59.869952 15424 solver.cpp:590] Iteration 9900, lr = 0.01
I1005 16:20:02.347661 15424 solver.cpp:468] Snapshotting to binary proto file _iter_10000.caffemodel
I1005 16:20:02.348461 15424 solver.cpp:753] Snapshotting solver state to binary proto file _iter_10000.solverstate
I1005 16:20:02.372994 15424 solver.cpp:327] Iteration 10000, loss = 0.0992173
I1005 16:20:02.373021 15424 solver.cpp:332] Optimization Done.
I1005 16:20:02.373026 15424 caffe.cpp:215] Optimization Done.
I1005 16:20:02.471740 15435 caffe.cpp:184] Using GPUs 0
I1005 16:20:03.033485 15435 solver.cpp:54] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "fixed"
momentum: 0.9
solver_mode: GPU
device_id: 0
net: "basic/model0_part9.prototxt"
I1005 16:20:03.033516 15435 solver.cpp:97] Creating training net from net file: basic/model0_part9.prototxt
I1005 16:20:03.033684 15435 net.cpp:339] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_layer
I1005 16:20:03.033730 15435 net.cpp:50] Initializing net from parameters: 
name: "basic/model0_part9.prototxt"
state {
  phase: TRAIN
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TRAIN
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.part9.train"
    batch_size: 20000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1005 16:20:03.033808 15435 layer_factory.hpp:76] Creating layer data_layer
I1005 16:20:03.047466 15435 net.cpp:110] Creating Layer data_layer
I1005 16:20:03.047495 15435 net.cpp:433] data_layer -> data_blob
I1005 16:20:03.047528 15435 net.cpp:433] data_layer -> label_blob
I1005 16:20:03.048126 15439 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.part9.train
I1005 16:20:03.730937 15435 data_layer.cpp:45] output data size: 20000,61,1,1
I1005 16:20:03.735985 15435 net.cpp:155] Setting up data_layer
I1005 16:20:03.736026 15435 net.cpp:163] Top shape: 20000 61 1 1 (1220000)
I1005 16:20:03.736033 15435 net.cpp:163] Top shape: 20000 (20000)
I1005 16:20:03.736039 15435 layer_factory.hpp:76] Creating layer hidden_sum_layer
I1005 16:20:03.736052 15435 net.cpp:110] Creating Layer hidden_sum_layer
I1005 16:20:03.736054 15435 net.cpp:477] hidden_sum_layer <- data_blob
I1005 16:20:03.736064 15435 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I1005 16:20:03.736431 15435 net.cpp:155] Setting up hidden_sum_layer
I1005 16:20:03.736438 15435 net.cpp:163] Top shape: 20000 10 (200000)
I1005 16:20:03.736460 15435 layer_factory.hpp:76] Creating layer hidden_act_layer
I1005 16:20:03.736477 15435 net.cpp:110] Creating Layer hidden_act_layer
I1005 16:20:03.736479 15435 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I1005 16:20:03.736484 15435 net.cpp:433] hidden_act_layer -> hidden_act_blob
I1005 16:20:06.974603 15435 net.cpp:155] Setting up hidden_act_layer
I1005 16:20:06.974625 15435 net.cpp:163] Top shape: 20000 10 (200000)
I1005 16:20:06.974630 15435 layer_factory.hpp:76] Creating layer output_sum_layer
I1005 16:20:06.974639 15435 net.cpp:110] Creating Layer output_sum_layer
I1005 16:20:06.974643 15435 net.cpp:477] output_sum_layer <- hidden_act_blob
I1005 16:20:06.974648 15435 net.cpp:433] output_sum_layer -> output_sum_blob
I1005 16:20:06.974730 15435 net.cpp:155] Setting up output_sum_layer
I1005 16:20:06.974738 15435 net.cpp:163] Top shape: 20000 1 (20000)
I1005 16:20:06.974745 15435 layer_factory.hpp:76] Creating layer output_act_layer
I1005 16:20:06.974750 15435 net.cpp:110] Creating Layer output_act_layer
I1005 16:20:06.974752 15435 net.cpp:477] output_act_layer <- output_sum_blob
I1005 16:20:06.974756 15435 net.cpp:433] output_act_layer -> output_act_blob
I1005 16:20:06.974812 15435 net.cpp:155] Setting up output_act_layer
I1005 16:20:06.974817 15435 net.cpp:163] Top shape: 20000 1 (20000)
I1005 16:20:06.974831 15435 layer_factory.hpp:76] Creating layer error_layer
I1005 16:20:06.974836 15435 net.cpp:110] Creating Layer error_layer
I1005 16:20:06.974839 15435 net.cpp:477] error_layer <- output_act_blob
I1005 16:20:06.974841 15435 net.cpp:477] error_layer <- label_blob
I1005 16:20:06.974845 15435 net.cpp:433] error_layer -> error_blob
I1005 16:20:06.974869 15435 net.cpp:155] Setting up error_layer
I1005 16:20:06.974874 15435 net.cpp:163] Top shape: (1)
I1005 16:20:06.974876 15435 net.cpp:168]     with loss weight 1
I1005 16:20:06.974892 15435 net.cpp:236] error_layer needs backward computation.
I1005 16:20:06.974895 15435 net.cpp:236] output_act_layer needs backward computation.
I1005 16:20:06.974896 15435 net.cpp:236] output_sum_layer needs backward computation.
I1005 16:20:06.974899 15435 net.cpp:236] hidden_act_layer needs backward computation.
I1005 16:20:06.974900 15435 net.cpp:236] hidden_sum_layer needs backward computation.
I1005 16:20:06.974903 15435 net.cpp:240] data_layer does not need backward computation.
I1005 16:20:06.974905 15435 net.cpp:283] This network produces output error_blob
I1005 16:20:06.974910 15435 net.cpp:297] Network initialization done.
I1005 16:20:06.974911 15435 net.cpp:298] Memory required for data: 6720004
I1005 16:20:06.975041 15435 solver.cpp:187] Creating test net (#0) specified by net file: basic/model0_part9.prototxt
I1005 16:20:06.975055 15435 net.cpp:339] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_layer
I1005 16:20:06.975090 15435 net.cpp:50] Initializing net from parameters: 
name: "basic/model0_part9.prototxt"
state {
  phase: TEST
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TEST
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.part9.test"
    batch_size: 2000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1005 16:20:06.975111 15435 layer_factory.hpp:76] Creating layer data_layer
I1005 16:20:06.976305 15435 net.cpp:110] Creating Layer data_layer
I1005 16:20:06.976320 15435 net.cpp:433] data_layer -> data_blob
I1005 16:20:06.976325 15435 net.cpp:433] data_layer -> label_blob
I1005 16:20:06.976894 15441 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.part9.test
I1005 16:20:06.976964 15435 data_layer.cpp:45] output data size: 2000,61,1,1
I1005 16:20:06.978325 15435 net.cpp:155] Setting up data_layer
I1005 16:20:06.978335 15435 net.cpp:163] Top shape: 2000 61 1 1 (122000)
I1005 16:20:06.978338 15435 net.cpp:163] Top shape: 2000 (2000)
I1005 16:20:06.978343 15435 layer_factory.hpp:76] Creating layer hidden_sum_layer
I1005 16:20:06.978354 15435 net.cpp:110] Creating Layer hidden_sum_layer
I1005 16:20:06.978358 15435 net.cpp:477] hidden_sum_layer <- data_blob
I1005 16:20:06.978364 15435 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I1005 16:20:06.978483 15435 net.cpp:155] Setting up hidden_sum_layer
I1005 16:20:06.978489 15435 net.cpp:163] Top shape: 2000 10 (20000)
I1005 16:20:06.978498 15435 layer_factory.hpp:76] Creating layer hidden_act_layer
I1005 16:20:06.978505 15435 net.cpp:110] Creating Layer hidden_act_layer
I1005 16:20:06.978508 15435 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I1005 16:20:06.978529 15435 net.cpp:433] hidden_act_layer -> hidden_act_blob
I1005 16:20:06.978705 15435 net.cpp:155] Setting up hidden_act_layer
I1005 16:20:06.978713 15435 net.cpp:163] Top shape: 2000 10 (20000)
I1005 16:20:06.978718 15435 layer_factory.hpp:76] Creating layer output_sum_layer
I1005 16:20:06.978724 15435 net.cpp:110] Creating Layer output_sum_layer
I1005 16:20:06.978727 15435 net.cpp:477] output_sum_layer <- hidden_act_blob
I1005 16:20:06.978734 15435 net.cpp:433] output_sum_layer -> output_sum_blob
I1005 16:20:06.978799 15435 net.cpp:155] Setting up output_sum_layer
I1005 16:20:06.978806 15435 net.cpp:163] Top shape: 2000 1 (2000)
I1005 16:20:06.978812 15435 layer_factory.hpp:76] Creating layer output_act_layer
I1005 16:20:06.978818 15435 net.cpp:110] Creating Layer output_act_layer
I1005 16:20:06.978823 15435 net.cpp:477] output_act_layer <- output_sum_blob
I1005 16:20:06.978829 15435 net.cpp:433] output_act_layer -> output_act_blob
I1005 16:20:06.978885 15435 net.cpp:155] Setting up output_act_layer
I1005 16:20:06.978890 15435 net.cpp:163] Top shape: 2000 1 (2000)
I1005 16:20:06.978893 15435 layer_factory.hpp:76] Creating layer error_layer
I1005 16:20:06.978899 15435 net.cpp:110] Creating Layer error_layer
I1005 16:20:06.978902 15435 net.cpp:477] error_layer <- output_act_blob
I1005 16:20:06.978906 15435 net.cpp:477] error_layer <- label_blob
I1005 16:20:06.978910 15435 net.cpp:433] error_layer -> error_blob
I1005 16:20:06.978936 15435 net.cpp:155] Setting up error_layer
I1005 16:20:06.978940 15435 net.cpp:163] Top shape: (1)
I1005 16:20:06.978942 15435 net.cpp:168]     with loss weight 1
I1005 16:20:06.978952 15435 net.cpp:236] error_layer needs backward computation.
I1005 16:20:06.978956 15435 net.cpp:236] output_act_layer needs backward computation.
I1005 16:20:06.978960 15435 net.cpp:236] output_sum_layer needs backward computation.
I1005 16:20:06.978962 15435 net.cpp:236] hidden_act_layer needs backward computation.
I1005 16:20:06.978966 15435 net.cpp:236] hidden_sum_layer needs backward computation.
I1005 16:20:06.978970 15435 net.cpp:240] data_layer does not need backward computation.
I1005 16:20:06.978972 15435 net.cpp:283] This network produces output error_blob
I1005 16:20:06.978979 15435 net.cpp:297] Network initialization done.
I1005 16:20:06.978984 15435 net.cpp:298] Memory required for data: 672004
I1005 16:20:06.979009 15435 solver.cpp:66] Solver scaffolding done.
I1005 16:20:06.979104 15435 caffe.cpp:212] Starting Optimization
I1005 16:20:06.979113 15435 solver.cpp:294] Solving basic/model0_part9.prototxt
I1005 16:20:06.979116 15435 solver.cpp:295] Learning Rate Policy: fixed
I1005 16:20:06.979342 15435 solver.cpp:347] Iteration 0, Testing net (#0)
I1005 16:20:06.979395 15435 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 16:20:07.255575 15435 solver.cpp:415]     Test net output #0: error_blob = 0.129145 (* 1 = 0.129145 loss)
I1005 16:20:07.256885 15435 solver.cpp:243] Iteration 0, loss = 0.127454
I1005 16:20:07.256903 15435 solver.cpp:259]     Train net output #0: error_blob = 0.127454 (* 1 = 0.127454 loss)
I1005 16:20:07.256916 15435 solver.cpp:590] Iteration 0, lr = 0.01
I1005 16:20:09.688623 15435 solver.cpp:243] Iteration 100, loss = 0.11325
I1005 16:20:09.688657 15435 solver.cpp:259]     Train net output #0: error_blob = 0.11325 (* 1 = 0.11325 loss)
I1005 16:20:09.688664 15435 solver.cpp:590] Iteration 100, lr = 0.01
I1005 16:20:12.167014 15435 solver.cpp:243] Iteration 200, loss = 0.112933
I1005 16:20:12.167062 15435 solver.cpp:259]     Train net output #0: error_blob = 0.112933 (* 1 = 0.112933 loss)
I1005 16:20:12.167071 15435 solver.cpp:590] Iteration 200, lr = 0.01
I1005 16:20:14.666085 15435 solver.cpp:243] Iteration 300, loss = 0.111907
I1005 16:20:14.666126 15435 solver.cpp:259]     Train net output #0: error_blob = 0.111907 (* 1 = 0.111907 loss)
I1005 16:20:14.666132 15435 solver.cpp:590] Iteration 300, lr = 0.01
I1005 16:20:17.171615 15435 solver.cpp:243] Iteration 400, loss = 0.107755
I1005 16:20:17.171653 15435 solver.cpp:259]     Train net output #0: error_blob = 0.107755 (* 1 = 0.107755 loss)
I1005 16:20:17.171700 15435 solver.cpp:590] Iteration 400, lr = 0.01
I1005 16:20:19.644601 15435 solver.cpp:243] Iteration 500, loss = 0.108894
I1005 16:20:19.644634 15435 solver.cpp:259]     Train net output #0: error_blob = 0.108894 (* 1 = 0.108894 loss)
I1005 16:20:19.644639 15435 solver.cpp:590] Iteration 500, lr = 0.01
I1005 16:20:22.110595 15435 solver.cpp:243] Iteration 600, loss = 0.109312
I1005 16:20:22.110643 15435 solver.cpp:259]     Train net output #0: error_blob = 0.109312 (* 1 = 0.109312 loss)
I1005 16:20:22.110651 15435 solver.cpp:590] Iteration 600, lr = 0.01
I1005 16:20:24.581816 15435 solver.cpp:243] Iteration 700, loss = 0.104146
I1005 16:20:24.581866 15435 solver.cpp:259]     Train net output #0: error_blob = 0.104146 (* 1 = 0.104146 loss)
I1005 16:20:24.581876 15435 solver.cpp:590] Iteration 700, lr = 0.01
I1005 16:20:27.058660 15435 solver.cpp:243] Iteration 800, loss = 0.107759
I1005 16:20:27.058699 15435 solver.cpp:259]     Train net output #0: error_blob = 0.107759 (* 1 = 0.107759 loss)
I1005 16:20:27.058706 15435 solver.cpp:590] Iteration 800, lr = 0.01
I1005 16:20:29.517107 15435 solver.cpp:243] Iteration 900, loss = 0.105754
I1005 16:20:29.517148 15435 solver.cpp:259]     Train net output #0: error_blob = 0.105754 (* 1 = 0.105754 loss)
I1005 16:20:29.517153 15435 solver.cpp:590] Iteration 900, lr = 0.01
I1005 16:20:29.564255 15435 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 16:20:31.974726 15435 solver.cpp:347] Iteration 1000, Testing net (#0)
I1005 16:20:32.262456 15435 solver.cpp:415]     Test net output #0: error_blob = 0.110457 (* 1 = 0.110457 loss)
I1005 16:20:32.263116 15435 solver.cpp:243] Iteration 1000, loss = 0.10197
I1005 16:20:32.263156 15435 solver.cpp:259]     Train net output #0: error_blob = 0.10197 (* 1 = 0.10197 loss)
I1005 16:20:32.263178 15435 solver.cpp:590] Iteration 1000, lr = 0.01
I1005 16:20:34.693799 15435 solver.cpp:243] Iteration 1100, loss = 0.106093
I1005 16:20:34.693872 15435 solver.cpp:259]     Train net output #0: error_blob = 0.106093 (* 1 = 0.106093 loss)
I1005 16:20:34.693884 15435 solver.cpp:590] Iteration 1100, lr = 0.01
I1005 16:20:37.167857 15435 solver.cpp:243] Iteration 1200, loss = 0.104588
I1005 16:20:37.167902 15435 solver.cpp:259]     Train net output #0: error_blob = 0.104588 (* 1 = 0.104588 loss)
I1005 16:20:37.167911 15435 solver.cpp:590] Iteration 1200, lr = 0.01
I1005 16:20:39.681599 15435 solver.cpp:243] Iteration 1300, loss = 0.10085
I1005 16:20:39.681635 15435 solver.cpp:259]     Train net output #0: error_blob = 0.10085 (* 1 = 0.10085 loss)
I1005 16:20:39.681646 15435 solver.cpp:590] Iteration 1300, lr = 0.01
I1005 16:20:42.156034 15435 solver.cpp:243] Iteration 1400, loss = 0.104478
I1005 16:20:42.156066 15435 solver.cpp:259]     Train net output #0: error_blob = 0.104478 (* 1 = 0.104478 loss)
I1005 16:20:42.156072 15435 solver.cpp:590] Iteration 1400, lr = 0.01
I1005 16:20:44.613960 15435 solver.cpp:243] Iteration 1500, loss = 0.102598
I1005 16:20:44.614002 15435 solver.cpp:259]     Train net output #0: error_blob = 0.102598 (* 1 = 0.102598 loss)
I1005 16:20:44.614008 15435 solver.cpp:590] Iteration 1500, lr = 0.01
I1005 16:20:47.060650 15435 solver.cpp:243] Iteration 1600, loss = 0.0996086
I1005 16:20:47.060690 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0996086 (* 1 = 0.0996086 loss)
I1005 16:20:47.060698 15435 solver.cpp:590] Iteration 1600, lr = 0.01
I1005 16:20:49.509354 15435 solver.cpp:243] Iteration 1700, loss = 0.101662
I1005 16:20:49.509385 15435 solver.cpp:259]     Train net output #0: error_blob = 0.101662 (* 1 = 0.101662 loss)
I1005 16:20:49.509392 15435 solver.cpp:590] Iteration 1700, lr = 0.01
I1005 16:20:51.965975 15435 solver.cpp:243] Iteration 1800, loss = 0.102966
I1005 16:20:51.966006 15435 solver.cpp:259]     Train net output #0: error_blob = 0.102966 (* 1 = 0.102966 loss)
I1005 16:20:51.966012 15435 solver.cpp:590] Iteration 1800, lr = 0.01
I1005 16:20:52.164410 15435 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 16:20:54.464172 15435 solver.cpp:243] Iteration 1900, loss = 0.0997504
I1005 16:20:54.464215 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0997504 (* 1 = 0.0997504 loss)
I1005 16:20:54.464221 15435 solver.cpp:590] Iteration 1900, lr = 0.01
I1005 16:20:56.901353 15435 solver.cpp:347] Iteration 2000, Testing net (#0)
I1005 16:20:57.181754 15435 solver.cpp:415]     Test net output #0: error_blob = 0.112778 (* 1 = 0.112778 loss)
I1005 16:20:57.182411 15435 solver.cpp:243] Iteration 2000, loss = 0.100604
I1005 16:20:57.182428 15435 solver.cpp:259]     Train net output #0: error_blob = 0.100604 (* 1 = 0.100604 loss)
I1005 16:20:57.182435 15435 solver.cpp:590] Iteration 2000, lr = 0.01
I1005 16:20:59.601975 15435 solver.cpp:243] Iteration 2100, loss = 0.100007
I1005 16:20:59.602023 15435 solver.cpp:259]     Train net output #0: error_blob = 0.100007 (* 1 = 0.100007 loss)
I1005 16:20:59.602032 15435 solver.cpp:590] Iteration 2100, lr = 0.01
I1005 16:21:02.060897 15435 solver.cpp:243] Iteration 2200, loss = 0.0992744
I1005 16:21:02.060935 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0992744 (* 1 = 0.0992744 loss)
I1005 16:21:02.060943 15435 solver.cpp:590] Iteration 2200, lr = 0.01
I1005 16:21:04.541507 15435 solver.cpp:243] Iteration 2300, loss = 0.101322
I1005 16:21:04.541554 15435 solver.cpp:259]     Train net output #0: error_blob = 0.101322 (* 1 = 0.101322 loss)
I1005 16:21:04.541564 15435 solver.cpp:590] Iteration 2300, lr = 0.01
I1005 16:21:07.029939 15435 solver.cpp:243] Iteration 2400, loss = 0.0993729
I1005 16:21:07.031028 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0993729 (* 1 = 0.0993729 loss)
I1005 16:21:07.031036 15435 solver.cpp:590] Iteration 2400, lr = 0.01
I1005 16:21:09.489629 15435 solver.cpp:243] Iteration 2500, loss = 0.0981702
I1005 16:21:09.489660 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0981702 (* 1 = 0.0981702 loss)
I1005 16:21:09.489665 15435 solver.cpp:590] Iteration 2500, lr = 0.01
I1005 16:21:11.934487 15435 solver.cpp:243] Iteration 2600, loss = 0.101652
I1005 16:21:11.934519 15435 solver.cpp:259]     Train net output #0: error_blob = 0.101652 (* 1 = 0.101652 loss)
I1005 16:21:11.934525 15435 solver.cpp:590] Iteration 2600, lr = 0.01
I1005 16:21:14.375182 15435 solver.cpp:243] Iteration 2700, loss = 0.0978416
I1005 16:21:14.375222 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0978416 (* 1 = 0.0978416 loss)
I1005 16:21:14.375228 15435 solver.cpp:590] Iteration 2700, lr = 0.01
I1005 16:21:14.717727 15435 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 16:21:16.799002 15435 solver.cpp:243] Iteration 2800, loss = 0.097947
I1005 16:21:16.799031 15435 solver.cpp:259]     Train net output #0: error_blob = 0.097947 (* 1 = 0.097947 loss)
I1005 16:21:16.799036 15435 solver.cpp:590] Iteration 2800, lr = 0.01
I1005 16:21:19.267133 15435 solver.cpp:243] Iteration 2900, loss = 0.101728
I1005 16:21:19.267174 15435 solver.cpp:259]     Train net output #0: error_blob = 0.101728 (* 1 = 0.101728 loss)
I1005 16:21:19.267179 15435 solver.cpp:590] Iteration 2900, lr = 0.01
I1005 16:21:21.673328 15435 solver.cpp:347] Iteration 3000, Testing net (#0)
I1005 16:21:22.019505 15435 solver.cpp:415]     Test net output #0: error_blob = 0.116056 (* 1 = 0.116056 loss)
I1005 16:21:22.020123 15435 solver.cpp:243] Iteration 3000, loss = 0.096961
I1005 16:21:22.020134 15435 solver.cpp:259]     Train net output #0: error_blob = 0.096961 (* 1 = 0.096961 loss)
I1005 16:21:22.020139 15435 solver.cpp:590] Iteration 3000, lr = 0.01
I1005 16:21:24.431627 15435 solver.cpp:243] Iteration 3100, loss = 0.0982543
I1005 16:21:24.431665 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0982543 (* 1 = 0.0982543 loss)
I1005 16:21:24.431671 15435 solver.cpp:590] Iteration 3100, lr = 0.01
I1005 16:21:26.857167 15435 solver.cpp:243] Iteration 3200, loss = 0.101507
I1005 16:21:26.857197 15435 solver.cpp:259]     Train net output #0: error_blob = 0.101507 (* 1 = 0.101507 loss)
I1005 16:21:26.857203 15435 solver.cpp:590] Iteration 3200, lr = 0.01
I1005 16:21:29.298218 15435 solver.cpp:243] Iteration 3300, loss = 0.096836
I1005 16:21:29.298251 15435 solver.cpp:259]     Train net output #0: error_blob = 0.096836 (* 1 = 0.096836 loss)
I1005 16:21:29.298257 15435 solver.cpp:590] Iteration 3300, lr = 0.01
I1005 16:21:31.750041 15435 solver.cpp:243] Iteration 3400, loss = 0.0980918
I1005 16:21:31.750072 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0980918 (* 1 = 0.0980918 loss)
I1005 16:21:31.750075 15435 solver.cpp:590] Iteration 3400, lr = 0.01
I1005 16:21:34.187047 15435 solver.cpp:243] Iteration 3500, loss = 0.101332
I1005 16:21:34.187086 15435 solver.cpp:259]     Train net output #0: error_blob = 0.101332 (* 1 = 0.101332 loss)
I1005 16:21:34.187091 15435 solver.cpp:590] Iteration 3500, lr = 0.01
I1005 16:21:36.659026 15435 solver.cpp:243] Iteration 3600, loss = 0.0968885
I1005 16:21:36.659056 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0968885 (* 1 = 0.0968885 loss)
I1005 16:21:36.659062 15435 solver.cpp:590] Iteration 3600, lr = 0.01
I1005 16:21:37.154144 15435 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 16:21:39.114282 15435 solver.cpp:243] Iteration 3700, loss = 0.0983347
I1005 16:21:39.114315 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0983347 (* 1 = 0.0983347 loss)
I1005 16:21:39.114322 15435 solver.cpp:590] Iteration 3700, lr = 0.01
I1005 16:21:41.580996 15435 solver.cpp:243] Iteration 3800, loss = 0.101021
I1005 16:21:41.581027 15435 solver.cpp:259]     Train net output #0: error_blob = 0.101021 (* 1 = 0.101021 loss)
I1005 16:21:41.581035 15435 solver.cpp:590] Iteration 3800, lr = 0.01
I1005 16:21:44.026918 15435 solver.cpp:243] Iteration 3900, loss = 0.0977261
I1005 16:21:44.026950 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0977261 (* 1 = 0.0977261 loss)
I1005 16:21:44.026957 15435 solver.cpp:590] Iteration 3900, lr = 0.01
I1005 16:21:46.471760 15435 solver.cpp:347] Iteration 4000, Testing net (#0)
I1005 16:21:46.805176 15435 solver.cpp:415]     Test net output #0: error_blob = 0.118345 (* 1 = 0.118345 loss)
I1005 16:21:46.805796 15435 solver.cpp:243] Iteration 4000, loss = 0.098763
I1005 16:21:46.805806 15435 solver.cpp:259]     Train net output #0: error_blob = 0.098763 (* 1 = 0.098763 loss)
I1005 16:21:46.805811 15435 solver.cpp:590] Iteration 4000, lr = 0.01
I1005 16:21:49.201982 15435 solver.cpp:243] Iteration 4100, loss = 0.0990441
I1005 16:21:49.202023 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0990441 (* 1 = 0.0990441 loss)
I1005 16:21:49.202026 15435 solver.cpp:590] Iteration 4100, lr = 0.01
I1005 16:21:51.642099 15435 solver.cpp:243] Iteration 4200, loss = 0.0963247
I1005 16:21:51.642130 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0963247 (* 1 = 0.0963247 loss)
I1005 16:21:51.642135 15435 solver.cpp:590] Iteration 4200, lr = 0.01
I1005 16:21:54.106380 15435 solver.cpp:243] Iteration 4300, loss = 0.0992621
I1005 16:21:54.106410 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0992621 (* 1 = 0.0992621 loss)
I1005 16:21:54.106420 15435 solver.cpp:590] Iteration 4300, lr = 0.01
I1005 16:21:56.554940 15435 solver.cpp:243] Iteration 4400, loss = 0.0991788
I1005 16:21:56.554970 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0991788 (* 1 = 0.0991788 loss)
I1005 16:21:56.554977 15435 solver.cpp:590] Iteration 4400, lr = 0.01
I1005 16:21:58.999841 15435 solver.cpp:243] Iteration 4500, loss = 0.0952338
I1005 16:21:58.999869 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0952338 (* 1 = 0.0952338 loss)
I1005 16:21:58.999874 15435 solver.cpp:590] Iteration 4500, lr = 0.01
I1005 16:21:59.640653 15435 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 16:22:01.470988 15435 solver.cpp:243] Iteration 4600, loss = 0.0984816
I1005 16:22:01.471017 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0984816 (* 1 = 0.0984816 loss)
I1005 16:22:01.471021 15435 solver.cpp:590] Iteration 4600, lr = 0.01
I1005 16:22:03.922565 15435 solver.cpp:243] Iteration 4700, loss = 0.0997061
I1005 16:22:03.922595 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0997061 (* 1 = 0.0997061 loss)
I1005 16:22:03.922600 15435 solver.cpp:590] Iteration 4700, lr = 0.01
I1005 16:22:06.399423 15435 solver.cpp:243] Iteration 4800, loss = 0.094612
I1005 16:22:06.399462 15435 solver.cpp:259]     Train net output #0: error_blob = 0.094612 (* 1 = 0.094612 loss)
I1005 16:22:06.399467 15435 solver.cpp:590] Iteration 4800, lr = 0.01
I1005 16:22:08.839648 15435 solver.cpp:243] Iteration 4900, loss = 0.097493
I1005 16:22:08.839772 15435 solver.cpp:259]     Train net output #0: error_blob = 0.097493 (* 1 = 0.097493 loss)
I1005 16:22:08.839779 15435 solver.cpp:590] Iteration 4900, lr = 0.01
I1005 16:22:11.270081 15435 solver.cpp:347] Iteration 5000, Testing net (#0)
I1005 16:22:11.612959 15435 solver.cpp:415]     Test net output #0: error_blob = 0.119513 (* 1 = 0.119513 loss)
I1005 16:22:11.613556 15435 solver.cpp:243] Iteration 5000, loss = 0.0997094
I1005 16:22:11.613566 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0997094 (* 1 = 0.0997094 loss)
I1005 16:22:11.613570 15435 solver.cpp:590] Iteration 5000, lr = 0.01
I1005 16:22:14.041779 15435 solver.cpp:243] Iteration 5100, loss = 0.0951276
I1005 16:22:14.041811 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0951276 (* 1 = 0.0951276 loss)
I1005 16:22:14.041818 15435 solver.cpp:590] Iteration 5100, lr = 0.01
I1005 16:22:16.467072 15435 solver.cpp:243] Iteration 5200, loss = 0.0967246
I1005 16:22:16.467104 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0967246 (* 1 = 0.0967246 loss)
I1005 16:22:16.467110 15435 solver.cpp:590] Iteration 5200, lr = 0.01
I1005 16:22:18.936091 15435 solver.cpp:243] Iteration 5300, loss = 0.0986565
I1005 16:22:18.936130 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0986565 (* 1 = 0.0986565 loss)
I1005 16:22:18.936137 15435 solver.cpp:590] Iteration 5300, lr = 0.01
I1005 16:22:21.421483 15435 solver.cpp:243] Iteration 5400, loss = 0.0948448
I1005 16:22:21.421512 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0948448 (* 1 = 0.0948448 loss)
I1005 16:22:21.421517 15435 solver.cpp:590] Iteration 5400, lr = 0.01
I1005 16:22:22.214790 15435 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 16:22:23.890648 15435 solver.cpp:243] Iteration 5500, loss = 0.0973859
I1005 16:22:23.890676 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0973859 (* 1 = 0.0973859 loss)
I1005 16:22:23.890682 15435 solver.cpp:590] Iteration 5500, lr = 0.01
I1005 16:22:26.335778 15435 solver.cpp:243] Iteration 5600, loss = 0.0966916
I1005 16:22:26.335819 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0966916 (* 1 = 0.0966916 loss)
I1005 16:22:26.335824 15435 solver.cpp:590] Iteration 5600, lr = 0.01
I1005 16:22:28.763505 15435 solver.cpp:243] Iteration 5700, loss = 0.0940709
I1005 16:22:28.763545 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0940709 (* 1 = 0.0940709 loss)
I1005 16:22:28.763551 15435 solver.cpp:590] Iteration 5700, lr = 0.01
I1005 16:22:31.222065 15435 solver.cpp:243] Iteration 5800, loss = 0.097776
I1005 16:22:31.222096 15435 solver.cpp:259]     Train net output #0: error_blob = 0.097776 (* 1 = 0.097776 loss)
I1005 16:22:31.222102 15435 solver.cpp:590] Iteration 5800, lr = 0.01
I1005 16:22:33.677734 15435 solver.cpp:243] Iteration 5900, loss = 0.0956864
I1005 16:22:33.677765 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0956864 (* 1 = 0.0956864 loss)
I1005 16:22:33.677770 15435 solver.cpp:590] Iteration 5900, lr = 0.01
I1005 16:22:36.125432 15435 solver.cpp:347] Iteration 6000, Testing net (#0)
I1005 16:22:36.468715 15435 solver.cpp:415]     Test net output #0: error_blob = 0.119944 (* 1 = 0.119944 loss)
I1005 16:22:36.469333 15435 solver.cpp:243] Iteration 6000, loss = 0.0939283
I1005 16:22:36.469343 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0939283 (* 1 = 0.0939283 loss)
I1005 16:22:36.469347 15435 solver.cpp:590] Iteration 6000, lr = 0.01
I1005 16:22:38.882169 15435 solver.cpp:243] Iteration 6100, loss = 0.0989183
I1005 16:22:38.882277 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0989183 (* 1 = 0.0989183 loss)
I1005 16:22:38.882283 15435 solver.cpp:590] Iteration 6100, lr = 0.01
I1005 16:22:41.340335 15435 solver.cpp:243] Iteration 6200, loss = 0.0939282
I1005 16:22:41.340375 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0939282 (* 1 = 0.0939282 loss)
I1005 16:22:41.340381 15435 solver.cpp:590] Iteration 6200, lr = 0.01
I1005 16:22:43.799120 15435 solver.cpp:243] Iteration 6300, loss = 0.0941122
I1005 16:22:43.799161 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0941122 (* 1 = 0.0941122 loss)
I1005 16:22:43.799167 15435 solver.cpp:590] Iteration 6300, lr = 0.01
I1005 16:22:44.732960 15435 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 16:22:46.257518 15435 solver.cpp:243] Iteration 6400, loss = 0.0983045
I1005 16:22:46.257549 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0983045 (* 1 = 0.0983045 loss)
I1005 16:22:46.257553 15435 solver.cpp:590] Iteration 6400, lr = 0.01
I1005 16:22:48.697127 15435 solver.cpp:243] Iteration 6500, loss = 0.09495
I1005 16:22:48.697157 15435 solver.cpp:259]     Train net output #0: error_blob = 0.09495 (* 1 = 0.09495 loss)
I1005 16:22:48.697162 15435 solver.cpp:590] Iteration 6500, lr = 0.01
I1005 16:22:51.155175 15435 solver.cpp:243] Iteration 6600, loss = 0.0947991
I1005 16:22:51.155203 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0947991 (* 1 = 0.0947991 loss)
I1005 16:22:51.155210 15435 solver.cpp:590] Iteration 6600, lr = 0.01
I1005 16:22:53.611285 15435 solver.cpp:243] Iteration 6700, loss = 0.0993265
I1005 16:22:53.611315 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0993265 (* 1 = 0.0993265 loss)
I1005 16:22:53.611320 15435 solver.cpp:590] Iteration 6700, lr = 0.01
I1005 16:22:56.070461 15435 solver.cpp:243] Iteration 6800, loss = 0.0940689
I1005 16:22:56.070492 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0940689 (* 1 = 0.0940689 loss)
I1005 16:22:56.070497 15435 solver.cpp:590] Iteration 6800, lr = 0.01
I1005 16:22:58.544127 15435 solver.cpp:243] Iteration 6900, loss = 0.0947392
I1005 16:22:58.544158 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0947392 (* 1 = 0.0947392 loss)
I1005 16:22:58.544163 15435 solver.cpp:590] Iteration 6900, lr = 0.01
I1005 16:23:00.979816 15435 solver.cpp:347] Iteration 7000, Testing net (#0)
I1005 16:23:01.282385 15435 solver.cpp:415]     Test net output #0: error_blob = 0.119908 (* 1 = 0.119908 loss)
I1005 16:23:01.282982 15435 solver.cpp:243] Iteration 7000, loss = 0.0996864
I1005 16:23:01.283000 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0996864 (* 1 = 0.0996864 loss)
I1005 16:23:01.283009 15435 solver.cpp:590] Iteration 7000, lr = 0.01
I1005 16:23:03.735414 15435 solver.cpp:243] Iteration 7100, loss = 0.0966671
I1005 16:23:03.735442 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0966671 (* 1 = 0.0966671 loss)
I1005 16:23:03.735447 15435 solver.cpp:590] Iteration 7100, lr = 0.01
I1005 16:23:06.217177 15435 solver.cpp:243] Iteration 7200, loss = 0.0954362
I1005 16:23:06.217205 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0954362 (* 1 = 0.0954362 loss)
I1005 16:23:06.217209 15435 solver.cpp:590] Iteration 7200, lr = 0.01
I1005 16:23:07.301620 15435 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 16:23:08.683488 15435 solver.cpp:243] Iteration 7300, loss = 0.0985843
I1005 16:23:08.683519 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0985843 (* 1 = 0.0985843 loss)
I1005 16:23:08.683524 15435 solver.cpp:590] Iteration 7300, lr = 0.01
I1005 16:23:11.127719 15435 solver.cpp:243] Iteration 7400, loss = 0.0940325
I1005 16:23:11.127784 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0940325 (* 1 = 0.0940325 loss)
I1005 16:23:11.127789 15435 solver.cpp:590] Iteration 7400, lr = 0.01
I1005 16:23:13.586613 15435 solver.cpp:243] Iteration 7500, loss = 0.0969729
I1005 16:23:13.586652 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0969729 (* 1 = 0.0969729 loss)
I1005 16:23:13.586657 15435 solver.cpp:590] Iteration 7500, lr = 0.01
I1005 16:23:16.032357 15435 solver.cpp:243] Iteration 7600, loss = 0.0972134
I1005 16:23:16.032395 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0972134 (* 1 = 0.0972134 loss)
I1005 16:23:16.032400 15435 solver.cpp:590] Iteration 7600, lr = 0.01
I1005 16:23:18.510352 15435 solver.cpp:243] Iteration 7700, loss = 0.0938998
I1005 16:23:18.510391 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0938998 (* 1 = 0.0938998 loss)
I1005 16:23:18.510397 15435 solver.cpp:590] Iteration 7700, lr = 0.01
I1005 16:23:20.976966 15435 solver.cpp:243] Iteration 7800, loss = 0.0962376
I1005 16:23:20.976995 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0962376 (* 1 = 0.0962376 loss)
I1005 16:23:20.977000 15435 solver.cpp:590] Iteration 7800, lr = 0.01
I1005 16:23:23.433054 15435 solver.cpp:243] Iteration 7900, loss = 0.0986427
I1005 16:23:23.433084 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0986427 (* 1 = 0.0986427 loss)
I1005 16:23:23.433089 15435 solver.cpp:590] Iteration 7900, lr = 0.01
I1005 16:23:25.867367 15435 solver.cpp:347] Iteration 8000, Testing net (#0)
I1005 16:23:26.151341 15435 solver.cpp:415]     Test net output #0: error_blob = 0.119639 (* 1 = 0.119639 loss)
I1005 16:23:26.152014 15435 solver.cpp:243] Iteration 8000, loss = 0.0930999
I1005 16:23:26.152046 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0930999 (* 1 = 0.0930999 loss)
I1005 16:23:26.152061 15435 solver.cpp:590] Iteration 8000, lr = 0.01
I1005 16:23:28.558471 15435 solver.cpp:243] Iteration 8100, loss = 0.0958087
I1005 16:23:28.558512 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0958087 (* 1 = 0.0958087 loss)
I1005 16:23:28.558517 15435 solver.cpp:590] Iteration 8100, lr = 0.01
I1005 16:23:29.778798 15435 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 16:23:30.998780 15435 solver.cpp:243] Iteration 8200, loss = 0.098703
I1005 16:23:30.998811 15435 solver.cpp:259]     Train net output #0: error_blob = 0.098703 (* 1 = 0.098703 loss)
I1005 16:23:30.998816 15435 solver.cpp:590] Iteration 8200, lr = 0.01
I1005 16:23:33.438973 15435 solver.cpp:243] Iteration 8300, loss = 0.0929011
I1005 16:23:33.439014 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0929011 (* 1 = 0.0929011 loss)
I1005 16:23:33.439020 15435 solver.cpp:590] Iteration 8300, lr = 0.01
I1005 16:23:35.888800 15435 solver.cpp:243] Iteration 8400, loss = 0.0948013
I1005 16:23:35.888828 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0948013 (* 1 = 0.0948013 loss)
I1005 16:23:35.888833 15435 solver.cpp:590] Iteration 8400, lr = 0.01
I1005 16:23:38.309111 15435 solver.cpp:243] Iteration 8500, loss = 0.0986666
I1005 16:23:38.309154 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0986666 (* 1 = 0.0986666 loss)
I1005 16:23:38.309159 15435 solver.cpp:590] Iteration 8500, lr = 0.01
I1005 16:23:40.749459 15435 solver.cpp:243] Iteration 8600, loss = 0.0937856
I1005 16:23:40.749498 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0937856 (* 1 = 0.0937856 loss)
I1005 16:23:40.749505 15435 solver.cpp:590] Iteration 8600, lr = 0.01
I1005 16:23:43.205587 15435 solver.cpp:243] Iteration 8700, loss = 0.0948983
I1005 16:23:43.205677 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0948983 (* 1 = 0.0948983 loss)
I1005 16:23:43.205684 15435 solver.cpp:590] Iteration 8700, lr = 0.01
I1005 16:23:45.657337 15435 solver.cpp:243] Iteration 8800, loss = 0.0959955
I1005 16:23:45.657366 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0959955 (* 1 = 0.0959955 loss)
I1005 16:23:45.657371 15435 solver.cpp:590] Iteration 8800, lr = 0.01
I1005 16:23:48.121809 15435 solver.cpp:243] Iteration 8900, loss = 0.0928837
I1005 16:23:48.121837 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0928837 (* 1 = 0.0928837 loss)
I1005 16:23:48.121844 15435 solver.cpp:590] Iteration 8900, lr = 0.01
I1005 16:23:50.543408 15435 solver.cpp:347] Iteration 9000, Testing net (#0)
I1005 16:23:50.848784 15435 solver.cpp:415]     Test net output #0: error_blob = 0.119348 (* 1 = 0.119348 loss)
I1005 16:23:50.849381 15435 solver.cpp:243] Iteration 9000, loss = 0.0950814
I1005 16:23:50.849391 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0950814 (* 1 = 0.0950814 loss)
I1005 16:23:50.849395 15435 solver.cpp:590] Iteration 9000, lr = 0.01
I1005 16:23:52.172201 15435 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 16:23:53.232372 15435 solver.cpp:243] Iteration 9100, loss = 0.0953868
I1005 16:23:53.232403 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0953868 (* 1 = 0.0953868 loss)
I1005 16:23:53.232409 15435 solver.cpp:590] Iteration 9100, lr = 0.01
I1005 16:23:55.703224 15435 solver.cpp:243] Iteration 9200, loss = 0.0915741
I1005 16:23:55.703256 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0915741 (* 1 = 0.0915741 loss)
I1005 16:23:55.703261 15435 solver.cpp:590] Iteration 9200, lr = 0.01
I1005 16:23:58.166574 15435 solver.cpp:243] Iteration 9300, loss = 0.0963085
I1005 16:23:58.166613 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0963085 (* 1 = 0.0963085 loss)
I1005 16:23:58.166620 15435 solver.cpp:590] Iteration 9300, lr = 0.01
I1005 16:24:00.633883 15435 solver.cpp:243] Iteration 9400, loss = 0.0923055
I1005 16:24:00.633913 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0923055 (* 1 = 0.0923055 loss)
I1005 16:24:00.633919 15435 solver.cpp:590] Iteration 9400, lr = 0.01
I1005 16:24:03.080613 15435 solver.cpp:243] Iteration 9500, loss = 0.0926075
I1005 16:24:03.080652 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0926075 (* 1 = 0.0926075 loss)
I1005 16:24:03.080658 15435 solver.cpp:590] Iteration 9500, lr = 0.01
I1005 16:24:05.546010 15435 solver.cpp:243] Iteration 9600, loss = 0.096566
I1005 16:24:05.546041 15435 solver.cpp:259]     Train net output #0: error_blob = 0.096566 (* 1 = 0.096566 loss)
I1005 16:24:05.546047 15435 solver.cpp:590] Iteration 9600, lr = 0.01
I1005 16:24:08.035563 15435 solver.cpp:243] Iteration 9700, loss = 0.0923273
I1005 16:24:08.035594 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0923273 (* 1 = 0.0923273 loss)
I1005 16:24:08.035598 15435 solver.cpp:590] Iteration 9700, lr = 0.01
I1005 16:24:10.484354 15435 solver.cpp:243] Iteration 9800, loss = 0.0930217
I1005 16:24:10.484385 15435 solver.cpp:259]     Train net output #0: error_blob = 0.0930217 (* 1 = 0.0930217 loss)
I1005 16:24:10.484390 15435 solver.cpp:590] Iteration 9800, lr = 0.01
I1005 16:24:12.920218 15435 solver.cpp:243] Iteration 9900, loss = 0.098405
I1005 16:24:12.920248 15435 solver.cpp:259]     Train net output #0: error_blob = 0.098405 (* 1 = 0.098405 loss)
I1005 16:24:12.920253 15435 solver.cpp:590] Iteration 9900, lr = 0.01
I1005 16:24:15.339959 15435 solver.cpp:468] Snapshotting to binary proto file _iter_10000.caffemodel
I1005 16:24:15.341361 15435 solver.cpp:753] Snapshotting solver state to binary proto file _iter_10000.solverstate
I1005 16:24:15.364266 15435 solver.cpp:327] Iteration 10000, loss = 0.0920091
I1005 16:24:15.364302 15435 solver.cpp:347] Iteration 10000, Testing net (#0)
I1005 16:24:15.533505 15435 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 16:24:15.639204 15435 solver.cpp:415]     Test net output #0: error_blob = 0.119081 (* 1 = 0.119081 loss)
I1005 16:24:15.639225 15435 solver.cpp:332] Optimization Done.
I1005 16:24:15.639228 15435 caffe.cpp:215] Optimization Done.
I1005 16:24:15.703645 15445 caffe.cpp:184] Using GPUs 0
I1005 16:24:16.262843 15445 solver.cpp:54] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "fixed"
momentum: 0.9
solver_mode: GPU
device_id: 0
net: "basic/model0_part4.prototxt"
I1005 16:24:16.262873 15445 solver.cpp:97] Creating training net from net file: basic/model0_part4.prototxt
I1005 16:24:16.263020 15445 net.cpp:339] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_layer
I1005 16:24:16.263056 15445 net.cpp:50] Initializing net from parameters: 
name: "basic/model0_part4.prototxt"
state {
  phase: TRAIN
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TRAIN
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.part4.train"
    batch_size: 20000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1005 16:24:16.263094 15445 layer_factory.hpp:76] Creating layer data_layer
I1005 16:24:16.276412 15445 net.cpp:110] Creating Layer data_layer
I1005 16:24:16.276440 15445 net.cpp:433] data_layer -> data_blob
I1005 16:24:16.276463 15445 net.cpp:433] data_layer -> label_blob
I1005 16:24:16.277035 15449 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.part4.train
I1005 16:24:16.960165 15445 data_layer.cpp:45] output data size: 20000,61,1,1
I1005 16:24:16.965103 15445 net.cpp:155] Setting up data_layer
I1005 16:24:16.965144 15445 net.cpp:163] Top shape: 20000 61 1 1 (1220000)
I1005 16:24:16.965147 15445 net.cpp:163] Top shape: 20000 (20000)
I1005 16:24:16.965153 15445 layer_factory.hpp:76] Creating layer hidden_sum_layer
I1005 16:24:16.965165 15445 net.cpp:110] Creating Layer hidden_sum_layer
I1005 16:24:16.965173 15445 net.cpp:477] hidden_sum_layer <- data_blob
I1005 16:24:16.965181 15445 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I1005 16:24:16.965525 15445 net.cpp:155] Setting up hidden_sum_layer
I1005 16:24:16.965533 15445 net.cpp:163] Top shape: 20000 10 (200000)
I1005 16:24:16.965554 15445 layer_factory.hpp:76] Creating layer hidden_act_layer
I1005 16:24:16.965561 15445 net.cpp:110] Creating Layer hidden_act_layer
I1005 16:24:16.965565 15445 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I1005 16:24:16.965569 15445 net.cpp:433] hidden_act_layer -> hidden_act_blob
I1005 16:24:20.170267 15445 net.cpp:155] Setting up hidden_act_layer
I1005 16:24:20.170299 15445 net.cpp:163] Top shape: 20000 10 (200000)
I1005 16:24:20.170305 15445 layer_factory.hpp:76] Creating layer output_sum_layer
I1005 16:24:20.170313 15445 net.cpp:110] Creating Layer output_sum_layer
I1005 16:24:20.170316 15445 net.cpp:477] output_sum_layer <- hidden_act_blob
I1005 16:24:20.170321 15445 net.cpp:433] output_sum_layer -> output_sum_blob
I1005 16:24:20.170410 15445 net.cpp:155] Setting up output_sum_layer
I1005 16:24:20.170415 15445 net.cpp:163] Top shape: 20000 1 (20000)
I1005 16:24:20.170433 15445 layer_factory.hpp:76] Creating layer output_act_layer
I1005 16:24:20.170438 15445 net.cpp:110] Creating Layer output_act_layer
I1005 16:24:20.170439 15445 net.cpp:477] output_act_layer <- output_sum_blob
I1005 16:24:20.170442 15445 net.cpp:433] output_act_layer -> output_act_blob
I1005 16:24:20.170514 15445 net.cpp:155] Setting up output_act_layer
I1005 16:24:20.170519 15445 net.cpp:163] Top shape: 20000 1 (20000)
I1005 16:24:20.170536 15445 layer_factory.hpp:76] Creating layer error_layer
I1005 16:24:20.170542 15445 net.cpp:110] Creating Layer error_layer
I1005 16:24:20.170544 15445 net.cpp:477] error_layer <- output_act_blob
I1005 16:24:20.170547 15445 net.cpp:477] error_layer <- label_blob
I1005 16:24:20.170550 15445 net.cpp:433] error_layer -> error_blob
I1005 16:24:20.170575 15445 net.cpp:155] Setting up error_layer
I1005 16:24:20.170579 15445 net.cpp:163] Top shape: (1)
I1005 16:24:20.170581 15445 net.cpp:168]     with loss weight 1
I1005 16:24:20.170596 15445 net.cpp:236] error_layer needs backward computation.
I1005 16:24:20.170599 15445 net.cpp:236] output_act_layer needs backward computation.
I1005 16:24:20.170601 15445 net.cpp:236] output_sum_layer needs backward computation.
I1005 16:24:20.170603 15445 net.cpp:236] hidden_act_layer needs backward computation.
I1005 16:24:20.170605 15445 net.cpp:236] hidden_sum_layer needs backward computation.
I1005 16:24:20.170608 15445 net.cpp:240] data_layer does not need backward computation.
I1005 16:24:20.170609 15445 net.cpp:283] This network produces output error_blob
I1005 16:24:20.170614 15445 net.cpp:297] Network initialization done.
I1005 16:24:20.170616 15445 net.cpp:298] Memory required for data: 6720004
I1005 16:24:20.170744 15445 solver.cpp:187] Creating test net (#0) specified by net file: basic/model0_part4.prototxt
I1005 16:24:20.170759 15445 net.cpp:339] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_layer
I1005 16:24:20.170792 15445 net.cpp:50] Initializing net from parameters: 
name: "basic/model0_part4.prototxt"
state {
  phase: TEST
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TEST
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.part4.test"
    batch_size: 2000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1005 16:24:20.170814 15445 layer_factory.hpp:76] Creating layer data_layer
I1005 16:24:20.172067 15445 net.cpp:110] Creating Layer data_layer
I1005 16:24:20.172083 15445 net.cpp:433] data_layer -> data_blob
I1005 16:24:20.172088 15445 net.cpp:433] data_layer -> label_blob
I1005 16:24:20.172649 15451 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.part4.test
I1005 16:24:20.172716 15445 data_layer.cpp:45] output data size: 2000,61,1,1
I1005 16:24:20.174177 15445 net.cpp:155] Setting up data_layer
I1005 16:24:20.174192 15445 net.cpp:163] Top shape: 2000 61 1 1 (122000)
I1005 16:24:20.174196 15445 net.cpp:163] Top shape: 2000 (2000)
I1005 16:24:20.174199 15445 layer_factory.hpp:76] Creating layer hidden_sum_layer
I1005 16:24:20.174207 15445 net.cpp:110] Creating Layer hidden_sum_layer
I1005 16:24:20.174209 15445 net.cpp:477] hidden_sum_layer <- data_blob
I1005 16:24:20.174213 15445 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I1005 16:24:20.174338 15445 net.cpp:155] Setting up hidden_sum_layer
I1005 16:24:20.174343 15445 net.cpp:163] Top shape: 2000 10 (20000)
I1005 16:24:20.174350 15445 layer_factory.hpp:76] Creating layer hidden_act_layer
I1005 16:24:20.174355 15445 net.cpp:110] Creating Layer hidden_act_layer
I1005 16:24:20.174357 15445 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I1005 16:24:20.174373 15445 net.cpp:433] hidden_act_layer -> hidden_act_blob
I1005 16:24:20.174547 15445 net.cpp:155] Setting up hidden_act_layer
I1005 16:24:20.174554 15445 net.cpp:163] Top shape: 2000 10 (20000)
I1005 16:24:20.174558 15445 layer_factory.hpp:76] Creating layer output_sum_layer
I1005 16:24:20.174562 15445 net.cpp:110] Creating Layer output_sum_layer
I1005 16:24:20.174564 15445 net.cpp:477] output_sum_layer <- hidden_act_blob
I1005 16:24:20.174568 15445 net.cpp:433] output_sum_layer -> output_sum_blob
I1005 16:24:20.174626 15445 net.cpp:155] Setting up output_sum_layer
I1005 16:24:20.174631 15445 net.cpp:163] Top shape: 2000 1 (2000)
I1005 16:24:20.174636 15445 layer_factory.hpp:76] Creating layer output_act_layer
I1005 16:24:20.174640 15445 net.cpp:110] Creating Layer output_act_layer
I1005 16:24:20.174643 15445 net.cpp:477] output_act_layer <- output_sum_blob
I1005 16:24:20.174645 15445 net.cpp:433] output_act_layer -> output_act_blob
I1005 16:24:20.174693 15445 net.cpp:155] Setting up output_act_layer
I1005 16:24:20.174697 15445 net.cpp:163] Top shape: 2000 1 (2000)
I1005 16:24:20.174700 15445 layer_factory.hpp:76] Creating layer error_layer
I1005 16:24:20.174703 15445 net.cpp:110] Creating Layer error_layer
I1005 16:24:20.174705 15445 net.cpp:477] error_layer <- output_act_blob
I1005 16:24:20.174707 15445 net.cpp:477] error_layer <- label_blob
I1005 16:24:20.174710 15445 net.cpp:433] error_layer -> error_blob
I1005 16:24:20.174729 15445 net.cpp:155] Setting up error_layer
I1005 16:24:20.174732 15445 net.cpp:163] Top shape: (1)
I1005 16:24:20.174734 15445 net.cpp:168]     with loss weight 1
I1005 16:24:20.174742 15445 net.cpp:236] error_layer needs backward computation.
I1005 16:24:20.174744 15445 net.cpp:236] output_act_layer needs backward computation.
I1005 16:24:20.174746 15445 net.cpp:236] output_sum_layer needs backward computation.
I1005 16:24:20.174748 15445 net.cpp:236] hidden_act_layer needs backward computation.
I1005 16:24:20.174751 15445 net.cpp:236] hidden_sum_layer needs backward computation.
I1005 16:24:20.174752 15445 net.cpp:240] data_layer does not need backward computation.
I1005 16:24:20.174754 15445 net.cpp:283] This network produces output error_blob
I1005 16:24:20.174758 15445 net.cpp:297] Network initialization done.
I1005 16:24:20.174760 15445 net.cpp:298] Memory required for data: 672004
I1005 16:24:20.174780 15445 solver.cpp:66] Solver scaffolding done.
I1005 16:24:20.174872 15445 caffe.cpp:212] Starting Optimization
I1005 16:24:20.174878 15445 solver.cpp:294] Solving basic/model0_part4.prototxt
I1005 16:24:20.174880 15445 solver.cpp:295] Learning Rate Policy: fixed
I1005 16:24:20.175019 15445 solver.cpp:347] Iteration 0, Testing net (#0)
I1005 16:24:20.175074 15445 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 16:24:20.449282 15445 solver.cpp:415]     Test net output #0: error_blob = 0.128193 (* 1 = 0.128193 loss)
I1005 16:24:20.450762 15445 solver.cpp:243] Iteration 0, loss = 0.127259
I1005 16:24:20.450811 15445 solver.cpp:259]     Train net output #0: error_blob = 0.127259 (* 1 = 0.127259 loss)
I1005 16:24:20.450836 15445 solver.cpp:590] Iteration 0, lr = 0.01
I1005 16:24:22.872745 15445 solver.cpp:243] Iteration 100, loss = 0.116456
I1005 16:24:22.872786 15445 solver.cpp:259]     Train net output #0: error_blob = 0.116456 (* 1 = 0.116456 loss)
I1005 16:24:22.872792 15445 solver.cpp:590] Iteration 100, lr = 0.01
I1005 16:24:25.376751 15445 solver.cpp:243] Iteration 200, loss = 0.110076
I1005 16:24:25.376781 15445 solver.cpp:259]     Train net output #0: error_blob = 0.110076 (* 1 = 0.110076 loss)
I1005 16:24:25.376786 15445 solver.cpp:590] Iteration 200, lr = 0.01
I1005 16:24:27.857663 15445 solver.cpp:243] Iteration 300, loss = 0.110906
I1005 16:24:27.857694 15445 solver.cpp:259]     Train net output #0: error_blob = 0.110906 (* 1 = 0.110906 loss)
I1005 16:24:27.857699 15445 solver.cpp:590] Iteration 300, lr = 0.01
I1005 16:24:30.377872 15445 solver.cpp:243] Iteration 400, loss = 0.10911
I1005 16:24:30.377903 15445 solver.cpp:259]     Train net output #0: error_blob = 0.10911 (* 1 = 0.10911 loss)
I1005 16:24:30.377930 15445 solver.cpp:590] Iteration 400, lr = 0.01
I1005 16:24:32.922860 15445 solver.cpp:243] Iteration 500, loss = 0.107968
I1005 16:24:32.922901 15445 solver.cpp:259]     Train net output #0: error_blob = 0.107968 (* 1 = 0.107968 loss)
I1005 16:24:32.922906 15445 solver.cpp:590] Iteration 500, lr = 0.01
I1005 16:24:35.465484 15445 solver.cpp:243] Iteration 600, loss = 0.105606
I1005 16:24:35.465523 15445 solver.cpp:259]     Train net output #0: error_blob = 0.105606 (* 1 = 0.105606 loss)
I1005 16:24:35.465531 15445 solver.cpp:590] Iteration 600, lr = 0.01
I1005 16:24:37.973297 15445 solver.cpp:243] Iteration 700, loss = 0.106059
I1005 16:24:37.973345 15445 solver.cpp:259]     Train net output #0: error_blob = 0.106059 (* 1 = 0.106059 loss)
I1005 16:24:37.973352 15445 solver.cpp:590] Iteration 700, lr = 0.01
I1005 16:24:40.457857 15445 solver.cpp:243] Iteration 800, loss = 0.107439
I1005 16:24:40.457890 15445 solver.cpp:259]     Train net output #0: error_blob = 0.107439 (* 1 = 0.107439 loss)
I1005 16:24:40.457895 15445 solver.cpp:590] Iteration 800, lr = 0.01
I1005 16:24:42.984256 15445 solver.cpp:243] Iteration 900, loss = 0.107149
I1005 16:24:42.984302 15445 solver.cpp:259]     Train net output #0: error_blob = 0.107149 (* 1 = 0.107149 loss)
I1005 16:24:42.984309 15445 solver.cpp:590] Iteration 900, lr = 0.01
I1005 16:24:43.034204 15445 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 16:24:45.465874 15445 solver.cpp:347] Iteration 1000, Testing net (#0)
I1005 16:24:45.738171 15445 solver.cpp:415]     Test net output #0: error_blob = 0.102196 (* 1 = 0.102196 loss)
I1005 16:24:45.738951 15445 solver.cpp:243] Iteration 1000, loss = 0.105862
I1005 16:24:45.738970 15445 solver.cpp:259]     Train net output #0: error_blob = 0.105862 (* 1 = 0.105862 loss)
I1005 16:24:45.738998 15445 solver.cpp:590] Iteration 1000, lr = 0.01
I1005 16:24:48.224691 15445 solver.cpp:243] Iteration 1100, loss = 0.102141
I1005 16:24:48.224737 15445 solver.cpp:259]     Train net output #0: error_blob = 0.102141 (* 1 = 0.102141 loss)
I1005 16:24:48.224745 15445 solver.cpp:590] Iteration 1100, lr = 0.01
I1005 16:24:50.742890 15445 solver.cpp:243] Iteration 1200, loss = 0.104989
I1005 16:24:50.742931 15445 solver.cpp:259]     Train net output #0: error_blob = 0.104989 (* 1 = 0.104989 loss)
I1005 16:24:50.742940 15445 solver.cpp:590] Iteration 1200, lr = 0.01
I1005 16:24:53.255437 15445 solver.cpp:243] Iteration 1300, loss = 0.104488
I1005 16:24:53.255477 15445 solver.cpp:259]     Train net output #0: error_blob = 0.104488 (* 1 = 0.104488 loss)
I1005 16:24:53.255486 15445 solver.cpp:590] Iteration 1300, lr = 0.01
I1005 16:24:55.733633 15445 solver.cpp:243] Iteration 1400, loss = 0.104668
I1005 16:24:55.733675 15445 solver.cpp:259]     Train net output #0: error_blob = 0.104668 (* 1 = 0.104668 loss)
I1005 16:24:55.733680 15445 solver.cpp:590] Iteration 1400, lr = 0.01
I1005 16:24:58.229342 15445 solver.cpp:243] Iteration 1500, loss = 0.101808
I1005 16:24:58.229385 15445 solver.cpp:259]     Train net output #0: error_blob = 0.101808 (* 1 = 0.101808 loss)
I1005 16:24:58.229390 15445 solver.cpp:590] Iteration 1500, lr = 0.01
I1005 16:25:00.694787 15445 solver.cpp:243] Iteration 1600, loss = 0.102704
I1005 16:25:00.694835 15445 solver.cpp:259]     Train net output #0: error_blob = 0.102704 (* 1 = 0.102704 loss)
I1005 16:25:00.694844 15445 solver.cpp:590] Iteration 1600, lr = 0.01
I1005 16:25:03.238968 15445 solver.cpp:243] Iteration 1700, loss = 0.1054
I1005 16:25:03.239001 15445 solver.cpp:259]     Train net output #0: error_blob = 0.1054 (* 1 = 0.1054 loss)
I1005 16:25:03.239007 15445 solver.cpp:590] Iteration 1700, lr = 0.01
I1005 16:25:05.749841 15445 solver.cpp:243] Iteration 1800, loss = 0.10473
I1005 16:25:05.749872 15445 solver.cpp:259]     Train net output #0: error_blob = 0.10473 (* 1 = 0.10473 loss)
I1005 16:25:05.749876 15445 solver.cpp:590] Iteration 1800, lr = 0.01
I1005 16:25:05.954113 15445 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 16:25:08.290287 15445 solver.cpp:243] Iteration 1900, loss = 0.103655
I1005 16:25:08.290330 15445 solver.cpp:259]     Train net output #0: error_blob = 0.103655 (* 1 = 0.103655 loss)
I1005 16:25:08.290335 15445 solver.cpp:590] Iteration 1900, lr = 0.01
I1005 16:25:10.776495 15445 solver.cpp:347] Iteration 2000, Testing net (#0)
I1005 16:25:11.117261 15445 solver.cpp:415]     Test net output #0: error_blob = 0.10062 (* 1 = 0.10062 loss)
I1005 16:25:11.117871 15445 solver.cpp:243] Iteration 2000, loss = 0.0998654
I1005 16:25:11.117887 15445 solver.cpp:259]     Train net output #0: error_blob = 0.0998654 (* 1 = 0.0998654 loss)
I1005 16:25:11.117894 15445 solver.cpp:590] Iteration 2000, lr = 0.01
I1005 16:25:13.572454 15445 solver.cpp:243] Iteration 2100, loss = 0.102941
I1005 16:25:13.572517 15445 solver.cpp:259]     Train net output #0: error_blob = 0.102941 (* 1 = 0.102941 loss)
I1005 16:25:13.572526 15445 solver.cpp:590] Iteration 2100, lr = 0.01
I1005 16:25:16.079457 15445 solver.cpp:243] Iteration 2200, loss = 0.10264
I1005 16:25:16.079582 15445 solver.cpp:259]     Train net output #0: error_blob = 0.10264 (* 1 = 0.10264 loss)
I1005 16:25:16.079591 15445 solver.cpp:590] Iteration 2200, lr = 0.01
I1005 16:25:18.621107 15445 solver.cpp:243] Iteration 2300, loss = 0.104017
I1005 16:25:18.621152 15445 solver.cpp:259]     Train net output #0: error_blob = 0.104017 (* 1 = 0.104017 loss)
I1005 16:25:18.621160 15445 solver.cpp:590] Iteration 2300, lr = 0.01
I1005 16:25:21.104089 15445 solver.cpp:243] Iteration 2400, loss = 0.100392
I1005 16:25:21.104120 15445 solver.cpp:259]     Train net output #0: error_blob = 0.100392 (* 1 = 0.100392 loss)
I1005 16:25:21.104126 15445 solver.cpp:590] Iteration 2400, lr = 0.01
I1005 16:25:23.619401 15445 solver.cpp:243] Iteration 2500, loss = 0.100677
I1005 16:25:23.619432 15445 solver.cpp:259]     Train net output #0: error_blob = 0.100677 (* 1 = 0.100677 loss)
I1005 16:25:23.619438 15445 solver.cpp:590] Iteration 2500, lr = 0.01
I1005 16:25:26.124383 15445 solver.cpp:243] Iteration 2600, loss = 0.104077
I1005 16:25:26.124420 15445 solver.cpp:259]     Train net output #0: error_blob = 0.104077 (* 1 = 0.104077 loss)
I1005 16:25:26.124429 15445 solver.cpp:590] Iteration 2600, lr = 0.01
I1005 16:25:28.648959 15445 solver.cpp:243] Iteration 2700, loss = 0.103438
I1005 16:25:28.648996 15445 solver.cpp:259]     Train net output #0: error_blob = 0.103438 (* 1 = 0.103438 loss)
I1005 16:25:28.649004 15445 solver.cpp:590] Iteration 2700, lr = 0.01
I1005 16:25:29.008038 15445 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 16:25:31.170758 15445 solver.cpp:243] Iteration 2800, loss = 0.102995
I1005 16:25:31.170807 15445 solver.cpp:259]     Train net output #0: error_blob = 0.102995 (* 1 = 0.102995 loss)
I1005 16:25:31.170815 15445 solver.cpp:590] Iteration 2800, lr = 0.01
I1005 16:25:33.637984 15445 solver.cpp:243] Iteration 2900, loss = 0.0986974
I1005 16:25:33.638025 15445 solver.cpp:259]     Train net output #0: error_blob = 0.0986974 (* 1 = 0.0986974 loss)
I1005 16:25:33.638030 15445 solver.cpp:590] Iteration 2900, lr = 0.01
I1005 16:25:36.095304 15445 solver.cpp:347] Iteration 3000, Testing net (#0)
I1005 16:25:36.379961 15445 solver.cpp:415]     Test net output #0: error_blob = 0.0999531 (* 1 = 0.0999531 loss)
I1005 16:25:36.380619 15445 solver.cpp:243] Iteration 3000, loss = 0.101138
I1005 16:25:36.380637 15445 solver.cpp:259]     Train net output #0: error_blob = 0.101138 (* 1 = 0.101138 loss)
I1005 16:25:36.380645 15445 solver.cpp:590] Iteration 3000, lr = 0.01
I1005 16:25:38.812690 15445 solver.cpp:243] Iteration 3100, loss = 0.101673
I1005 16:25:38.812717 15445 solver.cpp:259]     Train net output #0: error_blob = 0.101673 (* 1 = 0.101673 loss)
I1005 16:25:38.812723 15445 solver.cpp:590] Iteration 3100, lr = 0.01
I1005 16:25:41.306999 15445 solver.cpp:243] Iteration 3200, loss = 0.103028
I1005 16:25:41.307037 15445 solver.cpp:259]     Train net output #0: error_blob = 0.103028 (* 1 = 0.103028 loss)
I1005 16:25:41.307044 15445 solver.cpp:590] Iteration 3200, lr = 0.01
I1005 16:25:43.792278 15445 solver.cpp:243] Iteration 3300, loss = 0.0998459
I1005 16:25:43.792315 15445 solver.cpp:259]     Train net output #0: error_blob = 0.0998459 (* 1 = 0.0998459 loss)
I1005 16:25:43.792322 15445 solver.cpp:590] Iteration 3300, lr = 0.01
I1005 16:25:46.266355 15445 solver.cpp:243] Iteration 3400, loss = 0.0996238
I1005 16:25:46.266458 15445 solver.cpp:259]     Train net output #0: error_blob = 0.0996238 (* 1 = 0.0996238 loss)
I1005 16:25:46.266464 15445 solver.cpp:590] Iteration 3400, lr = 0.01
I1005 16:25:48.799146 15445 solver.cpp:243] Iteration 3500, loss = 0.102772
I1005 16:25:48.799196 15445 solver.cpp:259]     Train net output #0: error_blob = 0.102772 (* 1 = 0.102772 loss)
I1005 16:25:48.799204 15445 solver.cpp:590] Iteration 3500, lr = 0.01
I1005 16:25:51.331163 15445 solver.cpp:243] Iteration 3600, loss = 0.102395
I1005 16:25:51.331202 15445 solver.cpp:259]     Train net output #0: error_blob = 0.102395 (* 1 = 0.102395 loss)
I1005 16:25:51.331207 15445 solver.cpp:590] Iteration 3600, lr = 0.01
I1005 16:25:51.828479 15445 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 16:25:53.816287 15445 solver.cpp:243] Iteration 3700, loss = 0.102237
I1005 16:25:53.816329 15445 solver.cpp:259]     Train net output #0: error_blob = 0.102237 (* 1 = 0.102237 loss)
I1005 16:25:53.816335 15445 solver.cpp:590] Iteration 3700, lr = 0.01
I1005 16:25:56.281246 15445 solver.cpp:243] Iteration 3800, loss = 0.0980987
I1005 16:25:56.281275 15445 solver.cpp:259]     Train net output #0: error_blob = 0.0980987 (* 1 = 0.0980987 loss)
I1005 16:25:56.281280 15445 solver.cpp:590] Iteration 3800, lr = 0.01
I1005 16:25:58.787888 15445 solver.cpp:243] Iteration 3900, loss = 0.0998266
I1005 16:25:58.787919 15445 solver.cpp:259]     Train net output #0: error_blob = 0.0998266 (* 1 = 0.0998266 loss)
I1005 16:25:58.787924 15445 solver.cpp:590] Iteration 3900, lr = 0.01
I1005 16:26:01.238379 15445 solver.cpp:347] Iteration 4000, Testing net (#0)
I1005 16:26:01.522835 15445 solver.cpp:415]     Test net output #0: error_blob = 0.0992821 (* 1 = 0.0992821 loss)
I1005 16:26:01.523535 15445 solver.cpp:243] Iteration 4000, loss = 0.10094
I1005 16:26:01.523553 15445 solver.cpp:259]     Train net output #0: error_blob = 0.10094 (* 1 = 0.10094 loss)
I1005 16:26:01.523561 15445 solver.cpp:590] Iteration 4000, lr = 0.01
I1005 16:26:03.963393 15445 solver.cpp:243] Iteration 4100, loss = 0.102138
I1005 16:26:03.963434 15445 solver.cpp:259]     Train net output #0: error_blob = 0.102138 (* 1 = 0.102138 loss)
I1005 16:26:03.963439 15445 solver.cpp:590] Iteration 4100, lr = 0.01
I1005 16:26:06.439553 15445 solver.cpp:243] Iteration 4200, loss = 0.0992003
I1005 16:26:06.439584 15445 solver.cpp:259]     Train net output #0: error_blob = 0.0992003 (* 1 = 0.0992003 loss)
I1005 16:26:06.439590 15445 solver.cpp:590] Iteration 4200, lr = 0.01
I1005 16:26:08.932214 15445 solver.cpp:243] Iteration 4300, loss = 0.0983842
I1005 16:26:08.932245 15445 solver.cpp:259]     Train net output #0: error_blob = 0.0983842 (* 1 = 0.0983842 loss)
I1005 16:26:08.932250 15445 solver.cpp:590] Iteration 4300, lr = 0.01
I1005 16:26:11.398116 15445 solver.cpp:243] Iteration 4400, loss = 0.101562
I1005 16:26:11.398146 15445 solver.cpp:259]     Train net output #0: error_blob = 0.101562 (* 1 = 0.101562 loss)
I1005 16:26:11.398152 15445 solver.cpp:590] Iteration 4400, lr = 0.01
I1005 16:26:13.848083 15445 solver.cpp:243] Iteration 4500, loss = 0.101888
I1005 16:26:13.848122 15445 solver.cpp:259]     Train net output #0: error_blob = 0.101888 (* 1 = 0.101888 loss)
I1005 16:26:13.848129 15445 solver.cpp:590] Iteration 4500, lr = 0.01
I1005 16:26:14.472864 15445 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 16:26:16.257943 15445 solver.cpp:243] Iteration 4600, loss = 0.10151
I1005 16:26:16.257973 15445 solver.cpp:259]     Train net output #0: error_blob = 0.10151 (* 1 = 0.10151 loss)
I1005 16:26:16.257977 15445 solver.cpp:590] Iteration 4600, lr = 0.01
I1005 16:26:18.739852 15445 solver.cpp:243] Iteration 4700, loss = 0.0976228
I1005 16:26:18.740859 15445 solver.cpp:259]     Train net output #0: error_blob = 0.0976228 (* 1 = 0.0976228 loss)
I1005 16:26:18.740869 15445 solver.cpp:590] Iteration 4700, lr = 0.01
I1005 16:26:21.233249 15445 solver.cpp:243] Iteration 4800, loss = 0.0989475
I1005 16:26:21.233283 15445 solver.cpp:259]     Train net output #0: error_blob = 0.0989475 (* 1 = 0.0989475 loss)
I1005 16:26:21.233290 15445 solver.cpp:590] Iteration 4800, lr = 0.01
I1005 16:26:23.708865 15445 solver.cpp:243] Iteration 4900, loss = 0.100166
I1005 16:26:23.708895 15445 solver.cpp:259]     Train net output #0: error_blob = 0.100166 (* 1 = 0.100166 loss)
I1005 16:26:23.708899 15445 solver.cpp:590] Iteration 4900, lr = 0.01
I1005 16:26:26.149225 15445 solver.cpp:347] Iteration 5000, Testing net (#0)
I1005 16:26:26.529052 15445 solver.cpp:415]     Test net output #0: error_blob = 0.0985795 (* 1 = 0.0985795 loss)
I1005 16:26:26.529661 15445 solver.cpp:243] Iteration 5000, loss = 0.101893
I1005 16:26:26.529675 15445 solver.cpp:259]     Train net output #0: error_blob = 0.101893 (* 1 = 0.101893 loss)
I1005 16:26:26.529680 15445 solver.cpp:590] Iteration 5000, lr = 0.01
I1005 16:26:28.988376 15445 solver.cpp:243] Iteration 5100, loss = 0.0985509
I1005 16:26:28.988407 15445 solver.cpp:259]     Train net output #0: error_blob = 0.0985509 (* 1 = 0.0985509 loss)
I1005 16:26:28.988414 15445 solver.cpp:590] Iteration 5100, lr = 0.01
I1005 16:26:31.446226 15445 solver.cpp:243] Iteration 5200, loss = 0.096564
I1005 16:26:31.446256 15445 solver.cpp:259]     Train net output #0: error_blob = 0.096564 (* 1 = 0.096564 loss)
I1005 16:26:31.446261 15445 solver.cpp:590] Iteration 5200, lr = 0.01
I1005 16:26:33.967118 15445 solver.cpp:243] Iteration 5300, loss = 0.100401
I1005 16:26:33.967149 15445 solver.cpp:259]     Train net output #0: error_blob = 0.100401 (* 1 = 0.100401 loss)
I1005 16:26:33.967156 15445 solver.cpp:590] Iteration 5300, lr = 0.01
I1005 16:26:36.468155 15445 solver.cpp:243] Iteration 5400, loss = 0.10133
I1005 16:26:36.468189 15445 solver.cpp:259]     Train net output #0: error_blob = 0.10133 (* 1 = 0.10133 loss)
I1005 16:26:36.468196 15445 solver.cpp:590] Iteration 5400, lr = 0.01
I1005 16:26:37.278671 15445 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 16:26:38.958868 15445 solver.cpp:243] Iteration 5500, loss = 0.100894
I1005 16:26:38.958899 15445 solver.cpp:259]     Train net output #0: error_blob = 0.100894 (* 1 = 0.100894 loss)
I1005 16:26:38.958904 15445 solver.cpp:590] Iteration 5500, lr = 0.01
I1005 16:26:41.429532 15445 solver.cpp:243] Iteration 5600, loss = 0.0971593
I1005 16:26:41.429572 15445 solver.cpp:259]     Train net output #0: error_blob = 0.0971593 (* 1 = 0.0971593 loss)
I1005 16:26:41.429577 15445 solver.cpp:590] Iteration 5600, lr = 0.01
I1005 16:26:43.933214 15445 solver.cpp:243] Iteration 5700, loss = 0.098241
I1005 16:26:43.933245 15445 solver.cpp:259]     Train net output #0: error_blob = 0.098241 (* 1 = 0.098241 loss)
I1005 16:26:43.933250 15445 solver.cpp:590] Iteration 5700, lr = 0.01
I1005 16:26:46.420116 15445 solver.cpp:243] Iteration 5800, loss = 0.0996732
I1005 16:26:46.420146 15445 solver.cpp:259]     Train net output #0: error_blob = 0.0996732 (* 1 = 0.0996732 loss)
I1005 16:26:46.420151 15445 solver.cpp:590] Iteration 5800, lr = 0.01
I1005 16:26:48.886937 15445 solver.cpp:243] Iteration 5900, loss = 0.101477
I1005 16:26:48.887025 15445 solver.cpp:259]     Train net output #0: error_blob = 0.101477 (* 1 = 0.101477 loss)
I1005 16:26:48.887032 15445 solver.cpp:590] Iteration 5900, lr = 0.01
I1005 16:26:51.340914 15445 solver.cpp:347] Iteration 6000, Testing net (#0)
I1005 16:26:51.629345 15445 solver.cpp:415]     Test net output #0: error_blob = 0.0979003 (* 1 = 0.0979003 loss)
I1005 16:26:51.629966 15445 solver.cpp:243] Iteration 6000, loss = 0.0978576
I1005 16:26:51.629978 15445 solver.cpp:259]     Train net output #0: error_blob = 0.0978576 (* 1 = 0.0978576 loss)
I1005 16:26:51.629987 15445 solver.cpp:590] Iteration 6000, lr = 0.01
I1005 16:26:54.121968 15445 solver.cpp:243] Iteration 6100, loss = 0.0957041
I1005 16:26:54.122006 15445 solver.cpp:259]     Train net output #0: error_blob = 0.0957041 (* 1 = 0.0957041 loss)
I1005 16:26:54.122014 15445 solver.cpp:590] Iteration 6100, lr = 0.01
I1005 16:26:56.595851 15445 solver.cpp:243] Iteration 6200, loss = 0.0993665
I1005 16:26:56.595886 15445 solver.cpp:259]     Train net output #0: error_blob = 0.0993665 (* 1 = 0.0993665 loss)
I1005 16:26:56.595893 15445 solver.cpp:590] Iteration 6200, lr = 0.01
I1005 16:26:59.126157 15445 solver.cpp:243] Iteration 6300, loss = 0.100749
I1005 16:26:59.126204 15445 solver.cpp:259]     Train net output #0: error_blob = 0.100749 (* 1 = 0.100749 loss)
I1005 16:26:59.126211 15445 solver.cpp:590] Iteration 6300, lr = 0.01
I1005 16:27:00.094483 15445 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 16:27:01.664914 15445 solver.cpp:243] Iteration 6400, loss = 0.100185
I1005 16:27:01.664960 15445 solver.cpp:259]     Train net output #0: error_blob = 0.100185 (* 1 = 0.100185 loss)
I1005 16:27:01.664968 15445 solver.cpp:590] Iteration 6400, lr = 0.01
I1005 16:27:04.184170 15445 solver.cpp:243] Iteration 6500, loss = 0.0968943
I1005 16:27:04.184208 15445 solver.cpp:259]     Train net output #0: error_blob = 0.0968943 (* 1 = 0.0968943 loss)
I1005 16:27:04.184216 15445 solver.cpp:590] Iteration 6500, lr = 0.01
I1005 16:27:06.716049 15445 solver.cpp:243] Iteration 6600, loss = 0.0976222
I1005 16:27:06.716094 15445 solver.cpp:259]     Train net output #0: error_blob = 0.0976222 (* 1 = 0.0976222 loss)
I1005 16:27:06.716101 15445 solver.cpp:590] Iteration 6600, lr = 0.01
I1005 16:27:09.238544 15445 solver.cpp:243] Iteration 6700, loss = 0.0991677
I1005 16:27:09.238574 15445 solver.cpp:259]     Train net output #0: error_blob = 0.0991677 (* 1 = 0.0991677 loss)
I1005 16:27:09.238579 15445 solver.cpp:590] Iteration 6700, lr = 0.01
I1005 16:27:11.749327 15445 solver.cpp:243] Iteration 6800, loss = 0.100963
I1005 16:27:11.749359 15445 solver.cpp:259]     Train net output #0: error_blob = 0.100963 (* 1 = 0.100963 loss)
I1005 16:27:11.749364 15445 solver.cpp:590] Iteration 6800, lr = 0.01
I1005 16:27:14.275198 15445 solver.cpp:243] Iteration 6900, loss = 0.0971928
I1005 16:27:14.275230 15445 solver.cpp:259]     Train net output #0: error_blob = 0.0971928 (* 1 = 0.0971928 loss)
I1005 16:27:14.275235 15445 solver.cpp:590] Iteration 6900, lr = 0.01
I1005 16:27:16.734247 15445 solver.cpp:347] Iteration 7000, Testing net (#0)
I1005 16:27:17.006708 15445 solver.cpp:415]     Test net output #0: error_blob = 0.0972733 (* 1 = 0.0972733 loss)
I1005 16:27:17.007307 15445 solver.cpp:243] Iteration 7000, loss = 0.0955283
I1005 16:27:17.007321 15445 solver.cpp:259]     Train net output #0: error_blob = 0.0955283 (* 1 = 0.0955283 loss)
I1005 16:27:17.007325 15445 solver.cpp:590] Iteration 7000, lr = 0.01
I1005 16:27:19.624032 15445 solver.cpp:243] Iteration 7100, loss = 0.0986564
I1005 16:27:19.624138 15445 solver.cpp:259]     Train net output #0: error_blob = 0.0986564 (* 1 = 0.0986564 loss)
I1005 16:27:19.624145 15445 solver.cpp:590] Iteration 7100, lr = 0.01
I1005 16:27:22.106714 15445 solver.cpp:243] Iteration 7200, loss = 0.100374
I1005 16:27:22.106746 15445 solver.cpp:259]     Train net output #0: error_blob = 0.100374 (* 1 = 0.100374 loss)
I1005 16:27:22.106755 15445 solver.cpp:590] Iteration 7200, lr = 0.01
I1005 16:27:23.193955 15445 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 16:27:24.600026 15445 solver.cpp:243] Iteration 7300, loss = 0.0995846
I1005 16:27:24.600059 15445 solver.cpp:259]     Train net output #0: error_blob = 0.0995846 (* 1 = 0.0995846 loss)
I1005 16:27:24.600067 15445 solver.cpp:590] Iteration 7300, lr = 0.01
I1005 16:27:27.102272 15445 solver.cpp:243] Iteration 7400, loss = 0.0961317
I1005 16:27:27.102299 15445 solver.cpp:259]     Train net output #0: error_blob = 0.0961317 (* 1 = 0.0961317 loss)
I1005 16:27:27.102304 15445 solver.cpp:590] Iteration 7400, lr = 0.01
I1005 16:27:29.568617 15445 solver.cpp:243] Iteration 7500, loss = 0.0971825
I1005 16:27:29.568656 15445 solver.cpp:259]     Train net output #0: error_blob = 0.0971825 (* 1 = 0.0971825 loss)
I1005 16:27:29.568661 15445 solver.cpp:590] Iteration 7500, lr = 0.01
I1005 16:27:32.046222 15445 solver.cpp:243] Iteration 7600, loss = 0.0984002
I1005 16:27:32.046253 15445 solver.cpp:259]     Train net output #0: error_blob = 0.0984002 (* 1 = 0.0984002 loss)
I1005 16:27:32.046258 15445 solver.cpp:590] Iteration 7600, lr = 0.01
I1005 16:27:34.549764 15445 solver.cpp:243] Iteration 7700, loss = 0.100235
I1005 16:27:34.549795 15445 solver.cpp:259]     Train net output #0: error_blob = 0.100235 (* 1 = 0.100235 loss)
I1005 16:27:34.549800 15445 solver.cpp:590] Iteration 7700, lr = 0.01
I1005 16:27:37.019899 15445 solver.cpp:243] Iteration 7800, loss = 0.0966761
I1005 16:27:37.019932 15445 solver.cpp:259]     Train net output #0: error_blob = 0.0966761 (* 1 = 0.0966761 loss)
I1005 16:27:37.019938 15445 solver.cpp:590] Iteration 7800, lr = 0.01
I1005 16:27:39.504696 15445 solver.cpp:243] Iteration 7900, loss = 0.0952575
I1005 16:27:39.504724 15445 solver.cpp:259]     Train net output #0: error_blob = 0.0952575 (* 1 = 0.0952575 loss)
I1005 16:27:39.504729 15445 solver.cpp:590] Iteration 7900, lr = 0.01
I1005 16:27:41.947938 15445 solver.cpp:347] Iteration 8000, Testing net (#0)
I1005 16:27:42.219995 15445 solver.cpp:415]     Test net output #0: error_blob = 0.0967328 (* 1 = 0.0967328 loss)
I1005 16:27:42.220613 15445 solver.cpp:243] Iteration 8000, loss = 0.0984648
I1005 16:27:42.220626 15445 solver.cpp:259]     Train net output #0: error_blob = 0.0984648 (* 1 = 0.0984648 loss)
I1005 16:27:42.220633 15445 solver.cpp:590] Iteration 8000, lr = 0.01
I1005 16:27:44.613072 15445 solver.cpp:243] Iteration 8100, loss = 0.100371
I1005 16:27:44.613101 15445 solver.cpp:259]     Train net output #0: error_blob = 0.100371 (* 1 = 0.100371 loss)
I1005 16:27:44.613106 15445 solver.cpp:590] Iteration 8100, lr = 0.01
I1005 16:27:45.859381 15445 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 16:27:47.112746 15445 solver.cpp:243] Iteration 8200, loss = 0.0990085
I1005 16:27:47.112774 15445 solver.cpp:259]     Train net output #0: error_blob = 0.0990085 (* 1 = 0.0990085 loss)
I1005 16:27:47.112779 15445 solver.cpp:590] Iteration 8200, lr = 0.01
I1005 16:27:49.594501 15445 solver.cpp:243] Iteration 8300, loss = 0.0952333
I1005 16:27:49.594529 15445 solver.cpp:259]     Train net output #0: error_blob = 0.0952333 (* 1 = 0.0952333 loss)
I1005 16:27:49.594533 15445 solver.cpp:590] Iteration 8300, lr = 0.01
I1005 16:27:52.058974 15445 solver.cpp:243] Iteration 8400, loss = 0.0968425
I1005 16:27:52.059074 15445 solver.cpp:259]     Train net output #0: error_blob = 0.0968425 (* 1 = 0.0968425 loss)
I1005 16:27:52.059079 15445 solver.cpp:590] Iteration 8400, lr = 0.01
I1005 16:27:54.533557 15445 solver.cpp:243] Iteration 8500, loss = 0.0980177
I1005 16:27:54.533586 15445 solver.cpp:259]     Train net output #0: error_blob = 0.0980177 (* 1 = 0.0980177 loss)
I1005 16:27:54.533589 15445 solver.cpp:590] Iteration 8500, lr = 0.01
I1005 16:27:57.030520 15445 solver.cpp:243] Iteration 8600, loss = 0.0999951
I1005 16:27:57.030550 15445 solver.cpp:259]     Train net output #0: error_blob = 0.0999951 (* 1 = 0.0999951 loss)
I1005 16:27:57.030555 15445 solver.cpp:590] Iteration 8600, lr = 0.01
I1005 16:27:59.519613 15445 solver.cpp:243] Iteration 8700, loss = 0.0961705
I1005 16:27:59.519640 15445 solver.cpp:259]     Train net output #0: error_blob = 0.0961705 (* 1 = 0.0961705 loss)
I1005 16:27:59.519645 15445 solver.cpp:590] Iteration 8700, lr = 0.01
I1005 16:28:02.046651 15445 solver.cpp:243] Iteration 8800, loss = 0.0943117
I1005 16:28:02.046682 15445 solver.cpp:259]     Train net output #0: error_blob = 0.0943117 (* 1 = 0.0943117 loss)
I1005 16:28:02.046687 15445 solver.cpp:590] Iteration 8800, lr = 0.01
I1005 16:28:04.529572 15445 solver.cpp:243] Iteration 8900, loss = 0.098409
I1005 16:28:04.529602 15445 solver.cpp:259]     Train net output #0: error_blob = 0.098409 (* 1 = 0.098409 loss)
I1005 16:28:04.529605 15445 solver.cpp:590] Iteration 8900, lr = 0.01
I1005 16:28:06.936071 15445 solver.cpp:347] Iteration 9000, Testing net (#0)
I1005 16:28:07.245303 15445 solver.cpp:415]     Test net output #0: error_blob = 0.0962945 (* 1 = 0.0962945 loss)
I1005 16:28:07.245906 15445 solver.cpp:243] Iteration 9000, loss = 0.100397
I1005 16:28:07.245919 15445 solver.cpp:259]     Train net output #0: error_blob = 0.100397 (* 1 = 0.100397 loss)
I1005 16:28:07.245924 15445 solver.cpp:590] Iteration 9000, lr = 0.01
I1005 16:28:08.588330 15445 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 16:28:09.673564 15445 solver.cpp:243] Iteration 9100, loss = 0.0987803
I1005 16:28:09.673591 15445 solver.cpp:259]     Train net output #0: error_blob = 0.0987803 (* 1 = 0.0987803 loss)
I1005 16:28:09.673595 15445 solver.cpp:590] Iteration 9100, lr = 0.01
I1005 16:28:12.169247 15445 solver.cpp:243] Iteration 9200, loss = 0.0946755
I1005 16:28:12.169275 15445 solver.cpp:259]     Train net output #0: error_blob = 0.0946755 (* 1 = 0.0946755 loss)
I1005 16:28:12.169281 15445 solver.cpp:590] Iteration 9200, lr = 0.01
I1005 16:28:14.673686 15445 solver.cpp:243] Iteration 9300, loss = 0.0963967
I1005 16:28:14.673713 15445 solver.cpp:259]     Train net output #0: error_blob = 0.0963967 (* 1 = 0.0963967 loss)
I1005 16:28:14.673718 15445 solver.cpp:590] Iteration 9300, lr = 0.01
I1005 16:28:17.138629 15445 solver.cpp:243] Iteration 9400, loss = 0.0976784
I1005 16:28:17.138656 15445 solver.cpp:259]     Train net output #0: error_blob = 0.0976784 (* 1 = 0.0976784 loss)
I1005 16:28:17.138660 15445 solver.cpp:590] Iteration 9400, lr = 0.01
I1005 16:28:19.632649 15445 solver.cpp:243] Iteration 9500, loss = 0.0996604
I1005 16:28:19.632678 15445 solver.cpp:259]     Train net output #0: error_blob = 0.0996604 (* 1 = 0.0996604 loss)
I1005 16:28:19.632681 15445 solver.cpp:590] Iteration 9500, lr = 0.01
I1005 16:28:22.114169 15445 solver.cpp:243] Iteration 9600, loss = 0.095404
I1005 16:28:22.115232 15445 solver.cpp:259]     Train net output #0: error_blob = 0.095404 (* 1 = 0.095404 loss)
I1005 16:28:22.115239 15445 solver.cpp:590] Iteration 9600, lr = 0.01
I1005 16:28:24.630475 15445 solver.cpp:243] Iteration 9700, loss = 0.0939769
I1005 16:28:24.630503 15445 solver.cpp:259]     Train net output #0: error_blob = 0.0939769 (* 1 = 0.0939769 loss)
I1005 16:28:24.630507 15445 solver.cpp:590] Iteration 9700, lr = 0.01
I1005 16:28:27.108077 15445 solver.cpp:243] Iteration 9800, loss = 0.0979347
I1005 16:28:27.108104 15445 solver.cpp:259]     Train net output #0: error_blob = 0.0979347 (* 1 = 0.0979347 loss)
I1005 16:28:27.108108 15445 solver.cpp:590] Iteration 9800, lr = 0.01
I1005 16:28:29.599313 15445 solver.cpp:243] Iteration 9900, loss = 0.0996802
I1005 16:28:29.599341 15445 solver.cpp:259]     Train net output #0: error_blob = 0.0996802 (* 1 = 0.0996802 loss)
I1005 16:28:29.599346 15445 solver.cpp:590] Iteration 9900, lr = 0.01
I1005 16:28:32.050590 15445 solver.cpp:468] Snapshotting to binary proto file _iter_10000.caffemodel
I1005 16:28:32.052366 15445 solver.cpp:753] Snapshotting solver state to binary proto file _iter_10000.solverstate
I1005 16:28:32.075415 15445 solver.cpp:327] Iteration 10000, loss = 0.0982353
I1005 16:28:32.075440 15445 solver.cpp:347] Iteration 10000, Testing net (#0)
I1005 16:28:32.284454 15445 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 16:28:32.392804 15445 solver.cpp:415]     Test net output #0: error_blob = 0.0960247 (* 1 = 0.0960247 loss)
I1005 16:28:32.392823 15445 solver.cpp:332] Optimization Done.
I1005 16:28:32.392827 15445 caffe.cpp:215] Optimization Done.
