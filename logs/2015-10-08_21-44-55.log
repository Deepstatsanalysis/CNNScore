I1008 21:44:55.201447  3632 caffe.cpp:184] Using GPUs 0
I1008 21:44:55.782730  3632 solver.cpp:54] Initializing solver from parameters: 
test_iter: 1
test_interval: 100
base_lr: 0.1
display: 100
max_iter: 5000
lr_policy: "inv"
gamma: 0.0004
power: 2
momentum: 0.9
solver_mode: GPU
device_id: 0
net: "two_hidden/model3_part2.prototxt"
I1008 21:44:55.782765  3632 solver.cpp:97] Creating training net from net file: two_hidden/model3_part2.prototxt
I1008 21:44:55.782943  3632 net.cpp:339] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_layer
I1008 21:44:55.782987  3632 net.cpp:50] Initializing net from parameters: 
name: "two_hidden/model3_part2.prototxt"
state {
  phase: TRAIN
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TRAIN
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.part2.train"
    batch_size: 40000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer1"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob1"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer1"
  type: "Sigmoid"
  bottom: "hidden_sum_blob1"
  top: "hidden_act_blob1"
}
layer {
  name: "hidden_sum_layer2"
  type: "InnerProduct"
  bottom: "hidden_act_blob1"
  top: "hidden_sum_blob2"
  inner_product_param {
    num_output: 5
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer2"
  type: "Sigmoid"
  bottom: "hidden_sum_blob2"
  top: "hidden_act_blob2"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob2"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1008 21:44:55.783030  3632 layer_factory.hpp:76] Creating layer data_layer
I1008 21:44:55.809625  3632 net.cpp:110] Creating Layer data_layer
I1008 21:44:55.809659  3632 net.cpp:433] data_layer -> data_blob
I1008 21:44:55.809707  3632 net.cpp:433] data_layer -> label_blob
I1008 21:44:55.810286  3636 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.part2.train
I1008 21:44:56.497562  3632 data_layer.cpp:45] output data size: 40000,61,1,1
I1008 21:44:56.507979  3632 net.cpp:155] Setting up data_layer
I1008 21:44:56.508021  3632 net.cpp:163] Top shape: 40000 61 1 1 (2440000)
I1008 21:44:56.508026  3632 net.cpp:163] Top shape: 40000 (40000)
I1008 21:44:56.508044  3632 layer_factory.hpp:76] Creating layer hidden_sum_layer1
I1008 21:44:56.508055  3632 net.cpp:110] Creating Layer hidden_sum_layer1
I1008 21:44:56.508059  3632 net.cpp:477] hidden_sum_layer1 <- data_blob
I1008 21:44:56.508069  3632 net.cpp:433] hidden_sum_layer1 -> hidden_sum_blob1
I1008 21:44:56.508484  3632 net.cpp:155] Setting up hidden_sum_layer1
I1008 21:44:56.508496  3632 net.cpp:163] Top shape: 40000 10 (400000)
I1008 21:44:56.508518  3632 layer_factory.hpp:76] Creating layer hidden_act_layer1
I1008 21:44:56.508536  3632 net.cpp:110] Creating Layer hidden_act_layer1
I1008 21:44:56.508538  3632 net.cpp:477] hidden_act_layer1 <- hidden_sum_blob1
I1008 21:44:56.508543  3632 net.cpp:433] hidden_act_layer1 -> hidden_act_blob1
I1008 21:44:59.736258  3632 net.cpp:155] Setting up hidden_act_layer1
I1008 21:44:59.736289  3632 net.cpp:163] Top shape: 40000 10 (400000)
I1008 21:44:59.736292  3632 layer_factory.hpp:76] Creating layer hidden_sum_layer2
I1008 21:44:59.736302  3632 net.cpp:110] Creating Layer hidden_sum_layer2
I1008 21:44:59.736305  3632 net.cpp:477] hidden_sum_layer2 <- hidden_act_blob1
I1008 21:44:59.736311  3632 net.cpp:433] hidden_sum_layer2 -> hidden_sum_blob2
I1008 21:44:59.736423  3632 net.cpp:155] Setting up hidden_sum_layer2
I1008 21:44:59.736429  3632 net.cpp:163] Top shape: 40000 5 (200000)
I1008 21:44:59.736454  3632 layer_factory.hpp:76] Creating layer hidden_act_layer2
I1008 21:44:59.736459  3632 net.cpp:110] Creating Layer hidden_act_layer2
I1008 21:44:59.736461  3632 net.cpp:477] hidden_act_layer2 <- hidden_sum_blob2
I1008 21:44:59.736464  3632 net.cpp:433] hidden_act_layer2 -> hidden_act_blob2
I1008 21:44:59.736552  3632 net.cpp:155] Setting up hidden_act_layer2
I1008 21:44:59.736557  3632 net.cpp:163] Top shape: 40000 5 (200000)
I1008 21:44:59.736568  3632 layer_factory.hpp:76] Creating layer output_sum_layer
I1008 21:44:59.736573  3632 net.cpp:110] Creating Layer output_sum_layer
I1008 21:44:59.736575  3632 net.cpp:477] output_sum_layer <- hidden_act_blob2
I1008 21:44:59.736589  3632 net.cpp:433] output_sum_layer -> output_sum_blob
I1008 21:44:59.736667  3632 net.cpp:155] Setting up output_sum_layer
I1008 21:44:59.736672  3632 net.cpp:163] Top shape: 40000 1 (40000)
I1008 21:44:59.736688  3632 layer_factory.hpp:76] Creating layer output_act_layer
I1008 21:44:59.736692  3632 net.cpp:110] Creating Layer output_act_layer
I1008 21:44:59.736695  3632 net.cpp:477] output_act_layer <- output_sum_blob
I1008 21:44:59.736697  3632 net.cpp:433] output_act_layer -> output_act_blob
I1008 21:44:59.736840  3632 net.cpp:155] Setting up output_act_layer
I1008 21:44:59.736846  3632 net.cpp:163] Top shape: 40000 1 (40000)
I1008 21:44:59.736860  3632 layer_factory.hpp:76] Creating layer error_layer
I1008 21:44:59.736865  3632 net.cpp:110] Creating Layer error_layer
I1008 21:44:59.736867  3632 net.cpp:477] error_layer <- output_act_blob
I1008 21:44:59.736871  3632 net.cpp:477] error_layer <- label_blob
I1008 21:44:59.736874  3632 net.cpp:433] error_layer -> error_blob
I1008 21:44:59.736899  3632 net.cpp:155] Setting up error_layer
I1008 21:44:59.736903  3632 net.cpp:163] Top shape: (1)
I1008 21:44:59.736906  3632 net.cpp:168]     with loss weight 1
I1008 21:44:59.736922  3632 net.cpp:236] error_layer needs backward computation.
I1008 21:44:59.736925  3632 net.cpp:236] output_act_layer needs backward computation.
I1008 21:44:59.736927  3632 net.cpp:236] output_sum_layer needs backward computation.
I1008 21:44:59.736929  3632 net.cpp:236] hidden_act_layer2 needs backward computation.
I1008 21:44:59.736932  3632 net.cpp:236] hidden_sum_layer2 needs backward computation.
I1008 21:44:59.736933  3632 net.cpp:236] hidden_act_layer1 needs backward computation.
I1008 21:44:59.736935  3632 net.cpp:236] hidden_sum_layer1 needs backward computation.
I1008 21:44:59.736937  3632 net.cpp:240] data_layer does not need backward computation.
I1008 21:44:59.736939  3632 net.cpp:283] This network produces output error_blob
I1008 21:44:59.736945  3632 net.cpp:297] Network initialization done.
I1008 21:44:59.736948  3632 net.cpp:298] Memory required for data: 15040004
I1008 21:44:59.737097  3632 solver.cpp:187] Creating test net (#0) specified by net file: two_hidden/model3_part2.prototxt
I1008 21:44:59.737119  3632 net.cpp:339] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_layer
I1008 21:44:59.737164  3632 net.cpp:50] Initializing net from parameters: 
name: "two_hidden/model3_part2.prototxt"
state {
  phase: TEST
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TEST
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.part2.test"
    batch_size: 4000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer1"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob1"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer1"
  type: "Sigmoid"
  bottom: "hidden_sum_blob1"
  top: "hidden_act_blob1"
}
layer {
  name: "hidden_sum_layer2"
  type: "InnerProduct"
  bottom: "hidden_act_blob1"
  top: "hidden_sum_blob2"
  inner_product_param {
    num_output: 5
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer2"
  type: "Sigmoid"
  bottom: "hidden_sum_blob2"
  top: "hidden_act_blob2"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob2"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1008 21:44:59.737206  3632 layer_factory.hpp:76] Creating layer data_layer
I1008 21:44:59.739662  3632 net.cpp:110] Creating Layer data_layer
I1008 21:44:59.739670  3632 net.cpp:433] data_layer -> data_blob
I1008 21:44:59.739677  3632 net.cpp:433] data_layer -> label_blob
I1008 21:44:59.740243  3638 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.part2.test
I1008 21:44:59.740319  3632 data_layer.cpp:45] output data size: 4000,61,1,1
I1008 21:44:59.742236  3632 net.cpp:155] Setting up data_layer
I1008 21:44:59.742250  3632 net.cpp:163] Top shape: 4000 61 1 1 (244000)
I1008 21:44:59.742254  3632 net.cpp:163] Top shape: 4000 (4000)
I1008 21:44:59.742259  3632 layer_factory.hpp:76] Creating layer hidden_sum_layer1
I1008 21:44:59.742267  3632 net.cpp:110] Creating Layer hidden_sum_layer1
I1008 21:44:59.742270  3632 net.cpp:477] hidden_sum_layer1 <- data_blob
I1008 21:44:59.742274  3632 net.cpp:433] hidden_sum_layer1 -> hidden_sum_blob1
I1008 21:44:59.742398  3632 net.cpp:155] Setting up hidden_sum_layer1
I1008 21:44:59.742404  3632 net.cpp:163] Top shape: 4000 10 (40000)
I1008 21:44:59.742411  3632 layer_factory.hpp:76] Creating layer hidden_act_layer1
I1008 21:44:59.742416  3632 net.cpp:110] Creating Layer hidden_act_layer1
I1008 21:44:59.742419  3632 net.cpp:477] hidden_act_layer1 <- hidden_sum_blob1
I1008 21:44:59.742421  3632 net.cpp:433] hidden_act_layer1 -> hidden_act_blob1
I1008 21:44:59.742486  3632 net.cpp:155] Setting up hidden_act_layer1
I1008 21:44:59.742491  3632 net.cpp:163] Top shape: 4000 10 (40000)
I1008 21:44:59.742493  3632 layer_factory.hpp:76] Creating layer hidden_sum_layer2
I1008 21:44:59.742496  3632 net.cpp:110] Creating Layer hidden_sum_layer2
I1008 21:44:59.742499  3632 net.cpp:477] hidden_sum_layer2 <- hidden_act_blob1
I1008 21:44:59.742502  3632 net.cpp:433] hidden_sum_layer2 -> hidden_sum_blob2
I1008 21:44:59.742564  3632 net.cpp:155] Setting up hidden_sum_layer2
I1008 21:44:59.742569  3632 net.cpp:163] Top shape: 4000 5 (20000)
I1008 21:44:59.742574  3632 layer_factory.hpp:76] Creating layer hidden_act_layer2
I1008 21:44:59.742578  3632 net.cpp:110] Creating Layer hidden_act_layer2
I1008 21:44:59.742580  3632 net.cpp:477] hidden_act_layer2 <- hidden_sum_blob2
I1008 21:44:59.742584  3632 net.cpp:433] hidden_act_layer2 -> hidden_act_blob2
I1008 21:44:59.742636  3632 net.cpp:155] Setting up hidden_act_layer2
I1008 21:44:59.742640  3632 net.cpp:163] Top shape: 4000 5 (20000)
I1008 21:44:59.742643  3632 layer_factory.hpp:76] Creating layer output_sum_layer
I1008 21:44:59.742647  3632 net.cpp:110] Creating Layer output_sum_layer
I1008 21:44:59.742650  3632 net.cpp:477] output_sum_layer <- hidden_act_blob2
I1008 21:44:59.742652  3632 net.cpp:433] output_sum_layer -> output_sum_blob
I1008 21:44:59.742707  3632 net.cpp:155] Setting up output_sum_layer
I1008 21:44:59.742712  3632 net.cpp:163] Top shape: 4000 1 (4000)
I1008 21:44:59.742717  3632 layer_factory.hpp:76] Creating layer output_act_layer
I1008 21:44:59.742722  3632 net.cpp:110] Creating Layer output_act_layer
I1008 21:44:59.742723  3632 net.cpp:477] output_act_layer <- output_sum_blob
I1008 21:44:59.742727  3632 net.cpp:433] output_act_layer -> output_act_blob
I1008 21:44:59.742774  3632 net.cpp:155] Setting up output_act_layer
I1008 21:44:59.742780  3632 net.cpp:163] Top shape: 4000 1 (4000)
I1008 21:44:59.742782  3632 layer_factory.hpp:76] Creating layer error_layer
I1008 21:44:59.742786  3632 net.cpp:110] Creating Layer error_layer
I1008 21:44:59.742789  3632 net.cpp:477] error_layer <- output_act_blob
I1008 21:44:59.742802  3632 net.cpp:477] error_layer <- label_blob
I1008 21:44:59.742806  3632 net.cpp:433] error_layer -> error_blob
I1008 21:44:59.742828  3632 net.cpp:155] Setting up error_layer
I1008 21:44:59.742832  3632 net.cpp:163] Top shape: (1)
I1008 21:44:59.742835  3632 net.cpp:168]     with loss weight 1
I1008 21:44:59.742842  3632 net.cpp:236] error_layer needs backward computation.
I1008 21:44:59.742846  3632 net.cpp:236] output_act_layer needs backward computation.
I1008 21:44:59.742847  3632 net.cpp:236] output_sum_layer needs backward computation.
I1008 21:44:59.742849  3632 net.cpp:236] hidden_act_layer2 needs backward computation.
I1008 21:44:59.742852  3632 net.cpp:236] hidden_sum_layer2 needs backward computation.
I1008 21:44:59.742854  3632 net.cpp:236] hidden_act_layer1 needs backward computation.
I1008 21:44:59.742856  3632 net.cpp:236] hidden_sum_layer1 needs backward computation.
I1008 21:44:59.742858  3632 net.cpp:240] data_layer does not need backward computation.
I1008 21:44:59.742861  3632 net.cpp:283] This network produces output error_blob
I1008 21:44:59.742866  3632 net.cpp:297] Network initialization done.
I1008 21:44:59.742868  3632 net.cpp:298] Memory required for data: 1504004
I1008 21:44:59.742890  3632 solver.cpp:66] Solver scaffolding done.
I1008 21:44:59.743019  3632 caffe.cpp:212] Starting Optimization
I1008 21:44:59.743026  3632 solver.cpp:294] Solving two_hidden/model3_part2.prototxt
I1008 21:44:59.743028  3632 solver.cpp:295] Learning Rate Policy: inv
I1008 21:44:59.743306  3632 solver.cpp:347] Iteration 0, Testing net (#0)
I1008 21:44:59.743369  3632 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 21:44:59.752687  3632 solver.cpp:415]     Test net output #0: error_blob = 0.126072 (* 1 = 0.126072 loss)
I1008 21:44:59.754779  3632 solver.cpp:243] Iteration 0, loss = 0.126114
I1008 21:44:59.754794  3632 solver.cpp:259]     Train net output #0: error_blob = 0.126114 (* 1 = 0.126114 loss)
I1008 21:44:59.754817  3632 solver.cpp:590] Iteration 0, lr = 0.1
I1008 21:45:04.577453  3632 solver.cpp:347] Iteration 100, Testing net (#0)
I1008 21:45:04.579331  3632 solver.cpp:415]     Test net output #0: error_blob = 0.121576 (* 1 = 0.121576 loss)
I1008 21:45:04.634235  3632 solver.cpp:243] Iteration 100, loss = 0.121793
I1008 21:45:04.634268  3632 solver.cpp:259]     Train net output #0: error_blob = 0.121793 (* 1 = 0.121793 loss)
I1008 21:45:04.634275  3632 solver.cpp:590] Iteration 100, lr = 0.0924556
I1008 21:45:09.504528  3632 solver.cpp:347] Iteration 200, Testing net (#0)
I1008 21:45:09.506428  3632 solver.cpp:415]     Test net output #0: error_blob = 0.114334 (* 1 = 0.114334 loss)
I1008 21:45:09.560164  3632 solver.cpp:243] Iteration 200, loss = 0.114973
I1008 21:45:09.560204  3632 solver.cpp:259]     Train net output #0: error_blob = 0.114973 (* 1 = 0.114973 loss)
I1008 21:45:09.560223  3632 solver.cpp:590] Iteration 200, lr = 0.0857339
I1008 21:45:14.511979  3632 solver.cpp:347] Iteration 300, Testing net (#0)
I1008 21:45:14.513820  3632 solver.cpp:415]     Test net output #0: error_blob = 0.107996 (* 1 = 0.107996 loss)
I1008 21:45:14.565057  3632 solver.cpp:243] Iteration 300, loss = 0.10897
I1008 21:45:14.565091  3632 solver.cpp:259]     Train net output #0: error_blob = 0.10897 (* 1 = 0.10897 loss)
I1008 21:45:14.565100  3632 solver.cpp:590] Iteration 300, lr = 0.0797194
I1008 21:45:19.474627  3632 solver.cpp:347] Iteration 400, Testing net (#0)
I1008 21:45:19.476485  3632 solver.cpp:415]     Test net output #0: error_blob = 0.104469 (* 1 = 0.104469 loss)
I1008 21:45:19.526661  3632 solver.cpp:243] Iteration 400, loss = 0.107569
I1008 21:45:19.526698  3632 solver.cpp:259]     Train net output #0: error_blob = 0.107569 (* 1 = 0.107569 loss)
I1008 21:45:19.526710  3632 solver.cpp:590] Iteration 400, lr = 0.0743163
I1008 21:45:24.490126  3632 solver.cpp:347] Iteration 500, Testing net (#0)
I1008 21:45:24.492015  3632 solver.cpp:415]     Test net output #0: error_blob = 0.102564 (* 1 = 0.102564 loss)
I1008 21:45:24.540748  3632 solver.cpp:243] Iteration 500, loss = 0.104996
I1008 21:45:24.540812  3632 solver.cpp:259]     Train net output #0: error_blob = 0.104996 (* 1 = 0.104996 loss)
I1008 21:45:24.540823  3632 solver.cpp:590] Iteration 500, lr = 0.0694444
I1008 21:45:29.464030  3632 solver.cpp:347] Iteration 600, Testing net (#0)
I1008 21:45:29.465912  3632 solver.cpp:415]     Test net output #0: error_blob = 0.101405 (* 1 = 0.101405 loss)
I1008 21:45:29.514935  3632 solver.cpp:243] Iteration 600, loss = 0.103364
I1008 21:45:29.514967  3632 solver.cpp:259]     Train net output #0: error_blob = 0.103364 (* 1 = 0.103364 loss)
I1008 21:45:29.514978  3632 solver.cpp:590] Iteration 600, lr = 0.0650364
I1008 21:45:34.460592  3632 solver.cpp:347] Iteration 700, Testing net (#0)
I1008 21:45:34.462481  3632 solver.cpp:415]     Test net output #0: error_blob = 0.101542 (* 1 = 0.101542 loss)
I1008 21:45:34.511158  3632 solver.cpp:243] Iteration 700, loss = 0.103285
I1008 21:45:34.511194  3632 solver.cpp:259]     Train net output #0: error_blob = 0.103285 (* 1 = 0.103285 loss)
I1008 21:45:34.511205  3632 solver.cpp:590] Iteration 700, lr = 0.0610352
I1008 21:45:39.449247  3632 solver.cpp:347] Iteration 800, Testing net (#0)
I1008 21:45:39.451066  3632 solver.cpp:415]     Test net output #0: error_blob = 0.100683 (* 1 = 0.100683 loss)
I1008 21:45:39.501225  3632 solver.cpp:243] Iteration 800, loss = 0.102878
I1008 21:45:39.501260  3632 solver.cpp:259]     Train net output #0: error_blob = 0.102878 (* 1 = 0.102878 loss)
I1008 21:45:39.501279  3632 solver.cpp:590] Iteration 800, lr = 0.0573921
I1008 21:45:44.462736  3632 solver.cpp:347] Iteration 900, Testing net (#0)
I1008 21:45:44.464591  3632 solver.cpp:415]     Test net output #0: error_blob = 0.100276 (* 1 = 0.100276 loss)
I1008 21:45:44.516053  3632 solver.cpp:243] Iteration 900, loss = 0.102051
I1008 21:45:44.516086  3632 solver.cpp:259]     Train net output #0: error_blob = 0.102051 (* 1 = 0.102051 loss)
I1008 21:45:44.516096  3632 solver.cpp:590] Iteration 900, lr = 0.0540657
I1008 21:45:49.435573  3632 solver.cpp:347] Iteration 1000, Testing net (#0)
I1008 21:45:49.437441  3632 solver.cpp:415]     Test net output #0: error_blob = 0.100357 (* 1 = 0.100357 loss)
I1008 21:45:49.487887  3632 solver.cpp:243] Iteration 1000, loss = 0.100688
I1008 21:45:49.487925  3632 solver.cpp:259]     Train net output #0: error_blob = 0.100688 (* 1 = 0.100688 loss)
I1008 21:45:49.487936  3632 solver.cpp:590] Iteration 1000, lr = 0.0510204
I1008 21:45:49.488068  3632 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 21:45:54.400687  3632 solver.cpp:347] Iteration 1100, Testing net (#0)
I1008 21:45:54.402524  3632 solver.cpp:415]     Test net output #0: error_blob = 0.10001 (* 1 = 0.10001 loss)
I1008 21:45:54.453063  3632 solver.cpp:243] Iteration 1100, loss = 0.100747
I1008 21:45:54.453096  3632 solver.cpp:259]     Train net output #0: error_blob = 0.100747 (* 1 = 0.100747 loss)
I1008 21:45:54.453105  3632 solver.cpp:590] Iteration 1100, lr = 0.0482253
I1008 21:45:59.372877  3632 solver.cpp:347] Iteration 1200, Testing net (#0)
I1008 21:45:59.374735  3632 solver.cpp:415]     Test net output #0: error_blob = 0.100034 (* 1 = 0.100034 loss)
I1008 21:45:59.427220  3632 solver.cpp:243] Iteration 1200, loss = 0.101276
I1008 21:45:59.427258  3632 solver.cpp:259]     Train net output #0: error_blob = 0.101276 (* 1 = 0.101276 loss)
I1008 21:45:59.427266  3632 solver.cpp:590] Iteration 1200, lr = 0.0456538
I1008 21:46:04.343567  3632 solver.cpp:347] Iteration 1300, Testing net (#0)
I1008 21:46:04.345464  3632 solver.cpp:415]     Test net output #0: error_blob = 0.0996838 (* 1 = 0.0996838 loss)
I1008 21:46:04.394405  3632 solver.cpp:243] Iteration 1300, loss = 0.100911
I1008 21:46:04.394438  3632 solver.cpp:259]     Train net output #0: error_blob = 0.100911 (* 1 = 0.100911 loss)
I1008 21:46:04.394449  3632 solver.cpp:590] Iteration 1300, lr = 0.0432825
I1008 21:46:09.373466  3632 solver.cpp:347] Iteration 1400, Testing net (#0)
I1008 21:46:09.375339  3632 solver.cpp:415]     Test net output #0: error_blob = 0.0998328 (* 1 = 0.0998328 loss)
I1008 21:46:09.427050  3632 solver.cpp:243] Iteration 1400, loss = 0.100352
I1008 21:46:09.427088  3632 solver.cpp:259]     Train net output #0: error_blob = 0.100352 (* 1 = 0.100352 loss)
I1008 21:46:09.427098  3632 solver.cpp:590] Iteration 1400, lr = 0.0410914
I1008 21:46:14.346660  3632 solver.cpp:347] Iteration 1500, Testing net (#0)
I1008 21:46:14.348556  3632 solver.cpp:415]     Test net output #0: error_blob = 0.100241 (* 1 = 0.100241 loss)
I1008 21:46:14.398283  3632 solver.cpp:243] Iteration 1500, loss = 0.0997438
I1008 21:46:14.398315  3632 solver.cpp:259]     Train net output #0: error_blob = 0.0997438 (* 1 = 0.0997438 loss)
I1008 21:46:14.398325  3632 solver.cpp:590] Iteration 1500, lr = 0.0390625
I1008 21:46:19.337838  3632 solver.cpp:347] Iteration 1600, Testing net (#0)
I1008 21:46:19.339725  3632 solver.cpp:415]     Test net output #0: error_blob = 0.0990712 (* 1 = 0.0990712 loss)
I1008 21:46:19.388663  3632 solver.cpp:243] Iteration 1600, loss = 0.0996059
I1008 21:46:19.388697  3632 solver.cpp:259]     Train net output #0: error_blob = 0.0996059 (* 1 = 0.0996059 loss)
I1008 21:46:19.388708  3632 solver.cpp:590] Iteration 1600, lr = 0.0371803
I1008 21:46:24.363119  3632 solver.cpp:347] Iteration 1700, Testing net (#0)
I1008 21:46:24.364966  3632 solver.cpp:415]     Test net output #0: error_blob = 0.0999179 (* 1 = 0.0999179 loss)
I1008 21:46:24.416582  3632 solver.cpp:243] Iteration 1700, loss = 0.0983218
I1008 21:46:24.416616  3632 solver.cpp:259]     Train net output #0: error_blob = 0.0983218 (* 1 = 0.0983218 loss)
I1008 21:46:24.416625  3632 solver.cpp:590] Iteration 1700, lr = 0.0354308
I1008 21:46:29.405750  3632 solver.cpp:347] Iteration 1800, Testing net (#0)
I1008 21:46:29.407601  3632 solver.cpp:415]     Test net output #0: error_blob = 0.0997311 (* 1 = 0.0997311 loss)
I1008 21:46:29.461004  3632 solver.cpp:243] Iteration 1800, loss = 0.0999135
I1008 21:46:29.461036  3632 solver.cpp:259]     Train net output #0: error_blob = 0.0999135 (* 1 = 0.0999135 loss)
I1008 21:46:29.461046  3632 solver.cpp:590] Iteration 1800, lr = 0.0338021
I1008 21:46:34.390516  3632 solver.cpp:347] Iteration 1900, Testing net (#0)
I1008 21:46:34.392352  3632 solver.cpp:415]     Test net output #0: error_blob = 0.0991076 (* 1 = 0.0991076 loss)
I1008 21:46:34.443464  3632 solver.cpp:243] Iteration 1900, loss = 0.0987489
I1008 21:46:34.443500  3632 solver.cpp:259]     Train net output #0: error_blob = 0.0987489 (* 1 = 0.0987489 loss)
I1008 21:46:34.443519  3632 solver.cpp:590] Iteration 1900, lr = 0.0322831
I1008 21:46:39.384446  3632 solver.cpp:347] Iteration 2000, Testing net (#0)
I1008 21:46:39.386298  3632 solver.cpp:415]     Test net output #0: error_blob = 0.0985394 (* 1 = 0.0985394 loss)
I1008 21:46:39.436730  3632 solver.cpp:243] Iteration 2000, loss = 0.098174
I1008 21:46:39.436767  3632 solver.cpp:259]     Train net output #0: error_blob = 0.098174 (* 1 = 0.098174 loss)
I1008 21:46:39.436776  3632 solver.cpp:590] Iteration 2000, lr = 0.0308642
I1008 21:46:39.436908  3632 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 21:46:44.399268  3632 solver.cpp:347] Iteration 2100, Testing net (#0)
I1008 21:46:44.401144  3632 solver.cpp:415]     Test net output #0: error_blob = 0.0989986 (* 1 = 0.0989986 loss)
I1008 21:46:44.454587  3632 solver.cpp:243] Iteration 2100, loss = 0.0989055
I1008 21:46:44.454618  3632 solver.cpp:259]     Train net output #0: error_blob = 0.0989055 (* 1 = 0.0989055 loss)
I1008 21:46:44.454625  3632 solver.cpp:590] Iteration 2100, lr = 0.0295369
I1008 21:46:49.359935  3632 solver.cpp:347] Iteration 2200, Testing net (#0)
I1008 21:46:49.361835  3632 solver.cpp:415]     Test net output #0: error_blob = 0.0992036 (* 1 = 0.0992036 loss)
I1008 21:46:49.414661  3632 solver.cpp:243] Iteration 2200, loss = 0.0981682
I1008 21:46:49.414701  3632 solver.cpp:259]     Train net output #0: error_blob = 0.0981682 (* 1 = 0.0981682 loss)
I1008 21:46:49.414710  3632 solver.cpp:590] Iteration 2200, lr = 0.0282933
I1008 21:46:54.283149  3632 solver.cpp:347] Iteration 2300, Testing net (#0)
I1008 21:46:54.284998  3632 solver.cpp:415]     Test net output #0: error_blob = 0.0988707 (* 1 = 0.0988707 loss)
I1008 21:46:54.335188  3632 solver.cpp:243] Iteration 2300, loss = 0.0986674
I1008 21:46:54.335216  3632 solver.cpp:259]     Train net output #0: error_blob = 0.0986674 (* 1 = 0.0986674 loss)
I1008 21:46:54.335223  3632 solver.cpp:590] Iteration 2300, lr = 0.0271267
I1008 21:46:59.283233  3632 solver.cpp:347] Iteration 2400, Testing net (#0)
I1008 21:46:59.285099  3632 solver.cpp:415]     Test net output #0: error_blob = 0.0991369 (* 1 = 0.0991369 loss)
I1008 21:46:59.335561  3632 solver.cpp:243] Iteration 2400, loss = 0.0965157
I1008 21:46:59.335590  3632 solver.cpp:259]     Train net output #0: error_blob = 0.0965157 (* 1 = 0.0965157 loss)
I1008 21:46:59.335597  3632 solver.cpp:590] Iteration 2400, lr = 0.0260308
I1008 21:47:04.294121  3632 solver.cpp:347] Iteration 2500, Testing net (#0)
I1008 21:47:04.295964  3632 solver.cpp:415]     Test net output #0: error_blob = 0.0998224 (* 1 = 0.0998224 loss)
I1008 21:47:04.346590  3632 solver.cpp:243] Iteration 2500, loss = 0.097284
I1008 21:47:04.346628  3632 solver.cpp:259]     Train net output #0: error_blob = 0.097284 (* 1 = 0.097284 loss)
I1008 21:47:04.346637  3632 solver.cpp:590] Iteration 2500, lr = 0.025
I1008 21:47:09.331874  3632 solver.cpp:347] Iteration 2600, Testing net (#0)
I1008 21:47:09.333736  3632 solver.cpp:415]     Test net output #0: error_blob = 0.0988688 (* 1 = 0.0988688 loss)
I1008 21:47:09.385331  3632 solver.cpp:243] Iteration 2600, loss = 0.0974698
I1008 21:47:09.385365  3632 solver.cpp:259]     Train net output #0: error_blob = 0.0974698 (* 1 = 0.0974698 loss)
I1008 21:47:09.385373  3632 solver.cpp:590] Iteration 2600, lr = 0.0240292
I1008 21:47:14.300354  3632 solver.cpp:347] Iteration 2700, Testing net (#0)
I1008 21:47:14.302249  3632 solver.cpp:415]     Test net output #0: error_blob = 0.097589 (* 1 = 0.097589 loss)
I1008 21:47:14.354609  3632 solver.cpp:243] Iteration 2700, loss = 0.0989251
I1008 21:47:14.354641  3632 solver.cpp:259]     Train net output #0: error_blob = 0.0989251 (* 1 = 0.0989251 loss)
I1008 21:47:14.354648  3632 solver.cpp:590] Iteration 2700, lr = 0.0231139
I1008 21:47:19.229601  3632 solver.cpp:347] Iteration 2800, Testing net (#0)
I1008 21:47:19.231480  3632 solver.cpp:415]     Test net output #0: error_blob = 0.0980985 (* 1 = 0.0980985 loss)
I1008 21:47:19.285615  3632 solver.cpp:243] Iteration 2800, loss = 0.0970867
I1008 21:47:19.285642  3632 solver.cpp:259]     Train net output #0: error_blob = 0.0970867 (* 1 = 0.0970867 loss)
I1008 21:47:19.285650  3632 solver.cpp:590] Iteration 2800, lr = 0.0222499
I1008 21:47:24.214282  3632 solver.cpp:347] Iteration 2900, Testing net (#0)
I1008 21:47:24.216140  3632 solver.cpp:415]     Test net output #0: error_blob = 0.0986329 (* 1 = 0.0986329 loss)
I1008 21:47:24.268456  3632 solver.cpp:243] Iteration 2900, loss = 0.0967471
I1008 21:47:24.268503  3632 solver.cpp:259]     Train net output #0: error_blob = 0.0967471 (* 1 = 0.0967471 loss)
I1008 21:47:24.268513  3632 solver.cpp:590] Iteration 2900, lr = 0.0214335
I1008 21:47:29.233240  3632 solver.cpp:347] Iteration 3000, Testing net (#0)
I1008 21:47:29.235071  3632 solver.cpp:415]     Test net output #0: error_blob = 0.099086 (* 1 = 0.099086 loss)
I1008 21:47:29.286430  3632 solver.cpp:243] Iteration 3000, loss = 0.0968443
I1008 21:47:29.286459  3632 solver.cpp:259]     Train net output #0: error_blob = 0.0968443 (* 1 = 0.0968443 loss)
I1008 21:47:29.286466  3632 solver.cpp:590] Iteration 3000, lr = 0.0206612
I1008 21:47:29.286568  3632 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 21:47:34.263659  3632 solver.cpp:347] Iteration 3100, Testing net (#0)
I1008 21:47:34.265518  3632 solver.cpp:415]     Test net output #0: error_blob = 0.0998158 (* 1 = 0.0998158 loss)
I1008 21:47:34.319767  3632 solver.cpp:243] Iteration 3100, loss = 0.0959932
I1008 21:47:34.319813  3632 solver.cpp:259]     Train net output #0: error_blob = 0.0959932 (* 1 = 0.0959932 loss)
I1008 21:47:34.319823  3632 solver.cpp:590] Iteration 3100, lr = 0.0199298
I1008 21:47:39.327467  3632 solver.cpp:347] Iteration 3200, Testing net (#0)
I1008 21:47:39.329321  3632 solver.cpp:415]     Test net output #0: error_blob = 0.0965389 (* 1 = 0.0965389 loss)
I1008 21:47:39.382962  3632 solver.cpp:243] Iteration 3200, loss = 0.0978965
I1008 21:47:39.383066  3632 solver.cpp:259]     Train net output #0: error_blob = 0.0978965 (* 1 = 0.0978965 loss)
I1008 21:47:39.383086  3632 solver.cpp:590] Iteration 3200, lr = 0.0192367
I1008 21:47:44.361351  3632 solver.cpp:347] Iteration 3300, Testing net (#0)
I1008 21:47:44.363188  3632 solver.cpp:415]     Test net output #0: error_blob = 0.0982897 (* 1 = 0.0982897 loss)
I1008 21:47:44.416862  3632 solver.cpp:243] Iteration 3300, loss = 0.0970784
I1008 21:47:44.416898  3632 solver.cpp:259]     Train net output #0: error_blob = 0.0970784 (* 1 = 0.0970784 loss)
I1008 21:47:44.416906  3632 solver.cpp:590] Iteration 3300, lr = 0.0185791
I1008 21:47:49.323312  3632 solver.cpp:347] Iteration 3400, Testing net (#0)
I1008 21:47:49.325214  3632 solver.cpp:415]     Test net output #0: error_blob = 0.0990163 (* 1 = 0.0990163 loss)
I1008 21:47:49.376526  3632 solver.cpp:243] Iteration 3400, loss = 0.0961158
I1008 21:47:49.376556  3632 solver.cpp:259]     Train net output #0: error_blob = 0.0961158 (* 1 = 0.0961158 loss)
I1008 21:47:49.376564  3632 solver.cpp:590] Iteration 3400, lr = 0.0179546
I1008 21:47:54.355269  3632 solver.cpp:347] Iteration 3500, Testing net (#0)
I1008 21:47:54.357091  3632 solver.cpp:415]     Test net output #0: error_blob = 0.0981455 (* 1 = 0.0981455 loss)
I1008 21:47:54.410678  3632 solver.cpp:243] Iteration 3500, loss = 0.0972184
I1008 21:47:54.410724  3632 solver.cpp:259]     Train net output #0: error_blob = 0.0972184 (* 1 = 0.0972184 loss)
I1008 21:47:54.410735  3632 solver.cpp:590] Iteration 3500, lr = 0.0173611
I1008 21:47:59.332957  3632 solver.cpp:347] Iteration 3600, Testing net (#0)
I1008 21:47:59.334847  3632 solver.cpp:415]     Test net output #0: error_blob = 0.097943 (* 1 = 0.097943 loss)
I1008 21:47:59.386682  3632 solver.cpp:243] Iteration 3600, loss = 0.0944693
I1008 21:47:59.386714  3632 solver.cpp:259]     Train net output #0: error_blob = 0.0944693 (* 1 = 0.0944693 loss)
I1008 21:47:59.386721  3632 solver.cpp:590] Iteration 3600, lr = 0.0167966
I1008 21:48:04.292737  3632 solver.cpp:347] Iteration 3700, Testing net (#0)
I1008 21:48:04.294631  3632 solver.cpp:415]     Test net output #0: error_blob = 0.0991489 (* 1 = 0.0991489 loss)
I1008 21:48:04.347270  3632 solver.cpp:243] Iteration 3700, loss = 0.0971454
I1008 21:48:04.347302  3632 solver.cpp:259]     Train net output #0: error_blob = 0.0971454 (* 1 = 0.0971454 loss)
I1008 21:48:04.347309  3632 solver.cpp:590] Iteration 3700, lr = 0.0162591
I1008 21:48:09.299396  3632 solver.cpp:347] Iteration 3800, Testing net (#0)
I1008 21:48:09.301268  3632 solver.cpp:415]     Test net output #0: error_blob = 0.0994242 (* 1 = 0.0994242 loss)
I1008 21:48:09.354190  3632 solver.cpp:243] Iteration 3800, loss = 0.0953254
I1008 21:48:09.354223  3632 solver.cpp:259]     Train net output #0: error_blob = 0.0953254 (* 1 = 0.0953254 loss)
I1008 21:48:09.354233  3632 solver.cpp:590] Iteration 3800, lr = 0.015747
I1008 21:48:14.326583  3632 solver.cpp:347] Iteration 3900, Testing net (#0)
I1008 21:48:14.328498  3632 solver.cpp:415]     Test net output #0: error_blob = 0.0982466 (* 1 = 0.0982466 loss)
I1008 21:48:14.383397  3632 solver.cpp:243] Iteration 3900, loss = 0.0955843
I1008 21:48:14.383427  3632 solver.cpp:259]     Train net output #0: error_blob = 0.0955843 (* 1 = 0.0955843 loss)
I1008 21:48:14.383435  3632 solver.cpp:590] Iteration 3900, lr = 0.0152588
I1008 21:48:19.286144  3632 solver.cpp:347] Iteration 4000, Testing net (#0)
I1008 21:48:19.288018  3632 solver.cpp:415]     Test net output #0: error_blob = 0.098367 (* 1 = 0.098367 loss)
I1008 21:48:19.338384  3632 solver.cpp:243] Iteration 4000, loss = 0.0968699
I1008 21:48:19.338414  3632 solver.cpp:259]     Train net output #0: error_blob = 0.0968699 (* 1 = 0.0968699 loss)
I1008 21:48:19.338421  3632 solver.cpp:590] Iteration 4000, lr = 0.0147929
I1008 21:48:19.338503  3632 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 21:48:24.242746  3632 solver.cpp:347] Iteration 4100, Testing net (#0)
I1008 21:48:24.244657  3632 solver.cpp:415]     Test net output #0: error_blob = 0.0985319 (* 1 = 0.0985319 loss)
I1008 21:48:24.299356  3632 solver.cpp:243] Iteration 4100, loss = 0.0968358
I1008 21:48:24.299384  3632 solver.cpp:259]     Train net output #0: error_blob = 0.0968358 (* 1 = 0.0968358 loss)
I1008 21:48:24.299391  3632 solver.cpp:590] Iteration 4100, lr = 0.014348
I1008 21:48:29.217703  3632 solver.cpp:347] Iteration 4200, Testing net (#0)
I1008 21:48:29.219589  3632 solver.cpp:415]     Test net output #0: error_blob = 0.097061 (* 1 = 0.097061 loss)
I1008 21:48:29.269632  3632 solver.cpp:243] Iteration 4200, loss = 0.0967068
I1008 21:48:29.269662  3632 solver.cpp:259]     Train net output #0: error_blob = 0.0967068 (* 1 = 0.0967068 loss)
I1008 21:48:29.269670  3632 solver.cpp:590] Iteration 4200, lr = 0.0139229
I1008 21:48:34.170421  3632 solver.cpp:347] Iteration 4300, Testing net (#0)
I1008 21:48:34.172297  3632 solver.cpp:415]     Test net output #0: error_blob = 0.0982635 (* 1 = 0.0982635 loss)
I1008 21:48:34.225882  3632 solver.cpp:243] Iteration 4300, loss = 0.0951716
I1008 21:48:34.225919  3632 solver.cpp:259]     Train net output #0: error_blob = 0.0951716 (* 1 = 0.0951716 loss)
I1008 21:48:34.225925  3632 solver.cpp:590] Iteration 4300, lr = 0.0135164
I1008 21:48:39.188318  3632 solver.cpp:347] Iteration 4400, Testing net (#0)
I1008 21:48:39.190146  3632 solver.cpp:415]     Test net output #0: error_blob = 0.0983676 (* 1 = 0.0983676 loss)
I1008 21:48:39.240679  3632 solver.cpp:243] Iteration 4400, loss = 0.095769
I1008 21:48:39.240717  3632 solver.cpp:259]     Train net output #0: error_blob = 0.095769 (* 1 = 0.095769 loss)
I1008 21:48:39.240725  3632 solver.cpp:590] Iteration 4400, lr = 0.0131275
I1008 21:48:44.252183  3632 solver.cpp:347] Iteration 4500, Testing net (#0)
I1008 21:48:44.254067  3632 solver.cpp:415]     Test net output #0: error_blob = 0.0973796 (* 1 = 0.0973796 loss)
I1008 21:48:44.307153  3632 solver.cpp:243] Iteration 4500, loss = 0.0961763
I1008 21:48:44.307183  3632 solver.cpp:259]     Train net output #0: error_blob = 0.0961763 (* 1 = 0.0961763 loss)
I1008 21:48:44.307190  3632 solver.cpp:590] Iteration 4500, lr = 0.0127551
I1008 21:48:49.303063  3632 solver.cpp:347] Iteration 4600, Testing net (#0)
I1008 21:48:49.304898  3632 solver.cpp:415]     Test net output #0: error_blob = 0.0978056 (* 1 = 0.0978056 loss)
I1008 21:48:49.358296  3632 solver.cpp:243] Iteration 4600, loss = 0.0971723
I1008 21:48:49.358331  3632 solver.cpp:259]     Train net output #0: error_blob = 0.0971723 (* 1 = 0.0971723 loss)
I1008 21:48:49.358341  3632 solver.cpp:590] Iteration 4600, lr = 0.0123983
I1008 21:48:54.315783  3632 solver.cpp:347] Iteration 4700, Testing net (#0)
I1008 21:48:54.317689  3632 solver.cpp:415]     Test net output #0: error_blob = 0.0973232 (* 1 = 0.0973232 loss)
I1008 21:48:54.370698  3632 solver.cpp:243] Iteration 4700, loss = 0.0963694
I1008 21:48:54.370728  3632 solver.cpp:259]     Train net output #0: error_blob = 0.0963694 (* 1 = 0.0963694 loss)
I1008 21:48:54.370736  3632 solver.cpp:590] Iteration 4700, lr = 0.0120563
I1008 21:48:59.327095  3632 solver.cpp:347] Iteration 4800, Testing net (#0)
I1008 21:48:59.328996  3632 solver.cpp:415]     Test net output #0: error_blob = 0.0976325 (* 1 = 0.0976325 loss)
I1008 21:48:59.380828  3632 solver.cpp:243] Iteration 4800, loss = 0.0950182
I1008 21:48:59.380861  3632 solver.cpp:259]     Train net output #0: error_blob = 0.0950182 (* 1 = 0.0950182 loss)
I1008 21:48:59.380870  3632 solver.cpp:590] Iteration 4800, lr = 0.0117283
I1008 21:49:04.247709  3632 solver.cpp:347] Iteration 4900, Testing net (#0)
I1008 21:49:04.249624  3632 solver.cpp:415]     Test net output #0: error_blob = 0.0975541 (* 1 = 0.0975541 loss)
I1008 21:49:04.301203  3632 solver.cpp:243] Iteration 4900, loss = 0.0954421
I1008 21:49:04.301237  3632 solver.cpp:259]     Train net output #0: error_blob = 0.0954421 (* 1 = 0.0954421 loss)
I1008 21:49:04.301246  3632 solver.cpp:590] Iteration 4900, lr = 0.0114134
I1008 21:49:09.235291  3632 solver.cpp:468] Snapshotting to binary proto file _iter_5000.caffemodel
I1008 21:49:09.237226  3632 solver.cpp:753] Snapshotting solver state to binary proto file _iter_5000.solverstate
I1008 21:49:09.284370  3632 solver.cpp:327] Iteration 5000, loss = 0.0942963
I1008 21:49:09.284399  3632 solver.cpp:347] Iteration 5000, Testing net (#0)
I1008 21:49:09.284713  3632 solver.cpp:415]     Test net output #0: error_blob = 0.0976604 (* 1 = 0.0976604 loss)
I1008 21:49:09.284724  3632 solver.cpp:332] Optimization Done.
I1008 21:49:09.284729  3632 caffe.cpp:215] Optimization Done.
I1008 21:49:09.441485  3641 caffe.cpp:184] Using GPUs 0
I1008 21:49:10.000447  3641 solver.cpp:54] Initializing solver from parameters: 
test_iter: 1
test_interval: 100
base_lr: 0.1
display: 100
max_iter: 5000
lr_policy: "inv"
gamma: 0.0004
power: 2
momentum: 0.9
solver_mode: GPU
device_id: 0
net: "two_hidden/model3_part5.prototxt"
I1008 21:49:10.000479  3641 solver.cpp:97] Creating training net from net file: two_hidden/model3_part5.prototxt
I1008 21:49:10.000679  3641 net.cpp:339] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_layer
I1008 21:49:10.000731  3641 net.cpp:50] Initializing net from parameters: 
name: "two_hidden/model3_part5.prototxt"
state {
  phase: TRAIN
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TRAIN
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.part5.train"
    batch_size: 40000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer1"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob1"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer1"
  type: "Sigmoid"
  bottom: "hidden_sum_blob1"
  top: "hidden_act_blob1"
}
layer {
  name: "hidden_sum_layer2"
  type: "InnerProduct"
  bottom: "hidden_act_blob1"
  top: "hidden_sum_blob2"
  inner_product_param {
    num_output: 5
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer2"
  type: "Sigmoid"
  bottom: "hidden_sum_blob2"
  top: "hidden_act_blob2"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob2"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1008 21:49:10.000816  3641 layer_factory.hpp:76] Creating layer data_layer
I1008 21:49:10.027240  3641 net.cpp:110] Creating Layer data_layer
I1008 21:49:10.027268  3641 net.cpp:433] data_layer -> data_blob
I1008 21:49:10.027290  3641 net.cpp:433] data_layer -> label_blob
I1008 21:49:10.027895  3645 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.part5.train
I1008 21:49:10.713282  3641 data_layer.cpp:45] output data size: 40000,61,1,1
I1008 21:49:10.723678  3641 net.cpp:155] Setting up data_layer
I1008 21:49:10.723733  3641 net.cpp:163] Top shape: 40000 61 1 1 (2440000)
I1008 21:49:10.723737  3641 net.cpp:163] Top shape: 40000 (40000)
I1008 21:49:10.723743  3641 layer_factory.hpp:76] Creating layer hidden_sum_layer1
I1008 21:49:10.723755  3641 net.cpp:110] Creating Layer hidden_sum_layer1
I1008 21:49:10.723760  3641 net.cpp:477] hidden_sum_layer1 <- data_blob
I1008 21:49:10.723770  3641 net.cpp:433] hidden_sum_layer1 -> hidden_sum_blob1
I1008 21:49:10.724153  3641 net.cpp:155] Setting up hidden_sum_layer1
I1008 21:49:10.724161  3641 net.cpp:163] Top shape: 40000 10 (400000)
I1008 21:49:10.724184  3641 layer_factory.hpp:76] Creating layer hidden_act_layer1
I1008 21:49:10.724190  3641 net.cpp:110] Creating Layer hidden_act_layer1
I1008 21:49:10.724194  3641 net.cpp:477] hidden_act_layer1 <- hidden_sum_blob1
I1008 21:49:10.724196  3641 net.cpp:433] hidden_act_layer1 -> hidden_act_blob1
I1008 21:49:13.936342  3641 net.cpp:155] Setting up hidden_act_layer1
I1008 21:49:13.936363  3641 net.cpp:163] Top shape: 40000 10 (400000)
I1008 21:49:13.936367  3641 layer_factory.hpp:76] Creating layer hidden_sum_layer2
I1008 21:49:13.936389  3641 net.cpp:110] Creating Layer hidden_sum_layer2
I1008 21:49:13.936393  3641 net.cpp:477] hidden_sum_layer2 <- hidden_act_blob1
I1008 21:49:13.936398  3641 net.cpp:433] hidden_sum_layer2 -> hidden_sum_blob2
I1008 21:49:13.936514  3641 net.cpp:155] Setting up hidden_sum_layer2
I1008 21:49:13.936522  3641 net.cpp:163] Top shape: 40000 5 (200000)
I1008 21:49:13.936555  3641 layer_factory.hpp:76] Creating layer hidden_act_layer2
I1008 21:49:13.936563  3641 net.cpp:110] Creating Layer hidden_act_layer2
I1008 21:49:13.936565  3641 net.cpp:477] hidden_act_layer2 <- hidden_sum_blob2
I1008 21:49:13.936569  3641 net.cpp:433] hidden_act_layer2 -> hidden_act_blob2
I1008 21:49:13.936638  3641 net.cpp:155] Setting up hidden_act_layer2
I1008 21:49:13.936643  3641 net.cpp:163] Top shape: 40000 5 (200000)
I1008 21:49:13.936646  3641 layer_factory.hpp:76] Creating layer output_sum_layer
I1008 21:49:13.936650  3641 net.cpp:110] Creating Layer output_sum_layer
I1008 21:49:13.936662  3641 net.cpp:477] output_sum_layer <- hidden_act_blob2
I1008 21:49:13.936666  3641 net.cpp:433] output_sum_layer -> output_sum_blob
I1008 21:49:13.936748  3641 net.cpp:155] Setting up output_sum_layer
I1008 21:49:13.936753  3641 net.cpp:163] Top shape: 40000 1 (40000)
I1008 21:49:13.936758  3641 layer_factory.hpp:76] Creating layer output_act_layer
I1008 21:49:13.936772  3641 net.cpp:110] Creating Layer output_act_layer
I1008 21:49:13.936774  3641 net.cpp:477] output_act_layer <- output_sum_blob
I1008 21:49:13.936777  3641 net.cpp:433] output_act_layer -> output_act_blob
I1008 21:49:13.936933  3641 net.cpp:155] Setting up output_act_layer
I1008 21:49:13.936939  3641 net.cpp:163] Top shape: 40000 1 (40000)
I1008 21:49:13.936942  3641 layer_factory.hpp:76] Creating layer error_layer
I1008 21:49:13.936959  3641 net.cpp:110] Creating Layer error_layer
I1008 21:49:13.936960  3641 net.cpp:477] error_layer <- output_act_blob
I1008 21:49:13.936964  3641 net.cpp:477] error_layer <- label_blob
I1008 21:49:13.936967  3641 net.cpp:433] error_layer -> error_blob
I1008 21:49:13.936993  3641 net.cpp:155] Setting up error_layer
I1008 21:49:13.937007  3641 net.cpp:163] Top shape: (1)
I1008 21:49:13.937010  3641 net.cpp:168]     with loss weight 1
I1008 21:49:13.937036  3641 net.cpp:236] error_layer needs backward computation.
I1008 21:49:13.937038  3641 net.cpp:236] output_act_layer needs backward computation.
I1008 21:49:13.937041  3641 net.cpp:236] output_sum_layer needs backward computation.
I1008 21:49:13.937042  3641 net.cpp:236] hidden_act_layer2 needs backward computation.
I1008 21:49:13.937046  3641 net.cpp:236] hidden_sum_layer2 needs backward computation.
I1008 21:49:13.937047  3641 net.cpp:236] hidden_act_layer1 needs backward computation.
I1008 21:49:13.937049  3641 net.cpp:236] hidden_sum_layer1 needs backward computation.
I1008 21:49:13.937052  3641 net.cpp:240] data_layer does not need backward computation.
I1008 21:49:13.937053  3641 net.cpp:283] This network produces output error_blob
I1008 21:49:13.937059  3641 net.cpp:297] Network initialization done.
I1008 21:49:13.937062  3641 net.cpp:298] Memory required for data: 15040004
I1008 21:49:13.937208  3641 solver.cpp:187] Creating test net (#0) specified by net file: two_hidden/model3_part5.prototxt
I1008 21:49:13.937232  3641 net.cpp:339] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_layer
I1008 21:49:13.937278  3641 net.cpp:50] Initializing net from parameters: 
name: "two_hidden/model3_part5.prototxt"
state {
  phase: TEST
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TEST
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.part5.test"
    batch_size: 4000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer1"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob1"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer1"
  type: "Sigmoid"
  bottom: "hidden_sum_blob1"
  top: "hidden_act_blob1"
}
layer {
  name: "hidden_sum_layer2"
  type: "InnerProduct"
  bottom: "hidden_act_blob1"
  top: "hidden_sum_blob2"
  inner_product_param {
    num_output: 5
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer2"
  type: "Sigmoid"
  bottom: "hidden_sum_blob2"
  top: "hidden_act_blob2"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob2"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1008 21:49:13.937317  3641 layer_factory.hpp:76] Creating layer data_layer
I1008 21:49:13.939700  3641 net.cpp:110] Creating Layer data_layer
I1008 21:49:13.939718  3641 net.cpp:433] data_layer -> data_blob
I1008 21:49:13.939723  3641 net.cpp:433] data_layer -> label_blob
I1008 21:49:13.940289  3647 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.part5.test
I1008 21:49:13.940359  3641 data_layer.cpp:45] output data size: 4000,61,1,1
I1008 21:49:13.942335  3641 net.cpp:155] Setting up data_layer
I1008 21:49:13.942350  3641 net.cpp:163] Top shape: 4000 61 1 1 (244000)
I1008 21:49:13.942353  3641 net.cpp:163] Top shape: 4000 (4000)
I1008 21:49:13.942358  3641 layer_factory.hpp:76] Creating layer hidden_sum_layer1
I1008 21:49:13.942368  3641 net.cpp:110] Creating Layer hidden_sum_layer1
I1008 21:49:13.942370  3641 net.cpp:477] hidden_sum_layer1 <- data_blob
I1008 21:49:13.942374  3641 net.cpp:433] hidden_sum_layer1 -> hidden_sum_blob1
I1008 21:49:13.942499  3641 net.cpp:155] Setting up hidden_sum_layer1
I1008 21:49:13.942505  3641 net.cpp:163] Top shape: 4000 10 (40000)
I1008 21:49:13.942517  3641 layer_factory.hpp:76] Creating layer hidden_act_layer1
I1008 21:49:13.942526  3641 net.cpp:110] Creating Layer hidden_act_layer1
I1008 21:49:13.942530  3641 net.cpp:477] hidden_act_layer1 <- hidden_sum_blob1
I1008 21:49:13.942535  3641 net.cpp:433] hidden_act_layer1 -> hidden_act_blob1
I1008 21:49:13.942607  3641 net.cpp:155] Setting up hidden_act_layer1
I1008 21:49:13.942615  3641 net.cpp:163] Top shape: 4000 10 (40000)
I1008 21:49:13.942618  3641 layer_factory.hpp:76] Creating layer hidden_sum_layer2
I1008 21:49:13.942625  3641 net.cpp:110] Creating Layer hidden_sum_layer2
I1008 21:49:13.942631  3641 net.cpp:477] hidden_sum_layer2 <- hidden_act_blob1
I1008 21:49:13.942636  3641 net.cpp:433] hidden_sum_layer2 -> hidden_sum_blob2
I1008 21:49:13.942705  3641 net.cpp:155] Setting up hidden_sum_layer2
I1008 21:49:13.942713  3641 net.cpp:163] Top shape: 4000 5 (20000)
I1008 21:49:13.942723  3641 layer_factory.hpp:76] Creating layer hidden_act_layer2
I1008 21:49:13.942728  3641 net.cpp:110] Creating Layer hidden_act_layer2
I1008 21:49:13.942733  3641 net.cpp:477] hidden_act_layer2 <- hidden_sum_blob2
I1008 21:49:13.942737  3641 net.cpp:433] hidden_act_layer2 -> hidden_act_blob2
I1008 21:49:13.942795  3641 net.cpp:155] Setting up hidden_act_layer2
I1008 21:49:13.942803  3641 net.cpp:163] Top shape: 4000 5 (20000)
I1008 21:49:13.942808  3641 layer_factory.hpp:76] Creating layer output_sum_layer
I1008 21:49:13.942814  3641 net.cpp:110] Creating Layer output_sum_layer
I1008 21:49:13.942818  3641 net.cpp:477] output_sum_layer <- hidden_act_blob2
I1008 21:49:13.942823  3641 net.cpp:433] output_sum_layer -> output_sum_blob
I1008 21:49:13.942893  3641 net.cpp:155] Setting up output_sum_layer
I1008 21:49:13.942899  3641 net.cpp:163] Top shape: 4000 1 (4000)
I1008 21:49:13.942909  3641 layer_factory.hpp:76] Creating layer output_act_layer
I1008 21:49:13.942915  3641 net.cpp:110] Creating Layer output_act_layer
I1008 21:49:13.942920  3641 net.cpp:477] output_act_layer <- output_sum_blob
I1008 21:49:13.942925  3641 net.cpp:433] output_act_layer -> output_act_blob
I1008 21:49:13.942981  3641 net.cpp:155] Setting up output_act_layer
I1008 21:49:13.942987  3641 net.cpp:163] Top shape: 4000 1 (4000)
I1008 21:49:13.942991  3641 layer_factory.hpp:76] Creating layer error_layer
I1008 21:49:13.942998  3641 net.cpp:110] Creating Layer error_layer
I1008 21:49:13.943003  3641 net.cpp:477] error_layer <- output_act_blob
I1008 21:49:13.943020  3641 net.cpp:477] error_layer <- label_blob
I1008 21:49:13.943027  3641 net.cpp:433] error_layer -> error_blob
I1008 21:49:13.943053  3641 net.cpp:155] Setting up error_layer
I1008 21:49:13.943059  3641 net.cpp:163] Top shape: (1)
I1008 21:49:13.943063  3641 net.cpp:168]     with loss weight 1
I1008 21:49:13.943075  3641 net.cpp:236] error_layer needs backward computation.
I1008 21:49:13.943079  3641 net.cpp:236] output_act_layer needs backward computation.
I1008 21:49:13.943084  3641 net.cpp:236] output_sum_layer needs backward computation.
I1008 21:49:13.943089  3641 net.cpp:236] hidden_act_layer2 needs backward computation.
I1008 21:49:13.943094  3641 net.cpp:236] hidden_sum_layer2 needs backward computation.
I1008 21:49:13.943099  3641 net.cpp:236] hidden_act_layer1 needs backward computation.
I1008 21:49:13.943102  3641 net.cpp:236] hidden_sum_layer1 needs backward computation.
I1008 21:49:13.943109  3641 net.cpp:240] data_layer does not need backward computation.
I1008 21:49:13.943112  3641 net.cpp:283] This network produces output error_blob
I1008 21:49:13.943121  3641 net.cpp:297] Network initialization done.
I1008 21:49:13.943125  3641 net.cpp:298] Memory required for data: 1504004
I1008 21:49:13.943153  3641 solver.cpp:66] Solver scaffolding done.
I1008 21:49:13.943382  3641 caffe.cpp:212] Starting Optimization
I1008 21:49:13.943389  3641 solver.cpp:294] Solving two_hidden/model3_part5.prototxt
I1008 21:49:13.943398  3641 solver.cpp:295] Learning Rate Policy: inv
I1008 21:49:13.943568  3641 solver.cpp:347] Iteration 0, Testing net (#0)
I1008 21:49:13.943636  3641 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 21:49:13.953160  3641 solver.cpp:415]     Test net output #0: error_blob = 0.141353 (* 1 = 0.141353 loss)
I1008 21:49:13.955260  3641 solver.cpp:243] Iteration 0, loss = 0.138258
I1008 21:49:13.955276  3641 solver.cpp:259]     Train net output #0: error_blob = 0.138258 (* 1 = 0.138258 loss)
I1008 21:49:13.955296  3641 solver.cpp:590] Iteration 0, lr = 0.1
I1008 21:49:18.873899  3641 solver.cpp:347] Iteration 100, Testing net (#0)
I1008 21:49:18.875798  3641 solver.cpp:415]     Test net output #0: error_blob = 0.122541 (* 1 = 0.122541 loss)
I1008 21:49:18.927625  3641 solver.cpp:243] Iteration 100, loss = 0.122887
I1008 21:49:18.927655  3641 solver.cpp:259]     Train net output #0: error_blob = 0.122887 (* 1 = 0.122887 loss)
I1008 21:49:18.927664  3641 solver.cpp:590] Iteration 100, lr = 0.0924556
I1008 21:49:23.868818  3641 solver.cpp:347] Iteration 200, Testing net (#0)
I1008 21:49:23.870637  3641 solver.cpp:415]     Test net output #0: error_blob = 0.117288 (* 1 = 0.117288 loss)
I1008 21:49:23.922194  3641 solver.cpp:243] Iteration 200, loss = 0.11832
I1008 21:49:23.922240  3641 solver.cpp:259]     Train net output #0: error_blob = 0.11832 (* 1 = 0.11832 loss)
I1008 21:49:23.922248  3641 solver.cpp:590] Iteration 200, lr = 0.0857339
I1008 21:49:28.864387  3641 solver.cpp:347] Iteration 300, Testing net (#0)
I1008 21:49:28.866282  3641 solver.cpp:415]     Test net output #0: error_blob = 0.112079 (* 1 = 0.112079 loss)
I1008 21:49:28.915182  3641 solver.cpp:243] Iteration 300, loss = 0.112686
I1008 21:49:28.915212  3641 solver.cpp:259]     Train net output #0: error_blob = 0.112686 (* 1 = 0.112686 loss)
I1008 21:49:28.915220  3641 solver.cpp:590] Iteration 300, lr = 0.0797194
I1008 21:49:33.886736  3641 solver.cpp:347] Iteration 400, Testing net (#0)
I1008 21:49:33.888634  3641 solver.cpp:415]     Test net output #0: error_blob = 0.108925 (* 1 = 0.108925 loss)
I1008 21:49:33.939415  3641 solver.cpp:243] Iteration 400, loss = 0.110039
I1008 21:49:33.939446  3641 solver.cpp:259]     Train net output #0: error_blob = 0.110039 (* 1 = 0.110039 loss)
I1008 21:49:33.939455  3641 solver.cpp:590] Iteration 400, lr = 0.0743163
I1008 21:49:38.850013  3641 solver.cpp:347] Iteration 500, Testing net (#0)
I1008 21:49:38.851861  3641 solver.cpp:415]     Test net output #0: error_blob = 0.105558 (* 1 = 0.105558 loss)
I1008 21:49:38.907414  3641 solver.cpp:243] Iteration 500, loss = 0.106992
I1008 21:49:38.907476  3641 solver.cpp:259]     Train net output #0: error_blob = 0.106992 (* 1 = 0.106992 loss)
I1008 21:49:38.907487  3641 solver.cpp:590] Iteration 500, lr = 0.0694444
I1008 21:49:43.826820  3641 solver.cpp:347] Iteration 600, Testing net (#0)
I1008 21:49:43.828663  3641 solver.cpp:415]     Test net output #0: error_blob = 0.102503 (* 1 = 0.102503 loss)
I1008 21:49:43.883080  3641 solver.cpp:243] Iteration 600, loss = 0.106758
I1008 21:49:43.883116  3641 solver.cpp:259]     Train net output #0: error_blob = 0.106758 (* 1 = 0.106758 loss)
I1008 21:49:43.883136  3641 solver.cpp:590] Iteration 600, lr = 0.0650364
I1008 21:49:48.843531  3641 solver.cpp:347] Iteration 700, Testing net (#0)
I1008 21:49:48.845357  3641 solver.cpp:415]     Test net output #0: error_blob = 0.100561 (* 1 = 0.100561 loss)
I1008 21:49:48.898126  3641 solver.cpp:243] Iteration 700, loss = 0.104133
I1008 21:49:48.898162  3641 solver.cpp:259]     Train net output #0: error_blob = 0.104133 (* 1 = 0.104133 loss)
I1008 21:49:48.898172  3641 solver.cpp:590] Iteration 700, lr = 0.0610352
I1008 21:49:53.868218  3641 solver.cpp:347] Iteration 800, Testing net (#0)
I1008 21:49:53.870035  3641 solver.cpp:415]     Test net output #0: error_blob = 0.0993432 (* 1 = 0.0993432 loss)
I1008 21:49:53.925206  3641 solver.cpp:243] Iteration 800, loss = 0.103796
I1008 21:49:53.925240  3641 solver.cpp:259]     Train net output #0: error_blob = 0.103796 (* 1 = 0.103796 loss)
I1008 21:49:53.925259  3641 solver.cpp:590] Iteration 800, lr = 0.0573921
I1008 21:49:58.819175  3641 solver.cpp:347] Iteration 900, Testing net (#0)
I1008 21:49:58.821015  3641 solver.cpp:415]     Test net output #0: error_blob = 0.0985189 (* 1 = 0.0985189 loss)
I1008 21:49:58.873172  3641 solver.cpp:243] Iteration 900, loss = 0.102685
I1008 21:49:58.873205  3641 solver.cpp:259]     Train net output #0: error_blob = 0.102685 (* 1 = 0.102685 loss)
I1008 21:49:58.873214  3641 solver.cpp:590] Iteration 900, lr = 0.0540657
I1008 21:50:03.769217  3641 solver.cpp:347] Iteration 1000, Testing net (#0)
I1008 21:50:03.771100  3641 solver.cpp:415]     Test net output #0: error_blob = 0.0974283 (* 1 = 0.0974283 loss)
I1008 21:50:03.826441  3641 solver.cpp:243] Iteration 1000, loss = 0.101739
I1008 21:50:03.826472  3641 solver.cpp:259]     Train net output #0: error_blob = 0.101739 (* 1 = 0.101739 loss)
I1008 21:50:03.826478  3641 solver.cpp:590] Iteration 1000, lr = 0.0510204
I1008 21:50:03.826592  3641 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 21:50:08.752812  3641 solver.cpp:347] Iteration 1100, Testing net (#0)
I1008 21:50:08.754658  3641 solver.cpp:415]     Test net output #0: error_blob = 0.0969501 (* 1 = 0.0969501 loss)
I1008 21:50:08.806015  3641 solver.cpp:243] Iteration 1100, loss = 0.101443
I1008 21:50:08.806059  3641 solver.cpp:259]     Train net output #0: error_blob = 0.101443 (* 1 = 0.101443 loss)
I1008 21:50:08.806071  3641 solver.cpp:590] Iteration 1100, lr = 0.0482253
I1008 21:50:13.688614  3641 solver.cpp:347] Iteration 1200, Testing net (#0)
I1008 21:50:13.690492  3641 solver.cpp:415]     Test net output #0: error_blob = 0.0966133 (* 1 = 0.0966133 loss)
I1008 21:50:13.740808  3641 solver.cpp:243] Iteration 1200, loss = 0.102013
I1008 21:50:13.740842  3641 solver.cpp:259]     Train net output #0: error_blob = 0.102013 (* 1 = 0.102013 loss)
I1008 21:50:13.740854  3641 solver.cpp:590] Iteration 1200, lr = 0.0456538
I1008 21:50:18.731856  3641 solver.cpp:347] Iteration 1300, Testing net (#0)
I1008 21:50:18.733685  3641 solver.cpp:415]     Test net output #0: error_blob = 0.0959482 (* 1 = 0.0959482 loss)
I1008 21:50:18.784075  3641 solver.cpp:243] Iteration 1300, loss = 0.10064
I1008 21:50:18.784108  3641 solver.cpp:259]     Train net output #0: error_blob = 0.10064 (* 1 = 0.10064 loss)
I1008 21:50:18.784117  3641 solver.cpp:590] Iteration 1300, lr = 0.0432825
I1008 21:50:23.757328  3641 solver.cpp:347] Iteration 1400, Testing net (#0)
I1008 21:50:23.759165  3641 solver.cpp:415]     Test net output #0: error_blob = 0.0960384 (* 1 = 0.0960384 loss)
I1008 21:50:23.812786  3641 solver.cpp:243] Iteration 1400, loss = 0.100882
I1008 21:50:23.812824  3641 solver.cpp:259]     Train net output #0: error_blob = 0.100882 (* 1 = 0.100882 loss)
I1008 21:50:23.812831  3641 solver.cpp:590] Iteration 1400, lr = 0.0410914
I1008 21:50:28.745856  3641 solver.cpp:347] Iteration 1500, Testing net (#0)
I1008 21:50:28.747676  3641 solver.cpp:415]     Test net output #0: error_blob = 0.0956118 (* 1 = 0.0956118 loss)
I1008 21:50:28.801028  3641 solver.cpp:243] Iteration 1500, loss = 0.101451
I1008 21:50:28.801074  3641 solver.cpp:259]     Train net output #0: error_blob = 0.101451 (* 1 = 0.101451 loss)
I1008 21:50:28.801082  3641 solver.cpp:590] Iteration 1500, lr = 0.0390625
I1008 21:50:33.785239  3641 solver.cpp:347] Iteration 1600, Testing net (#0)
I1008 21:50:33.787058  3641 solver.cpp:415]     Test net output #0: error_blob = 0.0954271 (* 1 = 0.0954271 loss)
I1008 21:50:33.839094  3641 solver.cpp:243] Iteration 1600, loss = 0.100344
I1008 21:50:33.839123  3641 solver.cpp:259]     Train net output #0: error_blob = 0.100344 (* 1 = 0.100344 loss)
I1008 21:50:33.839129  3641 solver.cpp:590] Iteration 1600, lr = 0.0371803
I1008 21:50:38.715101  3641 solver.cpp:347] Iteration 1700, Testing net (#0)
I1008 21:50:38.716996  3641 solver.cpp:415]     Test net output #0: error_blob = 0.0954024 (* 1 = 0.0954024 loss)
I1008 21:50:38.771862  3641 solver.cpp:243] Iteration 1700, loss = 0.100278
I1008 21:50:38.771891  3641 solver.cpp:259]     Train net output #0: error_blob = 0.100278 (* 1 = 0.100278 loss)
I1008 21:50:38.771898  3641 solver.cpp:590] Iteration 1700, lr = 0.0354308
I1008 21:50:43.714499  3641 solver.cpp:347] Iteration 1800, Testing net (#0)
I1008 21:50:43.716393  3641 solver.cpp:415]     Test net output #0: error_blob = 0.0955104 (* 1 = 0.0955104 loss)
I1008 21:50:43.769050  3641 solver.cpp:243] Iteration 1800, loss = 0.0993974
I1008 21:50:43.769088  3641 solver.cpp:259]     Train net output #0: error_blob = 0.0993974 (* 1 = 0.0993974 loss)
I1008 21:50:43.769095  3641 solver.cpp:590] Iteration 1800, lr = 0.0338021
I1008 21:50:48.715888  3641 solver.cpp:347] Iteration 1900, Testing net (#0)
I1008 21:50:48.717733  3641 solver.cpp:415]     Test net output #0: error_blob = 0.0956596 (* 1 = 0.0956596 loss)
I1008 21:50:48.772409  3641 solver.cpp:243] Iteration 1900, loss = 0.099773
I1008 21:50:48.772532  3641 solver.cpp:259]     Train net output #0: error_blob = 0.099773 (* 1 = 0.099773 loss)
I1008 21:50:48.772542  3641 solver.cpp:590] Iteration 1900, lr = 0.0322831
I1008 21:50:53.749367  3641 solver.cpp:347] Iteration 2000, Testing net (#0)
I1008 21:50:53.751214  3641 solver.cpp:415]     Test net output #0: error_blob = 0.0953347 (* 1 = 0.0953347 loss)
I1008 21:50:53.803467  3641 solver.cpp:243] Iteration 2000, loss = 0.0986345
I1008 21:50:53.803495  3641 solver.cpp:259]     Train net output #0: error_blob = 0.0986345 (* 1 = 0.0986345 loss)
I1008 21:50:53.803501  3641 solver.cpp:590] Iteration 2000, lr = 0.0308642
I1008 21:50:53.803586  3641 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 21:50:58.689079  3641 solver.cpp:347] Iteration 2100, Testing net (#0)
I1008 21:50:58.690917  3641 solver.cpp:415]     Test net output #0: error_blob = 0.0955566 (* 1 = 0.0955566 loss)
I1008 21:50:58.742738  3641 solver.cpp:243] Iteration 2100, loss = 0.100762
I1008 21:50:58.742772  3641 solver.cpp:259]     Train net output #0: error_blob = 0.100762 (* 1 = 0.100762 loss)
I1008 21:50:58.742781  3641 solver.cpp:590] Iteration 2100, lr = 0.0295369
I1008 21:51:03.724994  3641 solver.cpp:347] Iteration 2200, Testing net (#0)
I1008 21:51:03.726861  3641 solver.cpp:415]     Test net output #0: error_blob = 0.0953249 (* 1 = 0.0953249 loss)
I1008 21:51:03.780714  3641 solver.cpp:243] Iteration 2200, loss = 0.0981727
I1008 21:51:03.780741  3641 solver.cpp:259]     Train net output #0: error_blob = 0.0981727 (* 1 = 0.0981727 loss)
I1008 21:51:03.780748  3641 solver.cpp:590] Iteration 2200, lr = 0.0282933
I1008 21:51:08.697680  3641 solver.cpp:347] Iteration 2300, Testing net (#0)
I1008 21:51:08.699563  3641 solver.cpp:415]     Test net output #0: error_blob = 0.0950616 (* 1 = 0.0950616 loss)
I1008 21:51:08.753186  3641 solver.cpp:243] Iteration 2300, loss = 0.0988474
I1008 21:51:08.753214  3641 solver.cpp:259]     Train net output #0: error_blob = 0.0988474 (* 1 = 0.0988474 loss)
I1008 21:51:08.753221  3641 solver.cpp:590] Iteration 2300, lr = 0.0271267
I1008 21:51:13.679286  3641 solver.cpp:347] Iteration 2400, Testing net (#0)
I1008 21:51:13.681140  3641 solver.cpp:415]     Test net output #0: error_blob = 0.0946142 (* 1 = 0.0946142 loss)
I1008 21:51:13.732022  3641 solver.cpp:243] Iteration 2400, loss = 0.0977892
I1008 21:51:13.732058  3641 solver.cpp:259]     Train net output #0: error_blob = 0.0977892 (* 1 = 0.0977892 loss)
I1008 21:51:13.732069  3641 solver.cpp:590] Iteration 2400, lr = 0.0260308
I1008 21:51:18.717238  3641 solver.cpp:347] Iteration 2500, Testing net (#0)
I1008 21:51:18.719120  3641 solver.cpp:415]     Test net output #0: error_blob = 0.0945397 (* 1 = 0.0945397 loss)
I1008 21:51:18.772933  3641 solver.cpp:243] Iteration 2500, loss = 0.0974416
I1008 21:51:18.773020  3641 solver.cpp:259]     Train net output #0: error_blob = 0.0974416 (* 1 = 0.0974416 loss)
I1008 21:51:18.773027  3641 solver.cpp:590] Iteration 2500, lr = 0.025
I1008 21:51:23.743307  3641 solver.cpp:347] Iteration 2600, Testing net (#0)
I1008 21:51:23.745141  3641 solver.cpp:415]     Test net output #0: error_blob = 0.0943636 (* 1 = 0.0943636 loss)
I1008 21:51:23.797049  3641 solver.cpp:243] Iteration 2600, loss = 0.0974035
I1008 21:51:23.797083  3641 solver.cpp:259]     Train net output #0: error_blob = 0.0974035 (* 1 = 0.0974035 loss)
I1008 21:51:23.797092  3641 solver.cpp:590] Iteration 2600, lr = 0.0240292
I1008 21:51:28.734201  3641 solver.cpp:347] Iteration 2700, Testing net (#0)
I1008 21:51:28.736093  3641 solver.cpp:415]     Test net output #0: error_blob = 0.0945282 (* 1 = 0.0945282 loss)
I1008 21:51:28.788765  3641 solver.cpp:243] Iteration 2700, loss = 0.0983251
I1008 21:51:28.788795  3641 solver.cpp:259]     Train net output #0: error_blob = 0.0983251 (* 1 = 0.0983251 loss)
I1008 21:51:28.788805  3641 solver.cpp:590] Iteration 2700, lr = 0.0231139
I1008 21:51:33.722040  3641 solver.cpp:347] Iteration 2800, Testing net (#0)
I1008 21:51:33.723917  3641 solver.cpp:415]     Test net output #0: error_blob = 0.0943902 (* 1 = 0.0943902 loss)
I1008 21:51:33.774121  3641 solver.cpp:243] Iteration 2800, loss = 0.0971043
I1008 21:51:33.774152  3641 solver.cpp:259]     Train net output #0: error_blob = 0.0971043 (* 1 = 0.0971043 loss)
I1008 21:51:33.774161  3641 solver.cpp:590] Iteration 2800, lr = 0.0222499
I1008 21:51:38.758563  3641 solver.cpp:347] Iteration 2900, Testing net (#0)
I1008 21:51:38.760437  3641 solver.cpp:415]     Test net output #0: error_blob = 0.0941891 (* 1 = 0.0941891 loss)
I1008 21:51:38.811648  3641 solver.cpp:243] Iteration 2900, loss = 0.0979003
I1008 21:51:38.811678  3641 solver.cpp:259]     Train net output #0: error_blob = 0.0979003 (* 1 = 0.0979003 loss)
I1008 21:51:38.811686  3641 solver.cpp:590] Iteration 2900, lr = 0.0214335
I1008 21:51:43.744863  3641 solver.cpp:347] Iteration 3000, Testing net (#0)
I1008 21:51:43.746742  3641 solver.cpp:415]     Test net output #0: error_blob = 0.094392 (* 1 = 0.094392 loss)
I1008 21:51:43.801036  3641 solver.cpp:243] Iteration 3000, loss = 0.0986091
I1008 21:51:43.801065  3641 solver.cpp:259]     Train net output #0: error_blob = 0.0986091 (* 1 = 0.0986091 loss)
I1008 21:51:43.801072  3641 solver.cpp:590] Iteration 3000, lr = 0.0206612
I1008 21:51:43.801161  3641 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 21:51:48.696352  3641 solver.cpp:347] Iteration 3100, Testing net (#0)
I1008 21:51:48.698227  3641 solver.cpp:415]     Test net output #0: error_blob = 0.0941401 (* 1 = 0.0941401 loss)
I1008 21:51:48.748873  3641 solver.cpp:243] Iteration 3100, loss = 0.0974984
I1008 21:51:48.748903  3641 solver.cpp:259]     Train net output #0: error_blob = 0.0974984 (* 1 = 0.0974984 loss)
I1008 21:51:48.748909  3641 solver.cpp:590] Iteration 3100, lr = 0.0199298
I1008 21:51:53.668540  3641 solver.cpp:347] Iteration 3200, Testing net (#0)
I1008 21:51:53.670420  3641 solver.cpp:415]     Test net output #0: error_blob = 0.0942485 (* 1 = 0.0942485 loss)
I1008 21:51:53.720608  3641 solver.cpp:243] Iteration 3200, loss = 0.0975506
I1008 21:51:53.720636  3641 solver.cpp:259]     Train net output #0: error_blob = 0.0975506 (* 1 = 0.0975506 loss)
I1008 21:51:53.720643  3641 solver.cpp:590] Iteration 3200, lr = 0.0192367
I1008 21:51:58.594184  3641 solver.cpp:347] Iteration 3300, Testing net (#0)
I1008 21:51:58.596077  3641 solver.cpp:415]     Test net output #0: error_blob = 0.0945194 (* 1 = 0.0945194 loss)
I1008 21:51:58.646049  3641 solver.cpp:243] Iteration 3300, loss = 0.0971254
I1008 21:51:58.646080  3641 solver.cpp:259]     Train net output #0: error_blob = 0.0971254 (* 1 = 0.0971254 loss)
I1008 21:51:58.646086  3641 solver.cpp:590] Iteration 3300, lr = 0.0185791
I1008 21:52:03.534076  3641 solver.cpp:347] Iteration 3400, Testing net (#0)
I1008 21:52:03.535980  3641 solver.cpp:415]     Test net output #0: error_blob = 0.0947896 (* 1 = 0.0947896 loss)
I1008 21:52:03.586233  3641 solver.cpp:243] Iteration 3400, loss = 0.0974062
I1008 21:52:03.586261  3641 solver.cpp:259]     Train net output #0: error_blob = 0.0974062 (* 1 = 0.0974062 loss)
I1008 21:52:03.586266  3641 solver.cpp:590] Iteration 3400, lr = 0.0179546
I1008 21:52:08.525821  3641 solver.cpp:347] Iteration 3500, Testing net (#0)
I1008 21:52:08.527672  3641 solver.cpp:415]     Test net output #0: error_blob = 0.0945692 (* 1 = 0.0945692 loss)
I1008 21:52:08.578269  3641 solver.cpp:243] Iteration 3500, loss = 0.0965433
I1008 21:52:08.578295  3641 solver.cpp:259]     Train net output #0: error_blob = 0.0965433 (* 1 = 0.0965433 loss)
I1008 21:52:08.578302  3641 solver.cpp:590] Iteration 3500, lr = 0.0173611
I1008 21:52:13.550268  3641 solver.cpp:347] Iteration 3600, Testing net (#0)
I1008 21:52:13.552167  3641 solver.cpp:415]     Test net output #0: error_blob = 0.094692 (* 1 = 0.094692 loss)
I1008 21:52:13.603890  3641 solver.cpp:243] Iteration 3600, loss = 0.0988949
I1008 21:52:13.603917  3641 solver.cpp:259]     Train net output #0: error_blob = 0.0988949 (* 1 = 0.0988949 loss)
I1008 21:52:13.603924  3641 solver.cpp:590] Iteration 3600, lr = 0.0167966
I1008 21:52:18.489619  3641 solver.cpp:347] Iteration 3700, Testing net (#0)
I1008 21:52:18.491529  3641 solver.cpp:415]     Test net output #0: error_blob = 0.094627 (* 1 = 0.094627 loss)
I1008 21:52:18.542701  3641 solver.cpp:243] Iteration 3700, loss = 0.0962414
I1008 21:52:18.542733  3641 solver.cpp:259]     Train net output #0: error_blob = 0.0962414 (* 1 = 0.0962414 loss)
I1008 21:52:18.542739  3641 solver.cpp:590] Iteration 3700, lr = 0.0162591
I1008 21:52:23.457721  3641 solver.cpp:347] Iteration 3800, Testing net (#0)
I1008 21:52:23.459559  3641 solver.cpp:415]     Test net output #0: error_blob = 0.0947683 (* 1 = 0.0947683 loss)
I1008 21:52:23.512260  3641 solver.cpp:243] Iteration 3800, loss = 0.0969238
I1008 21:52:23.512289  3641 solver.cpp:259]     Train net output #0: error_blob = 0.0969238 (* 1 = 0.0969238 loss)
I1008 21:52:23.512295  3641 solver.cpp:590] Iteration 3800, lr = 0.015747
I1008 21:52:28.444118  3641 solver.cpp:347] Iteration 3900, Testing net (#0)
I1008 21:52:28.446002  3641 solver.cpp:415]     Test net output #0: error_blob = 0.094714 (* 1 = 0.094714 loss)
I1008 21:52:28.497166  3641 solver.cpp:243] Iteration 3900, loss = 0.0960885
I1008 21:52:28.497195  3641 solver.cpp:259]     Train net output #0: error_blob = 0.0960885 (* 1 = 0.0960885 loss)
I1008 21:52:28.497201  3641 solver.cpp:590] Iteration 3900, lr = 0.0152588
I1008 21:52:33.406008  3641 solver.cpp:347] Iteration 4000, Testing net (#0)
I1008 21:52:33.407907  3641 solver.cpp:415]     Test net output #0: error_blob = 0.0945759 (* 1 = 0.0945759 loss)
I1008 21:52:33.457212  3641 solver.cpp:243] Iteration 4000, loss = 0.0957001
I1008 21:52:33.457252  3641 solver.cpp:259]     Train net output #0: error_blob = 0.0957001 (* 1 = 0.0957001 loss)
I1008 21:52:33.457259  3641 solver.cpp:590] Iteration 4000, lr = 0.0147929
I1008 21:52:33.457381  3641 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 21:52:38.388130  3641 solver.cpp:347] Iteration 4100, Testing net (#0)
I1008 21:52:38.390043  3641 solver.cpp:415]     Test net output #0: error_blob = 0.0944008 (* 1 = 0.0944008 loss)
I1008 21:52:38.441958  3641 solver.cpp:243] Iteration 4100, loss = 0.0957415
I1008 21:52:38.441994  3641 solver.cpp:259]     Train net output #0: error_blob = 0.0957415 (* 1 = 0.0957415 loss)
I1008 21:52:38.442004  3641 solver.cpp:590] Iteration 4100, lr = 0.014348
I1008 21:52:43.372514  3641 solver.cpp:347] Iteration 4200, Testing net (#0)
I1008 21:52:43.374325  3641 solver.cpp:415]     Test net output #0: error_blob = 0.0945233 (* 1 = 0.0945233 loss)
I1008 21:52:43.425634  3641 solver.cpp:243] Iteration 4200, loss = 0.0966427
I1008 21:52:43.425667  3641 solver.cpp:259]     Train net output #0: error_blob = 0.0966427 (* 1 = 0.0966427 loss)
I1008 21:52:43.425675  3641 solver.cpp:590] Iteration 4200, lr = 0.0139229
I1008 21:52:48.380048  3641 solver.cpp:347] Iteration 4300, Testing net (#0)
I1008 21:52:48.381902  3641 solver.cpp:415]     Test net output #0: error_blob = 0.0945324 (* 1 = 0.0945324 loss)
I1008 21:52:48.433195  3641 solver.cpp:243] Iteration 4300, loss = 0.0956829
I1008 21:52:48.433228  3641 solver.cpp:259]     Train net output #0: error_blob = 0.0956829 (* 1 = 0.0956829 loss)
I1008 21:52:48.433238  3641 solver.cpp:590] Iteration 4300, lr = 0.0135164
I1008 21:52:53.361112  3641 solver.cpp:347] Iteration 4400, Testing net (#0)
I1008 21:52:53.363013  3641 solver.cpp:415]     Test net output #0: error_blob = 0.0944525 (* 1 = 0.0944525 loss)
I1008 21:52:53.414372  3641 solver.cpp:243] Iteration 4400, loss = 0.0967804
I1008 21:52:53.414405  3641 solver.cpp:259]     Train net output #0: error_blob = 0.0967804 (* 1 = 0.0967804 loss)
I1008 21:52:53.414414  3641 solver.cpp:590] Iteration 4400, lr = 0.0131275
I1008 21:52:58.435653  3641 solver.cpp:347] Iteration 4500, Testing net (#0)
I1008 21:52:58.437592  3641 solver.cpp:415]     Test net output #0: error_blob = 0.0943768 (* 1 = 0.0943768 loss)
I1008 21:52:58.489408  3641 solver.cpp:243] Iteration 4500, loss = 0.0972219
I1008 21:52:58.489497  3641 solver.cpp:259]     Train net output #0: error_blob = 0.0972219 (* 1 = 0.0972219 loss)
I1008 21:52:58.489506  3641 solver.cpp:590] Iteration 4500, lr = 0.0127551
I1008 21:53:03.375984  3641 solver.cpp:347] Iteration 4600, Testing net (#0)
I1008 21:53:03.377903  3641 solver.cpp:415]     Test net output #0: error_blob = 0.0943472 (* 1 = 0.0943472 loss)
I1008 21:53:03.428349  3641 solver.cpp:243] Iteration 4600, loss = 0.096191
I1008 21:53:03.428378  3641 solver.cpp:259]     Train net output #0: error_blob = 0.096191 (* 1 = 0.096191 loss)
I1008 21:53:03.428385  3641 solver.cpp:590] Iteration 4600, lr = 0.0123983
I1008 21:53:08.341405  3641 solver.cpp:347] Iteration 4700, Testing net (#0)
I1008 21:53:08.343250  3641 solver.cpp:415]     Test net output #0: error_blob = 0.0942499 (* 1 = 0.0942499 loss)
I1008 21:53:08.392907  3641 solver.cpp:243] Iteration 4700, loss = 0.0962485
I1008 21:53:08.392941  3641 solver.cpp:259]     Train net output #0: error_blob = 0.0962485 (* 1 = 0.0962485 loss)
I1008 21:53:08.392951  3641 solver.cpp:590] Iteration 4700, lr = 0.0120563
I1008 21:53:13.280764  3641 solver.cpp:347] Iteration 4800, Testing net (#0)
I1008 21:53:13.282616  3641 solver.cpp:415]     Test net output #0: error_blob = 0.0941811 (* 1 = 0.0941811 loss)
I1008 21:53:13.333106  3641 solver.cpp:243] Iteration 4800, loss = 0.0960326
I1008 21:53:13.333132  3641 solver.cpp:259]     Train net output #0: error_blob = 0.0960326 (* 1 = 0.0960326 loss)
I1008 21:53:13.333139  3641 solver.cpp:590] Iteration 4800, lr = 0.0117283
I1008 21:53:18.252645  3641 solver.cpp:347] Iteration 4900, Testing net (#0)
I1008 21:53:18.254513  3641 solver.cpp:415]     Test net output #0: error_blob = 0.0944049 (* 1 = 0.0944049 loss)
I1008 21:53:18.305773  3641 solver.cpp:243] Iteration 4900, loss = 0.0963405
I1008 21:53:18.305809  3641 solver.cpp:259]     Train net output #0: error_blob = 0.0963405 (* 1 = 0.0963405 loss)
I1008 21:53:18.305819  3641 solver.cpp:590] Iteration 4900, lr = 0.0114134
I1008 21:53:23.241665  3641 solver.cpp:468] Snapshotting to binary proto file _iter_5000.caffemodel
I1008 21:53:23.243585  3641 solver.cpp:753] Snapshotting solver state to binary proto file _iter_5000.solverstate
I1008 21:53:23.293385  3641 solver.cpp:327] Iteration 5000, loss = 0.0955767
I1008 21:53:23.293413  3641 solver.cpp:347] Iteration 5000, Testing net (#0)
I1008 21:53:23.293751  3641 solver.cpp:415]     Test net output #0: error_blob = 0.0944012 (* 1 = 0.0944012 loss)
I1008 21:53:23.293758  3641 solver.cpp:332] Optimization Done.
I1008 21:53:23.293762  3641 caffe.cpp:215] Optimization Done.
I1008 21:53:23.419734  3656 caffe.cpp:184] Using GPUs 0
I1008 21:53:23.983285  3656 solver.cpp:54] Initializing solver from parameters: 
base_lr: 0.1
display: 100
max_iter: 5000
lr_policy: "inv"
gamma: 0.0004
power: 2
momentum: 0.9
solver_mode: GPU
device_id: 0
net: "two_hidden/model3_full.prototxt"
I1008 21:53:23.983316  3656 solver.cpp:97] Creating training net from net file: two_hidden/model3_full.prototxt
I1008 21:53:23.983525  3656 net.cpp:50] Initializing net from parameters: 
name: "two_hidden/model3_full.prototxt"
state {
  phase: TRAIN
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.full"
    batch_size: 40000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer1"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob1"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer1"
  type: "Sigmoid"
  bottom: "hidden_sum_blob1"
  top: "hidden_act_blob1"
}
layer {
  name: "hidden_sum_layer2"
  type: "InnerProduct"
  bottom: "hidden_act_blob1"
  top: "hidden_sum_blob2"
  inner_product_param {
    num_output: 5
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer2"
  type: "Sigmoid"
  bottom: "hidden_sum_blob2"
  top: "hidden_act_blob2"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob2"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1008 21:53:23.983577  3656 layer_factory.hpp:76] Creating layer data_layer
I1008 21:53:24.010185  3656 net.cpp:110] Creating Layer data_layer
I1008 21:53:24.010206  3656 net.cpp:433] data_layer -> data_blob
I1008 21:53:24.010229  3656 net.cpp:433] data_layer -> label_blob
I1008 21:53:24.010795  3660 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.full
I1008 21:53:24.696002  3656 data_layer.cpp:45] output data size: 40000,61,1,1
I1008 21:53:24.706534  3656 net.cpp:155] Setting up data_layer
I1008 21:53:24.706584  3656 net.cpp:163] Top shape: 40000 61 1 1 (2440000)
I1008 21:53:24.706591  3656 net.cpp:163] Top shape: 40000 (40000)
I1008 21:53:24.706598  3656 layer_factory.hpp:76] Creating layer hidden_sum_layer1
I1008 21:53:24.706612  3656 net.cpp:110] Creating Layer hidden_sum_layer1
I1008 21:53:24.706619  3656 net.cpp:477] hidden_sum_layer1 <- data_blob
I1008 21:53:24.706631  3656 net.cpp:433] hidden_sum_layer1 -> hidden_sum_blob1
I1008 21:53:24.707036  3656 net.cpp:155] Setting up hidden_sum_layer1
I1008 21:53:24.707042  3656 net.cpp:163] Top shape: 40000 10 (400000)
I1008 21:53:24.707057  3656 layer_factory.hpp:76] Creating layer hidden_act_layer1
I1008 21:53:24.707067  3656 net.cpp:110] Creating Layer hidden_act_layer1
I1008 21:53:24.707072  3656 net.cpp:477] hidden_act_layer1 <- hidden_sum_blob1
I1008 21:53:24.707077  3656 net.cpp:433] hidden_act_layer1 -> hidden_act_blob1
I1008 21:53:27.937367  3656 net.cpp:155] Setting up hidden_act_layer1
I1008 21:53:27.937398  3656 net.cpp:163] Top shape: 40000 10 (400000)
I1008 21:53:27.937403  3656 layer_factory.hpp:76] Creating layer hidden_sum_layer2
I1008 21:53:27.937415  3656 net.cpp:110] Creating Layer hidden_sum_layer2
I1008 21:53:27.937418  3656 net.cpp:477] hidden_sum_layer2 <- hidden_act_blob1
I1008 21:53:27.937427  3656 net.cpp:433] hidden_sum_layer2 -> hidden_sum_blob2
I1008 21:53:27.938307  3656 net.cpp:155] Setting up hidden_sum_layer2
I1008 21:53:27.938314  3656 net.cpp:163] Top shape: 40000 5 (200000)
I1008 21:53:27.938321  3656 layer_factory.hpp:76] Creating layer hidden_act_layer2
I1008 21:53:27.938328  3656 net.cpp:110] Creating Layer hidden_act_layer2
I1008 21:53:27.938331  3656 net.cpp:477] hidden_act_layer2 <- hidden_sum_blob2
I1008 21:53:27.938359  3656 net.cpp:433] hidden_act_layer2 -> hidden_act_blob2
I1008 21:53:27.938434  3656 net.cpp:155] Setting up hidden_act_layer2
I1008 21:53:27.938441  3656 net.cpp:163] Top shape: 40000 5 (200000)
I1008 21:53:27.938443  3656 layer_factory.hpp:76] Creating layer output_sum_layer
I1008 21:53:27.938448  3656 net.cpp:110] Creating Layer output_sum_layer
I1008 21:53:27.938452  3656 net.cpp:477] output_sum_layer <- hidden_act_blob2
I1008 21:53:27.938467  3656 net.cpp:433] output_sum_layer -> output_sum_blob
I1008 21:53:27.938567  3656 net.cpp:155] Setting up output_sum_layer
I1008 21:53:27.938572  3656 net.cpp:163] Top shape: 40000 1 (40000)
I1008 21:53:27.938580  3656 layer_factory.hpp:76] Creating layer output_act_layer
I1008 21:53:27.938585  3656 net.cpp:110] Creating Layer output_act_layer
I1008 21:53:27.938588  3656 net.cpp:477] output_act_layer <- output_sum_blob
I1008 21:53:27.938593  3656 net.cpp:433] output_act_layer -> output_act_blob
I1008 21:53:27.938737  3656 net.cpp:155] Setting up output_act_layer
I1008 21:53:27.938745  3656 net.cpp:163] Top shape: 40000 1 (40000)
I1008 21:53:27.938748  3656 layer_factory.hpp:76] Creating layer error_layer
I1008 21:53:27.938756  3656 net.cpp:110] Creating Layer error_layer
I1008 21:53:27.938760  3656 net.cpp:477] error_layer <- output_act_blob
I1008 21:53:27.938765  3656 net.cpp:477] error_layer <- label_blob
I1008 21:53:27.938771  3656 net.cpp:433] error_layer -> error_blob
I1008 21:53:27.938802  3656 net.cpp:155] Setting up error_layer
I1008 21:53:27.938807  3656 net.cpp:163] Top shape: (1)
I1008 21:53:27.938809  3656 net.cpp:168]     with loss weight 1
I1008 21:53:27.938829  3656 net.cpp:236] error_layer needs backward computation.
I1008 21:53:27.938833  3656 net.cpp:236] output_act_layer needs backward computation.
I1008 21:53:27.938837  3656 net.cpp:236] output_sum_layer needs backward computation.
I1008 21:53:27.938841  3656 net.cpp:236] hidden_act_layer2 needs backward computation.
I1008 21:53:27.938846  3656 net.cpp:236] hidden_sum_layer2 needs backward computation.
I1008 21:53:27.938850  3656 net.cpp:236] hidden_act_layer1 needs backward computation.
I1008 21:53:27.938853  3656 net.cpp:236] hidden_sum_layer1 needs backward computation.
I1008 21:53:27.938858  3656 net.cpp:240] data_layer does not need backward computation.
I1008 21:53:27.938860  3656 net.cpp:283] This network produces output error_blob
I1008 21:53:27.938869  3656 net.cpp:297] Network initialization done.
I1008 21:53:27.938873  3656 net.cpp:298] Memory required for data: 15040004
I1008 21:53:27.938901  3656 solver.cpp:66] Solver scaffolding done.
I1008 21:53:27.939026  3656 caffe.cpp:212] Starting Optimization
I1008 21:53:27.939033  3656 solver.cpp:294] Solving two_hidden/model3_full.prototxt
I1008 21:53:27.939035  3656 solver.cpp:295] Learning Rate Policy: inv
I1008 21:53:27.941373  3656 solver.cpp:243] Iteration 0, loss = 0.127742
I1008 21:53:27.941387  3656 solver.cpp:259]     Train net output #0: error_blob = 0.127742 (* 1 = 0.127742 loss)
I1008 21:53:27.941403  3656 solver.cpp:590] Iteration 0, lr = 0.1
I1008 21:53:27.944082  3656 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 21:53:33.052340  3656 solver.cpp:243] Iteration 100, loss = 0.120969
I1008 21:53:33.052388  3656 solver.cpp:259]     Train net output #0: error_blob = 0.120969 (* 1 = 0.120969 loss)
I1008 21:53:33.052400  3656 solver.cpp:590] Iteration 100, lr = 0.0924556
I1008 21:53:38.183174  3656 solver.cpp:243] Iteration 200, loss = 0.115274
I1008 21:53:38.183217  3656 solver.cpp:259]     Train net output #0: error_blob = 0.115274 (* 1 = 0.115274 loss)
I1008 21:53:38.183224  3656 solver.cpp:590] Iteration 200, lr = 0.0857339
I1008 21:53:43.238217  3656 solver.cpp:243] Iteration 300, loss = 0.111026
I1008 21:53:43.238265  3656 solver.cpp:259]     Train net output #0: error_blob = 0.111026 (* 1 = 0.111026 loss)
I1008 21:53:43.238276  3656 solver.cpp:590] Iteration 300, lr = 0.0797194
I1008 21:53:48.334074  3656 solver.cpp:243] Iteration 400, loss = 0.107493
I1008 21:53:48.334143  3656 solver.cpp:259]     Train net output #0: error_blob = 0.107493 (* 1 = 0.107493 loss)
I1008 21:53:48.334152  3656 solver.cpp:590] Iteration 400, lr = 0.0743163
I1008 21:53:53.500047  3656 solver.cpp:243] Iteration 500, loss = 0.105542
I1008 21:53:53.501878  3656 solver.cpp:259]     Train net output #0: error_blob = 0.105542 (* 1 = 0.105542 loss)
I1008 21:53:53.501890  3656 solver.cpp:590] Iteration 500, lr = 0.0694444
I1008 21:53:58.731375  3656 solver.cpp:243] Iteration 600, loss = 0.104365
I1008 21:53:58.731420  3656 solver.cpp:259]     Train net output #0: error_blob = 0.104365 (* 1 = 0.104365 loss)
I1008 21:53:58.731431  3656 solver.cpp:590] Iteration 600, lr = 0.0650364
I1008 21:54:03.902724  3656 solver.cpp:243] Iteration 700, loss = 0.103362
I1008 21:54:03.902755  3656 solver.cpp:259]     Train net output #0: error_blob = 0.103362 (* 1 = 0.103362 loss)
I1008 21:54:03.902761  3656 solver.cpp:590] Iteration 700, lr = 0.0610352
I1008 21:54:09.046784  3656 solver.cpp:243] Iteration 800, loss = 0.10292
I1008 21:54:09.046816  3656 solver.cpp:259]     Train net output #0: error_blob = 0.10292 (* 1 = 0.10292 loss)
I1008 21:54:09.046823  3656 solver.cpp:590] Iteration 800, lr = 0.0573921
I1008 21:54:14.137961  3656 solver.cpp:243] Iteration 900, loss = 0.101738
I1008 21:54:14.138008  3656 solver.cpp:259]     Train net output #0: error_blob = 0.101738 (* 1 = 0.101738 loss)
I1008 21:54:14.138017  3656 solver.cpp:590] Iteration 900, lr = 0.0540657
I1008 21:54:19.295420  3656 solver.cpp:243] Iteration 1000, loss = 0.101408
I1008 21:54:19.295456  3656 solver.cpp:259]     Train net output #0: error_blob = 0.101408 (* 1 = 0.101408 loss)
I1008 21:54:19.295464  3656 solver.cpp:590] Iteration 1000, lr = 0.0510204
I1008 21:54:19.347177  3656 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 21:54:24.469730  3656 solver.cpp:243] Iteration 1100, loss = 0.100899
I1008 21:54:24.469812  3656 solver.cpp:259]     Train net output #0: error_blob = 0.100899 (* 1 = 0.100899 loss)
I1008 21:54:24.469825  3656 solver.cpp:590] Iteration 1100, lr = 0.0482253
I1008 21:54:29.566121  3656 solver.cpp:243] Iteration 1200, loss = 0.10108
I1008 21:54:29.566162  3656 solver.cpp:259]     Train net output #0: error_blob = 0.10108 (* 1 = 0.10108 loss)
I1008 21:54:29.566170  3656 solver.cpp:590] Iteration 1200, lr = 0.0456538
I1008 21:54:34.656368  3656 solver.cpp:243] Iteration 1300, loss = 0.100959
I1008 21:54:34.656416  3656 solver.cpp:259]     Train net output #0: error_blob = 0.100959 (* 1 = 0.100959 loss)
I1008 21:54:34.656427  3656 solver.cpp:590] Iteration 1300, lr = 0.0432825
I1008 21:54:39.796216  3656 solver.cpp:243] Iteration 1400, loss = 0.100164
I1008 21:54:39.796260  3656 solver.cpp:259]     Train net output #0: error_blob = 0.100164 (* 1 = 0.100164 loss)
I1008 21:54:39.796270  3656 solver.cpp:590] Iteration 1400, lr = 0.0410914
I1008 21:54:44.977962  3656 solver.cpp:243] Iteration 1500, loss = 0.100059
I1008 21:54:44.978005  3656 solver.cpp:259]     Train net output #0: error_blob = 0.100059 (* 1 = 0.100059 loss)
I1008 21:54:44.978015  3656 solver.cpp:590] Iteration 1500, lr = 0.0390625
I1008 21:54:50.255364  3656 solver.cpp:243] Iteration 1600, loss = 0.0993001
I1008 21:54:50.255409  3656 solver.cpp:259]     Train net output #0: error_blob = 0.0993001 (* 1 = 0.0993001 loss)
I1008 21:54:50.255421  3656 solver.cpp:590] Iteration 1600, lr = 0.0371803
I1008 21:54:55.437815  3656 solver.cpp:243] Iteration 1700, loss = 0.0983499
I1008 21:54:55.437897  3656 solver.cpp:259]     Train net output #0: error_blob = 0.0983499 (* 1 = 0.0983499 loss)
I1008 21:54:55.437911  3656 solver.cpp:590] Iteration 1700, lr = 0.0354308
I1008 21:55:00.630681  3656 solver.cpp:243] Iteration 1800, loss = 0.099079
I1008 21:55:00.630728  3656 solver.cpp:259]     Train net output #0: error_blob = 0.099079 (* 1 = 0.099079 loss)
I1008 21:55:00.630738  3656 solver.cpp:590] Iteration 1800, lr = 0.0338021
I1008 21:55:05.748363  3656 solver.cpp:243] Iteration 1900, loss = 0.0986212
I1008 21:55:05.748409  3656 solver.cpp:259]     Train net output #0: error_blob = 0.0986212 (* 1 = 0.0986212 loss)
I1008 21:55:05.748420  3656 solver.cpp:590] Iteration 1900, lr = 0.0322831
I1008 21:55:10.892513  3656 solver.cpp:243] Iteration 2000, loss = 0.0986245
I1008 21:55:10.892554  3656 solver.cpp:259]     Train net output #0: error_blob = 0.0986245 (* 1 = 0.0986245 loss)
I1008 21:55:10.892560  3656 solver.cpp:590] Iteration 2000, lr = 0.0308642
I1008 21:55:10.942404  3656 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 21:55:15.923177  3656 solver.cpp:243] Iteration 2100, loss = 0.0988408
I1008 21:55:15.923213  3656 solver.cpp:259]     Train net output #0: error_blob = 0.0988408 (* 1 = 0.0988408 loss)
I1008 21:55:15.923223  3656 solver.cpp:590] Iteration 2100, lr = 0.0295369
I1008 21:55:21.003214  3656 solver.cpp:243] Iteration 2200, loss = 0.098616
I1008 21:55:21.003254  3656 solver.cpp:259]     Train net output #0: error_blob = 0.098616 (* 1 = 0.098616 loss)
I1008 21:55:21.003262  3656 solver.cpp:590] Iteration 2200, lr = 0.0282933
I1008 21:55:26.136153  3656 solver.cpp:243] Iteration 2300, loss = 0.0981966
I1008 21:55:26.136247  3656 solver.cpp:259]     Train net output #0: error_blob = 0.0981966 (* 1 = 0.0981966 loss)
I1008 21:55:26.136256  3656 solver.cpp:590] Iteration 2300, lr = 0.0271267
I1008 21:55:31.243252  3656 solver.cpp:243] Iteration 2400, loss = 0.0973785
I1008 21:55:31.243285  3656 solver.cpp:259]     Train net output #0: error_blob = 0.0973785 (* 1 = 0.0973785 loss)
I1008 21:55:31.243296  3656 solver.cpp:590] Iteration 2400, lr = 0.0260308
I1008 21:55:36.418947  3656 solver.cpp:243] Iteration 2500, loss = 0.097575
I1008 21:55:36.418992  3656 solver.cpp:259]     Train net output #0: error_blob = 0.097575 (* 1 = 0.097575 loss)
I1008 21:55:36.419003  3656 solver.cpp:590] Iteration 2500, lr = 0.025
I1008 21:55:41.554604  3656 solver.cpp:243] Iteration 2600, loss = 0.0976267
I1008 21:55:41.554646  3656 solver.cpp:259]     Train net output #0: error_blob = 0.0976267 (* 1 = 0.0976267 loss)
I1008 21:55:41.554656  3656 solver.cpp:590] Iteration 2600, lr = 0.0240292
I1008 21:55:46.778939  3656 solver.cpp:243] Iteration 2700, loss = 0.0983107
I1008 21:55:46.778978  3656 solver.cpp:259]     Train net output #0: error_blob = 0.0983107 (* 1 = 0.0983107 loss)
I1008 21:55:46.778985  3656 solver.cpp:590] Iteration 2700, lr = 0.0231139
I1008 21:55:51.872123  3656 solver.cpp:243] Iteration 2800, loss = 0.0972886
I1008 21:55:51.872164  3656 solver.cpp:259]     Train net output #0: error_blob = 0.0972886 (* 1 = 0.0972886 loss)
I1008 21:55:51.872171  3656 solver.cpp:590] Iteration 2800, lr = 0.0222499
I1008 21:55:57.016952  3656 solver.cpp:243] Iteration 2900, loss = 0.0973491
I1008 21:55:57.017029  3656 solver.cpp:259]     Train net output #0: error_blob = 0.0973491 (* 1 = 0.0973491 loss)
I1008 21:55:57.017041  3656 solver.cpp:590] Iteration 2900, lr = 0.0214335
I1008 21:56:02.156354  3656 solver.cpp:243] Iteration 3000, loss = 0.0971122
I1008 21:56:02.156388  3656 solver.cpp:259]     Train net output #0: error_blob = 0.0971122 (* 1 = 0.0971122 loss)
I1008 21:56:02.156399  3656 solver.cpp:590] Iteration 3000, lr = 0.0206612
I1008 21:56:02.207566  3656 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 21:56:07.317634  3656 solver.cpp:243] Iteration 3100, loss = 0.0974537
I1008 21:56:07.317674  3656 solver.cpp:259]     Train net output #0: error_blob = 0.0974537 (* 1 = 0.0974537 loss)
I1008 21:56:07.317682  3656 solver.cpp:590] Iteration 3100, lr = 0.0199298
I1008 21:56:12.476058  3656 solver.cpp:243] Iteration 3200, loss = 0.0971982
I1008 21:56:12.476094  3656 solver.cpp:259]     Train net output #0: error_blob = 0.0971982 (* 1 = 0.0971982 loss)
I1008 21:56:12.476104  3656 solver.cpp:590] Iteration 3200, lr = 0.0192367
I1008 21:56:17.683408  3656 solver.cpp:243] Iteration 3300, loss = 0.097201
I1008 21:56:17.683435  3656 solver.cpp:259]     Train net output #0: error_blob = 0.097201 (* 1 = 0.097201 loss)
I1008 21:56:17.683442  3656 solver.cpp:590] Iteration 3300, lr = 0.0185791
I1008 21:56:22.851253  3656 solver.cpp:243] Iteration 3400, loss = 0.0971435
I1008 21:56:22.851299  3656 solver.cpp:259]     Train net output #0: error_blob = 0.0971435 (* 1 = 0.0971435 loss)
I1008 21:56:22.851308  3656 solver.cpp:590] Iteration 3400, lr = 0.0179546
I1008 21:56:28.090507  3656 solver.cpp:243] Iteration 3500, loss = 0.0966188
I1008 21:56:28.092214  3656 solver.cpp:259]     Train net output #0: error_blob = 0.0966188 (* 1 = 0.0966188 loss)
I1008 21:56:28.092226  3656 solver.cpp:590] Iteration 3500, lr = 0.0173611
I1008 21:56:33.230473  3656 solver.cpp:243] Iteration 3600, loss = 0.0969175
I1008 21:56:33.230504  3656 solver.cpp:259]     Train net output #0: error_blob = 0.0969175 (* 1 = 0.0969175 loss)
I1008 21:56:33.230510  3656 solver.cpp:590] Iteration 3600, lr = 0.0167966
I1008 21:56:38.351337  3656 solver.cpp:243] Iteration 3700, loss = 0.0970086
I1008 21:56:38.351368  3656 solver.cpp:259]     Train net output #0: error_blob = 0.0970086 (* 1 = 0.0970086 loss)
I1008 21:56:38.351374  3656 solver.cpp:590] Iteration 3700, lr = 0.0162591
I1008 21:56:43.543409  3656 solver.cpp:243] Iteration 3800, loss = 0.0963767
I1008 21:56:43.543442  3656 solver.cpp:259]     Train net output #0: error_blob = 0.0963767 (* 1 = 0.0963767 loss)
I1008 21:56:43.543450  3656 solver.cpp:590] Iteration 3800, lr = 0.015747
I1008 21:56:48.660131  3656 solver.cpp:243] Iteration 3900, loss = 0.0964955
I1008 21:56:48.660169  3656 solver.cpp:259]     Train net output #0: error_blob = 0.0964955 (* 1 = 0.0964955 loss)
I1008 21:56:48.660176  3656 solver.cpp:590] Iteration 3900, lr = 0.0152588
I1008 21:56:53.750699  3656 solver.cpp:243] Iteration 4000, loss = 0.0966123
I1008 21:56:53.750730  3656 solver.cpp:259]     Train net output #0: error_blob = 0.0966123 (* 1 = 0.0966123 loss)
I1008 21:56:53.750737  3656 solver.cpp:590] Iteration 4000, lr = 0.0147929
I1008 21:56:53.802024  3656 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 21:56:58.903306  3656 solver.cpp:243] Iteration 4100, loss = 0.0963246
I1008 21:56:58.903403  3656 solver.cpp:259]     Train net output #0: error_blob = 0.0963246 (* 1 = 0.0963246 loss)
I1008 21:56:58.903414  3656 solver.cpp:590] Iteration 4100, lr = 0.014348
I1008 21:57:04.048353  3656 solver.cpp:243] Iteration 4200, loss = 0.09706
I1008 21:57:04.048382  3656 solver.cpp:259]     Train net output #0: error_blob = 0.09706 (* 1 = 0.09706 loss)
I1008 21:57:04.048389  3656 solver.cpp:590] Iteration 4200, lr = 0.0139229
I1008 21:57:09.182787  3656 solver.cpp:243] Iteration 4300, loss = 0.0960038
I1008 21:57:09.182821  3656 solver.cpp:259]     Train net output #0: error_blob = 0.0960038 (* 1 = 0.0960038 loss)
I1008 21:57:09.182831  3656 solver.cpp:590] Iteration 4300, lr = 0.0135164
I1008 21:57:14.319524  3656 solver.cpp:243] Iteration 4400, loss = 0.0957884
I1008 21:57:14.319552  3656 solver.cpp:259]     Train net output #0: error_blob = 0.0957884 (* 1 = 0.0957884 loss)
I1008 21:57:14.319560  3656 solver.cpp:590] Iteration 4400, lr = 0.0131275
I1008 21:57:19.437695  3656 solver.cpp:243] Iteration 4500, loss = 0.0963113
I1008 21:57:19.437726  3656 solver.cpp:259]     Train net output #0: error_blob = 0.0963113 (* 1 = 0.0963113 loss)
I1008 21:57:19.437734  3656 solver.cpp:590] Iteration 4500, lr = 0.0127551
I1008 21:57:24.595993  3656 solver.cpp:243] Iteration 4600, loss = 0.0967212
I1008 21:57:24.596032  3656 solver.cpp:259]     Train net output #0: error_blob = 0.0967212 (* 1 = 0.0967212 loss)
I1008 21:57:24.596040  3656 solver.cpp:590] Iteration 4600, lr = 0.0123983
I1008 21:57:29.667470  3656 solver.cpp:243] Iteration 4700, loss = 0.0960589
I1008 21:57:29.667634  3656 solver.cpp:259]     Train net output #0: error_blob = 0.0960589 (* 1 = 0.0960589 loss)
I1008 21:57:29.667642  3656 solver.cpp:590] Iteration 4700, lr = 0.0120563
I1008 21:57:34.859300  3656 solver.cpp:243] Iteration 4800, loss = 0.0960656
I1008 21:57:34.859340  3656 solver.cpp:259]     Train net output #0: error_blob = 0.0960656 (* 1 = 0.0960656 loss)
I1008 21:57:34.859347  3656 solver.cpp:590] Iteration 4800, lr = 0.0117283
I1008 21:57:39.976399  3656 solver.cpp:243] Iteration 4900, loss = 0.095896
I1008 21:57:39.976428  3656 solver.cpp:259]     Train net output #0: error_blob = 0.095896 (* 1 = 0.095896 loss)
I1008 21:57:39.976435  3656 solver.cpp:590] Iteration 4900, lr = 0.0114134
I1008 21:57:45.050261  3656 solver.cpp:468] Snapshotting to binary proto file _iter_5000.caffemodel
I1008 21:57:45.052166  3656 solver.cpp:753] Snapshotting solver state to binary proto file _iter_5000.solverstate
I1008 21:57:45.102473  3656 solver.cpp:327] Iteration 5000, loss = 0.0961748
I1008 21:57:45.102499  3656 solver.cpp:332] Optimization Done.
I1008 21:57:45.102504  3656 caffe.cpp:215] Optimization Done.
I1008 21:57:45.252326  3814 caffe.cpp:184] Using GPUs 0
I1008 21:57:45.812062  3814 solver.cpp:54] Initializing solver from parameters: 
test_iter: 1
test_interval: 100
base_lr: 0.1
display: 100
max_iter: 5000
lr_policy: "inv"
gamma: 0.0004
power: 2
momentum: 0.9
solver_mode: GPU
device_id: 0
net: "two_hidden/model3_part9.prototxt"
I1008 21:57:45.812094  3814 solver.cpp:97] Creating training net from net file: two_hidden/model3_part9.prototxt
I1008 21:57:45.812275  3814 net.cpp:339] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_layer
I1008 21:57:45.812321  3814 net.cpp:50] Initializing net from parameters: 
name: "two_hidden/model3_part9.prototxt"
state {
  phase: TRAIN
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TRAIN
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.part9.train"
    batch_size: 40000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer1"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob1"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer1"
  type: "Sigmoid"
  bottom: "hidden_sum_blob1"
  top: "hidden_act_blob1"
}
layer {
  name: "hidden_sum_layer2"
  type: "InnerProduct"
  bottom: "hidden_act_blob1"
  top: "hidden_sum_blob2"
  inner_product_param {
    num_output: 5
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer2"
  type: "Sigmoid"
  bottom: "hidden_sum_blob2"
  top: "hidden_act_blob2"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob2"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1008 21:57:45.812374  3814 layer_factory.hpp:76] Creating layer data_layer
I1008 21:57:45.838791  3814 net.cpp:110] Creating Layer data_layer
I1008 21:57:45.838811  3814 net.cpp:433] data_layer -> data_blob
I1008 21:57:45.838834  3814 net.cpp:433] data_layer -> label_blob
I1008 21:57:45.839452  3818 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.part9.train
I1008 21:57:46.525729  3814 data_layer.cpp:45] output data size: 40000,61,1,1
I1008 21:57:46.536164  3814 net.cpp:155] Setting up data_layer
I1008 21:57:46.536221  3814 net.cpp:163] Top shape: 40000 61 1 1 (2440000)
I1008 21:57:46.536231  3814 net.cpp:163] Top shape: 40000 (40000)
I1008 21:57:46.536239  3814 layer_factory.hpp:76] Creating layer hidden_sum_layer1
I1008 21:57:46.536255  3814 net.cpp:110] Creating Layer hidden_sum_layer1
I1008 21:57:46.536262  3814 net.cpp:477] hidden_sum_layer1 <- data_blob
I1008 21:57:46.536274  3814 net.cpp:433] hidden_sum_layer1 -> hidden_sum_blob1
I1008 21:57:46.536651  3814 net.cpp:155] Setting up hidden_sum_layer1
I1008 21:57:46.536660  3814 net.cpp:163] Top shape: 40000 10 (400000)
I1008 21:57:46.536671  3814 layer_factory.hpp:76] Creating layer hidden_act_layer1
I1008 21:57:46.536680  3814 net.cpp:110] Creating Layer hidden_act_layer1
I1008 21:57:46.536684  3814 net.cpp:477] hidden_act_layer1 <- hidden_sum_blob1
I1008 21:57:46.536690  3814 net.cpp:433] hidden_act_layer1 -> hidden_act_blob1
I1008 21:57:49.787188  3814 net.cpp:155] Setting up hidden_act_layer1
I1008 21:57:49.787221  3814 net.cpp:163] Top shape: 40000 10 (400000)
I1008 21:57:49.787226  3814 layer_factory.hpp:76] Creating layer hidden_sum_layer2
I1008 21:57:49.787235  3814 net.cpp:110] Creating Layer hidden_sum_layer2
I1008 21:57:49.787240  3814 net.cpp:477] hidden_sum_layer2 <- hidden_act_blob1
I1008 21:57:49.787248  3814 net.cpp:433] hidden_sum_layer2 -> hidden_sum_blob2
I1008 21:57:49.787386  3814 net.cpp:155] Setting up hidden_sum_layer2
I1008 21:57:49.787395  3814 net.cpp:163] Top shape: 40000 5 (200000)
I1008 21:57:49.787431  3814 layer_factory.hpp:76] Creating layer hidden_act_layer2
I1008 21:57:49.787443  3814 net.cpp:110] Creating Layer hidden_act_layer2
I1008 21:57:49.787447  3814 net.cpp:477] hidden_act_layer2 <- hidden_sum_blob2
I1008 21:57:49.787453  3814 net.cpp:433] hidden_act_layer2 -> hidden_act_blob2
I1008 21:57:49.787538  3814 net.cpp:155] Setting up hidden_act_layer2
I1008 21:57:49.787554  3814 net.cpp:163] Top shape: 40000 5 (200000)
I1008 21:57:49.787556  3814 layer_factory.hpp:76] Creating layer output_sum_layer
I1008 21:57:49.787560  3814 net.cpp:110] Creating Layer output_sum_layer
I1008 21:57:49.787572  3814 net.cpp:477] output_sum_layer <- hidden_act_blob2
I1008 21:57:49.787576  3814 net.cpp:433] output_sum_layer -> output_sum_blob
I1008 21:57:49.787689  3814 net.cpp:155] Setting up output_sum_layer
I1008 21:57:49.787695  3814 net.cpp:163] Top shape: 40000 1 (40000)
I1008 21:57:49.787711  3814 layer_factory.hpp:76] Creating layer output_act_layer
I1008 21:57:49.787715  3814 net.cpp:110] Creating Layer output_act_layer
I1008 21:57:49.787719  3814 net.cpp:477] output_act_layer <- output_sum_blob
I1008 21:57:49.787722  3814 net.cpp:433] output_act_layer -> output_act_blob
I1008 21:57:49.787875  3814 net.cpp:155] Setting up output_act_layer
I1008 21:57:49.787883  3814 net.cpp:163] Top shape: 40000 1 (40000)
I1008 21:57:49.787895  3814 layer_factory.hpp:76] Creating layer error_layer
I1008 21:57:49.787901  3814 net.cpp:110] Creating Layer error_layer
I1008 21:57:49.787904  3814 net.cpp:477] error_layer <- output_act_blob
I1008 21:57:49.787907  3814 net.cpp:477] error_layer <- label_blob
I1008 21:57:49.787914  3814 net.cpp:433] error_layer -> error_blob
I1008 21:57:49.787955  3814 net.cpp:155] Setting up error_layer
I1008 21:57:49.787960  3814 net.cpp:163] Top shape: (1)
I1008 21:57:49.787971  3814 net.cpp:168]     with loss weight 1
I1008 21:57:49.787992  3814 net.cpp:236] error_layer needs backward computation.
I1008 21:57:49.787997  3814 net.cpp:236] output_act_layer needs backward computation.
I1008 21:57:49.788002  3814 net.cpp:236] output_sum_layer needs backward computation.
I1008 21:57:49.788007  3814 net.cpp:236] hidden_act_layer2 needs backward computation.
I1008 21:57:49.788010  3814 net.cpp:236] hidden_sum_layer2 needs backward computation.
I1008 21:57:49.788013  3814 net.cpp:236] hidden_act_layer1 needs backward computation.
I1008 21:57:49.788017  3814 net.cpp:236] hidden_sum_layer1 needs backward computation.
I1008 21:57:49.788020  3814 net.cpp:240] data_layer does not need backward computation.
I1008 21:57:49.788025  3814 net.cpp:283] This network produces output error_blob
I1008 21:57:49.788033  3814 net.cpp:297] Network initialization done.
I1008 21:57:49.788038  3814 net.cpp:298] Memory required for data: 15040004
I1008 21:57:49.788184  3814 solver.cpp:187] Creating test net (#0) specified by net file: two_hidden/model3_part9.prototxt
I1008 21:57:49.788202  3814 net.cpp:339] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_layer
I1008 21:57:49.788274  3814 net.cpp:50] Initializing net from parameters: 
name: "two_hidden/model3_part9.prototxt"
state {
  phase: TEST
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TEST
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.part9.test"
    batch_size: 4000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer1"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob1"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer1"
  type: "Sigmoid"
  bottom: "hidden_sum_blob1"
  top: "hidden_act_blob1"
}
layer {
  name: "hidden_sum_layer2"
  type: "InnerProduct"
  bottom: "hidden_act_blob1"
  top: "hidden_sum_blob2"
  inner_product_param {
    num_output: 5
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer2"
  type: "Sigmoid"
  bottom: "hidden_sum_blob2"
  top: "hidden_act_blob2"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob2"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1008 21:57:49.788321  3814 layer_factory.hpp:76] Creating layer data_layer
I1008 21:57:49.790774  3814 net.cpp:110] Creating Layer data_layer
I1008 21:57:49.790781  3814 net.cpp:433] data_layer -> data_blob
I1008 21:57:49.790787  3814 net.cpp:433] data_layer -> label_blob
I1008 21:57:49.791337  3820 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.part9.test
I1008 21:57:49.791409  3814 data_layer.cpp:45] output data size: 4000,61,1,1
I1008 21:57:49.793297  3814 net.cpp:155] Setting up data_layer
I1008 21:57:49.793313  3814 net.cpp:163] Top shape: 4000 61 1 1 (244000)
I1008 21:57:49.793318  3814 net.cpp:163] Top shape: 4000 (4000)
I1008 21:57:49.793323  3814 layer_factory.hpp:76] Creating layer hidden_sum_layer1
I1008 21:57:49.793334  3814 net.cpp:110] Creating Layer hidden_sum_layer1
I1008 21:57:49.793339  3814 net.cpp:477] hidden_sum_layer1 <- data_blob
I1008 21:57:49.793347  3814 net.cpp:433] hidden_sum_layer1 -> hidden_sum_blob1
I1008 21:57:49.793474  3814 net.cpp:155] Setting up hidden_sum_layer1
I1008 21:57:49.793483  3814 net.cpp:163] Top shape: 4000 10 (40000)
I1008 21:57:49.793495  3814 layer_factory.hpp:76] Creating layer hidden_act_layer1
I1008 21:57:49.793503  3814 net.cpp:110] Creating Layer hidden_act_layer1
I1008 21:57:49.793508  3814 net.cpp:477] hidden_act_layer1 <- hidden_sum_blob1
I1008 21:57:49.793511  3814 net.cpp:433] hidden_act_layer1 -> hidden_act_blob1
I1008 21:57:49.793579  3814 net.cpp:155] Setting up hidden_act_layer1
I1008 21:57:49.793587  3814 net.cpp:163] Top shape: 4000 10 (40000)
I1008 21:57:49.793591  3814 layer_factory.hpp:76] Creating layer hidden_sum_layer2
I1008 21:57:49.793598  3814 net.cpp:110] Creating Layer hidden_sum_layer2
I1008 21:57:49.793603  3814 net.cpp:477] hidden_sum_layer2 <- hidden_act_blob1
I1008 21:57:49.793609  3814 net.cpp:433] hidden_sum_layer2 -> hidden_sum_blob2
I1008 21:57:49.793678  3814 net.cpp:155] Setting up hidden_sum_layer2
I1008 21:57:49.793685  3814 net.cpp:163] Top shape: 4000 5 (20000)
I1008 21:57:49.793694  3814 layer_factory.hpp:76] Creating layer hidden_act_layer2
I1008 21:57:49.793699  3814 net.cpp:110] Creating Layer hidden_act_layer2
I1008 21:57:49.793705  3814 net.cpp:477] hidden_act_layer2 <- hidden_sum_blob2
I1008 21:57:49.793710  3814 net.cpp:433] hidden_act_layer2 -> hidden_act_blob2
I1008 21:57:49.793766  3814 net.cpp:155] Setting up hidden_act_layer2
I1008 21:57:49.793772  3814 net.cpp:163] Top shape: 4000 5 (20000)
I1008 21:57:49.793776  3814 layer_factory.hpp:76] Creating layer output_sum_layer
I1008 21:57:49.793782  3814 net.cpp:110] Creating Layer output_sum_layer
I1008 21:57:49.793787  3814 net.cpp:477] output_sum_layer <- hidden_act_blob2
I1008 21:57:49.793792  3814 net.cpp:433] output_sum_layer -> output_sum_blob
I1008 21:57:49.793855  3814 net.cpp:155] Setting up output_sum_layer
I1008 21:57:49.793861  3814 net.cpp:163] Top shape: 4000 1 (4000)
I1008 21:57:49.793869  3814 layer_factory.hpp:76] Creating layer output_act_layer
I1008 21:57:49.793875  3814 net.cpp:110] Creating Layer output_act_layer
I1008 21:57:49.793879  3814 net.cpp:477] output_act_layer <- output_sum_blob
I1008 21:57:49.793884  3814 net.cpp:433] output_act_layer -> output_act_blob
I1008 21:57:49.793939  3814 net.cpp:155] Setting up output_act_layer
I1008 21:57:49.793946  3814 net.cpp:163] Top shape: 4000 1 (4000)
I1008 21:57:49.793951  3814 layer_factory.hpp:76] Creating layer error_layer
I1008 21:57:49.793958  3814 net.cpp:110] Creating Layer error_layer
I1008 21:57:49.793963  3814 net.cpp:477] error_layer <- output_act_blob
I1008 21:57:49.793979  3814 net.cpp:477] error_layer <- label_blob
I1008 21:57:49.793985  3814 net.cpp:433] error_layer -> error_blob
I1008 21:57:49.794013  3814 net.cpp:155] Setting up error_layer
I1008 21:57:49.794018  3814 net.cpp:163] Top shape: (1)
I1008 21:57:49.794023  3814 net.cpp:168]     with loss weight 1
I1008 21:57:49.794035  3814 net.cpp:236] error_layer needs backward computation.
I1008 21:57:49.794041  3814 net.cpp:236] output_act_layer needs backward computation.
I1008 21:57:49.794044  3814 net.cpp:236] output_sum_layer needs backward computation.
I1008 21:57:49.794049  3814 net.cpp:236] hidden_act_layer2 needs backward computation.
I1008 21:57:49.794052  3814 net.cpp:236] hidden_sum_layer2 needs backward computation.
I1008 21:57:49.794055  3814 net.cpp:236] hidden_act_layer1 needs backward computation.
I1008 21:57:49.794060  3814 net.cpp:236] hidden_sum_layer1 needs backward computation.
I1008 21:57:49.794065  3814 net.cpp:240] data_layer does not need backward computation.
I1008 21:57:49.794069  3814 net.cpp:283] This network produces output error_blob
I1008 21:57:49.794078  3814 net.cpp:297] Network initialization done.
I1008 21:57:49.794082  3814 net.cpp:298] Memory required for data: 1504004
I1008 21:57:49.794111  3814 solver.cpp:66] Solver scaffolding done.
I1008 21:57:49.794260  3814 caffe.cpp:212] Starting Optimization
I1008 21:57:49.794267  3814 solver.cpp:294] Solving two_hidden/model3_part9.prototxt
I1008 21:57:49.794270  3814 solver.cpp:295] Learning Rate Policy: inv
I1008 21:57:49.794518  3814 solver.cpp:347] Iteration 0, Testing net (#0)
I1008 21:57:49.794589  3814 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 21:57:49.804704  3814 solver.cpp:415]     Test net output #0: error_blob = 0.126286 (* 1 = 0.126286 loss)
I1008 21:57:49.806828  3814 solver.cpp:243] Iteration 0, loss = 0.126613
I1008 21:57:49.806843  3814 solver.cpp:259]     Train net output #0: error_blob = 0.126613 (* 1 = 0.126613 loss)
I1008 21:57:49.806864  3814 solver.cpp:590] Iteration 0, lr = 0.1
I1008 21:57:54.627250  3814 solver.cpp:347] Iteration 100, Testing net (#0)
I1008 21:57:54.629133  3814 solver.cpp:415]     Test net output #0: error_blob = 0.119152 (* 1 = 0.119152 loss)
I1008 21:57:54.679886  3814 solver.cpp:243] Iteration 100, loss = 0.118609
I1008 21:57:54.679919  3814 solver.cpp:259]     Train net output #0: error_blob = 0.118609 (* 1 = 0.118609 loss)
I1008 21:57:54.679927  3814 solver.cpp:590] Iteration 100, lr = 0.0924556
I1008 21:57:59.526872  3814 solver.cpp:347] Iteration 200, Testing net (#0)
I1008 21:57:59.528781  3814 solver.cpp:415]     Test net output #0: error_blob = 0.113872 (* 1 = 0.113872 loss)
I1008 21:57:59.580977  3814 solver.cpp:243] Iteration 200, loss = 0.11179
I1008 21:57:59.581008  3814 solver.cpp:259]     Train net output #0: error_blob = 0.11179 (* 1 = 0.11179 loss)
I1008 21:57:59.581017  3814 solver.cpp:590] Iteration 200, lr = 0.0857339
I1008 21:58:04.420483  3814 solver.cpp:347] Iteration 300, Testing net (#0)
I1008 21:58:04.422377  3814 solver.cpp:415]     Test net output #0: error_blob = 0.112091 (* 1 = 0.112091 loss)
I1008 21:58:04.472795  3814 solver.cpp:243] Iteration 300, loss = 0.108134
I1008 21:58:04.472833  3814 solver.cpp:259]     Train net output #0: error_blob = 0.108134 (* 1 = 0.108134 loss)
I1008 21:58:04.472841  3814 solver.cpp:590] Iteration 300, lr = 0.0797194
I1008 21:58:09.277247  3814 solver.cpp:347] Iteration 400, Testing net (#0)
I1008 21:58:09.279158  3814 solver.cpp:415]     Test net output #0: error_blob = 0.11174 (* 1 = 0.11174 loss)
I1008 21:58:09.330591  3814 solver.cpp:243] Iteration 400, loss = 0.104808
I1008 21:58:09.330628  3814 solver.cpp:259]     Train net output #0: error_blob = 0.104808 (* 1 = 0.104808 loss)
I1008 21:58:09.330636  3814 solver.cpp:590] Iteration 400, lr = 0.0743163
I1008 21:58:14.151137  3814 solver.cpp:347] Iteration 500, Testing net (#0)
I1008 21:58:14.153043  3814 solver.cpp:415]     Test net output #0: error_blob = 0.113231 (* 1 = 0.113231 loss)
I1008 21:58:14.206197  3814 solver.cpp:243] Iteration 500, loss = 0.10328
I1008 21:58:14.206251  3814 solver.cpp:259]     Train net output #0: error_blob = 0.10328 (* 1 = 0.10328 loss)
I1008 21:58:14.206262  3814 solver.cpp:590] Iteration 500, lr = 0.0694444
I1008 21:58:19.009516  3814 solver.cpp:347] Iteration 600, Testing net (#0)
I1008 21:58:19.011422  3814 solver.cpp:415]     Test net output #0: error_blob = 0.11461 (* 1 = 0.11461 loss)
I1008 21:58:19.062044  3814 solver.cpp:243] Iteration 600, loss = 0.103019
I1008 21:58:19.062075  3814 solver.cpp:259]     Train net output #0: error_blob = 0.103019 (* 1 = 0.103019 loss)
I1008 21:58:19.062083  3814 solver.cpp:590] Iteration 600, lr = 0.0650364
I1008 21:58:23.855595  3814 solver.cpp:347] Iteration 700, Testing net (#0)
I1008 21:58:23.857494  3814 solver.cpp:415]     Test net output #0: error_blob = 0.115667 (* 1 = 0.115667 loss)
I1008 21:58:23.908329  3814 solver.cpp:243] Iteration 700, loss = 0.101005
I1008 21:58:23.908357  3814 solver.cpp:259]     Train net output #0: error_blob = 0.101005 (* 1 = 0.101005 loss)
I1008 21:58:23.908363  3814 solver.cpp:590] Iteration 700, lr = 0.0610352
I1008 21:58:28.758124  3814 solver.cpp:347] Iteration 800, Testing net (#0)
I1008 21:58:28.760015  3814 solver.cpp:415]     Test net output #0: error_blob = 0.116735 (* 1 = 0.116735 loss)
I1008 21:58:28.812142  3814 solver.cpp:243] Iteration 800, loss = 0.101027
I1008 21:58:28.812175  3814 solver.cpp:259]     Train net output #0: error_blob = 0.101027 (* 1 = 0.101027 loss)
I1008 21:58:28.812182  3814 solver.cpp:590] Iteration 800, lr = 0.0573921
I1008 21:58:33.635182  3814 solver.cpp:347] Iteration 900, Testing net (#0)
I1008 21:58:33.637075  3814 solver.cpp:415]     Test net output #0: error_blob = 0.118487 (* 1 = 0.118487 loss)
I1008 21:58:33.687760  3814 solver.cpp:243] Iteration 900, loss = 0.101377
I1008 21:58:33.687789  3814 solver.cpp:259]     Train net output #0: error_blob = 0.101377 (* 1 = 0.101377 loss)
I1008 21:58:33.687796  3814 solver.cpp:590] Iteration 900, lr = 0.0540657
I1008 21:58:38.519999  3814 solver.cpp:347] Iteration 1000, Testing net (#0)
I1008 21:58:38.521895  3814 solver.cpp:415]     Test net output #0: error_blob = 0.118697 (* 1 = 0.118697 loss)
I1008 21:58:38.574216  3814 solver.cpp:243] Iteration 1000, loss = 0.0983307
I1008 21:58:38.574247  3814 solver.cpp:259]     Train net output #0: error_blob = 0.0983307 (* 1 = 0.0983307 loss)
I1008 21:58:38.574254  3814 solver.cpp:590] Iteration 1000, lr = 0.0510204
I1008 21:58:38.574338  3814 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 21:58:43.436385  3814 solver.cpp:347] Iteration 1100, Testing net (#0)
I1008 21:58:43.438271  3814 solver.cpp:415]     Test net output #0: error_blob = 0.118054 (* 1 = 0.118054 loss)
I1008 21:58:43.490134  3814 solver.cpp:243] Iteration 1100, loss = 0.0989153
I1008 21:58:43.490172  3814 solver.cpp:259]     Train net output #0: error_blob = 0.0989153 (* 1 = 0.0989153 loss)
I1008 21:58:43.490178  3814 solver.cpp:590] Iteration 1100, lr = 0.0482253
I1008 21:58:48.359159  3814 solver.cpp:347] Iteration 1200, Testing net (#0)
I1008 21:58:48.361048  3814 solver.cpp:415]     Test net output #0: error_blob = 0.119979 (* 1 = 0.119979 loss)
I1008 21:58:48.411731  3814 solver.cpp:243] Iteration 1200, loss = 0.0990471
I1008 21:58:48.411766  3814 solver.cpp:259]     Train net output #0: error_blob = 0.0990471 (* 1 = 0.0990471 loss)
I1008 21:58:48.411774  3814 solver.cpp:590] Iteration 1200, lr = 0.0456538
I1008 21:58:53.277663  3814 solver.cpp:347] Iteration 1300, Testing net (#0)
I1008 21:58:53.279577  3814 solver.cpp:415]     Test net output #0: error_blob = 0.121133 (* 1 = 0.121133 loss)
I1008 21:58:53.330585  3814 solver.cpp:243] Iteration 1300, loss = 0.0981543
I1008 21:58:53.330616  3814 solver.cpp:259]     Train net output #0: error_blob = 0.0981543 (* 1 = 0.0981543 loss)
I1008 21:58:53.330622  3814 solver.cpp:590] Iteration 1300, lr = 0.0432825
I1008 21:58:58.157476  3814 solver.cpp:347] Iteration 1400, Testing net (#0)
I1008 21:58:58.159363  3814 solver.cpp:415]     Test net output #0: error_blob = 0.119545 (* 1 = 0.119545 loss)
I1008 21:58:58.211556  3814 solver.cpp:243] Iteration 1400, loss = 0.0983066
I1008 21:58:58.211588  3814 solver.cpp:259]     Train net output #0: error_blob = 0.0983066 (* 1 = 0.0983066 loss)
I1008 21:58:58.211596  3814 solver.cpp:590] Iteration 1400, lr = 0.0410914
I1008 21:59:03.059896  3814 solver.cpp:347] Iteration 1500, Testing net (#0)
I1008 21:59:03.061790  3814 solver.cpp:415]     Test net output #0: error_blob = 0.120014 (* 1 = 0.120014 loss)
I1008 21:59:03.110328  3814 solver.cpp:243] Iteration 1500, loss = 0.0966853
I1008 21:59:03.110359  3814 solver.cpp:259]     Train net output #0: error_blob = 0.0966853 (* 1 = 0.0966853 loss)
I1008 21:59:03.110368  3814 solver.cpp:590] Iteration 1500, lr = 0.0390625
I1008 21:59:07.952743  3814 solver.cpp:347] Iteration 1600, Testing net (#0)
I1008 21:59:07.954649  3814 solver.cpp:415]     Test net output #0: error_blob = 0.121832 (* 1 = 0.121832 loss)
I1008 21:59:08.004418  3814 solver.cpp:243] Iteration 1600, loss = 0.0982114
I1008 21:59:08.004448  3814 solver.cpp:259]     Train net output #0: error_blob = 0.0982114 (* 1 = 0.0982114 loss)
I1008 21:59:08.004454  3814 solver.cpp:590] Iteration 1600, lr = 0.0371803
I1008 21:59:12.844696  3814 solver.cpp:347] Iteration 1700, Testing net (#0)
I1008 21:59:12.846597  3814 solver.cpp:415]     Test net output #0: error_blob = 0.119797 (* 1 = 0.119797 loss)
I1008 21:59:12.898036  3814 solver.cpp:243] Iteration 1700, loss = 0.0968075
I1008 21:59:12.898064  3814 solver.cpp:259]     Train net output #0: error_blob = 0.0968075 (* 1 = 0.0968075 loss)
I1008 21:59:12.898071  3814 solver.cpp:590] Iteration 1700, lr = 0.0354308
I1008 21:59:17.743650  3814 solver.cpp:347] Iteration 1800, Testing net (#0)
I1008 21:59:17.745563  3814 solver.cpp:415]     Test net output #0: error_blob = 0.119115 (* 1 = 0.119115 loss)
I1008 21:59:17.795109  3814 solver.cpp:243] Iteration 1800, loss = 0.0965367
I1008 21:59:17.795138  3814 solver.cpp:259]     Train net output #0: error_blob = 0.0965367 (* 1 = 0.0965367 loss)
I1008 21:59:17.795145  3814 solver.cpp:590] Iteration 1800, lr = 0.0338021
I1008 21:59:22.663239  3814 solver.cpp:347] Iteration 1900, Testing net (#0)
I1008 21:59:22.665133  3814 solver.cpp:415]     Test net output #0: error_blob = 0.122785 (* 1 = 0.122785 loss)
I1008 21:59:22.717737  3814 solver.cpp:243] Iteration 1900, loss = 0.0967021
I1008 21:59:22.717767  3814 solver.cpp:259]     Train net output #0: error_blob = 0.0967021 (* 1 = 0.0967021 loss)
I1008 21:59:22.717775  3814 solver.cpp:590] Iteration 1900, lr = 0.0322831
I1008 21:59:27.577844  3814 solver.cpp:347] Iteration 2000, Testing net (#0)
I1008 21:59:27.579742  3814 solver.cpp:415]     Test net output #0: error_blob = 0.122796 (* 1 = 0.122796 loss)
I1008 21:59:27.631209  3814 solver.cpp:243] Iteration 2000, loss = 0.0956037
I1008 21:59:27.631240  3814 solver.cpp:259]     Train net output #0: error_blob = 0.0956037 (* 1 = 0.0956037 loss)
I1008 21:59:27.631247  3814 solver.cpp:590] Iteration 2000, lr = 0.0308642
I1008 21:59:27.631346  3814 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 21:59:32.498791  3814 solver.cpp:347] Iteration 2100, Testing net (#0)
I1008 21:59:32.500687  3814 solver.cpp:415]     Test net output #0: error_blob = 0.122771 (* 1 = 0.122771 loss)
I1008 21:59:32.551411  3814 solver.cpp:243] Iteration 2100, loss = 0.0966614
I1008 21:59:32.551441  3814 solver.cpp:259]     Train net output #0: error_blob = 0.0966614 (* 1 = 0.0966614 loss)
I1008 21:59:32.551447  3814 solver.cpp:590] Iteration 2100, lr = 0.0295369
I1008 21:59:37.408952  3814 solver.cpp:347] Iteration 2200, Testing net (#0)
I1008 21:59:37.410861  3814 solver.cpp:415]     Test net output #0: error_blob = 0.122844 (* 1 = 0.122844 loss)
I1008 21:59:37.460541  3814 solver.cpp:243] Iteration 2200, loss = 0.0965187
I1008 21:59:37.460568  3814 solver.cpp:259]     Train net output #0: error_blob = 0.0965187 (* 1 = 0.0965187 loss)
I1008 21:59:37.460574  3814 solver.cpp:590] Iteration 2200, lr = 0.0282933
I1008 21:59:42.287921  3814 solver.cpp:347] Iteration 2300, Testing net (#0)
I1008 21:59:42.289844  3814 solver.cpp:415]     Test net output #0: error_blob = 0.122699 (* 1 = 0.122699 loss)
I1008 21:59:42.339453  3814 solver.cpp:243] Iteration 2300, loss = 0.0952804
I1008 21:59:42.339481  3814 solver.cpp:259]     Train net output #0: error_blob = 0.0952804 (* 1 = 0.0952804 loss)
I1008 21:59:42.339489  3814 solver.cpp:590] Iteration 2300, lr = 0.0271267
I1008 21:59:47.185693  3814 solver.cpp:347] Iteration 2400, Testing net (#0)
I1008 21:59:47.187613  3814 solver.cpp:415]     Test net output #0: error_blob = 0.122703 (* 1 = 0.122703 loss)
I1008 21:59:47.237148  3814 solver.cpp:243] Iteration 2400, loss = 0.0967121
I1008 21:59:47.237177  3814 solver.cpp:259]     Train net output #0: error_blob = 0.0967121 (* 1 = 0.0967121 loss)
I1008 21:59:47.237184  3814 solver.cpp:590] Iteration 2400, lr = 0.0260308
I1008 21:59:52.099252  3814 solver.cpp:347] Iteration 2500, Testing net (#0)
I1008 21:59:52.101152  3814 solver.cpp:415]     Test net output #0: error_blob = 0.120162 (* 1 = 0.120162 loss)
I1008 21:59:52.149519  3814 solver.cpp:243] Iteration 2500, loss = 0.0975213
I1008 21:59:52.149551  3814 solver.cpp:259]     Train net output #0: error_blob = 0.0975213 (* 1 = 0.0975213 loss)
I1008 21:59:52.149559  3814 solver.cpp:590] Iteration 2500, lr = 0.025
I1008 21:59:56.984437  3814 solver.cpp:347] Iteration 2600, Testing net (#0)
I1008 21:59:56.986340  3814 solver.cpp:415]     Test net output #0: error_blob = 0.118187 (* 1 = 0.118187 loss)
I1008 21:59:57.037142  3814 solver.cpp:243] Iteration 2600, loss = 0.0952261
I1008 21:59:57.037171  3814 solver.cpp:259]     Train net output #0: error_blob = 0.0952261 (* 1 = 0.0952261 loss)
I1008 21:59:57.037178  3814 solver.cpp:590] Iteration 2600, lr = 0.0240292
I1008 22:00:01.878233  3814 solver.cpp:347] Iteration 2700, Testing net (#0)
I1008 22:00:01.880141  3814 solver.cpp:415]     Test net output #0: error_blob = 0.118056 (* 1 = 0.118056 loss)
I1008 22:00:01.933229  3814 solver.cpp:243] Iteration 2700, loss = 0.0954283
I1008 22:00:01.933257  3814 solver.cpp:259]     Train net output #0: error_blob = 0.0954283 (* 1 = 0.0954283 loss)
I1008 22:00:01.933264  3814 solver.cpp:590] Iteration 2700, lr = 0.0231139
I1008 22:00:06.786103  3814 solver.cpp:347] Iteration 2800, Testing net (#0)
I1008 22:00:06.787986  3814 solver.cpp:415]     Test net output #0: error_blob = 0.117452 (* 1 = 0.117452 loss)
I1008 22:00:06.836863  3814 solver.cpp:243] Iteration 2800, loss = 0.096256
I1008 22:00:06.836896  3814 solver.cpp:259]     Train net output #0: error_blob = 0.096256 (* 1 = 0.096256 loss)
I1008 22:00:06.836906  3814 solver.cpp:590] Iteration 2800, lr = 0.0222499
I1008 22:00:11.673907  3814 solver.cpp:347] Iteration 2900, Testing net (#0)
I1008 22:00:11.675809  3814 solver.cpp:415]     Test net output #0: error_blob = 0.118169 (* 1 = 0.118169 loss)
I1008 22:00:11.724073  3814 solver.cpp:243] Iteration 2900, loss = 0.0945682
I1008 22:00:11.724104  3814 solver.cpp:259]     Train net output #0: error_blob = 0.0945682 (* 1 = 0.0945682 loss)
I1008 22:00:11.724112  3814 solver.cpp:590] Iteration 2900, lr = 0.0214335
I1008 22:00:16.567886  3814 solver.cpp:347] Iteration 3000, Testing net (#0)
I1008 22:00:16.569797  3814 solver.cpp:415]     Test net output #0: error_blob = 0.117304 (* 1 = 0.117304 loss)
I1008 22:00:16.619091  3814 solver.cpp:243] Iteration 3000, loss = 0.0956911
I1008 22:00:16.619118  3814 solver.cpp:259]     Train net output #0: error_blob = 0.0956911 (* 1 = 0.0956911 loss)
I1008 22:00:16.619124  3814 solver.cpp:590] Iteration 3000, lr = 0.0206612
I1008 22:00:16.619205  3814 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 22:00:21.454159  3814 solver.cpp:347] Iteration 3100, Testing net (#0)
I1008 22:00:21.456060  3814 solver.cpp:415]     Test net output #0: error_blob = 0.119401 (* 1 = 0.119401 loss)
I1008 22:00:21.507015  3814 solver.cpp:243] Iteration 3100, loss = 0.0936915
I1008 22:00:21.507046  3814 solver.cpp:259]     Train net output #0: error_blob = 0.0936915 (* 1 = 0.0936915 loss)
I1008 22:00:21.507053  3814 solver.cpp:590] Iteration 3100, lr = 0.0199298
I1008 22:00:26.392427  3814 solver.cpp:347] Iteration 3200, Testing net (#0)
I1008 22:00:26.394359  3814 solver.cpp:415]     Test net output #0: error_blob = 0.121085 (* 1 = 0.121085 loss)
I1008 22:00:26.443940  3814 solver.cpp:243] Iteration 3200, loss = 0.0952423
I1008 22:00:26.443969  3814 solver.cpp:259]     Train net output #0: error_blob = 0.0952423 (* 1 = 0.0952423 loss)
I1008 22:00:26.443976  3814 solver.cpp:590] Iteration 3200, lr = 0.0192367
I1008 22:00:31.278671  3814 solver.cpp:347] Iteration 3300, Testing net (#0)
I1008 22:00:31.280573  3814 solver.cpp:415]     Test net output #0: error_blob = 0.120957 (* 1 = 0.120957 loss)
I1008 22:00:31.330421  3814 solver.cpp:243] Iteration 3300, loss = 0.0949389
I1008 22:00:31.330449  3814 solver.cpp:259]     Train net output #0: error_blob = 0.0949389 (* 1 = 0.0949389 loss)
I1008 22:00:31.330456  3814 solver.cpp:590] Iteration 3300, lr = 0.0185791
I1008 22:00:36.201797  3814 solver.cpp:347] Iteration 3400, Testing net (#0)
I1008 22:00:36.203690  3814 solver.cpp:415]     Test net output #0: error_blob = 0.121655 (* 1 = 0.121655 loss)
I1008 22:00:36.253880  3814 solver.cpp:243] Iteration 3400, loss = 0.0944248
I1008 22:00:36.253909  3814 solver.cpp:259]     Train net output #0: error_blob = 0.0944248 (* 1 = 0.0944248 loss)
I1008 22:00:36.253919  3814 solver.cpp:590] Iteration 3400, lr = 0.0179546
I1008 22:00:41.135546  3814 solver.cpp:347] Iteration 3500, Testing net (#0)
I1008 22:00:41.137449  3814 solver.cpp:415]     Test net output #0: error_blob = 0.121514 (* 1 = 0.121514 loss)
I1008 22:00:41.188277  3814 solver.cpp:243] Iteration 3500, loss = 0.0953395
I1008 22:00:41.188310  3814 solver.cpp:259]     Train net output #0: error_blob = 0.0953395 (* 1 = 0.0953395 loss)
I1008 22:00:41.188319  3814 solver.cpp:590] Iteration 3500, lr = 0.0173611
I1008 22:00:46.056275  3814 solver.cpp:347] Iteration 3600, Testing net (#0)
I1008 22:00:46.058185  3814 solver.cpp:415]     Test net output #0: error_blob = 0.121469 (* 1 = 0.121469 loss)
I1008 22:00:46.109377  3814 solver.cpp:243] Iteration 3600, loss = 0.0943814
I1008 22:00:46.109407  3814 solver.cpp:259]     Train net output #0: error_blob = 0.0943814 (* 1 = 0.0943814 loss)
I1008 22:00:46.109414  3814 solver.cpp:590] Iteration 3600, lr = 0.0167966
I1008 22:00:50.941404  3814 solver.cpp:347] Iteration 3700, Testing net (#0)
I1008 22:00:50.943305  3814 solver.cpp:415]     Test net output #0: error_blob = 0.121186 (* 1 = 0.121186 loss)
I1008 22:00:50.991894  3814 solver.cpp:243] Iteration 3700, loss = 0.0953549
I1008 22:00:50.991925  3814 solver.cpp:259]     Train net output #0: error_blob = 0.0953549 (* 1 = 0.0953549 loss)
I1008 22:00:50.991936  3814 solver.cpp:590] Iteration 3700, lr = 0.0162591
I1008 22:00:55.822896  3814 solver.cpp:347] Iteration 3800, Testing net (#0)
I1008 22:00:55.824817  3814 solver.cpp:415]     Test net output #0: error_blob = 0.121321 (* 1 = 0.121321 loss)
I1008 22:00:55.873509  3814 solver.cpp:243] Iteration 3800, loss = 0.0947069
I1008 22:00:55.873538  3814 solver.cpp:259]     Train net output #0: error_blob = 0.0947069 (* 1 = 0.0947069 loss)
I1008 22:00:55.873544  3814 solver.cpp:590] Iteration 3800, lr = 0.015747
I1008 22:01:00.708564  3814 solver.cpp:347] Iteration 3900, Testing net (#0)
I1008 22:01:00.710474  3814 solver.cpp:415]     Test net output #0: error_blob = 0.119284 (* 1 = 0.119284 loss)
I1008 22:01:00.759785  3814 solver.cpp:243] Iteration 3900, loss = 0.0945899
I1008 22:01:00.759814  3814 solver.cpp:259]     Train net output #0: error_blob = 0.0945899 (* 1 = 0.0945899 loss)
I1008 22:01:00.759821  3814 solver.cpp:590] Iteration 3900, lr = 0.0152588
I1008 22:01:05.593516  3814 solver.cpp:347] Iteration 4000, Testing net (#0)
I1008 22:01:05.595438  3814 solver.cpp:415]     Test net output #0: error_blob = 0.117752 (* 1 = 0.117752 loss)
I1008 22:01:05.644973  3814 solver.cpp:243] Iteration 4000, loss = 0.0950723
I1008 22:01:05.645000  3814 solver.cpp:259]     Train net output #0: error_blob = 0.0950723 (* 1 = 0.0950723 loss)
I1008 22:01:05.645006  3814 solver.cpp:590] Iteration 4000, lr = 0.0147929
I1008 22:01:05.645089  3814 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 22:01:10.496582  3814 solver.cpp:347] Iteration 4100, Testing net (#0)
I1008 22:01:10.498459  3814 solver.cpp:415]     Test net output #0: error_blob = 0.11793 (* 1 = 0.11793 loss)
I1008 22:01:10.552438  3814 solver.cpp:243] Iteration 4100, loss = 0.0958703
I1008 22:01:10.552469  3814 solver.cpp:259]     Train net output #0: error_blob = 0.0958703 (* 1 = 0.0958703 loss)
I1008 22:01:10.552474  3814 solver.cpp:590] Iteration 4100, lr = 0.014348
I1008 22:01:15.420136  3814 solver.cpp:347] Iteration 4200, Testing net (#0)
I1008 22:01:15.422035  3814 solver.cpp:415]     Test net output #0: error_blob = 0.117902 (* 1 = 0.117902 loss)
I1008 22:01:15.472658  3814 solver.cpp:243] Iteration 4200, loss = 0.0941974
I1008 22:01:15.472689  3814 solver.cpp:259]     Train net output #0: error_blob = 0.0941974 (* 1 = 0.0941974 loss)
I1008 22:01:15.472697  3814 solver.cpp:590] Iteration 4200, lr = 0.0139229
I1008 22:01:20.314148  3814 solver.cpp:347] Iteration 4300, Testing net (#0)
I1008 22:01:20.316046  3814 solver.cpp:415]     Test net output #0: error_blob = 0.1174 (* 1 = 0.1174 loss)
I1008 22:01:20.367810  3814 solver.cpp:243] Iteration 4300, loss = 0.0949094
I1008 22:01:20.367841  3814 solver.cpp:259]     Train net output #0: error_blob = 0.0949094 (* 1 = 0.0949094 loss)
I1008 22:01:20.367848  3814 solver.cpp:590] Iteration 4300, lr = 0.0135164
I1008 22:01:25.200789  3814 solver.cpp:347] Iteration 4400, Testing net (#0)
I1008 22:01:25.202687  3814 solver.cpp:415]     Test net output #0: error_blob = 0.118083 (* 1 = 0.118083 loss)
I1008 22:01:25.254155  3814 solver.cpp:243] Iteration 4400, loss = 0.095696
I1008 22:01:25.254186  3814 solver.cpp:259]     Train net output #0: error_blob = 0.095696 (* 1 = 0.095696 loss)
I1008 22:01:25.254192  3814 solver.cpp:590] Iteration 4400, lr = 0.0131275
I1008 22:01:30.097266  3814 solver.cpp:347] Iteration 4500, Testing net (#0)
I1008 22:01:30.099167  3814 solver.cpp:415]     Test net output #0: error_blob = 0.119056 (* 1 = 0.119056 loss)
I1008 22:01:30.147284  3814 solver.cpp:243] Iteration 4500, loss = 0.0938773
I1008 22:01:30.147315  3814 solver.cpp:259]     Train net output #0: error_blob = 0.0938773 (* 1 = 0.0938773 loss)
I1008 22:01:30.147321  3814 solver.cpp:590] Iteration 4500, lr = 0.0127551
I1008 22:01:35.000691  3814 solver.cpp:347] Iteration 4600, Testing net (#0)
I1008 22:01:35.002595  3814 solver.cpp:415]     Test net output #0: error_blob = 0.121306 (* 1 = 0.121306 loss)
I1008 22:01:35.053477  3814 solver.cpp:243] Iteration 4600, loss = 0.0945748
I1008 22:01:35.053505  3814 solver.cpp:259]     Train net output #0: error_blob = 0.0945748 (* 1 = 0.0945748 loss)
I1008 22:01:35.053511  3814 solver.cpp:590] Iteration 4600, lr = 0.0123983
I1008 22:01:39.896945  3814 solver.cpp:347] Iteration 4700, Testing net (#0)
I1008 22:01:39.898840  3814 solver.cpp:415]     Test net output #0: error_blob = 0.121135 (* 1 = 0.121135 loss)
I1008 22:01:39.947054  3814 solver.cpp:243] Iteration 4700, loss = 0.0934733
I1008 22:01:39.947087  3814 solver.cpp:259]     Train net output #0: error_blob = 0.0934733 (* 1 = 0.0934733 loss)
I1008 22:01:39.947093  3814 solver.cpp:590] Iteration 4700, lr = 0.0120563
I1008 22:01:44.816902  3814 solver.cpp:347] Iteration 4800, Testing net (#0)
I1008 22:01:44.818785  3814 solver.cpp:415]     Test net output #0: error_blob = 0.120169 (* 1 = 0.120169 loss)
I1008 22:01:44.867146  3814 solver.cpp:243] Iteration 4800, loss = 0.094336
I1008 22:01:44.867183  3814 solver.cpp:259]     Train net output #0: error_blob = 0.094336 (* 1 = 0.094336 loss)
I1008 22:01:44.867192  3814 solver.cpp:590] Iteration 4800, lr = 0.0117283
I1008 22:01:49.720754  3814 solver.cpp:347] Iteration 4900, Testing net (#0)
I1008 22:01:49.722651  3814 solver.cpp:415]     Test net output #0: error_blob = 0.11717 (* 1 = 0.11717 loss)
I1008 22:01:49.774474  3814 solver.cpp:243] Iteration 4900, loss = 0.0951451
I1008 22:01:49.774504  3814 solver.cpp:259]     Train net output #0: error_blob = 0.0951451 (* 1 = 0.0951451 loss)
I1008 22:01:49.774512  3814 solver.cpp:590] Iteration 4900, lr = 0.0114134
I1008 22:01:54.633182  3814 solver.cpp:468] Snapshotting to binary proto file _iter_5000.caffemodel
I1008 22:01:54.635107  3814 solver.cpp:753] Snapshotting solver state to binary proto file _iter_5000.solverstate
I1008 22:01:54.682764  3814 solver.cpp:327] Iteration 5000, loss = 0.0934511
I1008 22:01:54.682788  3814 solver.cpp:347] Iteration 5000, Testing net (#0)
I1008 22:01:54.683081  3814 solver.cpp:415]     Test net output #0: error_blob = 0.118113 (* 1 = 0.118113 loss)
I1008 22:01:54.683092  3814 solver.cpp:332] Optimization Done.
I1008 22:01:54.683104  3814 caffe.cpp:215] Optimization Done.
I1008 22:01:54.816303  3987 caffe.cpp:184] Using GPUs 0
I1008 22:01:55.376061  3987 solver.cpp:54] Initializing solver from parameters: 
test_iter: 1
test_interval: 100
base_lr: 0.1
display: 100
max_iter: 5000
lr_policy: "inv"
gamma: 0.0004
power: 2
momentum: 0.9
solver_mode: GPU
device_id: 0
net: "two_hidden/model3_part0.prototxt"
I1008 22:01:55.376093  3987 solver.cpp:97] Creating training net from net file: two_hidden/model3_part0.prototxt
I1008 22:01:55.376278  3987 net.cpp:339] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_layer
I1008 22:01:55.376328  3987 net.cpp:50] Initializing net from parameters: 
name: "two_hidden/model3_part0.prototxt"
state {
  phase: TRAIN
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TRAIN
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.part0.train"
    batch_size: 40000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer1"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob1"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer1"
  type: "Sigmoid"
  bottom: "hidden_sum_blob1"
  top: "hidden_act_blob1"
}
layer {
  name: "hidden_sum_layer2"
  type: "InnerProduct"
  bottom: "hidden_act_blob1"
  top: "hidden_sum_blob2"
  inner_product_param {
    num_output: 5
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer2"
  type: "Sigmoid"
  bottom: "hidden_sum_blob2"
  top: "hidden_act_blob2"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob2"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1008 22:01:55.376406  3987 layer_factory.hpp:76] Creating layer data_layer
I1008 22:01:55.402938  3987 net.cpp:110] Creating Layer data_layer
I1008 22:01:55.402971  3987 net.cpp:433] data_layer -> data_blob
I1008 22:01:55.403003  3987 net.cpp:433] data_layer -> label_blob
I1008 22:01:55.403611  3991 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.part0.train
I1008 22:01:56.087105  3987 data_layer.cpp:45] output data size: 40000,61,1,1
I1008 22:01:56.097530  3987 net.cpp:155] Setting up data_layer
I1008 22:01:56.097573  3987 net.cpp:163] Top shape: 40000 61 1 1 (2440000)
I1008 22:01:56.097576  3987 net.cpp:163] Top shape: 40000 (40000)
I1008 22:01:56.097592  3987 layer_factory.hpp:76] Creating layer hidden_sum_layer1
I1008 22:01:56.097604  3987 net.cpp:110] Creating Layer hidden_sum_layer1
I1008 22:01:56.097609  3987 net.cpp:477] hidden_sum_layer1 <- data_blob
I1008 22:01:56.097618  3987 net.cpp:433] hidden_sum_layer1 -> hidden_sum_blob1
I1008 22:01:56.098001  3987 net.cpp:155] Setting up hidden_sum_layer1
I1008 22:01:56.098009  3987 net.cpp:163] Top shape: 40000 10 (400000)
I1008 22:01:56.098031  3987 layer_factory.hpp:76] Creating layer hidden_act_layer1
I1008 22:01:56.098047  3987 net.cpp:110] Creating Layer hidden_act_layer1
I1008 22:01:56.098050  3987 net.cpp:477] hidden_act_layer1 <- hidden_sum_blob1
I1008 22:01:56.098053  3987 net.cpp:433] hidden_act_layer1 -> hidden_act_blob1
I1008 22:01:59.319289  3987 net.cpp:155] Setting up hidden_act_layer1
I1008 22:01:59.319313  3987 net.cpp:163] Top shape: 40000 10 (400000)
I1008 22:01:59.319317  3987 layer_factory.hpp:76] Creating layer hidden_sum_layer2
I1008 22:01:59.319327  3987 net.cpp:110] Creating Layer hidden_sum_layer2
I1008 22:01:59.319330  3987 net.cpp:477] hidden_sum_layer2 <- hidden_act_blob1
I1008 22:01:59.319346  3987 net.cpp:433] hidden_sum_layer2 -> hidden_sum_blob2
I1008 22:01:59.319447  3987 net.cpp:155] Setting up hidden_sum_layer2
I1008 22:01:59.319453  3987 net.cpp:163] Top shape: 40000 5 (200000)
I1008 22:01:59.319485  3987 layer_factory.hpp:76] Creating layer hidden_act_layer2
I1008 22:01:59.319490  3987 net.cpp:110] Creating Layer hidden_act_layer2
I1008 22:01:59.319494  3987 net.cpp:477] hidden_act_layer2 <- hidden_sum_blob2
I1008 22:01:59.319495  3987 net.cpp:433] hidden_act_layer2 -> hidden_act_blob2
I1008 22:01:59.319558  3987 net.cpp:155] Setting up hidden_act_layer2
I1008 22:01:59.319562  3987 net.cpp:163] Top shape: 40000 5 (200000)
I1008 22:01:59.319564  3987 layer_factory.hpp:76] Creating layer output_sum_layer
I1008 22:01:59.319568  3987 net.cpp:110] Creating Layer output_sum_layer
I1008 22:01:59.319571  3987 net.cpp:477] output_sum_layer <- hidden_act_blob2
I1008 22:01:59.319572  3987 net.cpp:433] output_sum_layer -> output_sum_blob
I1008 22:01:59.319658  3987 net.cpp:155] Setting up output_sum_layer
I1008 22:01:59.319663  3987 net.cpp:163] Top shape: 40000 1 (40000)
I1008 22:01:59.319667  3987 layer_factory.hpp:76] Creating layer output_act_layer
I1008 22:01:59.319670  3987 net.cpp:110] Creating Layer output_act_layer
I1008 22:01:59.319672  3987 net.cpp:477] output_act_layer <- output_sum_blob
I1008 22:01:59.319674  3987 net.cpp:433] output_act_layer -> output_act_blob
I1008 22:01:59.319825  3987 net.cpp:155] Setting up output_act_layer
I1008 22:01:59.319831  3987 net.cpp:163] Top shape: 40000 1 (40000)
I1008 22:01:59.319834  3987 layer_factory.hpp:76] Creating layer error_layer
I1008 22:01:59.319839  3987 net.cpp:110] Creating Layer error_layer
I1008 22:01:59.319841  3987 net.cpp:477] error_layer <- output_act_blob
I1008 22:01:59.319844  3987 net.cpp:477] error_layer <- label_blob
I1008 22:01:59.319847  3987 net.cpp:433] error_layer -> error_blob
I1008 22:01:59.319881  3987 net.cpp:155] Setting up error_layer
I1008 22:01:59.319885  3987 net.cpp:163] Top shape: (1)
I1008 22:01:59.319886  3987 net.cpp:168]     with loss weight 1
I1008 22:01:59.319911  3987 net.cpp:236] error_layer needs backward computation.
I1008 22:01:59.319923  3987 net.cpp:236] output_act_layer needs backward computation.
I1008 22:01:59.319926  3987 net.cpp:236] output_sum_layer needs backward computation.
I1008 22:01:59.319927  3987 net.cpp:236] hidden_act_layer2 needs backward computation.
I1008 22:01:59.319929  3987 net.cpp:236] hidden_sum_layer2 needs backward computation.
I1008 22:01:59.319931  3987 net.cpp:236] hidden_act_layer1 needs backward computation.
I1008 22:01:59.319933  3987 net.cpp:236] hidden_sum_layer1 needs backward computation.
I1008 22:01:59.319936  3987 net.cpp:240] data_layer does not need backward computation.
I1008 22:01:59.319937  3987 net.cpp:283] This network produces output error_blob
I1008 22:01:59.319942  3987 net.cpp:297] Network initialization done.
I1008 22:01:59.319944  3987 net.cpp:298] Memory required for data: 15040004
I1008 22:01:59.320085  3987 solver.cpp:187] Creating test net (#0) specified by net file: two_hidden/model3_part0.prototxt
I1008 22:01:59.320096  3987 net.cpp:339] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_layer
I1008 22:01:59.320152  3987 net.cpp:50] Initializing net from parameters: 
name: "two_hidden/model3_part0.prototxt"
state {
  phase: TEST
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TEST
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.part0.test"
    batch_size: 4000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer1"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob1"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer1"
  type: "Sigmoid"
  bottom: "hidden_sum_blob1"
  top: "hidden_act_blob1"
}
layer {
  name: "hidden_sum_layer2"
  type: "InnerProduct"
  bottom: "hidden_act_blob1"
  top: "hidden_sum_blob2"
  inner_product_param {
    num_output: 5
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer2"
  type: "Sigmoid"
  bottom: "hidden_sum_blob2"
  top: "hidden_act_blob2"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob2"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1008 22:01:59.320181  3987 layer_factory.hpp:76] Creating layer data_layer
I1008 22:01:59.322511  3987 net.cpp:110] Creating Layer data_layer
I1008 22:01:59.322526  3987 net.cpp:433] data_layer -> data_blob
I1008 22:01:59.322541  3987 net.cpp:433] data_layer -> label_blob
I1008 22:01:59.323101  3993 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.part0.test
I1008 22:01:59.323204  3987 data_layer.cpp:45] output data size: 4000,61,1,1
I1008 22:01:59.325043  3987 net.cpp:155] Setting up data_layer
I1008 22:01:59.325054  3987 net.cpp:163] Top shape: 4000 61 1 1 (244000)
I1008 22:01:59.325058  3987 net.cpp:163] Top shape: 4000 (4000)
I1008 22:01:59.325062  3987 layer_factory.hpp:76] Creating layer hidden_sum_layer1
I1008 22:01:59.325068  3987 net.cpp:110] Creating Layer hidden_sum_layer1
I1008 22:01:59.325070  3987 net.cpp:477] hidden_sum_layer1 <- data_blob
I1008 22:01:59.325074  3987 net.cpp:433] hidden_sum_layer1 -> hidden_sum_blob1
I1008 22:01:59.325209  3987 net.cpp:155] Setting up hidden_sum_layer1
I1008 22:01:59.325214  3987 net.cpp:163] Top shape: 4000 10 (40000)
I1008 22:01:59.325220  3987 layer_factory.hpp:76] Creating layer hidden_act_layer1
I1008 22:01:59.325225  3987 net.cpp:110] Creating Layer hidden_act_layer1
I1008 22:01:59.325227  3987 net.cpp:477] hidden_act_layer1 <- hidden_sum_blob1
I1008 22:01:59.325230  3987 net.cpp:433] hidden_act_layer1 -> hidden_act_blob1
I1008 22:01:59.325312  3987 net.cpp:155] Setting up hidden_act_layer1
I1008 22:01:59.325317  3987 net.cpp:163] Top shape: 4000 10 (40000)
I1008 22:01:59.325320  3987 layer_factory.hpp:76] Creating layer hidden_sum_layer2
I1008 22:01:59.325323  3987 net.cpp:110] Creating Layer hidden_sum_layer2
I1008 22:01:59.325325  3987 net.cpp:477] hidden_sum_layer2 <- hidden_act_blob1
I1008 22:01:59.325328  3987 net.cpp:433] hidden_sum_layer2 -> hidden_sum_blob2
I1008 22:01:59.325392  3987 net.cpp:155] Setting up hidden_sum_layer2
I1008 22:01:59.325397  3987 net.cpp:163] Top shape: 4000 5 (20000)
I1008 22:01:59.325402  3987 layer_factory.hpp:76] Creating layer hidden_act_layer2
I1008 22:01:59.325405  3987 net.cpp:110] Creating Layer hidden_act_layer2
I1008 22:01:59.325407  3987 net.cpp:477] hidden_act_layer2 <- hidden_sum_blob2
I1008 22:01:59.325410  3987 net.cpp:433] hidden_act_layer2 -> hidden_act_blob2
I1008 22:01:59.325464  3987 net.cpp:155] Setting up hidden_act_layer2
I1008 22:01:59.325469  3987 net.cpp:163] Top shape: 4000 5 (20000)
I1008 22:01:59.325470  3987 layer_factory.hpp:76] Creating layer output_sum_layer
I1008 22:01:59.325474  3987 net.cpp:110] Creating Layer output_sum_layer
I1008 22:01:59.325476  3987 net.cpp:477] output_sum_layer <- hidden_act_blob2
I1008 22:01:59.325479  3987 net.cpp:433] output_sum_layer -> output_sum_blob
I1008 22:01:59.325536  3987 net.cpp:155] Setting up output_sum_layer
I1008 22:01:59.325541  3987 net.cpp:163] Top shape: 4000 1 (4000)
I1008 22:01:59.325546  3987 layer_factory.hpp:76] Creating layer output_act_layer
I1008 22:01:59.325549  3987 net.cpp:110] Creating Layer output_act_layer
I1008 22:01:59.325551  3987 net.cpp:477] output_act_layer <- output_sum_blob
I1008 22:01:59.325553  3987 net.cpp:433] output_act_layer -> output_act_blob
I1008 22:01:59.325605  3987 net.cpp:155] Setting up output_act_layer
I1008 22:01:59.325609  3987 net.cpp:163] Top shape: 4000 1 (4000)
I1008 22:01:59.325613  3987 layer_factory.hpp:76] Creating layer error_layer
I1008 22:01:59.325615  3987 net.cpp:110] Creating Layer error_layer
I1008 22:01:59.325618  3987 net.cpp:477] error_layer <- output_act_blob
I1008 22:01:59.325630  3987 net.cpp:477] error_layer <- label_blob
I1008 22:01:59.325634  3987 net.cpp:433] error_layer -> error_blob
I1008 22:01:59.325656  3987 net.cpp:155] Setting up error_layer
I1008 22:01:59.325660  3987 net.cpp:163] Top shape: (1)
I1008 22:01:59.325662  3987 net.cpp:168]     with loss weight 1
I1008 22:01:59.325670  3987 net.cpp:236] error_layer needs backward computation.
I1008 22:01:59.325671  3987 net.cpp:236] output_act_layer needs backward computation.
I1008 22:01:59.325673  3987 net.cpp:236] output_sum_layer needs backward computation.
I1008 22:01:59.325675  3987 net.cpp:236] hidden_act_layer2 needs backward computation.
I1008 22:01:59.325677  3987 net.cpp:236] hidden_sum_layer2 needs backward computation.
I1008 22:01:59.325680  3987 net.cpp:236] hidden_act_layer1 needs backward computation.
I1008 22:01:59.325681  3987 net.cpp:236] hidden_sum_layer1 needs backward computation.
I1008 22:01:59.325683  3987 net.cpp:240] data_layer does not need backward computation.
I1008 22:01:59.325685  3987 net.cpp:283] This network produces output error_blob
I1008 22:01:59.325690  3987 net.cpp:297] Network initialization done.
I1008 22:01:59.325692  3987 net.cpp:298] Memory required for data: 1504004
I1008 22:01:59.325716  3987 solver.cpp:66] Solver scaffolding done.
I1008 22:01:59.325850  3987 caffe.cpp:212] Starting Optimization
I1008 22:01:59.325856  3987 solver.cpp:294] Solving two_hidden/model3_part0.prototxt
I1008 22:01:59.325858  3987 solver.cpp:295] Learning Rate Policy: inv
I1008 22:01:59.326138  3987 solver.cpp:347] Iteration 0, Testing net (#0)
I1008 22:01:59.326200  3987 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 22:01:59.331161  3987 solver.cpp:415]     Test net output #0: error_blob = 0.124342 (* 1 = 0.124342 loss)
I1008 22:01:59.333245  3987 solver.cpp:243] Iteration 0, loss = 0.124384
I1008 22:01:59.333259  3987 solver.cpp:259]     Train net output #0: error_blob = 0.124384 (* 1 = 0.124384 loss)
I1008 22:01:59.333276  3987 solver.cpp:590] Iteration 0, lr = 0.1
I1008 22:02:04.128780  3987 solver.cpp:347] Iteration 100, Testing net (#0)
I1008 22:02:04.130622  3987 solver.cpp:415]     Test net output #0: error_blob = 0.121838 (* 1 = 0.121838 loss)
I1008 22:02:04.184272  3987 solver.cpp:243] Iteration 100, loss = 0.1203
I1008 22:02:04.184319  3987 solver.cpp:259]     Train net output #0: error_blob = 0.1203 (* 1 = 0.1203 loss)
I1008 22:02:04.184329  3987 solver.cpp:590] Iteration 100, lr = 0.0924556
I1008 22:02:09.105130  3987 solver.cpp:347] Iteration 200, Testing net (#0)
I1008 22:02:09.107007  3987 solver.cpp:415]     Test net output #0: error_blob = 0.117862 (* 1 = 0.117862 loss)
I1008 22:02:09.160995  3987 solver.cpp:243] Iteration 200, loss = 0.113477
I1008 22:02:09.161033  3987 solver.cpp:259]     Train net output #0: error_blob = 0.113477 (* 1 = 0.113477 loss)
I1008 22:02:09.161044  3987 solver.cpp:590] Iteration 200, lr = 0.0857339
I1008 22:02:14.047945  3987 solver.cpp:347] Iteration 300, Testing net (#0)
I1008 22:02:14.049801  3987 solver.cpp:415]     Test net output #0: error_blob = 0.109553 (* 1 = 0.109553 loss)
I1008 22:02:14.100242  3987 solver.cpp:243] Iteration 300, loss = 0.107827
I1008 22:02:14.100278  3987 solver.cpp:259]     Train net output #0: error_blob = 0.107827 (* 1 = 0.107827 loss)
I1008 22:02:14.100289  3987 solver.cpp:590] Iteration 300, lr = 0.0797194
I1008 22:02:19.016288  3987 solver.cpp:347] Iteration 400, Testing net (#0)
I1008 22:02:19.018136  3987 solver.cpp:415]     Test net output #0: error_blob = 0.109841 (* 1 = 0.109841 loss)
I1008 22:02:19.091162  3987 solver.cpp:243] Iteration 400, loss = 0.10535
I1008 22:02:19.091189  3987 solver.cpp:259]     Train net output #0: error_blob = 0.10535 (* 1 = 0.10535 loss)
I1008 22:02:19.091197  3987 solver.cpp:590] Iteration 400, lr = 0.0743163
I1008 22:02:24.076951  3987 solver.cpp:347] Iteration 500, Testing net (#0)
I1008 22:02:24.078793  3987 solver.cpp:415]     Test net output #0: error_blob = 0.107804 (* 1 = 0.107804 loss)
I1008 22:02:24.132066  3987 solver.cpp:243] Iteration 500, loss = 0.104214
I1008 22:02:24.132128  3987 solver.cpp:259]     Train net output #0: error_blob = 0.104214 (* 1 = 0.104214 loss)
I1008 22:02:24.132149  3987 solver.cpp:590] Iteration 500, lr = 0.0694444
I1008 22:02:29.026124  3987 solver.cpp:347] Iteration 600, Testing net (#0)
I1008 22:02:29.028028  3987 solver.cpp:415]     Test net output #0: error_blob = 0.108159 (* 1 = 0.108159 loss)
I1008 22:02:29.077083  3987 solver.cpp:243] Iteration 600, loss = 0.101638
I1008 22:02:29.077114  3987 solver.cpp:259]     Train net output #0: error_blob = 0.101638 (* 1 = 0.101638 loss)
I1008 22:02:29.077123  3987 solver.cpp:590] Iteration 600, lr = 0.0650364
I1008 22:02:34.019688  3987 solver.cpp:347] Iteration 700, Testing net (#0)
I1008 22:02:34.021580  3987 solver.cpp:415]     Test net output #0: error_blob = 0.107446 (* 1 = 0.107446 loss)
I1008 22:02:34.073606  3987 solver.cpp:243] Iteration 700, loss = 0.10156
I1008 22:02:34.073645  3987 solver.cpp:259]     Train net output #0: error_blob = 0.10156 (* 1 = 0.10156 loss)
I1008 22:02:34.073652  3987 solver.cpp:590] Iteration 700, lr = 0.0610352
I1008 22:02:38.937582  3987 solver.cpp:347] Iteration 800, Testing net (#0)
I1008 22:02:38.939479  3987 solver.cpp:415]     Test net output #0: error_blob = 0.106367 (* 1 = 0.106367 loss)
I1008 22:02:38.993455  3987 solver.cpp:243] Iteration 800, loss = 0.100943
I1008 22:02:38.993489  3987 solver.cpp:259]     Train net output #0: error_blob = 0.100943 (* 1 = 0.100943 loss)
I1008 22:02:38.993497  3987 solver.cpp:590] Iteration 800, lr = 0.0573921
I1008 22:02:43.912421  3987 solver.cpp:347] Iteration 900, Testing net (#0)
I1008 22:02:43.914283  3987 solver.cpp:415]     Test net output #0: error_blob = 0.10376 (* 1 = 0.10376 loss)
I1008 22:02:43.964736  3987 solver.cpp:243] Iteration 900, loss = 0.0998126
I1008 22:02:43.964773  3987 solver.cpp:259]     Train net output #0: error_blob = 0.0998126 (* 1 = 0.0998126 loss)
I1008 22:02:43.964783  3987 solver.cpp:590] Iteration 900, lr = 0.0540657
I1008 22:02:48.884909  3987 solver.cpp:347] Iteration 1000, Testing net (#0)
I1008 22:02:48.886761  3987 solver.cpp:415]     Test net output #0: error_blob = 0.105131 (* 1 = 0.105131 loss)
I1008 22:02:48.941421  3987 solver.cpp:243] Iteration 1000, loss = 0.098571
I1008 22:02:48.941463  3987 solver.cpp:259]     Train net output #0: error_blob = 0.098571 (* 1 = 0.098571 loss)
I1008 22:02:48.941472  3987 solver.cpp:590] Iteration 1000, lr = 0.0510204
I1008 22:02:48.990185  3987 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 22:02:53.842751  3987 solver.cpp:347] Iteration 1100, Testing net (#0)
I1008 22:02:53.844599  3987 solver.cpp:415]     Test net output #0: error_blob = 0.108315 (* 1 = 0.108315 loss)
I1008 22:02:53.899937  3987 solver.cpp:243] Iteration 1100, loss = 0.099083
I1008 22:02:53.899974  3987 solver.cpp:259]     Train net output #0: error_blob = 0.099083 (* 1 = 0.099083 loss)
I1008 22:02:53.899983  3987 solver.cpp:590] Iteration 1100, lr = 0.0482253
I1008 22:02:58.799247  3987 solver.cpp:347] Iteration 1200, Testing net (#0)
I1008 22:02:58.801134  3987 solver.cpp:415]     Test net output #0: error_blob = 0.106665 (* 1 = 0.106665 loss)
I1008 22:02:58.854662  3987 solver.cpp:243] Iteration 1200, loss = 0.0988298
I1008 22:02:58.854696  3987 solver.cpp:259]     Train net output #0: error_blob = 0.0988298 (* 1 = 0.0988298 loss)
I1008 22:02:58.854706  3987 solver.cpp:590] Iteration 1200, lr = 0.0456538
I1008 22:03:03.747640  3987 solver.cpp:347] Iteration 1300, Testing net (#0)
I1008 22:03:03.749492  3987 solver.cpp:415]     Test net output #0: error_blob = 0.1086 (* 1 = 0.1086 loss)
I1008 22:03:03.802716  3987 solver.cpp:243] Iteration 1300, loss = 0.0993145
I1008 22:03:03.802763  3987 solver.cpp:259]     Train net output #0: error_blob = 0.0993145 (* 1 = 0.0993145 loss)
I1008 22:03:03.802773  3987 solver.cpp:590] Iteration 1300, lr = 0.0432825
I1008 22:03:08.678550  3987 solver.cpp:347] Iteration 1400, Testing net (#0)
I1008 22:03:08.680387  3987 solver.cpp:415]     Test net output #0: error_blob = 0.101171 (* 1 = 0.101171 loss)
I1008 22:03:08.734316  3987 solver.cpp:243] Iteration 1400, loss = 0.0975101
I1008 22:03:08.734364  3987 solver.cpp:259]     Train net output #0: error_blob = 0.0975101 (* 1 = 0.0975101 loss)
I1008 22:03:08.734374  3987 solver.cpp:590] Iteration 1400, lr = 0.0410914
I1008 22:03:13.641536  3987 solver.cpp:347] Iteration 1500, Testing net (#0)
I1008 22:03:13.643438  3987 solver.cpp:415]     Test net output #0: error_blob = 0.104803 (* 1 = 0.104803 loss)
I1008 22:03:13.694911  3987 solver.cpp:243] Iteration 1500, loss = 0.0978995
I1008 22:03:13.694946  3987 solver.cpp:259]     Train net output #0: error_blob = 0.0978995 (* 1 = 0.0978995 loss)
I1008 22:03:13.694955  3987 solver.cpp:590] Iteration 1500, lr = 0.0390625
I1008 22:03:18.592201  3987 solver.cpp:347] Iteration 1600, Testing net (#0)
I1008 22:03:18.594095  3987 solver.cpp:415]     Test net output #0: error_blob = 0.105058 (* 1 = 0.105058 loss)
I1008 22:03:18.646309  3987 solver.cpp:243] Iteration 1600, loss = 0.0972903
I1008 22:03:18.646343  3987 solver.cpp:259]     Train net output #0: error_blob = 0.0972903 (* 1 = 0.0972903 loss)
I1008 22:03:18.646354  3987 solver.cpp:590] Iteration 1600, lr = 0.0371803
I1008 22:03:23.579411  3987 solver.cpp:347] Iteration 1700, Testing net (#0)
I1008 22:03:23.581296  3987 solver.cpp:415]     Test net output #0: error_blob = 0.106132 (* 1 = 0.106132 loss)
I1008 22:03:23.631393  3987 solver.cpp:243] Iteration 1700, loss = 0.0967704
I1008 22:03:23.631425  3987 solver.cpp:259]     Train net output #0: error_blob = 0.0967704 (* 1 = 0.0967704 loss)
I1008 22:03:23.631436  3987 solver.cpp:590] Iteration 1700, lr = 0.0354308
I1008 22:03:28.534559  3987 solver.cpp:347] Iteration 1800, Testing net (#0)
I1008 22:03:28.536448  3987 solver.cpp:415]     Test net output #0: error_blob = 0.106262 (* 1 = 0.106262 loss)
I1008 22:03:28.587661  3987 solver.cpp:243] Iteration 1800, loss = 0.0965052
I1008 22:03:28.587695  3987 solver.cpp:259]     Train net output #0: error_blob = 0.0965052 (* 1 = 0.0965052 loss)
I1008 22:03:28.587704  3987 solver.cpp:590] Iteration 1800, lr = 0.0338021
I1008 22:03:33.548209  3987 solver.cpp:347] Iteration 1900, Testing net (#0)
I1008 22:03:33.550127  3987 solver.cpp:415]     Test net output #0: error_blob = 0.105545 (* 1 = 0.105545 loss)
I1008 22:03:33.604748  3987 solver.cpp:243] Iteration 1900, loss = 0.0977478
I1008 22:03:33.604781  3987 solver.cpp:259]     Train net output #0: error_blob = 0.0977478 (* 1 = 0.0977478 loss)
I1008 22:03:33.604791  3987 solver.cpp:590] Iteration 1900, lr = 0.0322831
I1008 22:03:38.518318  3987 solver.cpp:347] Iteration 2000, Testing net (#0)
I1008 22:03:38.520181  3987 solver.cpp:415]     Test net output #0: error_blob = 0.10127 (* 1 = 0.10127 loss)
I1008 22:03:38.573467  3987 solver.cpp:243] Iteration 2000, loss = 0.0965751
I1008 22:03:38.573511  3987 solver.cpp:259]     Train net output #0: error_blob = 0.0965751 (* 1 = 0.0965751 loss)
I1008 22:03:38.573523  3987 solver.cpp:590] Iteration 2000, lr = 0.0308642
I1008 22:03:38.621990  3987 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 22:03:43.482472  3987 solver.cpp:347] Iteration 2100, Testing net (#0)
I1008 22:03:43.484333  3987 solver.cpp:415]     Test net output #0: error_blob = 0.103561 (* 1 = 0.103561 loss)
I1008 22:03:43.536190  3987 solver.cpp:243] Iteration 2100, loss = 0.0971039
I1008 22:03:43.536224  3987 solver.cpp:259]     Train net output #0: error_blob = 0.0971039 (* 1 = 0.0971039 loss)
I1008 22:03:43.536234  3987 solver.cpp:590] Iteration 2100, lr = 0.0295369
I1008 22:03:48.527640  3987 solver.cpp:347] Iteration 2200, Testing net (#0)
I1008 22:03:48.529484  3987 solver.cpp:415]     Test net output #0: error_blob = 0.107947 (* 1 = 0.107947 loss)
I1008 22:03:48.580862  3987 solver.cpp:243] Iteration 2200, loss = 0.0951177
I1008 22:03:48.580906  3987 solver.cpp:259]     Train net output #0: error_blob = 0.0951177 (* 1 = 0.0951177 loss)
I1008 22:03:48.580916  3987 solver.cpp:590] Iteration 2200, lr = 0.0282933
I1008 22:03:53.562685  3987 solver.cpp:347] Iteration 2300, Testing net (#0)
I1008 22:03:53.564591  3987 solver.cpp:415]     Test net output #0: error_blob = 0.104921 (* 1 = 0.104921 loss)
I1008 22:03:53.616122  3987 solver.cpp:243] Iteration 2300, loss = 0.0962921
I1008 22:03:53.616153  3987 solver.cpp:259]     Train net output #0: error_blob = 0.0962921 (* 1 = 0.0962921 loss)
I1008 22:03:53.616161  3987 solver.cpp:590] Iteration 2300, lr = 0.0271267
I1008 22:03:58.573112  3987 solver.cpp:347] Iteration 2400, Testing net (#0)
I1008 22:03:58.574935  3987 solver.cpp:415]     Test net output #0: error_blob = 0.108359 (* 1 = 0.108359 loss)
I1008 22:03:58.626513  3987 solver.cpp:243] Iteration 2400, loss = 0.0964654
I1008 22:03:58.626549  3987 solver.cpp:259]     Train net output #0: error_blob = 0.0964654 (* 1 = 0.0964654 loss)
I1008 22:03:58.626569  3987 solver.cpp:590] Iteration 2400, lr = 0.0260308
I1008 22:04:03.623878  3987 solver.cpp:347] Iteration 2500, Testing net (#0)
I1008 22:04:03.625708  3987 solver.cpp:415]     Test net output #0: error_blob = 0.101216 (* 1 = 0.101216 loss)
I1008 22:04:03.678457  3987 solver.cpp:243] Iteration 2500, loss = 0.0949695
I1008 22:04:03.678493  3987 solver.cpp:259]     Train net output #0: error_blob = 0.0949695 (* 1 = 0.0949695 loss)
I1008 22:04:03.678501  3987 solver.cpp:590] Iteration 2500, lr = 0.025
I1008 22:04:08.658907  3987 solver.cpp:347] Iteration 2600, Testing net (#0)
I1008 22:04:08.660815  3987 solver.cpp:415]     Test net output #0: error_blob = 0.10257 (* 1 = 0.10257 loss)
I1008 22:04:08.712270  3987 solver.cpp:243] Iteration 2600, loss = 0.0956185
I1008 22:04:08.712299  3987 solver.cpp:259]     Train net output #0: error_blob = 0.0956185 (* 1 = 0.0956185 loss)
I1008 22:04:08.712306  3987 solver.cpp:590] Iteration 2600, lr = 0.0240292
I1008 22:04:13.593029  3987 solver.cpp:347] Iteration 2700, Testing net (#0)
I1008 22:04:13.594914  3987 solver.cpp:415]     Test net output #0: error_blob = 0.104154 (* 1 = 0.104154 loss)
I1008 22:04:13.648535  3987 solver.cpp:243] Iteration 2700, loss = 0.0955544
I1008 22:04:13.648567  3987 solver.cpp:259]     Train net output #0: error_blob = 0.0955544 (* 1 = 0.0955544 loss)
I1008 22:04:13.648574  3987 solver.cpp:590] Iteration 2700, lr = 0.0231139
I1008 22:04:18.576074  3987 solver.cpp:347] Iteration 2800, Testing net (#0)
I1008 22:04:18.577945  3987 solver.cpp:415]     Test net output #0: error_blob = 0.105816 (* 1 = 0.105816 loss)
I1008 22:04:18.632292  3987 solver.cpp:243] Iteration 2800, loss = 0.095093
I1008 22:04:18.632339  3987 solver.cpp:259]     Train net output #0: error_blob = 0.095093 (* 1 = 0.095093 loss)
I1008 22:04:18.632349  3987 solver.cpp:590] Iteration 2800, lr = 0.0222499
I1008 22:04:23.548167  3987 solver.cpp:347] Iteration 2900, Testing net (#0)
I1008 22:04:23.550088  3987 solver.cpp:415]     Test net output #0: error_blob = 0.105693 (* 1 = 0.105693 loss)
I1008 22:04:23.605236  3987 solver.cpp:243] Iteration 2900, loss = 0.095193
I1008 22:04:23.605275  3987 solver.cpp:259]     Train net output #0: error_blob = 0.095193 (* 1 = 0.095193 loss)
I1008 22:04:23.605283  3987 solver.cpp:590] Iteration 2900, lr = 0.0214335
I1008 22:04:28.546897  3987 solver.cpp:347] Iteration 3000, Testing net (#0)
I1008 22:04:28.548724  3987 solver.cpp:415]     Test net output #0: error_blob = 0.106035 (* 1 = 0.106035 loss)
I1008 22:04:28.601599  3987 solver.cpp:243] Iteration 3000, loss = 0.0945651
I1008 22:04:28.601645  3987 solver.cpp:259]     Train net output #0: error_blob = 0.0945651 (* 1 = 0.0945651 loss)
I1008 22:04:28.601655  3987 solver.cpp:590] Iteration 3000, lr = 0.0206612
I1008 22:04:28.652186  3987 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 22:04:33.486240  3987 solver.cpp:347] Iteration 3100, Testing net (#0)
I1008 22:04:33.488102  3987 solver.cpp:415]     Test net output #0: error_blob = 0.0996807 (* 1 = 0.0996807 loss)
I1008 22:04:33.537819  3987 solver.cpp:243] Iteration 3100, loss = 0.0951307
I1008 22:04:33.537853  3987 solver.cpp:259]     Train net output #0: error_blob = 0.0951307 (* 1 = 0.0951307 loss)
I1008 22:04:33.537873  3987 solver.cpp:590] Iteration 3100, lr = 0.0199298
I1008 22:04:38.452424  3987 solver.cpp:347] Iteration 3200, Testing net (#0)
I1008 22:04:38.454313  3987 solver.cpp:415]     Test net output #0: error_blob = 0.102689 (* 1 = 0.102689 loss)
I1008 22:04:38.505678  3987 solver.cpp:243] Iteration 3200, loss = 0.0961254
I1008 22:04:38.505710  3987 solver.cpp:259]     Train net output #0: error_blob = 0.0961254 (* 1 = 0.0961254 loss)
I1008 22:04:38.505719  3987 solver.cpp:590] Iteration 3200, lr = 0.0192367
I1008 22:04:43.457466  3987 solver.cpp:347] Iteration 3300, Testing net (#0)
I1008 22:04:43.459349  3987 solver.cpp:415]     Test net output #0: error_blob = 0.108026 (* 1 = 0.108026 loss)
I1008 22:04:43.513280  3987 solver.cpp:243] Iteration 3300, loss = 0.0943343
I1008 22:04:43.513311  3987 solver.cpp:259]     Train net output #0: error_blob = 0.0943343 (* 1 = 0.0943343 loss)
I1008 22:04:43.513319  3987 solver.cpp:590] Iteration 3300, lr = 0.0185791
I1008 22:04:48.447887  3987 solver.cpp:347] Iteration 3400, Testing net (#0)
I1008 22:04:48.449789  3987 solver.cpp:415]     Test net output #0: error_blob = 0.104118 (* 1 = 0.104118 loss)
I1008 22:04:48.502672  3987 solver.cpp:243] Iteration 3400, loss = 0.0948368
I1008 22:04:48.502713  3987 solver.cpp:259]     Train net output #0: error_blob = 0.0948368 (* 1 = 0.0948368 loss)
I1008 22:04:48.502722  3987 solver.cpp:590] Iteration 3400, lr = 0.0179546
I1008 22:04:53.431233  3987 solver.cpp:347] Iteration 3500, Testing net (#0)
I1008 22:04:53.433130  3987 solver.cpp:415]     Test net output #0: error_blob = 0.107933 (* 1 = 0.107933 loss)
I1008 22:04:53.483872  3987 solver.cpp:243] Iteration 3500, loss = 0.0944445
I1008 22:04:53.483903  3987 solver.cpp:259]     Train net output #0: error_blob = 0.0944445 (* 1 = 0.0944445 loss)
I1008 22:04:53.483911  3987 solver.cpp:590] Iteration 3500, lr = 0.0173611
I1008 22:04:58.412029  3987 solver.cpp:347] Iteration 3600, Testing net (#0)
I1008 22:04:58.413928  3987 solver.cpp:415]     Test net output #0: error_blob = 0.102651 (* 1 = 0.102651 loss)
I1008 22:04:58.465975  3987 solver.cpp:243] Iteration 3600, loss = 0.094009
I1008 22:04:58.466017  3987 solver.cpp:259]     Train net output #0: error_blob = 0.094009 (* 1 = 0.094009 loss)
I1008 22:04:58.466025  3987 solver.cpp:590] Iteration 3600, lr = 0.0167966
I1008 22:05:03.376293  3987 solver.cpp:347] Iteration 3700, Testing net (#0)
I1008 22:05:03.378191  3987 solver.cpp:415]     Test net output #0: error_blob = 0.100922 (* 1 = 0.100922 loss)
I1008 22:05:03.432843  3987 solver.cpp:243] Iteration 3700, loss = 0.0932559
I1008 22:05:03.432870  3987 solver.cpp:259]     Train net output #0: error_blob = 0.0932559 (* 1 = 0.0932559 loss)
I1008 22:05:03.432878  3987 solver.cpp:590] Iteration 3700, lr = 0.0162591
I1008 22:05:08.380857  3987 solver.cpp:347] Iteration 3800, Testing net (#0)
I1008 22:05:08.382755  3987 solver.cpp:415]     Test net output #0: error_blob = 0.103531 (* 1 = 0.103531 loss)
I1008 22:05:08.434689  3987 solver.cpp:243] Iteration 3800, loss = 0.0956097
I1008 22:05:08.434716  3987 solver.cpp:259]     Train net output #0: error_blob = 0.0956097 (* 1 = 0.0956097 loss)
I1008 22:05:08.434723  3987 solver.cpp:590] Iteration 3800, lr = 0.015747
I1008 22:05:13.333026  3987 solver.cpp:347] Iteration 3900, Testing net (#0)
I1008 22:05:13.334874  3987 solver.cpp:415]     Test net output #0: error_blob = 0.105403 (* 1 = 0.105403 loss)
I1008 22:05:13.385110  3987 solver.cpp:243] Iteration 3900, loss = 0.0948309
I1008 22:05:13.385146  3987 solver.cpp:259]     Train net output #0: error_blob = 0.0948309 (* 1 = 0.0948309 loss)
I1008 22:05:13.385156  3987 solver.cpp:590] Iteration 3900, lr = 0.0152588
I1008 22:05:18.290565  3987 solver.cpp:347] Iteration 4000, Testing net (#0)
I1008 22:05:18.292428  3987 solver.cpp:415]     Test net output #0: error_blob = 0.105853 (* 1 = 0.105853 loss)
I1008 22:05:18.342823  3987 solver.cpp:243] Iteration 4000, loss = 0.0949992
I1008 22:05:18.342859  3987 solver.cpp:259]     Train net output #0: error_blob = 0.0949992 (* 1 = 0.0949992 loss)
I1008 22:05:18.342867  3987 solver.cpp:590] Iteration 4000, lr = 0.0147929
I1008 22:05:18.394140  3987 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 22:05:23.281980  3987 solver.cpp:347] Iteration 4100, Testing net (#0)
I1008 22:05:23.283821  3987 solver.cpp:415]     Test net output #0: error_blob = 0.106642 (* 1 = 0.106642 loss)
I1008 22:05:23.335876  3987 solver.cpp:243] Iteration 4100, loss = 0.0930683
I1008 22:05:23.335912  3987 solver.cpp:259]     Train net output #0: error_blob = 0.0930683 (* 1 = 0.0930683 loss)
I1008 22:05:23.335922  3987 solver.cpp:590] Iteration 4100, lr = 0.014348
I1008 22:05:28.285132  3987 solver.cpp:347] Iteration 4200, Testing net (#0)
I1008 22:05:28.286983  3987 solver.cpp:415]     Test net output #0: error_blob = 0.0988768 (* 1 = 0.0988768 loss)
I1008 22:05:28.338632  3987 solver.cpp:243] Iteration 4200, loss = 0.0943457
I1008 22:05:28.338665  3987 solver.cpp:259]     Train net output #0: error_blob = 0.0943457 (* 1 = 0.0943457 loss)
I1008 22:05:28.338675  3987 solver.cpp:590] Iteration 4200, lr = 0.0139229
I1008 22:05:33.329087  3987 solver.cpp:347] Iteration 4300, Testing net (#0)
I1008 22:05:33.330922  3987 solver.cpp:415]     Test net output #0: error_blob = 0.101911 (* 1 = 0.101911 loss)
I1008 22:05:33.383191  3987 solver.cpp:243] Iteration 4300, loss = 0.0943333
I1008 22:05:33.383236  3987 solver.cpp:259]     Train net output #0: error_blob = 0.0943333 (* 1 = 0.0943333 loss)
I1008 22:05:33.383245  3987 solver.cpp:590] Iteration 4300, lr = 0.0135164
I1008 22:05:38.318795  3987 solver.cpp:347] Iteration 4400, Testing net (#0)
I1008 22:05:38.320655  3987 solver.cpp:415]     Test net output #0: error_blob = 0.107828 (* 1 = 0.107828 loss)
I1008 22:05:38.371537  3987 solver.cpp:243] Iteration 4400, loss = 0.0933163
I1008 22:05:38.371573  3987 solver.cpp:259]     Train net output #0: error_blob = 0.0933163 (* 1 = 0.0933163 loss)
I1008 22:05:38.371583  3987 solver.cpp:590] Iteration 4400, lr = 0.0131275
I1008 22:05:43.323043  3987 solver.cpp:347] Iteration 4500, Testing net (#0)
I1008 22:05:43.324894  3987 solver.cpp:415]     Test net output #0: error_blob = 0.105125 (* 1 = 0.105125 loss)
I1008 22:05:43.376140  3987 solver.cpp:243] Iteration 4500, loss = 0.0933981
I1008 22:05:43.376176  3987 solver.cpp:259]     Train net output #0: error_blob = 0.0933981 (* 1 = 0.0933981 loss)
I1008 22:05:43.376186  3987 solver.cpp:590] Iteration 4500, lr = 0.0127551
I1008 22:05:48.311076  3987 solver.cpp:347] Iteration 4600, Testing net (#0)
I1008 22:05:48.312909  3987 solver.cpp:415]     Test net output #0: error_blob = 0.106603 (* 1 = 0.106603 loss)
I1008 22:05:48.363581  3987 solver.cpp:243] Iteration 4600, loss = 0.0946516
I1008 22:05:48.363611  3987 solver.cpp:259]     Train net output #0: error_blob = 0.0946516 (* 1 = 0.0946516 loss)
I1008 22:05:48.363618  3987 solver.cpp:590] Iteration 4600, lr = 0.0123983
I1008 22:05:53.308301  3987 solver.cpp:347] Iteration 4700, Testing net (#0)
I1008 22:05:53.310166  3987 solver.cpp:415]     Test net output #0: error_blob = 0.103924 (* 1 = 0.103924 loss)
I1008 22:05:53.362231  3987 solver.cpp:243] Iteration 4700, loss = 0.0937371
I1008 22:05:53.362269  3987 solver.cpp:259]     Train net output #0: error_blob = 0.0937371 (* 1 = 0.0937371 loss)
I1008 22:05:53.362280  3987 solver.cpp:590] Iteration 4700, lr = 0.0120563
I1008 22:05:58.261159  3987 solver.cpp:347] Iteration 4800, Testing net (#0)
I1008 22:05:58.263007  3987 solver.cpp:415]     Test net output #0: error_blob = 0.100182 (* 1 = 0.100182 loss)
I1008 22:05:58.313189  3987 solver.cpp:243] Iteration 4800, loss = 0.0940561
I1008 22:05:58.313223  3987 solver.cpp:259]     Train net output #0: error_blob = 0.0940561 (* 1 = 0.0940561 loss)
I1008 22:05:58.313233  3987 solver.cpp:590] Iteration 4800, lr = 0.0117283
I1008 22:06:03.290740  3987 solver.cpp:347] Iteration 4900, Testing net (#0)
I1008 22:06:03.292655  3987 solver.cpp:415]     Test net output #0: error_blob = 0.103233 (* 1 = 0.103233 loss)
I1008 22:06:03.342757  3987 solver.cpp:243] Iteration 4900, loss = 0.0931367
I1008 22:06:03.342797  3987 solver.cpp:259]     Train net output #0: error_blob = 0.0931367 (* 1 = 0.0931367 loss)
I1008 22:06:03.342804  3987 solver.cpp:590] Iteration 4900, lr = 0.0114134
I1008 22:06:08.283543  3987 solver.cpp:468] Snapshotting to binary proto file _iter_5000.caffemodel
I1008 22:06:08.286473  3987 solver.cpp:753] Snapshotting solver state to binary proto file _iter_5000.solverstate
I1008 22:06:08.333879  3987 solver.cpp:327] Iteration 5000, loss = 0.0938269
I1008 22:06:08.333909  3987 solver.cpp:347] Iteration 5000, Testing net (#0)
I1008 22:06:08.334220  3987 solver.cpp:415]     Test net output #0: error_blob = 0.104946 (* 1 = 0.104946 loss)
I1008 22:06:08.334229  3987 solver.cpp:332] Optimization Done.
I1008 22:06:08.334231  3987 caffe.cpp:215] Optimization Done.
I1008 22:06:08.470882  3998 caffe.cpp:184] Using GPUs 0
I1008 22:06:09.029296  3998 solver.cpp:54] Initializing solver from parameters: 
test_iter: 1
test_interval: 100
base_lr: 0.1
display: 100
max_iter: 5000
lr_policy: "inv"
gamma: 0.0004
power: 2
momentum: 0.9
solver_mode: GPU
device_id: 0
net: "two_hidden/model3_part1.prototxt"
I1008 22:06:09.029326  3998 solver.cpp:97] Creating training net from net file: two_hidden/model3_part1.prototxt
I1008 22:06:09.029490  3998 net.cpp:339] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_layer
I1008 22:06:09.029530  3998 net.cpp:50] Initializing net from parameters: 
name: "two_hidden/model3_part1.prototxt"
state {
  phase: TRAIN
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TRAIN
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.part1.train"
    batch_size: 40000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer1"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob1"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer1"
  type: "Sigmoid"
  bottom: "hidden_sum_blob1"
  top: "hidden_act_blob1"
}
layer {
  name: "hidden_sum_layer2"
  type: "InnerProduct"
  bottom: "hidden_act_blob1"
  top: "hidden_sum_blob2"
  inner_product_param {
    num_output: 5
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer2"
  type: "Sigmoid"
  bottom: "hidden_sum_blob2"
  top: "hidden_act_blob2"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob2"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1008 22:06:09.029569  3998 layer_factory.hpp:76] Creating layer data_layer
I1008 22:06:09.056025  3998 net.cpp:110] Creating Layer data_layer
I1008 22:06:09.056046  3998 net.cpp:433] data_layer -> data_blob
I1008 22:06:09.056067  3998 net.cpp:433] data_layer -> label_blob
I1008 22:06:09.056684  4002 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.part1.train
I1008 22:06:09.740015  3998 data_layer.cpp:45] output data size: 40000,61,1,1
I1008 22:06:09.750483  3998 net.cpp:155] Setting up data_layer
I1008 22:06:09.750530  3998 net.cpp:163] Top shape: 40000 61 1 1 (2440000)
I1008 22:06:09.750538  3998 net.cpp:163] Top shape: 40000 (40000)
I1008 22:06:09.750545  3998 layer_factory.hpp:76] Creating layer hidden_sum_layer1
I1008 22:06:09.750555  3998 net.cpp:110] Creating Layer hidden_sum_layer1
I1008 22:06:09.750560  3998 net.cpp:477] hidden_sum_layer1 <- data_blob
I1008 22:06:09.750569  3998 net.cpp:433] hidden_sum_layer1 -> hidden_sum_blob1
I1008 22:06:09.750932  3998 net.cpp:155] Setting up hidden_sum_layer1
I1008 22:06:09.750941  3998 net.cpp:163] Top shape: 40000 10 (400000)
I1008 22:06:09.750952  3998 layer_factory.hpp:76] Creating layer hidden_act_layer1
I1008 22:06:09.750957  3998 net.cpp:110] Creating Layer hidden_act_layer1
I1008 22:06:09.750960  3998 net.cpp:477] hidden_act_layer1 <- hidden_sum_blob1
I1008 22:06:09.750963  3998 net.cpp:433] hidden_act_layer1 -> hidden_act_blob1
I1008 22:06:12.954851  3998 net.cpp:155] Setting up hidden_act_layer1
I1008 22:06:12.954874  3998 net.cpp:163] Top shape: 40000 10 (400000)
I1008 22:06:12.954877  3998 layer_factory.hpp:76] Creating layer hidden_sum_layer2
I1008 22:06:12.954887  3998 net.cpp:110] Creating Layer hidden_sum_layer2
I1008 22:06:12.954890  3998 net.cpp:477] hidden_sum_layer2 <- hidden_act_blob1
I1008 22:06:12.954895  3998 net.cpp:433] hidden_sum_layer2 -> hidden_sum_blob2
I1008 22:06:12.954987  3998 net.cpp:155] Setting up hidden_sum_layer2
I1008 22:06:12.954991  3998 net.cpp:163] Top shape: 40000 5 (200000)
I1008 22:06:12.955014  3998 layer_factory.hpp:76] Creating layer hidden_act_layer2
I1008 22:06:12.955020  3998 net.cpp:110] Creating Layer hidden_act_layer2
I1008 22:06:12.955024  3998 net.cpp:477] hidden_act_layer2 <- hidden_sum_blob2
I1008 22:06:12.955026  3998 net.cpp:433] hidden_act_layer2 -> hidden_act_blob2
I1008 22:06:12.955082  3998 net.cpp:155] Setting up hidden_act_layer2
I1008 22:06:12.955086  3998 net.cpp:163] Top shape: 40000 5 (200000)
I1008 22:06:12.955088  3998 layer_factory.hpp:76] Creating layer output_sum_layer
I1008 22:06:12.955092  3998 net.cpp:110] Creating Layer output_sum_layer
I1008 22:06:12.955095  3998 net.cpp:477] output_sum_layer <- hidden_act_blob2
I1008 22:06:12.955097  3998 net.cpp:433] output_sum_layer -> output_sum_blob
I1008 22:06:12.955168  3998 net.cpp:155] Setting up output_sum_layer
I1008 22:06:12.955171  3998 net.cpp:163] Top shape: 40000 1 (40000)
I1008 22:06:12.955176  3998 layer_factory.hpp:76] Creating layer output_act_layer
I1008 22:06:12.955180  3998 net.cpp:110] Creating Layer output_act_layer
I1008 22:06:12.955183  3998 net.cpp:477] output_act_layer <- output_sum_blob
I1008 22:06:12.955185  3998 net.cpp:433] output_act_layer -> output_act_blob
I1008 22:06:12.955322  3998 net.cpp:155] Setting up output_act_layer
I1008 22:06:12.955328  3998 net.cpp:163] Top shape: 40000 1 (40000)
I1008 22:06:12.955332  3998 layer_factory.hpp:76] Creating layer error_layer
I1008 22:06:12.955339  3998 net.cpp:110] Creating Layer error_layer
I1008 22:06:12.955341  3998 net.cpp:477] error_layer <- output_act_blob
I1008 22:06:12.955344  3998 net.cpp:477] error_layer <- label_blob
I1008 22:06:12.955348  3998 net.cpp:433] error_layer -> error_blob
I1008 22:06:12.955373  3998 net.cpp:155] Setting up error_layer
I1008 22:06:12.955377  3998 net.cpp:163] Top shape: (1)
I1008 22:06:12.955379  3998 net.cpp:168]     with loss weight 1
I1008 22:06:12.955394  3998 net.cpp:236] error_layer needs backward computation.
I1008 22:06:12.955397  3998 net.cpp:236] output_act_layer needs backward computation.
I1008 22:06:12.955399  3998 net.cpp:236] output_sum_layer needs backward computation.
I1008 22:06:12.955401  3998 net.cpp:236] hidden_act_layer2 needs backward computation.
I1008 22:06:12.955404  3998 net.cpp:236] hidden_sum_layer2 needs backward computation.
I1008 22:06:12.955405  3998 net.cpp:236] hidden_act_layer1 needs backward computation.
I1008 22:06:12.955407  3998 net.cpp:236] hidden_sum_layer1 needs backward computation.
I1008 22:06:12.955410  3998 net.cpp:240] data_layer does not need backward computation.
I1008 22:06:12.955411  3998 net.cpp:283] This network produces output error_blob
I1008 22:06:12.955417  3998 net.cpp:297] Network initialization done.
I1008 22:06:12.955418  3998 net.cpp:298] Memory required for data: 15040004
I1008 22:06:12.955560  3998 solver.cpp:187] Creating test net (#0) specified by net file: two_hidden/model3_part1.prototxt
I1008 22:06:12.955579  3998 net.cpp:339] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_layer
I1008 22:06:12.955616  3998 net.cpp:50] Initializing net from parameters: 
name: "two_hidden/model3_part1.prototxt"
state {
  phase: TEST
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TEST
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.part1.test"
    batch_size: 4000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer1"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob1"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer1"
  type: "Sigmoid"
  bottom: "hidden_sum_blob1"
  top: "hidden_act_blob1"
}
layer {
  name: "hidden_sum_layer2"
  type: "InnerProduct"
  bottom: "hidden_act_blob1"
  top: "hidden_sum_blob2"
  inner_product_param {
    num_output: 5
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer2"
  type: "Sigmoid"
  bottom: "hidden_sum_blob2"
  top: "hidden_act_blob2"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob2"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1008 22:06:12.955646  3998 layer_factory.hpp:76] Creating layer data_layer
I1008 22:06:12.958374  3998 net.cpp:110] Creating Layer data_layer
I1008 22:06:12.958380  3998 net.cpp:433] data_layer -> data_blob
I1008 22:06:12.958386  3998 net.cpp:433] data_layer -> label_blob
I1008 22:06:12.959058  4004 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.part1.test
I1008 22:06:12.959128  3998 data_layer.cpp:45] output data size: 4000,61,1,1
I1008 22:06:12.961097  3998 net.cpp:155] Setting up data_layer
I1008 22:06:12.961112  3998 net.cpp:163] Top shape: 4000 61 1 1 (244000)
I1008 22:06:12.961117  3998 net.cpp:163] Top shape: 4000 (4000)
I1008 22:06:12.961120  3998 layer_factory.hpp:76] Creating layer hidden_sum_layer1
I1008 22:06:12.961129  3998 net.cpp:110] Creating Layer hidden_sum_layer1
I1008 22:06:12.961132  3998 net.cpp:477] hidden_sum_layer1 <- data_blob
I1008 22:06:12.961136  3998 net.cpp:433] hidden_sum_layer1 -> hidden_sum_blob1
I1008 22:06:12.961285  3998 net.cpp:155] Setting up hidden_sum_layer1
I1008 22:06:12.961292  3998 net.cpp:163] Top shape: 4000 10 (40000)
I1008 22:06:12.961304  3998 layer_factory.hpp:76] Creating layer hidden_act_layer1
I1008 22:06:12.961313  3998 net.cpp:110] Creating Layer hidden_act_layer1
I1008 22:06:12.961316  3998 net.cpp:477] hidden_act_layer1 <- hidden_sum_blob1
I1008 22:06:12.961323  3998 net.cpp:433] hidden_act_layer1 -> hidden_act_blob1
I1008 22:06:12.961400  3998 net.cpp:155] Setting up hidden_act_layer1
I1008 22:06:12.961407  3998 net.cpp:163] Top shape: 4000 10 (40000)
I1008 22:06:12.961412  3998 layer_factory.hpp:76] Creating layer hidden_sum_layer2
I1008 22:06:12.961419  3998 net.cpp:110] Creating Layer hidden_sum_layer2
I1008 22:06:12.961426  3998 net.cpp:477] hidden_sum_layer2 <- hidden_act_blob1
I1008 22:06:12.961432  3998 net.cpp:433] hidden_sum_layer2 -> hidden_sum_blob2
I1008 22:06:12.961511  3998 net.cpp:155] Setting up hidden_sum_layer2
I1008 22:06:12.961519  3998 net.cpp:163] Top shape: 4000 5 (20000)
I1008 22:06:12.961529  3998 layer_factory.hpp:76] Creating layer hidden_act_layer2
I1008 22:06:12.961535  3998 net.cpp:110] Creating Layer hidden_act_layer2
I1008 22:06:12.961542  3998 net.cpp:477] hidden_act_layer2 <- hidden_sum_blob2
I1008 22:06:12.961549  3998 net.cpp:433] hidden_act_layer2 -> hidden_act_blob2
I1008 22:06:12.961613  3998 net.cpp:155] Setting up hidden_act_layer2
I1008 22:06:12.961621  3998 net.cpp:163] Top shape: 4000 5 (20000)
I1008 22:06:12.961626  3998 layer_factory.hpp:76] Creating layer output_sum_layer
I1008 22:06:12.961633  3998 net.cpp:110] Creating Layer output_sum_layer
I1008 22:06:12.961637  3998 net.cpp:477] output_sum_layer <- hidden_act_blob2
I1008 22:06:12.961644  3998 net.cpp:433] output_sum_layer -> output_sum_blob
I1008 22:06:12.961714  3998 net.cpp:155] Setting up output_sum_layer
I1008 22:06:12.961719  3998 net.cpp:163] Top shape: 4000 1 (4000)
I1008 22:06:12.961730  3998 layer_factory.hpp:76] Creating layer output_act_layer
I1008 22:06:12.961737  3998 net.cpp:110] Creating Layer output_act_layer
I1008 22:06:12.961743  3998 net.cpp:477] output_act_layer <- output_sum_blob
I1008 22:06:12.961750  3998 net.cpp:433] output_act_layer -> output_act_blob
I1008 22:06:12.961813  3998 net.cpp:155] Setting up output_act_layer
I1008 22:06:12.961820  3998 net.cpp:163] Top shape: 4000 1 (4000)
I1008 22:06:12.961824  3998 layer_factory.hpp:76] Creating layer error_layer
I1008 22:06:12.961830  3998 net.cpp:110] Creating Layer error_layer
I1008 22:06:12.961835  3998 net.cpp:477] error_layer <- output_act_blob
I1008 22:06:12.961853  3998 net.cpp:477] error_layer <- label_blob
I1008 22:06:12.961860  3998 net.cpp:433] error_layer -> error_blob
I1008 22:06:12.961892  3998 net.cpp:155] Setting up error_layer
I1008 22:06:12.961899  3998 net.cpp:163] Top shape: (1)
I1008 22:06:12.961902  3998 net.cpp:168]     with loss weight 1
I1008 22:06:12.961916  3998 net.cpp:236] error_layer needs backward computation.
I1008 22:06:12.961921  3998 net.cpp:236] output_act_layer needs backward computation.
I1008 22:06:12.961925  3998 net.cpp:236] output_sum_layer needs backward computation.
I1008 22:06:12.961930  3998 net.cpp:236] hidden_act_layer2 needs backward computation.
I1008 22:06:12.961935  3998 net.cpp:236] hidden_sum_layer2 needs backward computation.
I1008 22:06:12.961941  3998 net.cpp:236] hidden_act_layer1 needs backward computation.
I1008 22:06:12.961944  3998 net.cpp:236] hidden_sum_layer1 needs backward computation.
I1008 22:06:12.961949  3998 net.cpp:240] data_layer does not need backward computation.
I1008 22:06:12.961953  3998 net.cpp:283] This network produces output error_blob
I1008 22:06:12.961966  3998 net.cpp:297] Network initialization done.
I1008 22:06:12.961971  3998 net.cpp:298] Memory required for data: 1504004
I1008 22:06:12.961999  3998 solver.cpp:66] Solver scaffolding done.
I1008 22:06:12.962230  3998 caffe.cpp:212] Starting Optimization
I1008 22:06:12.962246  3998 solver.cpp:294] Solving two_hidden/model3_part1.prototxt
I1008 22:06:12.962251  3998 solver.cpp:295] Learning Rate Policy: inv
I1008 22:06:12.962432  3998 solver.cpp:347] Iteration 0, Testing net (#0)
I1008 22:06:12.962507  3998 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 22:06:12.972589  3998 solver.cpp:415]     Test net output #0: error_blob = 0.145409 (* 1 = 0.145409 loss)
I1008 22:06:12.974676  3998 solver.cpp:243] Iteration 0, loss = 0.148732
I1008 22:06:12.974694  3998 solver.cpp:259]     Train net output #0: error_blob = 0.148732 (* 1 = 0.148732 loss)
I1008 22:06:12.974714  3998 solver.cpp:590] Iteration 0, lr = 0.1
I1008 22:06:18.044173  3998 solver.cpp:347] Iteration 100, Testing net (#0)
I1008 22:06:18.046025  3998 solver.cpp:415]     Test net output #0: error_blob = 0.122331 (* 1 = 0.122331 loss)
I1008 22:06:18.097010  3998 solver.cpp:243] Iteration 100, loss = 0.122513
I1008 22:06:18.097044  3998 solver.cpp:259]     Train net output #0: error_blob = 0.122513 (* 1 = 0.122513 loss)
I1008 22:06:18.097055  3998 solver.cpp:590] Iteration 100, lr = 0.0924556
I1008 22:06:23.214041  3998 solver.cpp:347] Iteration 200, Testing net (#0)
I1008 22:06:23.215939  3998 solver.cpp:415]     Test net output #0: error_blob = 0.118406 (* 1 = 0.118406 loss)
I1008 22:06:23.272040  3998 solver.cpp:243] Iteration 200, loss = 0.118352
I1008 22:06:23.272088  3998 solver.cpp:259]     Train net output #0: error_blob = 0.118352 (* 1 = 0.118352 loss)
I1008 22:06:23.272099  3998 solver.cpp:590] Iteration 200, lr = 0.0857339
I1008 22:06:28.368365  3998 solver.cpp:347] Iteration 300, Testing net (#0)
I1008 22:06:28.370223  3998 solver.cpp:415]     Test net output #0: error_blob = 0.113771 (* 1 = 0.113771 loss)
I1008 22:06:28.422806  3998 solver.cpp:243] Iteration 300, loss = 0.113581
I1008 22:06:28.422845  3998 solver.cpp:259]     Train net output #0: error_blob = 0.113581 (* 1 = 0.113581 loss)
I1008 22:06:28.422852  3998 solver.cpp:590] Iteration 300, lr = 0.0797194
I1008 22:06:33.620462  3998 solver.cpp:347] Iteration 400, Testing net (#0)
I1008 22:06:33.622306  3998 solver.cpp:415]     Test net output #0: error_blob = 0.109724 (* 1 = 0.109724 loss)
I1008 22:06:33.677147  3998 solver.cpp:243] Iteration 400, loss = 0.109678
I1008 22:06:33.677189  3998 solver.cpp:259]     Train net output #0: error_blob = 0.109678 (* 1 = 0.109678 loss)
I1008 22:06:33.677197  3998 solver.cpp:590] Iteration 400, lr = 0.0743163
I1008 22:06:38.788427  3998 solver.cpp:347] Iteration 500, Testing net (#0)
I1008 22:06:38.790271  3998 solver.cpp:415]     Test net output #0: error_blob = 0.10822 (* 1 = 0.10822 loss)
I1008 22:06:38.845024  3998 solver.cpp:243] Iteration 500, loss = 0.107331
I1008 22:06:38.845052  3998 solver.cpp:259]     Train net output #0: error_blob = 0.107331 (* 1 = 0.107331 loss)
I1008 22:06:38.845058  3998 solver.cpp:590] Iteration 500, lr = 0.0694444
I1008 22:06:43.885388  3998 solver.cpp:347] Iteration 600, Testing net (#0)
I1008 22:06:43.887202  3998 solver.cpp:415]     Test net output #0: error_blob = 0.106464 (* 1 = 0.106464 loss)
I1008 22:06:43.946542  3998 solver.cpp:243] Iteration 600, loss = 0.104687
I1008 22:06:43.946573  3998 solver.cpp:259]     Train net output #0: error_blob = 0.104687 (* 1 = 0.104687 loss)
I1008 22:06:43.946579  3998 solver.cpp:590] Iteration 600, lr = 0.0650364
I1008 22:06:49.057624  3998 solver.cpp:347] Iteration 700, Testing net (#0)
I1008 22:06:49.059478  3998 solver.cpp:415]     Test net output #0: error_blob = 0.105904 (* 1 = 0.105904 loss)
I1008 22:06:49.112057  3998 solver.cpp:243] Iteration 700, loss = 0.102737
I1008 22:06:49.112100  3998 solver.cpp:259]     Train net output #0: error_blob = 0.102737 (* 1 = 0.102737 loss)
I1008 22:06:49.112112  3998 solver.cpp:590] Iteration 700, lr = 0.0610352
I1008 22:06:54.151619  3998 solver.cpp:347] Iteration 800, Testing net (#0)
I1008 22:06:54.153533  3998 solver.cpp:415]     Test net output #0: error_blob = 0.107388 (* 1 = 0.107388 loss)
I1008 22:06:54.207154  3998 solver.cpp:243] Iteration 800, loss = 0.103398
I1008 22:06:54.207181  3998 solver.cpp:259]     Train net output #0: error_blob = 0.103398 (* 1 = 0.103398 loss)
I1008 22:06:54.207188  3998 solver.cpp:590] Iteration 800, lr = 0.0573921
I1008 22:06:59.170732  3998 solver.cpp:347] Iteration 900, Testing net (#0)
I1008 22:06:59.172638  3998 solver.cpp:415]     Test net output #0: error_blob = 0.107336 (* 1 = 0.107336 loss)
I1008 22:06:59.226083  3998 solver.cpp:243] Iteration 900, loss = 0.103008
I1008 22:06:59.226122  3998 solver.cpp:259]     Train net output #0: error_blob = 0.103008 (* 1 = 0.103008 loss)
I1008 22:06:59.226132  3998 solver.cpp:590] Iteration 900, lr = 0.0540657
I1008 22:07:04.318220  3998 solver.cpp:347] Iteration 1000, Testing net (#0)
I1008 22:07:04.320116  3998 solver.cpp:415]     Test net output #0: error_blob = 0.106141 (* 1 = 0.106141 loss)
I1008 22:07:04.320127  3998 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 22:07:04.372369  3998 solver.cpp:243] Iteration 1000, loss = 0.101705
I1008 22:07:04.372400  3998 solver.cpp:259]     Train net output #0: error_blob = 0.101705 (* 1 = 0.101705 loss)
I1008 22:07:04.372411  3998 solver.cpp:590] Iteration 1000, lr = 0.0510204
I1008 22:07:09.493031  3998 solver.cpp:347] Iteration 1100, Testing net (#0)
I1008 22:07:09.494935  3998 solver.cpp:415]     Test net output #0: error_blob = 0.104562 (* 1 = 0.104562 loss)
I1008 22:07:09.547746  3998 solver.cpp:243] Iteration 1100, loss = 0.102235
I1008 22:07:09.547791  3998 solver.cpp:259]     Train net output #0: error_blob = 0.102235 (* 1 = 0.102235 loss)
I1008 22:07:09.547802  3998 solver.cpp:590] Iteration 1100, lr = 0.0482253
I1008 22:07:14.561619  3998 solver.cpp:347] Iteration 1200, Testing net (#0)
I1008 22:07:14.563473  3998 solver.cpp:415]     Test net output #0: error_blob = 0.103982 (* 1 = 0.103982 loss)
I1008 22:07:14.616866  3998 solver.cpp:243] Iteration 1200, loss = 0.0997525
I1008 22:07:14.616905  3998 solver.cpp:259]     Train net output #0: error_blob = 0.0997525 (* 1 = 0.0997525 loss)
I1008 22:07:14.616912  3998 solver.cpp:590] Iteration 1200, lr = 0.0456538
I1008 22:07:19.640597  3998 solver.cpp:347] Iteration 1300, Testing net (#0)
I1008 22:07:19.642446  3998 solver.cpp:415]     Test net output #0: error_blob = 0.104206 (* 1 = 0.104206 loss)
I1008 22:07:19.695603  3998 solver.cpp:243] Iteration 1300, loss = 0.0999335
I1008 22:07:19.695643  3998 solver.cpp:259]     Train net output #0: error_blob = 0.0999335 (* 1 = 0.0999335 loss)
I1008 22:07:19.695652  3998 solver.cpp:590] Iteration 1300, lr = 0.0432825
I1008 22:07:24.823922  3998 solver.cpp:347] Iteration 1400, Testing net (#0)
I1008 22:07:24.825796  3998 solver.cpp:415]     Test net output #0: error_blob = 0.10615 (* 1 = 0.10615 loss)
I1008 22:07:24.877343  3998 solver.cpp:243] Iteration 1400, loss = 0.0998038
I1008 22:07:24.877389  3998 solver.cpp:259]     Train net output #0: error_blob = 0.0998038 (* 1 = 0.0998038 loss)
I1008 22:07:24.877399  3998 solver.cpp:590] Iteration 1400, lr = 0.0410914
I1008 22:07:29.977005  3998 solver.cpp:347] Iteration 1500, Testing net (#0)
I1008 22:07:29.978925  3998 solver.cpp:415]     Test net output #0: error_blob = 0.103843 (* 1 = 0.103843 loss)
I1008 22:07:30.033332  3998 solver.cpp:243] Iteration 1500, loss = 0.0998805
I1008 22:07:30.033360  3998 solver.cpp:259]     Train net output #0: error_blob = 0.0998805 (* 1 = 0.0998805 loss)
I1008 22:07:30.033368  3998 solver.cpp:590] Iteration 1500, lr = 0.0390625
I1008 22:07:35.332991  3998 solver.cpp:347] Iteration 1600, Testing net (#0)
I1008 22:07:35.334908  3998 solver.cpp:415]     Test net output #0: error_blob = 0.103754 (* 1 = 0.103754 loss)
I1008 22:07:35.389616  3998 solver.cpp:243] Iteration 1600, loss = 0.100018
I1008 22:07:35.389646  3998 solver.cpp:259]     Train net output #0: error_blob = 0.100018 (* 1 = 0.100018 loss)
I1008 22:07:35.389652  3998 solver.cpp:590] Iteration 1600, lr = 0.0371803
I1008 22:07:40.516885  3998 solver.cpp:347] Iteration 1700, Testing net (#0)
I1008 22:07:40.518805  3998 solver.cpp:415]     Test net output #0: error_blob = 0.103351 (* 1 = 0.103351 loss)
I1008 22:07:40.571388  3998 solver.cpp:243] Iteration 1700, loss = 0.0988411
I1008 22:07:40.571418  3998 solver.cpp:259]     Train net output #0: error_blob = 0.0988411 (* 1 = 0.0988411 loss)
I1008 22:07:40.571424  3998 solver.cpp:590] Iteration 1700, lr = 0.0354308
I1008 22:07:45.739387  3998 solver.cpp:347] Iteration 1800, Testing net (#0)
I1008 22:07:45.741245  3998 solver.cpp:415]     Test net output #0: error_blob = 0.103187 (* 1 = 0.103187 loss)
I1008 22:07:45.795161  3998 solver.cpp:243] Iteration 1800, loss = 0.0978376
I1008 22:07:45.795207  3998 solver.cpp:259]     Train net output #0: error_blob = 0.0978376 (* 1 = 0.0978376 loss)
I1008 22:07:45.795217  3998 solver.cpp:590] Iteration 1800, lr = 0.0338021
I1008 22:07:50.959015  3998 solver.cpp:347] Iteration 1900, Testing net (#0)
I1008 22:07:50.960882  3998 solver.cpp:415]     Test net output #0: error_blob = 0.10273 (* 1 = 0.10273 loss)
I1008 22:07:51.019053  3998 solver.cpp:243] Iteration 1900, loss = 0.0992216
I1008 22:07:51.019088  3998 solver.cpp:259]     Train net output #0: error_blob = 0.0992216 (* 1 = 0.0992216 loss)
I1008 22:07:51.019098  3998 solver.cpp:590] Iteration 1900, lr = 0.0322831
I1008 22:07:56.281164  3998 solver.cpp:347] Iteration 2000, Testing net (#0)
I1008 22:07:56.283049  3998 solver.cpp:415]     Test net output #0: error_blob = 0.1013 (* 1 = 0.1013 loss)
I1008 22:07:56.283058  3998 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 22:07:56.337257  3998 solver.cpp:243] Iteration 2000, loss = 0.0991451
I1008 22:07:56.337304  3998 solver.cpp:259]     Train net output #0: error_blob = 0.0991451 (* 1 = 0.0991451 loss)
I1008 22:07:56.337316  3998 solver.cpp:590] Iteration 2000, lr = 0.0308642
I1008 22:08:01.476727  3998 solver.cpp:347] Iteration 2100, Testing net (#0)
I1008 22:08:01.478579  3998 solver.cpp:415]     Test net output #0: error_blob = 0.101844 (* 1 = 0.101844 loss)
I1008 22:08:01.532155  3998 solver.cpp:243] Iteration 2100, loss = 0.0980672
I1008 22:08:01.532201  3998 solver.cpp:259]     Train net output #0: error_blob = 0.0980672 (* 1 = 0.0980672 loss)
I1008 22:08:01.532209  3998 solver.cpp:590] Iteration 2100, lr = 0.0295369
I1008 22:08:06.777967  3998 solver.cpp:347] Iteration 2200, Testing net (#0)
I1008 22:08:06.779811  3998 solver.cpp:415]     Test net output #0: error_blob = 0.102403 (* 1 = 0.102403 loss)
I1008 22:08:06.837072  3998 solver.cpp:243] Iteration 2200, loss = 0.098978
I1008 22:08:06.837107  3998 solver.cpp:259]     Train net output #0: error_blob = 0.098978 (* 1 = 0.098978 loss)
I1008 22:08:06.837116  3998 solver.cpp:590] Iteration 2200, lr = 0.0282933
I1008 22:08:12.083755  3998 solver.cpp:347] Iteration 2300, Testing net (#0)
I1008 22:08:12.085594  3998 solver.cpp:415]     Test net output #0: error_blob = 0.101381 (* 1 = 0.101381 loss)
I1008 22:08:12.138538  3998 solver.cpp:243] Iteration 2300, loss = 0.0967922
I1008 22:08:12.138571  3998 solver.cpp:259]     Train net output #0: error_blob = 0.0967922 (* 1 = 0.0967922 loss)
I1008 22:08:12.138578  3998 solver.cpp:590] Iteration 2300, lr = 0.0271267
I1008 22:08:17.288450  3998 solver.cpp:347] Iteration 2400, Testing net (#0)
I1008 22:08:17.290367  3998 solver.cpp:415]     Test net output #0: error_blob = 0.102421 (* 1 = 0.102421 loss)
I1008 22:08:17.343045  3998 solver.cpp:243] Iteration 2400, loss = 0.0971702
I1008 22:08:17.343075  3998 solver.cpp:259]     Train net output #0: error_blob = 0.0971702 (* 1 = 0.0971702 loss)
I1008 22:08:17.343081  3998 solver.cpp:590] Iteration 2400, lr = 0.0260308
I1008 22:08:22.607553  3998 solver.cpp:347] Iteration 2500, Testing net (#0)
I1008 22:08:22.609477  3998 solver.cpp:415]     Test net output #0: error_blob = 0.102163 (* 1 = 0.102163 loss)
I1008 22:08:22.660732  3998 solver.cpp:243] Iteration 2500, loss = 0.0971327
I1008 22:08:22.660773  3998 solver.cpp:259]     Train net output #0: error_blob = 0.0971327 (* 1 = 0.0971327 loss)
I1008 22:08:22.660779  3998 solver.cpp:590] Iteration 2500, lr = 0.025
I1008 22:08:27.895861  3998 solver.cpp:347] Iteration 2600, Testing net (#0)
I1008 22:08:27.897773  3998 solver.cpp:415]     Test net output #0: error_blob = 0.101807 (* 1 = 0.101807 loss)
I1008 22:08:27.954077  3998 solver.cpp:243] Iteration 2600, loss = 0.0975998
I1008 22:08:27.954107  3998 solver.cpp:259]     Train net output #0: error_blob = 0.0975998 (* 1 = 0.0975998 loss)
I1008 22:08:27.954113  3998 solver.cpp:590] Iteration 2600, lr = 0.0240292
I1008 22:08:33.170246  3998 solver.cpp:347] Iteration 2700, Testing net (#0)
I1008 22:08:33.172166  3998 solver.cpp:415]     Test net output #0: error_blob = 0.102393 (* 1 = 0.102393 loss)
I1008 22:08:33.225639  3998 solver.cpp:243] Iteration 2700, loss = 0.0978634
I1008 22:08:33.225666  3998 solver.cpp:259]     Train net output #0: error_blob = 0.0978634 (* 1 = 0.0978634 loss)
I1008 22:08:33.225672  3998 solver.cpp:590] Iteration 2700, lr = 0.0231139
I1008 22:08:38.339339  3998 solver.cpp:347] Iteration 2800, Testing net (#0)
I1008 22:08:38.341248  3998 solver.cpp:415]     Test net output #0: error_blob = 0.102964 (* 1 = 0.102964 loss)
I1008 22:08:38.395818  3998 solver.cpp:243] Iteration 2800, loss = 0.0970102
I1008 22:08:38.395850  3998 solver.cpp:259]     Train net output #0: error_blob = 0.0970102 (* 1 = 0.0970102 loss)
I1008 22:08:38.395860  3998 solver.cpp:590] Iteration 2800, lr = 0.0222499
I1008 22:08:43.547828  3998 solver.cpp:347] Iteration 2900, Testing net (#0)
I1008 22:08:43.549726  3998 solver.cpp:415]     Test net output #0: error_blob = 0.101871 (* 1 = 0.101871 loss)
I1008 22:08:43.604925  3998 solver.cpp:243] Iteration 2900, loss = 0.095916
I1008 22:08:43.604954  3998 solver.cpp:259]     Train net output #0: error_blob = 0.095916 (* 1 = 0.095916 loss)
I1008 22:08:43.604960  3998 solver.cpp:590] Iteration 2900, lr = 0.0214335
I1008 22:08:48.782044  3998 solver.cpp:347] Iteration 3000, Testing net (#0)
I1008 22:08:48.783956  3998 solver.cpp:415]     Test net output #0: error_blob = 0.102427 (* 1 = 0.102427 loss)
I1008 22:08:48.783965  3998 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 22:08:48.837527  3998 solver.cpp:243] Iteration 3000, loss = 0.0973299
I1008 22:08:48.837558  3998 solver.cpp:259]     Train net output #0: error_blob = 0.0973299 (* 1 = 0.0973299 loss)
I1008 22:08:48.837566  3998 solver.cpp:590] Iteration 3000, lr = 0.0206612
I1008 22:08:54.002926  3998 solver.cpp:347] Iteration 3100, Testing net (#0)
I1008 22:08:54.004859  3998 solver.cpp:415]     Test net output #0: error_blob = 0.101934 (* 1 = 0.101934 loss)
I1008 22:08:54.057765  3998 solver.cpp:243] Iteration 3100, loss = 0.097449
I1008 22:08:54.057801  3998 solver.cpp:259]     Train net output #0: error_blob = 0.097449 (* 1 = 0.097449 loss)
I1008 22:08:54.057808  3998 solver.cpp:590] Iteration 3100, lr = 0.0199298
I1008 22:08:59.302386  3998 solver.cpp:347] Iteration 3200, Testing net (#0)
I1008 22:08:59.304298  3998 solver.cpp:415]     Test net output #0: error_blob = 0.102946 (* 1 = 0.102946 loss)
I1008 22:08:59.357710  3998 solver.cpp:243] Iteration 3200, loss = 0.0966491
I1008 22:08:59.357745  3998 solver.cpp:259]     Train net output #0: error_blob = 0.0966491 (* 1 = 0.0966491 loss)
I1008 22:08:59.357753  3998 solver.cpp:590] Iteration 3200, lr = 0.0192367
I1008 22:09:04.488772  3998 solver.cpp:347] Iteration 3300, Testing net (#0)
I1008 22:09:04.490677  3998 solver.cpp:415]     Test net output #0: error_blob = 0.101217 (* 1 = 0.101217 loss)
I1008 22:09:04.545186  3998 solver.cpp:243] Iteration 3300, loss = 0.0975575
I1008 22:09:04.545217  3998 solver.cpp:259]     Train net output #0: error_blob = 0.0975575 (* 1 = 0.0975575 loss)
I1008 22:09:04.545225  3998 solver.cpp:590] Iteration 3300, lr = 0.0185791
I1008 22:09:09.706974  3998 solver.cpp:347] Iteration 3400, Testing net (#0)
I1008 22:09:09.708881  3998 solver.cpp:415]     Test net output #0: error_blob = 0.101752 (* 1 = 0.101752 loss)
I1008 22:09:09.760699  3998 solver.cpp:243] Iteration 3400, loss = 0.0955186
I1008 22:09:09.760728  3998 solver.cpp:259]     Train net output #0: error_blob = 0.0955186 (* 1 = 0.0955186 loss)
I1008 22:09:09.760735  3998 solver.cpp:590] Iteration 3400, lr = 0.0179546
I1008 22:09:14.917850  3998 solver.cpp:347] Iteration 3500, Testing net (#0)
I1008 22:09:14.919770  3998 solver.cpp:415]     Test net output #0: error_blob = 0.103275 (* 1 = 0.103275 loss)
I1008 22:09:14.971930  3998 solver.cpp:243] Iteration 3500, loss = 0.0959016
I1008 22:09:14.971958  3998 solver.cpp:259]     Train net output #0: error_blob = 0.0959016 (* 1 = 0.0959016 loss)
I1008 22:09:14.971966  3998 solver.cpp:590] Iteration 3500, lr = 0.0173611
I1008 22:09:20.115701  3998 solver.cpp:347] Iteration 3600, Testing net (#0)
I1008 22:09:20.117616  3998 solver.cpp:415]     Test net output #0: error_blob = 0.103169 (* 1 = 0.103169 loss)
I1008 22:09:20.173933  3998 solver.cpp:243] Iteration 3600, loss = 0.0960737
I1008 22:09:20.173961  3998 solver.cpp:259]     Train net output #0: error_blob = 0.0960737 (* 1 = 0.0960737 loss)
I1008 22:09:20.173969  3998 solver.cpp:590] Iteration 3600, lr = 0.0167966
I1008 22:09:25.286094  3998 solver.cpp:347] Iteration 3700, Testing net (#0)
I1008 22:09:25.287993  3998 solver.cpp:415]     Test net output #0: error_blob = 0.102844 (* 1 = 0.102844 loss)
I1008 22:09:25.344557  3998 solver.cpp:243] Iteration 3700, loss = 0.0963429
I1008 22:09:25.344594  3998 solver.cpp:259]     Train net output #0: error_blob = 0.0963429 (* 1 = 0.0963429 loss)
I1008 22:09:25.344601  3998 solver.cpp:590] Iteration 3700, lr = 0.0162591
I1008 22:09:30.463716  3998 solver.cpp:347] Iteration 3800, Testing net (#0)
I1008 22:09:30.465620  3998 solver.cpp:415]     Test net output #0: error_blob = 0.101912 (* 1 = 0.101912 loss)
I1008 22:09:30.518857  3998 solver.cpp:243] Iteration 3800, loss = 0.0967421
I1008 22:09:30.518890  3998 solver.cpp:259]     Train net output #0: error_blob = 0.0967421 (* 1 = 0.0967421 loss)
I1008 22:09:30.518899  3998 solver.cpp:590] Iteration 3800, lr = 0.015747
I1008 22:09:35.662664  3998 solver.cpp:347] Iteration 3900, Testing net (#0)
I1008 22:09:35.664566  3998 solver.cpp:415]     Test net output #0: error_blob = 0.100528 (* 1 = 0.100528 loss)
I1008 22:09:35.713456  3998 solver.cpp:243] Iteration 3900, loss = 0.096163
I1008 22:09:35.713485  3998 solver.cpp:259]     Train net output #0: error_blob = 0.096163 (* 1 = 0.096163 loss)
I1008 22:09:35.713491  3998 solver.cpp:590] Iteration 3900, lr = 0.0152588
I1008 22:09:40.872575  3998 solver.cpp:347] Iteration 4000, Testing net (#0)
I1008 22:09:40.874460  3998 solver.cpp:415]     Test net output #0: error_blob = 0.102051 (* 1 = 0.102051 loss)
I1008 22:09:40.874470  3998 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 22:09:40.926614  3998 solver.cpp:243] Iteration 4000, loss = 0.0949988
I1008 22:09:40.926642  3998 solver.cpp:259]     Train net output #0: error_blob = 0.0949988 (* 1 = 0.0949988 loss)
I1008 22:09:40.926650  3998 solver.cpp:590] Iteration 4000, lr = 0.0147929
I1008 22:09:46.124023  3998 solver.cpp:347] Iteration 4100, Testing net (#0)
I1008 22:09:46.126133  3998 solver.cpp:415]     Test net output #0: error_blob = 0.103713 (* 1 = 0.103713 loss)
I1008 22:09:46.182117  3998 solver.cpp:243] Iteration 4100, loss = 0.0964235
I1008 22:09:46.182145  3998 solver.cpp:259]     Train net output #0: error_blob = 0.0964235 (* 1 = 0.0964235 loss)
I1008 22:09:46.182152  3998 solver.cpp:590] Iteration 4100, lr = 0.014348
I1008 22:09:51.357589  3998 solver.cpp:347] Iteration 4200, Testing net (#0)
I1008 22:09:51.359513  3998 solver.cpp:415]     Test net output #0: error_blob = 0.102065 (* 1 = 0.102065 loss)
I1008 22:09:51.411106  3998 solver.cpp:243] Iteration 4200, loss = 0.0962181
I1008 22:09:51.411134  3998 solver.cpp:259]     Train net output #0: error_blob = 0.0962181 (* 1 = 0.0962181 loss)
I1008 22:09:51.411141  3998 solver.cpp:590] Iteration 4200, lr = 0.0139229
I1008 22:09:56.561853  3998 solver.cpp:347] Iteration 4300, Testing net (#0)
I1008 22:09:56.563771  3998 solver.cpp:415]     Test net output #0: error_blob = 0.101839 (* 1 = 0.101839 loss)
I1008 22:09:56.612421  3998 solver.cpp:243] Iteration 4300, loss = 0.0958714
I1008 22:09:56.612462  3998 solver.cpp:259]     Train net output #0: error_blob = 0.0958714 (* 1 = 0.0958714 loss)
I1008 22:09:56.612468  3998 solver.cpp:590] Iteration 4300, lr = 0.0135164
I1008 22:10:01.799641  3998 solver.cpp:347] Iteration 4400, Testing net (#0)
I1008 22:10:01.801498  3998 solver.cpp:415]     Test net output #0: error_blob = 0.101928 (* 1 = 0.101928 loss)
I1008 22:10:01.855972  3998 solver.cpp:243] Iteration 4400, loss = 0.0964648
I1008 22:10:01.856008  3998 solver.cpp:259]     Train net output #0: error_blob = 0.0964648 (* 1 = 0.0964648 loss)
I1008 22:10:01.856015  3998 solver.cpp:590] Iteration 4400, lr = 0.0131275
I1008 22:10:07.017421  3998 solver.cpp:347] Iteration 4500, Testing net (#0)
I1008 22:10:07.019321  3998 solver.cpp:415]     Test net output #0: error_blob = 0.101656 (* 1 = 0.101656 loss)
I1008 22:10:07.070902  3998 solver.cpp:243] Iteration 4500, loss = 0.0947294
I1008 22:10:07.070930  3998 solver.cpp:259]     Train net output #0: error_blob = 0.0947294 (* 1 = 0.0947294 loss)
I1008 22:10:07.070937  3998 solver.cpp:590] Iteration 4500, lr = 0.0127551
I1008 22:10:12.184839  3998 solver.cpp:347] Iteration 4600, Testing net (#0)
I1008 22:10:12.186694  3998 solver.cpp:415]     Test net output #0: error_blob = 0.101576 (* 1 = 0.101576 loss)
I1008 22:10:12.238719  3998 solver.cpp:243] Iteration 4600, loss = 0.0952051
I1008 22:10:12.238755  3998 solver.cpp:259]     Train net output #0: error_blob = 0.0952051 (* 1 = 0.0952051 loss)
I1008 22:10:12.238764  3998 solver.cpp:590] Iteration 4600, lr = 0.0123983
I1008 22:10:17.452800  3998 solver.cpp:347] Iteration 4700, Testing net (#0)
I1008 22:10:17.454732  3998 solver.cpp:415]     Test net output #0: error_blob = 0.0996732 (* 1 = 0.0996732 loss)
I1008 22:10:17.510545  3998 solver.cpp:243] Iteration 4700, loss = 0.0951446
I1008 22:10:17.510576  3998 solver.cpp:259]     Train net output #0: error_blob = 0.0951446 (* 1 = 0.0951446 loss)
I1008 22:10:17.510584  3998 solver.cpp:590] Iteration 4700, lr = 0.0120563
I1008 22:10:22.538277  3998 solver.cpp:347] Iteration 4800, Testing net (#0)
I1008 22:10:22.540217  3998 solver.cpp:415]     Test net output #0: error_blob = 0.100419 (* 1 = 0.100419 loss)
I1008 22:10:22.591686  3998 solver.cpp:243] Iteration 4800, loss = 0.0955704
I1008 22:10:22.591722  3998 solver.cpp:259]     Train net output #0: error_blob = 0.0955704 (* 1 = 0.0955704 loss)
I1008 22:10:22.591732  3998 solver.cpp:590] Iteration 4800, lr = 0.0117283
I1008 22:10:27.804661  3998 solver.cpp:347] Iteration 4900, Testing net (#0)
I1008 22:10:27.806494  3998 solver.cpp:415]     Test net output #0: error_blob = 0.101265 (* 1 = 0.101265 loss)
I1008 22:10:27.861006  3998 solver.cpp:243] Iteration 4900, loss = 0.096029
I1008 22:10:27.861040  3998 solver.cpp:259]     Train net output #0: error_blob = 0.096029 (* 1 = 0.096029 loss)
I1008 22:10:27.861052  3998 solver.cpp:590] Iteration 4900, lr = 0.0114134
I1008 22:10:33.020270  3998 solver.cpp:468] Snapshotting to binary proto file _iter_5000.caffemodel
I1008 22:10:33.022182  3998 solver.cpp:753] Snapshotting solver state to binary proto file _iter_5000.solverstate
I1008 22:10:33.022229  3998 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 22:10:33.070266  3998 solver.cpp:327] Iteration 5000, loss = 0.0955805
I1008 22:10:33.070297  3998 solver.cpp:347] Iteration 5000, Testing net (#0)
I1008 22:10:33.070596  3998 solver.cpp:415]     Test net output #0: error_blob = 0.100812 (* 1 = 0.100812 loss)
I1008 22:10:33.070605  3998 solver.cpp:332] Optimization Done.
I1008 22:10:33.070610  3998 caffe.cpp:215] Optimization Done.
I1008 22:10:33.196704  4025 caffe.cpp:184] Using GPUs 0
I1008 22:10:33.758698  4025 solver.cpp:54] Initializing solver from parameters: 
test_iter: 1
test_interval: 100
base_lr: 0.1
display: 100
max_iter: 5000
lr_policy: "inv"
gamma: 0.0004
power: 2
momentum: 0.9
solver_mode: GPU
device_id: 0
net: "two_hidden/model3_part8.prototxt"
I1008 22:10:33.758730  4025 solver.cpp:97] Creating training net from net file: two_hidden/model3_part8.prototxt
I1008 22:10:33.758905  4025 net.cpp:339] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_layer
I1008 22:10:33.758946  4025 net.cpp:50] Initializing net from parameters: 
name: "two_hidden/model3_part8.prototxt"
state {
  phase: TRAIN
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TRAIN
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.part8.train"
    batch_size: 40000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer1"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob1"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer1"
  type: "Sigmoid"
  bottom: "hidden_sum_blob1"
  top: "hidden_act_blob1"
}
layer {
  name: "hidden_sum_layer2"
  type: "InnerProduct"
  bottom: "hidden_act_blob1"
  top: "hidden_sum_blob2"
  inner_product_param {
    num_output: 5
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer2"
  type: "Sigmoid"
  bottom: "hidden_sum_blob2"
  top: "hidden_act_blob2"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob2"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1008 22:10:33.758988  4025 layer_factory.hpp:76] Creating layer data_layer
I1008 22:10:33.785271  4025 net.cpp:110] Creating Layer data_layer
I1008 22:10:33.785300  4025 net.cpp:433] data_layer -> data_blob
I1008 22:10:33.785322  4025 net.cpp:433] data_layer -> label_blob
I1008 22:10:33.785900  4029 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.part8.train
I1008 22:10:34.474311  4025 data_layer.cpp:45] output data size: 40000,61,1,1
I1008 22:10:34.484776  4025 net.cpp:155] Setting up data_layer
I1008 22:10:34.484822  4025 net.cpp:163] Top shape: 40000 61 1 1 (2440000)
I1008 22:10:34.484827  4025 net.cpp:163] Top shape: 40000 (40000)
I1008 22:10:34.484833  4025 layer_factory.hpp:76] Creating layer hidden_sum_layer1
I1008 22:10:34.484845  4025 net.cpp:110] Creating Layer hidden_sum_layer1
I1008 22:10:34.484849  4025 net.cpp:477] hidden_sum_layer1 <- data_blob
I1008 22:10:34.484859  4025 net.cpp:433] hidden_sum_layer1 -> hidden_sum_blob1
I1008 22:10:34.485221  4025 net.cpp:155] Setting up hidden_sum_layer1
I1008 22:10:34.485229  4025 net.cpp:163] Top shape: 40000 10 (400000)
I1008 22:10:34.485240  4025 layer_factory.hpp:76] Creating layer hidden_act_layer1
I1008 22:10:34.485247  4025 net.cpp:110] Creating Layer hidden_act_layer1
I1008 22:10:34.485251  4025 net.cpp:477] hidden_act_layer1 <- hidden_sum_blob1
I1008 22:10:34.485255  4025 net.cpp:433] hidden_act_layer1 -> hidden_act_blob1
I1008 22:10:37.716940  4025 net.cpp:155] Setting up hidden_act_layer1
I1008 22:10:37.716976  4025 net.cpp:163] Top shape: 40000 10 (400000)
I1008 22:10:37.716981  4025 layer_factory.hpp:76] Creating layer hidden_sum_layer2
I1008 22:10:37.716995  4025 net.cpp:110] Creating Layer hidden_sum_layer2
I1008 22:10:37.716998  4025 net.cpp:477] hidden_sum_layer2 <- hidden_act_blob1
I1008 22:10:37.717005  4025 net.cpp:433] hidden_sum_layer2 -> hidden_sum_blob2
I1008 22:10:37.717119  4025 net.cpp:155] Setting up hidden_sum_layer2
I1008 22:10:37.717124  4025 net.cpp:163] Top shape: 40000 5 (200000)
I1008 22:10:37.717157  4025 layer_factory.hpp:76] Creating layer hidden_act_layer2
I1008 22:10:37.717164  4025 net.cpp:110] Creating Layer hidden_act_layer2
I1008 22:10:37.717166  4025 net.cpp:477] hidden_act_layer2 <- hidden_sum_blob2
I1008 22:10:37.717170  4025 net.cpp:433] hidden_act_layer2 -> hidden_act_blob2
I1008 22:10:37.717234  4025 net.cpp:155] Setting up hidden_act_layer2
I1008 22:10:37.717238  4025 net.cpp:163] Top shape: 40000 5 (200000)
I1008 22:10:37.717252  4025 layer_factory.hpp:76] Creating layer output_sum_layer
I1008 22:10:37.717254  4025 net.cpp:110] Creating Layer output_sum_layer
I1008 22:10:37.717257  4025 net.cpp:477] output_sum_layer <- hidden_act_blob2
I1008 22:10:37.717259  4025 net.cpp:433] output_sum_layer -> output_sum_blob
I1008 22:10:37.717349  4025 net.cpp:155] Setting up output_sum_layer
I1008 22:10:37.717352  4025 net.cpp:163] Top shape: 40000 1 (40000)
I1008 22:10:37.717367  4025 layer_factory.hpp:76] Creating layer output_act_layer
I1008 22:10:37.717370  4025 net.cpp:110] Creating Layer output_act_layer
I1008 22:10:37.717372  4025 net.cpp:477] output_act_layer <- output_sum_blob
I1008 22:10:37.717375  4025 net.cpp:433] output_act_layer -> output_act_blob
I1008 22:10:37.717521  4025 net.cpp:155] Setting up output_act_layer
I1008 22:10:37.717527  4025 net.cpp:163] Top shape: 40000 1 (40000)
I1008 22:10:37.717540  4025 layer_factory.hpp:76] Creating layer error_layer
I1008 22:10:37.717546  4025 net.cpp:110] Creating Layer error_layer
I1008 22:10:37.717548  4025 net.cpp:477] error_layer <- output_act_blob
I1008 22:10:37.717551  4025 net.cpp:477] error_layer <- label_blob
I1008 22:10:37.717555  4025 net.cpp:433] error_layer -> error_blob
I1008 22:10:37.717588  4025 net.cpp:155] Setting up error_layer
I1008 22:10:37.717592  4025 net.cpp:163] Top shape: (1)
I1008 22:10:37.717594  4025 net.cpp:168]     with loss weight 1
I1008 22:10:37.717620  4025 net.cpp:236] error_layer needs backward computation.
I1008 22:10:37.717622  4025 net.cpp:236] output_act_layer needs backward computation.
I1008 22:10:37.717624  4025 net.cpp:236] output_sum_layer needs backward computation.
I1008 22:10:37.717627  4025 net.cpp:236] hidden_act_layer2 needs backward computation.
I1008 22:10:37.717628  4025 net.cpp:236] hidden_sum_layer2 needs backward computation.
I1008 22:10:37.717630  4025 net.cpp:236] hidden_act_layer1 needs backward computation.
I1008 22:10:37.717633  4025 net.cpp:236] hidden_sum_layer1 needs backward computation.
I1008 22:10:37.717634  4025 net.cpp:240] data_layer does not need backward computation.
I1008 22:10:37.717636  4025 net.cpp:283] This network produces output error_blob
I1008 22:10:37.717643  4025 net.cpp:297] Network initialization done.
I1008 22:10:37.717643  4025 net.cpp:298] Memory required for data: 15040004
I1008 22:10:37.717800  4025 solver.cpp:187] Creating test net (#0) specified by net file: two_hidden/model3_part8.prototxt
I1008 22:10:37.717828  4025 net.cpp:339] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_layer
I1008 22:10:37.717881  4025 net.cpp:50] Initializing net from parameters: 
name: "two_hidden/model3_part8.prototxt"
state {
  phase: TEST
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TEST
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.part8.test"
    batch_size: 4000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer1"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob1"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer1"
  type: "Sigmoid"
  bottom: "hidden_sum_blob1"
  top: "hidden_act_blob1"
}
layer {
  name: "hidden_sum_layer2"
  type: "InnerProduct"
  bottom: "hidden_act_blob1"
  top: "hidden_sum_blob2"
  inner_product_param {
    num_output: 5
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer2"
  type: "Sigmoid"
  bottom: "hidden_sum_blob2"
  top: "hidden_act_blob2"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob2"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1008 22:10:37.717922  4025 layer_factory.hpp:76] Creating layer data_layer
I1008 22:10:37.720227  4025 net.cpp:110] Creating Layer data_layer
I1008 22:10:37.720244  4025 net.cpp:433] data_layer -> data_blob
I1008 22:10:37.720250  4025 net.cpp:433] data_layer -> label_blob
I1008 22:10:37.720831  4031 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.part8.test
I1008 22:10:37.720908  4025 data_layer.cpp:45] output data size: 4000,61,1,1
I1008 22:10:37.722846  4025 net.cpp:155] Setting up data_layer
I1008 22:10:37.722862  4025 net.cpp:163] Top shape: 4000 61 1 1 (244000)
I1008 22:10:37.722867  4025 net.cpp:163] Top shape: 4000 (4000)
I1008 22:10:37.722872  4025 layer_factory.hpp:76] Creating layer hidden_sum_layer1
I1008 22:10:37.722883  4025 net.cpp:110] Creating Layer hidden_sum_layer1
I1008 22:10:37.722887  4025 net.cpp:477] hidden_sum_layer1 <- data_blob
I1008 22:10:37.722894  4025 net.cpp:433] hidden_sum_layer1 -> hidden_sum_blob1
I1008 22:10:37.723017  4025 net.cpp:155] Setting up hidden_sum_layer1
I1008 22:10:37.723026  4025 net.cpp:163] Top shape: 4000 10 (40000)
I1008 22:10:37.723037  4025 layer_factory.hpp:76] Creating layer hidden_act_layer1
I1008 22:10:37.723047  4025 net.cpp:110] Creating Layer hidden_act_layer1
I1008 22:10:37.723052  4025 net.cpp:477] hidden_act_layer1 <- hidden_sum_blob1
I1008 22:10:37.723057  4025 net.cpp:433] hidden_act_layer1 -> hidden_act_blob1
I1008 22:10:37.723125  4025 net.cpp:155] Setting up hidden_act_layer1
I1008 22:10:37.723132  4025 net.cpp:163] Top shape: 4000 10 (40000)
I1008 22:10:37.723135  4025 layer_factory.hpp:76] Creating layer hidden_sum_layer2
I1008 22:10:37.723142  4025 net.cpp:110] Creating Layer hidden_sum_layer2
I1008 22:10:37.723146  4025 net.cpp:477] hidden_sum_layer2 <- hidden_act_blob1
I1008 22:10:37.723152  4025 net.cpp:433] hidden_sum_layer2 -> hidden_sum_blob2
I1008 22:10:37.723222  4025 net.cpp:155] Setting up hidden_sum_layer2
I1008 22:10:37.723228  4025 net.cpp:163] Top shape: 4000 5 (20000)
I1008 22:10:37.723237  4025 layer_factory.hpp:76] Creating layer hidden_act_layer2
I1008 22:10:37.723242  4025 net.cpp:110] Creating Layer hidden_act_layer2
I1008 22:10:37.723244  4025 net.cpp:477] hidden_act_layer2 <- hidden_sum_blob2
I1008 22:10:37.723248  4025 net.cpp:433] hidden_act_layer2 -> hidden_act_blob2
I1008 22:10:37.723302  4025 net.cpp:155] Setting up hidden_act_layer2
I1008 22:10:37.723306  4025 net.cpp:163] Top shape: 4000 5 (20000)
I1008 22:10:37.723309  4025 layer_factory.hpp:76] Creating layer output_sum_layer
I1008 22:10:37.723314  4025 net.cpp:110] Creating Layer output_sum_layer
I1008 22:10:37.723315  4025 net.cpp:477] output_sum_layer <- hidden_act_blob2
I1008 22:10:37.723319  4025 net.cpp:433] output_sum_layer -> output_sum_blob
I1008 22:10:37.723376  4025 net.cpp:155] Setting up output_sum_layer
I1008 22:10:37.723378  4025 net.cpp:163] Top shape: 4000 1 (4000)
I1008 22:10:37.723383  4025 layer_factory.hpp:76] Creating layer output_act_layer
I1008 22:10:37.723387  4025 net.cpp:110] Creating Layer output_act_layer
I1008 22:10:37.723389  4025 net.cpp:477] output_act_layer <- output_sum_blob
I1008 22:10:37.723392  4025 net.cpp:433] output_act_layer -> output_act_blob
I1008 22:10:37.723441  4025 net.cpp:155] Setting up output_act_layer
I1008 22:10:37.723444  4025 net.cpp:163] Top shape: 4000 1 (4000)
I1008 22:10:37.723446  4025 layer_factory.hpp:76] Creating layer error_layer
I1008 22:10:37.723450  4025 net.cpp:110] Creating Layer error_layer
I1008 22:10:37.723453  4025 net.cpp:477] error_layer <- output_act_blob
I1008 22:10:37.723465  4025 net.cpp:477] error_layer <- label_blob
I1008 22:10:37.723469  4025 net.cpp:433] error_layer -> error_blob
I1008 22:10:37.723491  4025 net.cpp:155] Setting up error_layer
I1008 22:10:37.723495  4025 net.cpp:163] Top shape: (1)
I1008 22:10:37.723496  4025 net.cpp:168]     with loss weight 1
I1008 22:10:37.723503  4025 net.cpp:236] error_layer needs backward computation.
I1008 22:10:37.723506  4025 net.cpp:236] output_act_layer needs backward computation.
I1008 22:10:37.723508  4025 net.cpp:236] output_sum_layer needs backward computation.
I1008 22:10:37.723510  4025 net.cpp:236] hidden_act_layer2 needs backward computation.
I1008 22:10:37.723512  4025 net.cpp:236] hidden_sum_layer2 needs backward computation.
I1008 22:10:37.723515  4025 net.cpp:236] hidden_act_layer1 needs backward computation.
I1008 22:10:37.723516  4025 net.cpp:236] hidden_sum_layer1 needs backward computation.
I1008 22:10:37.723518  4025 net.cpp:240] data_layer does not need backward computation.
I1008 22:10:37.723521  4025 net.cpp:283] This network produces output error_blob
I1008 22:10:37.723526  4025 net.cpp:297] Network initialization done.
I1008 22:10:37.723528  4025 net.cpp:298] Memory required for data: 1504004
I1008 22:10:37.723551  4025 solver.cpp:66] Solver scaffolding done.
I1008 22:10:37.723829  4025 caffe.cpp:212] Starting Optimization
I1008 22:10:37.723837  4025 solver.cpp:294] Solving two_hidden/model3_part8.prototxt
I1008 22:10:37.723839  4025 solver.cpp:295] Learning Rate Policy: inv
I1008 22:10:37.724004  4025 solver.cpp:347] Iteration 0, Testing net (#0)
I1008 22:10:37.724064  4025 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 22:10:37.733470  4025 solver.cpp:415]     Test net output #0: error_blob = 0.161768 (* 1 = 0.161768 loss)
I1008 22:10:37.735556  4025 solver.cpp:243] Iteration 0, loss = 0.159319
I1008 22:10:37.735570  4025 solver.cpp:259]     Train net output #0: error_blob = 0.159319 (* 1 = 0.159319 loss)
I1008 22:10:37.735584  4025 solver.cpp:590] Iteration 0, lr = 0.1
I1008 22:10:42.593482  4025 solver.cpp:347] Iteration 100, Testing net (#0)
I1008 22:10:42.595309  4025 solver.cpp:415]     Test net output #0: error_blob = 0.120306 (* 1 = 0.120306 loss)
I1008 22:10:42.648160  4025 solver.cpp:243] Iteration 100, loss = 0.118584
I1008 22:10:42.648192  4025 solver.cpp:259]     Train net output #0: error_blob = 0.118584 (* 1 = 0.118584 loss)
I1008 22:10:42.648201  4025 solver.cpp:590] Iteration 100, lr = 0.0924556
I1008 22:10:47.596068  4025 solver.cpp:347] Iteration 200, Testing net (#0)
I1008 22:10:47.597985  4025 solver.cpp:415]     Test net output #0: error_blob = 0.11658 (* 1 = 0.11658 loss)
I1008 22:10:47.646941  4025 solver.cpp:243] Iteration 200, loss = 0.112902
I1008 22:10:47.646970  4025 solver.cpp:259]     Train net output #0: error_blob = 0.112902 (* 1 = 0.112902 loss)
I1008 22:10:47.646980  4025 solver.cpp:590] Iteration 200, lr = 0.0857339
I1008 22:10:52.486178  4025 solver.cpp:347] Iteration 300, Testing net (#0)
I1008 22:10:52.488008  4025 solver.cpp:415]     Test net output #0: error_blob = 0.114824 (* 1 = 0.114824 loss)
I1008 22:10:52.537747  4025 solver.cpp:243] Iteration 300, loss = 0.108508
I1008 22:10:52.537781  4025 solver.cpp:259]     Train net output #0: error_blob = 0.108508 (* 1 = 0.108508 loss)
I1008 22:10:52.537791  4025 solver.cpp:590] Iteration 300, lr = 0.0797194
I1008 22:10:57.366571  4025 solver.cpp:347] Iteration 400, Testing net (#0)
I1008 22:10:57.368450  4025 solver.cpp:415]     Test net output #0: error_blob = 0.113962 (* 1 = 0.113962 loss)
I1008 22:10:57.422407  4025 solver.cpp:243] Iteration 400, loss = 0.106553
I1008 22:10:57.422437  4025 solver.cpp:259]     Train net output #0: error_blob = 0.106553 (* 1 = 0.106553 loss)
I1008 22:10:57.422446  4025 solver.cpp:590] Iteration 400, lr = 0.0743163
I1008 22:11:02.318855  4025 solver.cpp:347] Iteration 500, Testing net (#0)
I1008 22:11:02.320703  4025 solver.cpp:415]     Test net output #0: error_blob = 0.112632 (* 1 = 0.112632 loss)
I1008 22:11:02.375232  4025 solver.cpp:243] Iteration 500, loss = 0.104861
I1008 22:11:02.375286  4025 solver.cpp:259]     Train net output #0: error_blob = 0.104861 (* 1 = 0.104861 loss)
I1008 22:11:02.375294  4025 solver.cpp:590] Iteration 500, lr = 0.0694444
I1008 22:11:07.322290  4025 solver.cpp:347] Iteration 600, Testing net (#0)
I1008 22:11:07.324149  4025 solver.cpp:415]     Test net output #0: error_blob = 0.111587 (* 1 = 0.111587 loss)
I1008 22:11:07.375625  4025 solver.cpp:243] Iteration 600, loss = 0.103726
I1008 22:11:07.375658  4025 solver.cpp:259]     Train net output #0: error_blob = 0.103726 (* 1 = 0.103726 loss)
I1008 22:11:07.375668  4025 solver.cpp:590] Iteration 600, lr = 0.0650364
I1008 22:11:12.243574  4025 solver.cpp:347] Iteration 700, Testing net (#0)
I1008 22:11:12.245414  4025 solver.cpp:415]     Test net output #0: error_blob = 0.110353 (* 1 = 0.110353 loss)
I1008 22:11:12.298662  4025 solver.cpp:243] Iteration 700, loss = 0.103764
I1008 22:11:12.298696  4025 solver.cpp:259]     Train net output #0: error_blob = 0.103764 (* 1 = 0.103764 loss)
I1008 22:11:12.298708  4025 solver.cpp:590] Iteration 700, lr = 0.0610352
I1008 22:11:17.188104  4025 solver.cpp:347] Iteration 800, Testing net (#0)
I1008 22:11:17.190007  4025 solver.cpp:415]     Test net output #0: error_blob = 0.108812 (* 1 = 0.108812 loss)
I1008 22:11:17.242702  4025 solver.cpp:243] Iteration 800, loss = 0.102055
I1008 22:11:17.242732  4025 solver.cpp:259]     Train net output #0: error_blob = 0.102055 (* 1 = 0.102055 loss)
I1008 22:11:17.242739  4025 solver.cpp:590] Iteration 800, lr = 0.0573921
I1008 22:11:22.114758  4025 solver.cpp:347] Iteration 900, Testing net (#0)
I1008 22:11:22.116650  4025 solver.cpp:415]     Test net output #0: error_blob = 0.108433 (* 1 = 0.108433 loss)
I1008 22:11:22.168553  4025 solver.cpp:243] Iteration 900, loss = 0.101534
I1008 22:11:22.168581  4025 solver.cpp:259]     Train net output #0: error_blob = 0.101534 (* 1 = 0.101534 loss)
I1008 22:11:22.168588  4025 solver.cpp:590] Iteration 900, lr = 0.0540657
I1008 22:11:27.080731  4025 solver.cpp:347] Iteration 1000, Testing net (#0)
I1008 22:11:27.082573  4025 solver.cpp:415]     Test net output #0: error_blob = 0.107792 (* 1 = 0.107792 loss)
I1008 22:11:27.135660  4025 solver.cpp:243] Iteration 1000, loss = 0.10087
I1008 22:11:27.135695  4025 solver.cpp:259]     Train net output #0: error_blob = 0.10087 (* 1 = 0.10087 loss)
I1008 22:11:27.135704  4025 solver.cpp:590] Iteration 1000, lr = 0.0510204
I1008 22:11:27.135836  4025 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 22:11:31.992911  4025 solver.cpp:347] Iteration 1100, Testing net (#0)
I1008 22:11:31.994812  4025 solver.cpp:415]     Test net output #0: error_blob = 0.107907 (* 1 = 0.107907 loss)
I1008 22:11:32.047101  4025 solver.cpp:243] Iteration 1100, loss = 0.100964
I1008 22:11:32.047129  4025 solver.cpp:259]     Train net output #0: error_blob = 0.100964 (* 1 = 0.100964 loss)
I1008 22:11:32.047137  4025 solver.cpp:590] Iteration 1100, lr = 0.0482253
I1008 22:11:36.958968  4025 solver.cpp:347] Iteration 1200, Testing net (#0)
I1008 22:11:36.960820  4025 solver.cpp:415]     Test net output #0: error_blob = 0.107699 (* 1 = 0.107699 loss)
I1008 22:11:37.012586  4025 solver.cpp:243] Iteration 1200, loss = 0.101737
I1008 22:11:37.012614  4025 solver.cpp:259]     Train net output #0: error_blob = 0.101737 (* 1 = 0.101737 loss)
I1008 22:11:37.012620  4025 solver.cpp:590] Iteration 1200, lr = 0.0456538
I1008 22:11:41.819377  4025 solver.cpp:347] Iteration 1300, Testing net (#0)
I1008 22:11:41.821264  4025 solver.cpp:415]     Test net output #0: error_blob = 0.107078 (* 1 = 0.107078 loss)
I1008 22:11:41.872217  4025 solver.cpp:243] Iteration 1300, loss = 0.0998947
I1008 22:11:41.872248  4025 solver.cpp:259]     Train net output #0: error_blob = 0.0998947 (* 1 = 0.0998947 loss)
I1008 22:11:41.872256  4025 solver.cpp:590] Iteration 1300, lr = 0.0432825
I1008 22:11:46.763317  4025 solver.cpp:347] Iteration 1400, Testing net (#0)
I1008 22:11:46.765149  4025 solver.cpp:415]     Test net output #0: error_blob = 0.105092 (* 1 = 0.105092 loss)
I1008 22:11:46.819702  4025 solver.cpp:243] Iteration 1400, loss = 0.0994498
I1008 22:11:46.819736  4025 solver.cpp:259]     Train net output #0: error_blob = 0.0994498 (* 1 = 0.0994498 loss)
I1008 22:11:46.819746  4025 solver.cpp:590] Iteration 1400, lr = 0.0410914
I1008 22:11:51.653421  4025 solver.cpp:347] Iteration 1500, Testing net (#0)
I1008 22:11:51.655279  4025 solver.cpp:415]     Test net output #0: error_blob = 0.10621 (* 1 = 0.10621 loss)
I1008 22:11:51.708356  4025 solver.cpp:243] Iteration 1500, loss = 0.0989335
I1008 22:11:51.708382  4025 solver.cpp:259]     Train net output #0: error_blob = 0.0989335 (* 1 = 0.0989335 loss)
I1008 22:11:51.708389  4025 solver.cpp:590] Iteration 1500, lr = 0.0390625
I1008 22:11:56.607977  4025 solver.cpp:347] Iteration 1600, Testing net (#0)
I1008 22:11:56.609882  4025 solver.cpp:415]     Test net output #0: error_blob = 0.106033 (* 1 = 0.106033 loss)
I1008 22:11:56.662401  4025 solver.cpp:243] Iteration 1600, loss = 0.0993452
I1008 22:11:56.662438  4025 solver.cpp:259]     Train net output #0: error_blob = 0.0993452 (* 1 = 0.0993452 loss)
I1008 22:11:56.662449  4025 solver.cpp:590] Iteration 1600, lr = 0.0371803
I1008 22:12:01.552397  4025 solver.cpp:347] Iteration 1700, Testing net (#0)
I1008 22:12:01.554296  4025 solver.cpp:415]     Test net output #0: error_blob = 0.105389 (* 1 = 0.105389 loss)
I1008 22:12:01.608877  4025 solver.cpp:243] Iteration 1700, loss = 0.100253
I1008 22:12:01.608906  4025 solver.cpp:259]     Train net output #0: error_blob = 0.100253 (* 1 = 0.100253 loss)
I1008 22:12:01.608913  4025 solver.cpp:590] Iteration 1700, lr = 0.0354308
I1008 22:12:06.525192  4025 solver.cpp:347] Iteration 1800, Testing net (#0)
I1008 22:12:06.527091  4025 solver.cpp:415]     Test net output #0: error_blob = 0.105636 (* 1 = 0.105636 loss)
I1008 22:12:06.578454  4025 solver.cpp:243] Iteration 1800, loss = 0.0985236
I1008 22:12:06.578481  4025 solver.cpp:259]     Train net output #0: error_blob = 0.0985236 (* 1 = 0.0985236 loss)
I1008 22:12:06.578488  4025 solver.cpp:590] Iteration 1800, lr = 0.0338021
I1008 22:12:11.477450  4025 solver.cpp:347] Iteration 1900, Testing net (#0)
I1008 22:12:11.479302  4025 solver.cpp:415]     Test net output #0: error_blob = 0.105189 (* 1 = 0.105189 loss)
I1008 22:12:11.529081  4025 solver.cpp:243] Iteration 1900, loss = 0.0980054
I1008 22:12:11.529116  4025 solver.cpp:259]     Train net output #0: error_blob = 0.0980054 (* 1 = 0.0980054 loss)
I1008 22:12:11.529129  4025 solver.cpp:590] Iteration 1900, lr = 0.0322831
I1008 22:12:16.470268  4025 solver.cpp:347] Iteration 2000, Testing net (#0)
I1008 22:12:16.472126  4025 solver.cpp:415]     Test net output #0: error_blob = 0.104889 (* 1 = 0.104889 loss)
I1008 22:12:16.523015  4025 solver.cpp:243] Iteration 2000, loss = 0.0979794
I1008 22:12:16.523049  4025 solver.cpp:259]     Train net output #0: error_blob = 0.0979794 (* 1 = 0.0979794 loss)
I1008 22:12:16.523058  4025 solver.cpp:590] Iteration 2000, lr = 0.0308642
I1008 22:12:16.523192  4025 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 22:12:21.474763  4025 solver.cpp:347] Iteration 2100, Testing net (#0)
I1008 22:12:21.476613  4025 solver.cpp:415]     Test net output #0: error_blob = 0.104892 (* 1 = 0.104892 loss)
I1008 22:12:21.526409  4025 solver.cpp:243] Iteration 2100, loss = 0.0984634
I1008 22:12:21.526444  4025 solver.cpp:259]     Train net output #0: error_blob = 0.0984634 (* 1 = 0.0984634 loss)
I1008 22:12:21.526453  4025 solver.cpp:590] Iteration 2100, lr = 0.0295369
I1008 22:12:26.476238  4025 solver.cpp:347] Iteration 2200, Testing net (#0)
I1008 22:12:26.478083  4025 solver.cpp:415]     Test net output #0: error_blob = 0.103835 (* 1 = 0.103835 loss)
I1008 22:12:26.529345  4025 solver.cpp:243] Iteration 2200, loss = 0.0989493
I1008 22:12:26.529379  4025 solver.cpp:259]     Train net output #0: error_blob = 0.0989493 (* 1 = 0.0989493 loss)
I1008 22:12:26.529389  4025 solver.cpp:590] Iteration 2200, lr = 0.0282933
I1008 22:12:31.455479  4025 solver.cpp:347] Iteration 2300, Testing net (#0)
I1008 22:12:31.457329  4025 solver.cpp:415]     Test net output #0: error_blob = 0.104378 (* 1 = 0.104378 loss)
I1008 22:12:31.508432  4025 solver.cpp:243] Iteration 2300, loss = 0.097509
I1008 22:12:31.508465  4025 solver.cpp:259]     Train net output #0: error_blob = 0.097509 (* 1 = 0.097509 loss)
I1008 22:12:31.508473  4025 solver.cpp:590] Iteration 2300, lr = 0.0271267
I1008 22:12:36.510478  4025 solver.cpp:347] Iteration 2400, Testing net (#0)
I1008 22:12:36.512382  4025 solver.cpp:415]     Test net output #0: error_blob = 0.104291 (* 1 = 0.104291 loss)
I1008 22:12:36.565150  4025 solver.cpp:243] Iteration 2400, loss = 0.0972079
I1008 22:12:36.565176  4025 solver.cpp:259]     Train net output #0: error_blob = 0.0972079 (* 1 = 0.0972079 loss)
I1008 22:12:36.565182  4025 solver.cpp:590] Iteration 2400, lr = 0.0260308
I1008 22:12:41.519052  4025 solver.cpp:347] Iteration 2500, Testing net (#0)
I1008 22:12:41.520943  4025 solver.cpp:415]     Test net output #0: error_blob = 0.104196 (* 1 = 0.104196 loss)
I1008 22:12:41.572509  4025 solver.cpp:243] Iteration 2500, loss = 0.0974429
I1008 22:12:41.572537  4025 solver.cpp:259]     Train net output #0: error_blob = 0.0974429 (* 1 = 0.0974429 loss)
I1008 22:12:41.572545  4025 solver.cpp:590] Iteration 2500, lr = 0.025
I1008 22:12:46.452450  4025 solver.cpp:347] Iteration 2600, Testing net (#0)
I1008 22:12:46.454300  4025 solver.cpp:415]     Test net output #0: error_blob = 0.103898 (* 1 = 0.103898 loss)
I1008 22:12:46.506080  4025 solver.cpp:243] Iteration 2600, loss = 0.0976175
I1008 22:12:46.506176  4025 solver.cpp:259]     Train net output #0: error_blob = 0.0976175 (* 1 = 0.0976175 loss)
I1008 22:12:46.506186  4025 solver.cpp:590] Iteration 2600, lr = 0.0240292
I1008 22:12:51.382390  4025 solver.cpp:347] Iteration 2700, Testing net (#0)
I1008 22:12:51.384301  4025 solver.cpp:415]     Test net output #0: error_blob = 0.1039 (* 1 = 0.1039 loss)
I1008 22:12:51.433887  4025 solver.cpp:243] Iteration 2700, loss = 0.0981107
I1008 22:12:51.433924  4025 solver.cpp:259]     Train net output #0: error_blob = 0.0981107 (* 1 = 0.0981107 loss)
I1008 22:12:51.433934  4025 solver.cpp:590] Iteration 2700, lr = 0.0231139
I1008 22:12:56.334645  4025 solver.cpp:347] Iteration 2800, Testing net (#0)
I1008 22:12:56.336482  4025 solver.cpp:415]     Test net output #0: error_blob = 0.103606 (* 1 = 0.103606 loss)
I1008 22:12:56.389003  4025 solver.cpp:243] Iteration 2800, loss = 0.0967257
I1008 22:12:56.389037  4025 solver.cpp:259]     Train net output #0: error_blob = 0.0967257 (* 1 = 0.0967257 loss)
I1008 22:12:56.389046  4025 solver.cpp:590] Iteration 2800, lr = 0.0222499
I1008 22:13:01.289355  4025 solver.cpp:347] Iteration 2900, Testing net (#0)
I1008 22:13:01.291247  4025 solver.cpp:415]     Test net output #0: error_blob = 0.102735 (* 1 = 0.102735 loss)
I1008 22:13:01.339516  4025 solver.cpp:243] Iteration 2900, loss = 0.0966987
I1008 22:13:01.339545  4025 solver.cpp:259]     Train net output #0: error_blob = 0.0966987 (* 1 = 0.0966987 loss)
I1008 22:13:01.339552  4025 solver.cpp:590] Iteration 2900, lr = 0.0214335
I1008 22:13:06.181922  4025 solver.cpp:347] Iteration 3000, Testing net (#0)
I1008 22:13:06.183779  4025 solver.cpp:415]     Test net output #0: error_blob = 0.102762 (* 1 = 0.102762 loss)
I1008 22:13:06.233364  4025 solver.cpp:243] Iteration 3000, loss = 0.0968601
I1008 22:13:06.233398  4025 solver.cpp:259]     Train net output #0: error_blob = 0.0968601 (* 1 = 0.0968601 loss)
I1008 22:13:06.233407  4025 solver.cpp:590] Iteration 3000, lr = 0.0206612
I1008 22:13:06.233544  4025 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 22:13:11.160641  4025 solver.cpp:347] Iteration 3100, Testing net (#0)
I1008 22:13:11.162519  4025 solver.cpp:415]     Test net output #0: error_blob = 0.101911 (* 1 = 0.101911 loss)
I1008 22:13:11.214864  4025 solver.cpp:243] Iteration 3100, loss = 0.0967088
I1008 22:13:11.214900  4025 solver.cpp:259]     Train net output #0: error_blob = 0.0967088 (* 1 = 0.0967088 loss)
I1008 22:13:11.214910  4025 solver.cpp:590] Iteration 3100, lr = 0.0199298
I1008 22:13:16.058825  4025 solver.cpp:347] Iteration 3200, Testing net (#0)
I1008 22:13:16.060715  4025 solver.cpp:415]     Test net output #0: error_blob = 0.102765 (* 1 = 0.102765 loss)
I1008 22:13:16.112859  4025 solver.cpp:243] Iteration 3200, loss = 0.0977445
I1008 22:13:16.112895  4025 solver.cpp:259]     Train net output #0: error_blob = 0.0977445 (* 1 = 0.0977445 loss)
I1008 22:13:16.112905  4025 solver.cpp:590] Iteration 3200, lr = 0.0192367
I1008 22:13:20.955032  4025 solver.cpp:347] Iteration 3300, Testing net (#0)
I1008 22:13:20.956945  4025 solver.cpp:415]     Test net output #0: error_blob = 0.102453 (* 1 = 0.102453 loss)
I1008 22:13:21.012603  4025 solver.cpp:243] Iteration 3300, loss = 0.0961675
I1008 22:13:21.012629  4025 solver.cpp:259]     Train net output #0: error_blob = 0.0961675 (* 1 = 0.0961675 loss)
I1008 22:13:21.012636  4025 solver.cpp:590] Iteration 3300, lr = 0.0185791
I1008 22:13:25.894457  4025 solver.cpp:347] Iteration 3400, Testing net (#0)
I1008 22:13:25.896363  4025 solver.cpp:415]     Test net output #0: error_blob = 0.102606 (* 1 = 0.102606 loss)
I1008 22:13:25.946632  4025 solver.cpp:243] Iteration 3400, loss = 0.0965613
I1008 22:13:25.946662  4025 solver.cpp:259]     Train net output #0: error_blob = 0.0965613 (* 1 = 0.0965613 loss)
I1008 22:13:25.946671  4025 solver.cpp:590] Iteration 3400, lr = 0.0179546
I1008 22:13:30.837682  4025 solver.cpp:347] Iteration 3500, Testing net (#0)
I1008 22:13:30.839592  4025 solver.cpp:415]     Test net output #0: error_blob = 0.102349 (* 1 = 0.102349 loss)
I1008 22:13:30.889389  4025 solver.cpp:243] Iteration 3500, loss = 0.0965552
I1008 22:13:30.889425  4025 solver.cpp:259]     Train net output #0: error_blob = 0.0965552 (* 1 = 0.0965552 loss)
I1008 22:13:30.889433  4025 solver.cpp:590] Iteration 3500, lr = 0.0173611
I1008 22:13:35.766003  4025 solver.cpp:347] Iteration 3600, Testing net (#0)
I1008 22:13:35.767916  4025 solver.cpp:415]     Test net output #0: error_blob = 0.10212 (* 1 = 0.10212 loss)
I1008 22:13:35.818039  4025 solver.cpp:243] Iteration 3600, loss = 0.0958781
I1008 22:13:35.818066  4025 solver.cpp:259]     Train net output #0: error_blob = 0.0958781 (* 1 = 0.0958781 loss)
I1008 22:13:35.818076  4025 solver.cpp:590] Iteration 3600, lr = 0.0167966
I1008 22:13:40.704218  4025 solver.cpp:347] Iteration 3700, Testing net (#0)
I1008 22:13:40.706109  4025 solver.cpp:415]     Test net output #0: error_blob = 0.101855 (* 1 = 0.101855 loss)
I1008 22:13:40.759690  4025 solver.cpp:243] Iteration 3700, loss = 0.0969359
I1008 22:13:40.759716  4025 solver.cpp:259]     Train net output #0: error_blob = 0.0969359 (* 1 = 0.0969359 loss)
I1008 22:13:40.759723  4025 solver.cpp:590] Iteration 3700, lr = 0.0162591
I1008 22:13:45.694254  4025 solver.cpp:347] Iteration 3800, Testing net (#0)
I1008 22:13:45.696100  4025 solver.cpp:415]     Test net output #0: error_blob = 0.102368 (* 1 = 0.102368 loss)
I1008 22:13:45.748436  4025 solver.cpp:243] Iteration 3800, loss = 0.0954461
I1008 22:13:45.748468  4025 solver.cpp:259]     Train net output #0: error_blob = 0.0954461 (* 1 = 0.0954461 loss)
I1008 22:13:45.748481  4025 solver.cpp:590] Iteration 3800, lr = 0.015747
I1008 22:13:50.646350  4025 solver.cpp:347] Iteration 3900, Testing net (#0)
I1008 22:13:50.648196  4025 solver.cpp:415]     Test net output #0: error_blob = 0.103164 (* 1 = 0.103164 loss)
I1008 22:13:50.697772  4025 solver.cpp:243] Iteration 3900, loss = 0.0965191
I1008 22:13:50.697808  4025 solver.cpp:259]     Train net output #0: error_blob = 0.0965191 (* 1 = 0.0965191 loss)
I1008 22:13:50.697818  4025 solver.cpp:590] Iteration 3900, lr = 0.0152588
I1008 22:13:55.589920  4025 solver.cpp:347] Iteration 4000, Testing net (#0)
I1008 22:13:55.591745  4025 solver.cpp:415]     Test net output #0: error_blob = 0.103116 (* 1 = 0.103116 loss)
I1008 22:13:55.640947  4025 solver.cpp:243] Iteration 4000, loss = 0.096271
I1008 22:13:55.640974  4025 solver.cpp:259]     Train net output #0: error_blob = 0.096271 (* 1 = 0.096271 loss)
I1008 22:13:55.640980  4025 solver.cpp:590] Iteration 4000, lr = 0.0147929
I1008 22:13:55.641068  4025 blocking_queue.cpp:50] Data layer prefetch queue empty
I1008 22:14:00.527570  4025 solver.cpp:347] Iteration 4100, Testing net (#0)
I1008 22:14:00.529460  4025 solver.cpp:415]     Test net output #0: error_blob = 0.103068 (* 1 = 0.103068 loss)
I1008 22:14:00.580816  4025 solver.cpp:243] Iteration 4100, loss = 0.0953346
I1008 22:14:00.580845  4025 solver.cpp:259]     Train net output #0: error_blob = 0.0953346 (* 1 = 0.0953346 loss)
I1008 22:14:00.580853  4025 solver.cpp:590] Iteration 4100, lr = 0.014348
I1008 22:14:05.475998  4025 solver.cpp:347] Iteration 4200, Testing net (#0)
I1008 22:14:05.477890  4025 solver.cpp:415]     Test net output #0: error_blob = 0.102851 (* 1 = 0.102851 loss)
I1008 22:14:05.529253  4025 solver.cpp:243] Iteration 4200, loss = 0.0967863
I1008 22:14:05.529284  4025 solver.cpp:259]     Train net output #0: error_blob = 0.0967863 (* 1 = 0.0967863 loss)
I1008 22:14:05.529289  4025 solver.cpp:590] Iteration 4200, lr = 0.0139229
I1008 22:14:10.402190  4025 solver.cpp:347] Iteration 4300, Testing net (#0)
I1008 22:14:10.404096  4025 solver.cpp:415]     Test net output #0: error_blob = 0.100716 (* 1 = 0.100716 loss)
I1008 22:14:10.455104  4025 solver.cpp:243] Iteration 4300, loss = 0.0948785
I1008 22:14:10.455133  4025 solver.cpp:259]     Train net output #0: error_blob = 0.0948785 (* 1 = 0.0948785 loss)
I1008 22:14:10.455139  4025 solver.cpp:590] Iteration 4300, lr = 0.0135164
I1008 22:14:15.310961  4025 solver.cpp:347] Iteration 4400, Testing net (#0)
I1008 22:14:15.312863  4025 solver.cpp:415]     Test net output #0: error_blob = 0.10094 (* 1 = 0.10094 loss)
I1008 22:14:15.363136  4025 solver.cpp:243] Iteration 4400, loss = 0.0962119
I1008 22:14:15.363162  4025 solver.cpp:259]     Train net output #0: error_blob = 0.0962119 (* 1 = 0.0962119 loss)
I1008 22:14:15.363168  4025 solver.cpp:590] Iteration 4400, lr = 0.0131275
I1008 22:14:20.266305  4025 solver.cpp:347] Iteration 4500, Testing net (#0)
I1008 22:14:20.268218  4025 solver.cpp:415]     Test net output #0: error_blob = 0.100471 (* 1 = 0.100471 loss)
I1008 22:14:20.319349  4025 solver.cpp:243] Iteration 4500, loss = 0.0956677
I1008 22:14:20.319377  4025 solver.cpp:259]     Train net output #0: error_blob = 0.0956677 (* 1 = 0.0956677 loss)
I1008 22:14:20.319386  4025 solver.cpp:590] Iteration 4500, lr = 0.0127551
I1008 22:14:25.207437  4025 solver.cpp:347] Iteration 4600, Testing net (#0)
I1008 22:14:25.209332  4025 solver.cpp:415]     Test net output #0: error_blob = 0.100352 (* 1 = 0.100352 loss)
I1008 22:14:25.257638  4025 solver.cpp:243] Iteration 4600, loss = 0.0952519
I1008 22:14:25.257665  4025 solver.cpp:259]     Train net output #0: error_blob = 0.0952519 (* 1 = 0.0952519 loss)
I1008 22:14:25.257671  4025 solver.cpp:590] Iteration 4600, lr = 0.0123983
I1008 22:14:30.165352  4025 solver.cpp:347] Iteration 4700, Testing net (#0)
I1008 22:14:30.167246  4025 solver.cpp:415]     Test net output #0: error_blob = 0.0999614 (* 1 = 0.0999614 loss)
I1008 22:14:30.219043  4025 solver.cpp:243] Iteration 4700, loss = 0.0968859
I1008 22:14:30.219071  4025 solver.cpp:259]     Train net output #0: error_blob = 0.0968859 (* 1 = 0.0968859 loss)
I1008 22:14:30.219079  4025 solver.cpp:590] Iteration 4700, lr = 0.0120563
I1008 22:14:35.121700  4025 solver.cpp:347] Iteration 4800, Testing net (#0)
I1008 22:14:35.123592  4025 solver.cpp:415]     Test net output #0: error_blob = 0.10043 (* 1 = 0.10043 loss)
I1008 22:14:35.175166  4025 solver.cpp:243] Iteration 4800, loss = 0.0946539
I1008 22:14:35.175192  4025 solver.cpp:259]     Train net output #0: error_blob = 0.0946539 (* 1 = 0.0946539 loss)
I1008 22:14:35.175199  4025 solver.cpp:590] Iteration 4800, lr = 0.0117283
I1008 22:14:40.062407  4025 solver.cpp:347] Iteration 4900, Testing net (#0)
I1008 22:14:40.064309  4025 solver.cpp:415]     Test net output #0: error_blob = 0.100398 (* 1 = 0.100398 loss)
I1008 22:14:40.115718  4025 solver.cpp:243] Iteration 4900, loss = 0.0956165
I1008 22:14:40.115747  4025 solver.cpp:259]     Train net output #0: error_blob = 0.0956165 (* 1 = 0.0956165 loss)
I1008 22:14:40.115753  4025 solver.cpp:590] Iteration 4900, lr = 0.0114134
I1008 22:14:45.015277  4025 solver.cpp:468] Snapshotting to binary proto file _iter_5000.caffemodel
I1008 22:14:45.017220  4025 solver.cpp:753] Snapshotting solver state to binary proto file _iter_5000.solverstate
I1008 22:14:45.065078  4025 solver.cpp:327] Iteration 5000, loss = 0.0958502
I1008 22:14:45.065099  4025 solver.cpp:347] Iteration 5000, Testing net (#0)
I1008 22:14:45.065419  4025 solver.cpp:415]     Test net output #0: error_blob = 0.100419 (* 1 = 0.100419 loss)
I1008 22:14:45.065428  4025 solver.cpp:332] Optimization Done.
I1008 22:14:45.065430  4025 caffe.cpp:215] Optimization Done.
