I1002 00:37:49.497288 23672 caffe.cpp:184] Using GPUs 0
I1002 00:37:50.554149 23672 solver.cpp:54] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "fixed"
momentum: 0.9
solver_mode: GPU
device_id: 0
net: "model/NNScore/nnscore_model_0.prototxt"
I1002 00:37:50.554182 23672 solver.cpp:97] Creating training net from net file: model/NNScore/nnscore_model_0.prototxt
I1002 00:37:50.554348 23672 net.cpp:339] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_layer
I1002 00:37:50.554397 23672 net.cpp:50] Initializing net from parameters: 
name: "model/NNScore/nnscore_model_0.prototxt"
state {
  phase: TRAIN
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TRAIN
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.0.train"
    batch_size: 20000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1002 00:37:50.554463 23672 layer_factory.hpp:76] Creating layer data_layer
I1002 00:37:50.568413 23672 net.cpp:110] Creating Layer data_layer
I1002 00:37:50.568449 23672 net.cpp:433] data_layer -> data_blob
I1002 00:37:50.568470 23672 net.cpp:433] data_layer -> label_blob
I1002 00:37:50.569084 23676 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.0.train
I1002 00:37:51.289461 23672 data_layer.cpp:45] output data size: 20000,61,1,1
I1002 00:37:51.294524 23672 net.cpp:155] Setting up data_layer
I1002 00:37:51.294559 23672 net.cpp:163] Top shape: 20000 61 1 1 (1220000)
I1002 00:37:51.294574 23672 net.cpp:163] Top shape: 20000 (20000)
I1002 00:37:51.294581 23672 layer_factory.hpp:76] Creating layer hidden_sum_layer
I1002 00:37:51.294596 23672 net.cpp:110] Creating Layer hidden_sum_layer
I1002 00:37:51.294601 23672 net.cpp:477] hidden_sum_layer <- data_blob
I1002 00:37:51.294615 23672 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I1002 00:37:51.294982 23672 net.cpp:155] Setting up hidden_sum_layer
I1002 00:37:51.294991 23672 net.cpp:163] Top shape: 20000 10 (200000)
I1002 00:37:51.295006 23672 layer_factory.hpp:76] Creating layer hidden_act_layer
I1002 00:37:51.295018 23672 net.cpp:110] Creating Layer hidden_act_layer
I1002 00:37:51.295022 23672 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I1002 00:37:51.295027 23672 net.cpp:433] hidden_act_layer -> hidden_act_blob
I1002 00:37:54.691012 23672 net.cpp:155] Setting up hidden_act_layer
I1002 00:37:54.691037 23672 net.cpp:163] Top shape: 20000 10 (200000)
I1002 00:37:54.691043 23672 layer_factory.hpp:76] Creating layer output_sum_layer
I1002 00:37:54.691056 23672 net.cpp:110] Creating Layer output_sum_layer
I1002 00:37:54.691061 23672 net.cpp:477] output_sum_layer <- hidden_act_blob
I1002 00:37:54.691068 23672 net.cpp:433] output_sum_layer -> output_sum_blob
I1002 00:37:54.691160 23672 net.cpp:155] Setting up output_sum_layer
I1002 00:37:54.691169 23672 net.cpp:163] Top shape: 20000 1 (20000)
I1002 00:37:54.691179 23672 layer_factory.hpp:76] Creating layer output_act_layer
I1002 00:37:54.691186 23672 net.cpp:110] Creating Layer output_act_layer
I1002 00:37:54.691190 23672 net.cpp:477] output_act_layer <- output_sum_blob
I1002 00:37:54.691195 23672 net.cpp:433] output_act_layer -> output_act_blob
I1002 00:37:54.691259 23672 net.cpp:155] Setting up output_act_layer
I1002 00:37:54.691274 23672 net.cpp:163] Top shape: 20000 1 (20000)
I1002 00:37:54.691279 23672 layer_factory.hpp:76] Creating layer error_layer
I1002 00:37:54.691287 23672 net.cpp:110] Creating Layer error_layer
I1002 00:37:54.691290 23672 net.cpp:477] error_layer <- output_act_blob
I1002 00:37:54.691295 23672 net.cpp:477] error_layer <- label_blob
I1002 00:37:54.691300 23672 net.cpp:433] error_layer -> error_blob
I1002 00:37:54.691330 23672 net.cpp:155] Setting up error_layer
I1002 00:37:54.691336 23672 net.cpp:163] Top shape: (1)
I1002 00:37:54.691339 23672 net.cpp:168]     with loss weight 1
I1002 00:37:54.691359 23672 net.cpp:236] error_layer needs backward computation.
I1002 00:37:54.691364 23672 net.cpp:236] output_act_layer needs backward computation.
I1002 00:37:54.691367 23672 net.cpp:236] output_sum_layer needs backward computation.
I1002 00:37:54.691378 23672 net.cpp:236] hidden_act_layer needs backward computation.
I1002 00:37:54.691381 23672 net.cpp:236] hidden_sum_layer needs backward computation.
I1002 00:37:54.691385 23672 net.cpp:240] data_layer does not need backward computation.
I1002 00:37:54.691387 23672 net.cpp:283] This network produces output error_blob
I1002 00:37:54.691395 23672 net.cpp:297] Network initialization done.
I1002 00:37:54.691397 23672 net.cpp:298] Memory required for data: 6720004
I1002 00:37:54.691525 23672 solver.cpp:187] Creating test net (#0) specified by net file: model/NNScore/nnscore_model_0.prototxt
I1002 00:37:54.691541 23672 net.cpp:339] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_layer
I1002 00:37:54.691577 23672 net.cpp:50] Initializing net from parameters: 
name: "model/NNScore/nnscore_model_0.prototxt"
state {
  phase: TEST
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TEST
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.0.test"
    batch_size: 2000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1002 00:37:54.691606 23672 layer_factory.hpp:76] Creating layer data_layer
I1002 00:37:54.692795 23672 net.cpp:110] Creating Layer data_layer
I1002 00:37:54.692812 23672 net.cpp:433] data_layer -> data_blob
I1002 00:37:54.692819 23672 net.cpp:433] data_layer -> label_blob
I1002 00:37:54.693374 23678 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.0.test
I1002 00:37:54.693452 23672 data_layer.cpp:45] output data size: 2000,61,1,1
I1002 00:37:54.694816 23672 net.cpp:155] Setting up data_layer
I1002 00:37:54.694836 23672 net.cpp:163] Top shape: 2000 61 1 1 (122000)
I1002 00:37:54.694841 23672 net.cpp:163] Top shape: 2000 (2000)
I1002 00:37:54.694855 23672 layer_factory.hpp:76] Creating layer hidden_sum_layer
I1002 00:37:54.694864 23672 net.cpp:110] Creating Layer hidden_sum_layer
I1002 00:37:54.694867 23672 net.cpp:477] hidden_sum_layer <- data_blob
I1002 00:37:54.694874 23672 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I1002 00:37:54.695021 23672 net.cpp:155] Setting up hidden_sum_layer
I1002 00:37:54.695036 23672 net.cpp:163] Top shape: 2000 10 (20000)
I1002 00:37:54.695057 23672 layer_factory.hpp:76] Creating layer hidden_act_layer
I1002 00:37:54.695073 23672 net.cpp:110] Creating Layer hidden_act_layer
I1002 00:37:54.695080 23672 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I1002 00:37:54.695096 23672 net.cpp:433] hidden_act_layer -> hidden_act_blob
I1002 00:37:54.695294 23672 net.cpp:155] Setting up hidden_act_layer
I1002 00:37:54.695302 23672 net.cpp:163] Top shape: 2000 10 (20000)
I1002 00:37:54.695305 23672 layer_factory.hpp:76] Creating layer output_sum_layer
I1002 00:37:54.695322 23672 net.cpp:110] Creating Layer output_sum_layer
I1002 00:37:54.695325 23672 net.cpp:477] output_sum_layer <- hidden_act_blob
I1002 00:37:54.695332 23672 net.cpp:433] output_sum_layer -> output_sum_blob
I1002 00:37:54.695405 23672 net.cpp:155] Setting up output_sum_layer
I1002 00:37:54.695412 23672 net.cpp:163] Top shape: 2000 1 (2000)
I1002 00:37:54.695430 23672 layer_factory.hpp:76] Creating layer output_act_layer
I1002 00:37:54.695436 23672 net.cpp:110] Creating Layer output_act_layer
I1002 00:37:54.695441 23672 net.cpp:477] output_act_layer <- output_sum_blob
I1002 00:37:54.695446 23672 net.cpp:433] output_act_layer -> output_act_blob
I1002 00:37:54.695508 23672 net.cpp:155] Setting up output_act_layer
I1002 00:37:54.695514 23672 net.cpp:163] Top shape: 2000 1 (2000)
I1002 00:37:54.695518 23672 layer_factory.hpp:76] Creating layer error_layer
I1002 00:37:54.695533 23672 net.cpp:110] Creating Layer error_layer
I1002 00:37:54.695538 23672 net.cpp:477] error_layer <- output_act_blob
I1002 00:37:54.695541 23672 net.cpp:477] error_layer <- label_blob
I1002 00:37:54.695546 23672 net.cpp:433] error_layer -> error_blob
I1002 00:37:54.695572 23672 net.cpp:155] Setting up error_layer
I1002 00:37:54.695586 23672 net.cpp:163] Top shape: (1)
I1002 00:37:54.695590 23672 net.cpp:168]     with loss weight 1
I1002 00:37:54.695607 23672 net.cpp:236] error_layer needs backward computation.
I1002 00:37:54.695611 23672 net.cpp:236] output_act_layer needs backward computation.
I1002 00:37:54.695616 23672 net.cpp:236] output_sum_layer needs backward computation.
I1002 00:37:54.695618 23672 net.cpp:236] hidden_act_layer needs backward computation.
I1002 00:37:54.695621 23672 net.cpp:236] hidden_sum_layer needs backward computation.
I1002 00:37:54.695626 23672 net.cpp:240] data_layer does not need backward computation.
I1002 00:37:54.695628 23672 net.cpp:283] This network produces output error_blob
I1002 00:37:54.695636 23672 net.cpp:297] Network initialization done.
I1002 00:37:54.695638 23672 net.cpp:298] Memory required for data: 672004
I1002 00:37:54.695660 23672 solver.cpp:66] Solver scaffolding done.
I1002 00:37:54.695785 23672 caffe.cpp:212] Starting Optimization
I1002 00:37:54.695793 23672 solver.cpp:294] Solving model/NNScore/nnscore_model_0.prototxt
I1002 00:37:54.695796 23672 solver.cpp:295] Learning Rate Policy: fixed
I1002 00:37:54.695981 23672 solver.cpp:347] Iteration 0, Testing net (#0)
I1002 00:37:54.696035 23672 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:37:54.960458 23672 solver.cpp:415]     Test net output #0: error_blob = 0.13888 (* 1 = 0.13888 loss)
I1002 00:37:54.961829 23672 solver.cpp:243] Iteration 0, loss = 0.145967
I1002 00:37:54.961848 23672 solver.cpp:259]     Train net output #0: error_blob = 0.145967 (* 1 = 0.145967 loss)
I1002 00:37:54.961859 23672 solver.cpp:590] Iteration 0, lr = 0.01
I1002 00:37:57.479418 23672 solver.cpp:243] Iteration 100, loss = 0.122724
I1002 00:37:57.479454 23672 solver.cpp:259]     Train net output #0: error_blob = 0.122724 (* 1 = 0.122724 loss)
I1002 00:37:57.479461 23672 solver.cpp:590] Iteration 100, lr = 0.01
I1002 00:37:59.994027 23672 solver.cpp:243] Iteration 200, loss = 0.122684
I1002 00:37:59.994068 23672 solver.cpp:259]     Train net output #0: error_blob = 0.122684 (* 1 = 0.122684 loss)
I1002 00:37:59.994074 23672 solver.cpp:590] Iteration 200, lr = 0.01
I1002 00:38:02.463467 23672 solver.cpp:243] Iteration 300, loss = 0.121223
I1002 00:38:02.463507 23672 solver.cpp:259]     Train net output #0: error_blob = 0.121223 (* 1 = 0.121223 loss)
I1002 00:38:02.463512 23672 solver.cpp:590] Iteration 300, lr = 0.01
I1002 00:38:04.978967 23672 solver.cpp:243] Iteration 400, loss = 0.121426
I1002 00:38:04.979030 23672 solver.cpp:259]     Train net output #0: error_blob = 0.121426 (* 1 = 0.121426 loss)
I1002 00:38:04.979038 23672 solver.cpp:590] Iteration 400, lr = 0.01
I1002 00:38:07.487166 23672 solver.cpp:243] Iteration 500, loss = 0.12114
I1002 00:38:07.487207 23672 solver.cpp:259]     Train net output #0: error_blob = 0.12114 (* 1 = 0.12114 loss)
I1002 00:38:07.487215 23672 solver.cpp:590] Iteration 500, lr = 0.01
I1002 00:38:09.977363 23672 solver.cpp:243] Iteration 600, loss = 0.120605
I1002 00:38:09.977401 23672 solver.cpp:259]     Train net output #0: error_blob = 0.120605 (* 1 = 0.120605 loss)
I1002 00:38:09.977407 23672 solver.cpp:590] Iteration 600, lr = 0.01
I1002 00:38:12.449779 23672 solver.cpp:243] Iteration 700, loss = 0.120437
I1002 00:38:12.449821 23672 solver.cpp:259]     Train net output #0: error_blob = 0.120437 (* 1 = 0.120437 loss)
I1002 00:38:12.449827 23672 solver.cpp:590] Iteration 700, lr = 0.01
I1002 00:38:14.951180 23672 solver.cpp:243] Iteration 800, loss = 0.118452
I1002 00:38:14.951222 23672 solver.cpp:259]     Train net output #0: error_blob = 0.118452 (* 1 = 0.118452 loss)
I1002 00:38:14.951230 23672 solver.cpp:590] Iteration 800, lr = 0.01
I1002 00:38:17.448786 23672 solver.cpp:243] Iteration 900, loss = 0.118529
I1002 00:38:17.448825 23672 solver.cpp:259]     Train net output #0: error_blob = 0.118529 (* 1 = 0.118529 loss)
I1002 00:38:17.448832 23672 solver.cpp:590] Iteration 900, lr = 0.01
I1002 00:38:17.497884 23672 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:38:19.892997 23672 solver.cpp:347] Iteration 1000, Testing net (#0)
I1002 00:38:20.178933 23672 solver.cpp:415]     Test net output #0: error_blob = 0.122081 (* 1 = 0.122081 loss)
I1002 00:38:20.179606 23672 solver.cpp:243] Iteration 1000, loss = 0.12089
I1002 00:38:20.179620 23672 solver.cpp:259]     Train net output #0: error_blob = 0.12089 (* 1 = 0.12089 loss)
I1002 00:38:20.179626 23672 solver.cpp:590] Iteration 1000, lr = 0.01
I1002 00:38:22.692596 23672 solver.cpp:243] Iteration 1100, loss = 0.120774
I1002 00:38:22.692627 23672 solver.cpp:259]     Train net output #0: error_blob = 0.120774 (* 1 = 0.120774 loss)
I1002 00:38:22.692634 23672 solver.cpp:590] Iteration 1100, lr = 0.01
I1002 00:38:25.201009 23672 solver.cpp:243] Iteration 1200, loss = 0.119471
I1002 00:38:25.201037 23672 solver.cpp:259]     Train net output #0: error_blob = 0.119471 (* 1 = 0.119471 loss)
I1002 00:38:25.201045 23672 solver.cpp:590] Iteration 1200, lr = 0.01
I1002 00:38:27.740069 23672 solver.cpp:243] Iteration 1300, loss = 0.117585
I1002 00:38:27.740097 23672 solver.cpp:259]     Train net output #0: error_blob = 0.117585 (* 1 = 0.117585 loss)
I1002 00:38:27.740103 23672 solver.cpp:590] Iteration 1300, lr = 0.01
I1002 00:38:30.210515 23672 solver.cpp:243] Iteration 1400, loss = 0.117927
I1002 00:38:30.210546 23672 solver.cpp:259]     Train net output #0: error_blob = 0.117927 (* 1 = 0.117927 loss)
I1002 00:38:30.210551 23672 solver.cpp:590] Iteration 1400, lr = 0.01
I1002 00:38:32.698202 23672 solver.cpp:243] Iteration 1500, loss = 0.116856
I1002 00:38:32.698245 23672 solver.cpp:259]     Train net output #0: error_blob = 0.116856 (* 1 = 0.116856 loss)
I1002 00:38:32.698251 23672 solver.cpp:590] Iteration 1500, lr = 0.01
I1002 00:38:35.219784 23672 solver.cpp:243] Iteration 1600, loss = 0.118404
I1002 00:38:35.219816 23672 solver.cpp:259]     Train net output #0: error_blob = 0.118404 (* 1 = 0.118404 loss)
I1002 00:38:35.219822 23672 solver.cpp:590] Iteration 1600, lr = 0.01
I1002 00:38:37.732995 23672 solver.cpp:243] Iteration 1700, loss = 0.119075
I1002 00:38:37.733024 23672 solver.cpp:259]     Train net output #0: error_blob = 0.119075 (* 1 = 0.119075 loss)
I1002 00:38:37.733031 23672 solver.cpp:590] Iteration 1700, lr = 0.01
I1002 00:38:40.270894 23672 solver.cpp:243] Iteration 1800, loss = 0.117388
I1002 00:38:40.270923 23672 solver.cpp:259]     Train net output #0: error_blob = 0.117388 (* 1 = 0.117388 loss)
I1002 00:38:40.270930 23672 solver.cpp:590] Iteration 1800, lr = 0.01
I1002 00:38:40.470767 23672 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:38:42.747962 23672 solver.cpp:243] Iteration 1900, loss = 0.118342
I1002 00:38:42.748003 23672 solver.cpp:259]     Train net output #0: error_blob = 0.118342 (* 1 = 0.118342 loss)
I1002 00:38:42.748009 23672 solver.cpp:590] Iteration 1900, lr = 0.01
I1002 00:38:45.165891 23672 solver.cpp:347] Iteration 2000, Testing net (#0)
I1002 00:38:45.542572 23672 solver.cpp:415]     Test net output #0: error_blob = 0.120915 (* 1 = 0.120915 loss)
I1002 00:38:45.543187 23672 solver.cpp:243] Iteration 2000, loss = 0.114226
I1002 00:38:45.543198 23672 solver.cpp:259]     Train net output #0: error_blob = 0.114226 (* 1 = 0.114226 loss)
I1002 00:38:45.543202 23672 solver.cpp:590] Iteration 2000, lr = 0.01
I1002 00:38:48.081574 23672 solver.cpp:243] Iteration 2100, loss = 0.121333
I1002 00:38:48.081615 23672 solver.cpp:259]     Train net output #0: error_blob = 0.121333 (* 1 = 0.121333 loss)
I1002 00:38:48.081624 23672 solver.cpp:590] Iteration 2100, lr = 0.01
I1002 00:38:50.508402 23672 solver.cpp:243] Iteration 2200, loss = 0.118768
I1002 00:38:50.509480 23672 solver.cpp:259]     Train net output #0: error_blob = 0.118768 (* 1 = 0.118768 loss)
I1002 00:38:50.509493 23672 solver.cpp:590] Iteration 2200, lr = 0.01
I1002 00:38:53.113575 23672 solver.cpp:243] Iteration 2300, loss = 0.118108
I1002 00:38:53.113605 23672 solver.cpp:259]     Train net output #0: error_blob = 0.118108 (* 1 = 0.118108 loss)
I1002 00:38:53.113610 23672 solver.cpp:590] Iteration 2300, lr = 0.01
I1002 00:38:55.618597 23672 solver.cpp:243] Iteration 2400, loss = 0.115838
I1002 00:38:55.618640 23672 solver.cpp:259]     Train net output #0: error_blob = 0.115838 (* 1 = 0.115838 loss)
I1002 00:38:55.618646 23672 solver.cpp:590] Iteration 2400, lr = 0.01
I1002 00:38:58.145830 23672 solver.cpp:243] Iteration 2500, loss = 0.117424
I1002 00:38:58.145871 23672 solver.cpp:259]     Train net output #0: error_blob = 0.117424 (* 1 = 0.117424 loss)
I1002 00:38:58.145879 23672 solver.cpp:590] Iteration 2500, lr = 0.01
I1002 00:39:00.579319 23672 solver.cpp:243] Iteration 2600, loss = 0.117639
I1002 00:39:00.579349 23672 solver.cpp:259]     Train net output #0: error_blob = 0.117639 (* 1 = 0.117639 loss)
I1002 00:39:00.579355 23672 solver.cpp:590] Iteration 2600, lr = 0.01
I1002 00:39:03.109724 23672 solver.cpp:243] Iteration 2700, loss = 0.117791
I1002 00:39:03.109755 23672 solver.cpp:259]     Train net output #0: error_blob = 0.117791 (* 1 = 0.117791 loss)
I1002 00:39:03.109760 23672 solver.cpp:590] Iteration 2700, lr = 0.01
I1002 00:39:03.470038 23672 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:39:05.641911 23672 solver.cpp:243] Iteration 2800, loss = 0.119585
I1002 00:39:05.641942 23672 solver.cpp:259]     Train net output #0: error_blob = 0.119585 (* 1 = 0.119585 loss)
I1002 00:39:05.641947 23672 solver.cpp:590] Iteration 2800, lr = 0.01
I1002 00:39:08.158730 23672 solver.cpp:243] Iteration 2900, loss = 0.116414
I1002 00:39:08.158761 23672 solver.cpp:259]     Train net output #0: error_blob = 0.116414 (* 1 = 0.116414 loss)
I1002 00:39:08.158766 23672 solver.cpp:590] Iteration 2900, lr = 0.01
I1002 00:39:10.648053 23672 solver.cpp:347] Iteration 3000, Testing net (#0)
I1002 00:39:10.926785 23672 solver.cpp:415]     Test net output #0: error_blob = 0.123424 (* 1 = 0.123424 loss)
I1002 00:39:10.927398 23672 solver.cpp:243] Iteration 3000, loss = 0.115158
I1002 00:39:10.927409 23672 solver.cpp:259]     Train net output #0: error_blob = 0.115158 (* 1 = 0.115158 loss)
I1002 00:39:10.927415 23672 solver.cpp:590] Iteration 3000, lr = 0.01
I1002 00:39:13.383313 23672 solver.cpp:243] Iteration 3100, loss = 0.114729
I1002 00:39:13.383342 23672 solver.cpp:259]     Train net output #0: error_blob = 0.114729 (* 1 = 0.114729 loss)
I1002 00:39:13.383348 23672 solver.cpp:590] Iteration 3100, lr = 0.01
I1002 00:39:15.883908 23672 solver.cpp:243] Iteration 3200, loss = 0.116497
I1002 00:39:15.883946 23672 solver.cpp:259]     Train net output #0: error_blob = 0.116497 (* 1 = 0.116497 loss)
I1002 00:39:15.883951 23672 solver.cpp:590] Iteration 3200, lr = 0.01
I1002 00:39:18.312152 23672 solver.cpp:243] Iteration 3300, loss = 0.11781
I1002 00:39:18.312193 23672 solver.cpp:259]     Train net output #0: error_blob = 0.11781 (* 1 = 0.11781 loss)
I1002 00:39:18.312199 23672 solver.cpp:590] Iteration 3300, lr = 0.01
I1002 00:39:20.815639 23672 solver.cpp:243] Iteration 3400, loss = 0.116843
I1002 00:39:20.816644 23672 solver.cpp:259]     Train net output #0: error_blob = 0.116843 (* 1 = 0.116843 loss)
I1002 00:39:20.816655 23672 solver.cpp:590] Iteration 3400, lr = 0.01
I1002 00:39:23.331959 23672 solver.cpp:243] Iteration 3500, loss = 0.116429
I1002 00:39:23.331991 23672 solver.cpp:259]     Train net output #0: error_blob = 0.116429 (* 1 = 0.116429 loss)
I1002 00:39:23.331996 23672 solver.cpp:590] Iteration 3500, lr = 0.01
I1002 00:39:25.820582 23672 solver.cpp:243] Iteration 3600, loss = 0.120483
I1002 00:39:25.820611 23672 solver.cpp:259]     Train net output #0: error_blob = 0.120483 (* 1 = 0.120483 loss)
I1002 00:39:25.820615 23672 solver.cpp:590] Iteration 3600, lr = 0.01
I1002 00:39:26.316110 23672 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:39:28.310015 23672 solver.cpp:243] Iteration 3700, loss = 0.121896
I1002 00:39:28.310046 23672 solver.cpp:259]     Train net output #0: error_blob = 0.121896 (* 1 = 0.121896 loss)
I1002 00:39:28.310052 23672 solver.cpp:590] Iteration 3700, lr = 0.01
I1002 00:39:30.818140 23672 solver.cpp:243] Iteration 3800, loss = 0.117305
I1002 00:39:30.818169 23672 solver.cpp:259]     Train net output #0: error_blob = 0.117305 (* 1 = 0.117305 loss)
I1002 00:39:30.818173 23672 solver.cpp:590] Iteration 3800, lr = 0.01
I1002 00:39:33.352700 23672 solver.cpp:243] Iteration 3900, loss = 0.117922
I1002 00:39:33.352730 23672 solver.cpp:259]     Train net output #0: error_blob = 0.117922 (* 1 = 0.117922 loss)
I1002 00:39:33.352735 23672 solver.cpp:590] Iteration 3900, lr = 0.01
I1002 00:39:35.812094 23672 solver.cpp:347] Iteration 4000, Testing net (#0)
I1002 00:39:36.109484 23672 solver.cpp:415]     Test net output #0: error_blob = 0.125054 (* 1 = 0.125054 loss)
I1002 00:39:36.110134 23672 solver.cpp:243] Iteration 4000, loss = 0.115773
I1002 00:39:36.110146 23672 solver.cpp:259]     Train net output #0: error_blob = 0.115773 (* 1 = 0.115773 loss)
I1002 00:39:36.110152 23672 solver.cpp:590] Iteration 4000, lr = 0.01
I1002 00:39:38.542832 23672 solver.cpp:243] Iteration 4100, loss = 0.119306
I1002 00:39:38.542862 23672 solver.cpp:259]     Train net output #0: error_blob = 0.119306 (* 1 = 0.119306 loss)
I1002 00:39:38.542867 23672 solver.cpp:590] Iteration 4100, lr = 0.01
I1002 00:39:41.003037 23672 solver.cpp:243] Iteration 4200, loss = 0.113303
I1002 00:39:41.003067 23672 solver.cpp:259]     Train net output #0: error_blob = 0.113303 (* 1 = 0.113303 loss)
I1002 00:39:41.003072 23672 solver.cpp:590] Iteration 4200, lr = 0.01
I1002 00:39:43.507742 23672 solver.cpp:243] Iteration 4300, loss = 0.120148
I1002 00:39:43.507773 23672 solver.cpp:259]     Train net output #0: error_blob = 0.120148 (* 1 = 0.120148 loss)
I1002 00:39:43.507779 23672 solver.cpp:590] Iteration 4300, lr = 0.01
I1002 00:39:45.989997 23672 solver.cpp:243] Iteration 4400, loss = 0.117435
I1002 00:39:45.990028 23672 solver.cpp:259]     Train net output #0: error_blob = 0.117435 (* 1 = 0.117435 loss)
I1002 00:39:45.990033 23672 solver.cpp:590] Iteration 4400, lr = 0.01
I1002 00:39:48.490983 23672 solver.cpp:243] Iteration 4500, loss = 0.116168
I1002 00:39:48.491014 23672 solver.cpp:259]     Train net output #0: error_blob = 0.116168 (* 1 = 0.116168 loss)
I1002 00:39:48.491019 23672 solver.cpp:590] Iteration 4500, lr = 0.01
I1002 00:39:49.127616 23672 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:39:50.972153 23672 solver.cpp:243] Iteration 4600, loss = 0.114999
I1002 00:39:50.972223 23672 solver.cpp:259]     Train net output #0: error_blob = 0.114999 (* 1 = 0.114999 loss)
I1002 00:39:50.972229 23672 solver.cpp:590] Iteration 4600, lr = 0.01
I1002 00:39:53.457258 23672 solver.cpp:243] Iteration 4700, loss = 0.112114
I1002 00:39:53.457288 23672 solver.cpp:259]     Train net output #0: error_blob = 0.112114 (* 1 = 0.112114 loss)
I1002 00:39:53.457293 23672 solver.cpp:590] Iteration 4700, lr = 0.01
I1002 00:39:55.987792 23672 solver.cpp:243] Iteration 4800, loss = 0.115992
I1002 00:39:55.987821 23672 solver.cpp:259]     Train net output #0: error_blob = 0.115992 (* 1 = 0.115992 loss)
I1002 00:39:55.987826 23672 solver.cpp:590] Iteration 4800, lr = 0.01
I1002 00:39:58.497145 23672 solver.cpp:243] Iteration 4900, loss = 0.119177
I1002 00:39:58.497174 23672 solver.cpp:259]     Train net output #0: error_blob = 0.119177 (* 1 = 0.119177 loss)
I1002 00:39:58.497179 23672 solver.cpp:590] Iteration 4900, lr = 0.01
I1002 00:40:00.954288 23672 solver.cpp:347] Iteration 5000, Testing net (#0)
I1002 00:40:01.260795 23672 solver.cpp:415]     Test net output #0: error_blob = 0.11917 (* 1 = 0.11917 loss)
I1002 00:40:01.261417 23672 solver.cpp:243] Iteration 5000, loss = 0.118569
I1002 00:40:01.261427 23672 solver.cpp:259]     Train net output #0: error_blob = 0.118569 (* 1 = 0.118569 loss)
I1002 00:40:01.261431 23672 solver.cpp:590] Iteration 5000, lr = 0.01
I1002 00:40:03.723932 23672 solver.cpp:243] Iteration 5100, loss = 0.116451
I1002 00:40:03.723961 23672 solver.cpp:259]     Train net output #0: error_blob = 0.116451 (* 1 = 0.116451 loss)
I1002 00:40:03.723966 23672 solver.cpp:590] Iteration 5100, lr = 0.01
I1002 00:40:06.205926 23672 solver.cpp:243] Iteration 5200, loss = 0.117552
I1002 00:40:06.205956 23672 solver.cpp:259]     Train net output #0: error_blob = 0.117552 (* 1 = 0.117552 loss)
I1002 00:40:06.205961 23672 solver.cpp:590] Iteration 5200, lr = 0.01
I1002 00:40:08.693642 23672 solver.cpp:243] Iteration 5300, loss = 0.114308
I1002 00:40:08.693675 23672 solver.cpp:259]     Train net output #0: error_blob = 0.114308 (* 1 = 0.114308 loss)
I1002 00:40:08.693681 23672 solver.cpp:590] Iteration 5300, lr = 0.01
I1002 00:40:11.153669 23672 solver.cpp:243] Iteration 5400, loss = 0.117091
I1002 00:40:11.153700 23672 solver.cpp:259]     Train net output #0: error_blob = 0.117091 (* 1 = 0.117091 loss)
I1002 00:40:11.153707 23672 solver.cpp:590] Iteration 5400, lr = 0.01
I1002 00:40:11.945926 23672 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:40:13.622016 23672 solver.cpp:243] Iteration 5500, loss = 0.118302
I1002 00:40:13.622046 23672 solver.cpp:259]     Train net output #0: error_blob = 0.118302 (* 1 = 0.118302 loss)
I1002 00:40:13.622052 23672 solver.cpp:590] Iteration 5500, lr = 0.01
I1002 00:40:16.085835 23672 solver.cpp:243] Iteration 5600, loss = 0.113645
I1002 00:40:16.085876 23672 solver.cpp:259]     Train net output #0: error_blob = 0.113645 (* 1 = 0.113645 loss)
I1002 00:40:16.085881 23672 solver.cpp:590] Iteration 5600, lr = 0.01
I1002 00:40:18.612263 23672 solver.cpp:243] Iteration 5700, loss = 0.1167
I1002 00:40:18.612296 23672 solver.cpp:259]     Train net output #0: error_blob = 0.1167 (* 1 = 0.1167 loss)
I1002 00:40:18.612304 23672 solver.cpp:590] Iteration 5700, lr = 0.01
I1002 00:40:21.133435 23672 solver.cpp:243] Iteration 5800, loss = 0.116795
I1002 00:40:21.133589 23672 solver.cpp:259]     Train net output #0: error_blob = 0.116795 (* 1 = 0.116795 loss)
I1002 00:40:21.133597 23672 solver.cpp:590] Iteration 5800, lr = 0.01
I1002 00:40:23.645032 23672 solver.cpp:243] Iteration 5900, loss = 0.114886
I1002 00:40:23.645062 23672 solver.cpp:259]     Train net output #0: error_blob = 0.114886 (* 1 = 0.114886 loss)
I1002 00:40:23.645067 23672 solver.cpp:590] Iteration 5900, lr = 0.01
I1002 00:40:26.143707 23672 solver.cpp:347] Iteration 6000, Testing net (#0)
I1002 00:40:26.461536 23672 solver.cpp:415]     Test net output #0: error_blob = 0.124182 (* 1 = 0.124182 loss)
I1002 00:40:26.462155 23672 solver.cpp:243] Iteration 6000, loss = 0.11657
I1002 00:40:26.462165 23672 solver.cpp:259]     Train net output #0: error_blob = 0.11657 (* 1 = 0.11657 loss)
I1002 00:40:26.462170 23672 solver.cpp:590] Iteration 6000, lr = 0.01
I1002 00:40:28.898212 23672 solver.cpp:243] Iteration 6100, loss = 0.116387
I1002 00:40:28.898252 23672 solver.cpp:259]     Train net output #0: error_blob = 0.116387 (* 1 = 0.116387 loss)
I1002 00:40:28.898258 23672 solver.cpp:590] Iteration 6100, lr = 0.01
I1002 00:40:31.382719 23672 solver.cpp:243] Iteration 6200, loss = 0.112544
I1002 00:40:31.382751 23672 solver.cpp:259]     Train net output #0: error_blob = 0.112544 (* 1 = 0.112544 loss)
I1002 00:40:31.382758 23672 solver.cpp:590] Iteration 6200, lr = 0.01
I1002 00:40:33.886255 23672 solver.cpp:243] Iteration 6300, loss = 0.114201
I1002 00:40:33.886286 23672 solver.cpp:259]     Train net output #0: error_blob = 0.114201 (* 1 = 0.114201 loss)
I1002 00:40:33.886294 23672 solver.cpp:590] Iteration 6300, lr = 0.01
I1002 00:40:34.825646 23672 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:40:36.365566 23672 solver.cpp:243] Iteration 6400, loss = 0.115985
I1002 00:40:36.365600 23672 solver.cpp:259]     Train net output #0: error_blob = 0.115985 (* 1 = 0.115985 loss)
I1002 00:40:36.365607 23672 solver.cpp:590] Iteration 6400, lr = 0.01
I1002 00:40:38.887106 23672 solver.cpp:243] Iteration 6500, loss = 0.116481
I1002 00:40:38.887140 23672 solver.cpp:259]     Train net output #0: error_blob = 0.116481 (* 1 = 0.116481 loss)
I1002 00:40:38.887146 23672 solver.cpp:590] Iteration 6500, lr = 0.01
I1002 00:40:41.344997 23672 solver.cpp:243] Iteration 6600, loss = 0.118364
I1002 00:40:41.345029 23672 solver.cpp:259]     Train net output #0: error_blob = 0.118364 (* 1 = 0.118364 loss)
I1002 00:40:41.345034 23672 solver.cpp:590] Iteration 6600, lr = 0.01
I1002 00:40:43.887308 23672 solver.cpp:243] Iteration 6700, loss = 0.114517
I1002 00:40:43.887347 23672 solver.cpp:259]     Train net output #0: error_blob = 0.114517 (* 1 = 0.114517 loss)
I1002 00:40:43.887352 23672 solver.cpp:590] Iteration 6700, lr = 0.01
I1002 00:40:46.408819 23672 solver.cpp:243] Iteration 6800, loss = 0.11459
I1002 00:40:46.408849 23672 solver.cpp:259]     Train net output #0: error_blob = 0.11459 (* 1 = 0.11459 loss)
I1002 00:40:46.408855 23672 solver.cpp:590] Iteration 6800, lr = 0.01
I1002 00:40:48.925426 23672 solver.cpp:243] Iteration 6900, loss = 0.113346
I1002 00:40:48.925453 23672 solver.cpp:259]     Train net output #0: error_blob = 0.113346 (* 1 = 0.113346 loss)
I1002 00:40:48.925459 23672 solver.cpp:590] Iteration 6900, lr = 0.01
I1002 00:40:51.424510 23672 solver.cpp:347] Iteration 7000, Testing net (#0)
I1002 00:40:51.815706 23672 solver.cpp:415]     Test net output #0: error_blob = 0.126042 (* 1 = 0.126042 loss)
I1002 00:40:51.816323 23672 solver.cpp:243] Iteration 7000, loss = 0.118939
I1002 00:40:51.816335 23672 solver.cpp:259]     Train net output #0: error_blob = 0.118939 (* 1 = 0.118939 loss)
I1002 00:40:51.816345 23672 solver.cpp:590] Iteration 7000, lr = 0.01
I1002 00:40:54.282095 23672 solver.cpp:243] Iteration 7100, loss = 0.115297
I1002 00:40:54.282124 23672 solver.cpp:259]     Train net output #0: error_blob = 0.115297 (* 1 = 0.115297 loss)
I1002 00:40:54.282130 23672 solver.cpp:590] Iteration 7100, lr = 0.01
I1002 00:40:56.791465 23672 solver.cpp:243] Iteration 7200, loss = 0.114964
I1002 00:40:56.791493 23672 solver.cpp:259]     Train net output #0: error_blob = 0.114964 (* 1 = 0.114964 loss)
I1002 00:40:56.791499 23672 solver.cpp:590] Iteration 7200, lr = 0.01
I1002 00:40:57.874482 23672 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:40:59.273182 23672 solver.cpp:243] Iteration 7300, loss = 0.115037
I1002 00:40:59.273212 23672 solver.cpp:259]     Train net output #0: error_blob = 0.115037 (* 1 = 0.115037 loss)
I1002 00:40:59.273219 23672 solver.cpp:590] Iteration 7300, lr = 0.01
I1002 00:41:01.744990 23672 solver.cpp:243] Iteration 7400, loss = 0.114614
I1002 00:41:01.745021 23672 solver.cpp:259]     Train net output #0: error_blob = 0.114614 (* 1 = 0.114614 loss)
I1002 00:41:01.745026 23672 solver.cpp:590] Iteration 7400, lr = 0.01
I1002 00:41:04.235855 23672 solver.cpp:243] Iteration 7500, loss = 0.116326
I1002 00:41:04.235885 23672 solver.cpp:259]     Train net output #0: error_blob = 0.116326 (* 1 = 0.116326 loss)
I1002 00:41:04.235890 23672 solver.cpp:590] Iteration 7500, lr = 0.01
I1002 00:41:06.736876 23672 solver.cpp:243] Iteration 7600, loss = 0.115327
I1002 00:41:06.736914 23672 solver.cpp:259]     Train net output #0: error_blob = 0.115327 (* 1 = 0.115327 loss)
I1002 00:41:06.736922 23672 solver.cpp:590] Iteration 7600, lr = 0.01
I1002 00:41:09.252001 23672 solver.cpp:243] Iteration 7700, loss = 0.115426
I1002 00:41:09.252029 23672 solver.cpp:259]     Train net output #0: error_blob = 0.115426 (* 1 = 0.115426 loss)
I1002 00:41:09.252035 23672 solver.cpp:590] Iteration 7700, lr = 0.01
I1002 00:41:11.749421 23672 solver.cpp:243] Iteration 7800, loss = 0.115981
I1002 00:41:11.749452 23672 solver.cpp:259]     Train net output #0: error_blob = 0.115981 (* 1 = 0.115981 loss)
I1002 00:41:11.749459 23672 solver.cpp:590] Iteration 7800, lr = 0.01
I1002 00:41:14.248414 23672 solver.cpp:243] Iteration 7900, loss = 0.115806
I1002 00:41:14.248453 23672 solver.cpp:259]     Train net output #0: error_blob = 0.115806 (* 1 = 0.115806 loss)
I1002 00:41:14.248458 23672 solver.cpp:590] Iteration 7900, lr = 0.01
I1002 00:41:16.698755 23672 solver.cpp:347] Iteration 8000, Testing net (#0)
I1002 00:41:16.968467 23672 solver.cpp:415]     Test net output #0: error_blob = 0.125962 (* 1 = 0.125962 loss)
I1002 00:41:16.969120 23672 solver.cpp:243] Iteration 8000, loss = 0.11347
I1002 00:41:16.969132 23672 solver.cpp:259]     Train net output #0: error_blob = 0.11347 (* 1 = 0.11347 loss)
I1002 00:41:16.969138 23672 solver.cpp:590] Iteration 8000, lr = 0.01
I1002 00:41:19.417508 23672 solver.cpp:243] Iteration 8100, loss = 0.117554
I1002 00:41:19.417539 23672 solver.cpp:259]     Train net output #0: error_blob = 0.117554 (* 1 = 0.117554 loss)
I1002 00:41:19.417546 23672 solver.cpp:590] Iteration 8100, lr = 0.01
I1002 00:41:20.667655 23672 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:41:21.938364 23672 solver.cpp:243] Iteration 8200, loss = 0.116856
I1002 00:41:21.938508 23672 solver.cpp:259]     Train net output #0: error_blob = 0.116856 (* 1 = 0.116856 loss)
I1002 00:41:21.938514 23672 solver.cpp:590] Iteration 8200, lr = 0.01
I1002 00:41:24.429679 23672 solver.cpp:243] Iteration 8300, loss = 0.114164
I1002 00:41:24.429709 23672 solver.cpp:259]     Train net output #0: error_blob = 0.114164 (* 1 = 0.114164 loss)
I1002 00:41:24.429714 23672 solver.cpp:590] Iteration 8300, lr = 0.01
I1002 00:41:26.941117 23672 solver.cpp:243] Iteration 8400, loss = 0.114066
I1002 00:41:26.941146 23672 solver.cpp:259]     Train net output #0: error_blob = 0.114066 (* 1 = 0.114066 loss)
I1002 00:41:26.941151 23672 solver.cpp:590] Iteration 8400, lr = 0.01
I1002 00:41:29.450235 23672 solver.cpp:243] Iteration 8500, loss = 0.112073
I1002 00:41:29.450264 23672 solver.cpp:259]     Train net output #0: error_blob = 0.112073 (* 1 = 0.112073 loss)
I1002 00:41:29.450270 23672 solver.cpp:590] Iteration 8500, lr = 0.01
I1002 00:41:31.987586 23672 solver.cpp:243] Iteration 8600, loss = 0.118319
I1002 00:41:31.987617 23672 solver.cpp:259]     Train net output #0: error_blob = 0.118319 (* 1 = 0.118319 loss)
I1002 00:41:31.987622 23672 solver.cpp:590] Iteration 8600, lr = 0.01
I1002 00:41:34.494257 23672 solver.cpp:243] Iteration 8700, loss = 0.115665
I1002 00:41:34.494288 23672 solver.cpp:259]     Train net output #0: error_blob = 0.115665 (* 1 = 0.115665 loss)
I1002 00:41:34.494295 23672 solver.cpp:590] Iteration 8700, lr = 0.01
I1002 00:41:36.974776 23672 solver.cpp:243] Iteration 8800, loss = 0.115121
I1002 00:41:36.974807 23672 solver.cpp:259]     Train net output #0: error_blob = 0.115121 (* 1 = 0.115121 loss)
I1002 00:41:36.974812 23672 solver.cpp:590] Iteration 8800, lr = 0.01
I1002 00:41:39.475229 23672 solver.cpp:243] Iteration 8900, loss = 0.114324
I1002 00:41:39.475260 23672 solver.cpp:259]     Train net output #0: error_blob = 0.114324 (* 1 = 0.114324 loss)
I1002 00:41:39.475265 23672 solver.cpp:590] Iteration 8900, lr = 0.01
I1002 00:41:41.940872 23672 solver.cpp:347] Iteration 9000, Testing net (#0)
I1002 00:41:42.215926 23672 solver.cpp:415]     Test net output #0: error_blob = 0.127362 (* 1 = 0.127362 loss)
I1002 00:41:42.216550 23672 solver.cpp:243] Iteration 9000, loss = 0.116476
I1002 00:41:42.216565 23672 solver.cpp:259]     Train net output #0: error_blob = 0.116476 (* 1 = 0.116476 loss)
I1002 00:41:42.216570 23672 solver.cpp:590] Iteration 9000, lr = 0.01
I1002 00:41:43.625478 23672 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:41:44.718258 23672 solver.cpp:243] Iteration 9100, loss = 0.12031
I1002 00:41:44.718288 23672 solver.cpp:259]     Train net output #0: error_blob = 0.12031 (* 1 = 0.12031 loss)
I1002 00:41:44.718294 23672 solver.cpp:590] Iteration 9100, lr = 0.01
I1002 00:41:47.203249 23672 solver.cpp:243] Iteration 9200, loss = 0.115635
I1002 00:41:47.203280 23672 solver.cpp:259]     Train net output #0: error_blob = 0.115635 (* 1 = 0.115635 loss)
I1002 00:41:47.203286 23672 solver.cpp:590] Iteration 9200, lr = 0.01
I1002 00:41:49.692203 23672 solver.cpp:243] Iteration 9300, loss = 0.116373
I1002 00:41:49.692236 23672 solver.cpp:259]     Train net output #0: error_blob = 0.116373 (* 1 = 0.116373 loss)
I1002 00:41:49.692244 23672 solver.cpp:590] Iteration 9300, lr = 0.01
I1002 00:41:52.206447 23672 solver.cpp:243] Iteration 9400, loss = 0.113865
I1002 00:41:52.208206 23672 solver.cpp:259]     Train net output #0: error_blob = 0.113865 (* 1 = 0.113865 loss)
I1002 00:41:52.208220 23672 solver.cpp:590] Iteration 9400, lr = 0.01
I1002 00:41:54.718582 23672 solver.cpp:243] Iteration 9500, loss = 0.111934
I1002 00:41:54.718631 23672 solver.cpp:259]     Train net output #0: error_blob = 0.111934 (* 1 = 0.111934 loss)
I1002 00:41:54.718639 23672 solver.cpp:590] Iteration 9500, lr = 0.01
I1002 00:41:57.226186 23672 solver.cpp:243] Iteration 9600, loss = 0.112738
I1002 00:41:57.226222 23672 solver.cpp:259]     Train net output #0: error_blob = 0.112738 (* 1 = 0.112738 loss)
I1002 00:41:57.226229 23672 solver.cpp:590] Iteration 9600, lr = 0.01
I1002 00:41:59.738970 23672 solver.cpp:243] Iteration 9700, loss = 0.114307
I1002 00:41:59.739004 23672 solver.cpp:259]     Train net output #0: error_blob = 0.114307 (* 1 = 0.114307 loss)
I1002 00:41:59.739012 23672 solver.cpp:590] Iteration 9700, lr = 0.01
I1002 00:42:02.259472 23672 solver.cpp:243] Iteration 9800, loss = 0.115509
I1002 00:42:02.259503 23672 solver.cpp:259]     Train net output #0: error_blob = 0.115509 (* 1 = 0.115509 loss)
I1002 00:42:02.259510 23672 solver.cpp:590] Iteration 9800, lr = 0.01
I1002 00:42:04.748612 23672 solver.cpp:243] Iteration 9900, loss = 0.114794
I1002 00:42:04.748661 23672 solver.cpp:259]     Train net output #0: error_blob = 0.114794 (* 1 = 0.114794 loss)
I1002 00:42:04.748670 23672 solver.cpp:590] Iteration 9900, lr = 0.01
I1002 00:42:07.203078 23672 solver.cpp:468] Snapshotting to binary proto file _iter_10000.caffemodel
I1002 00:42:07.203943 23672 solver.cpp:753] Snapshotting solver state to binary proto file _iter_10000.solverstate
I1002 00:42:07.227797 23672 solver.cpp:327] Iteration 10000, loss = 0.116978
I1002 00:42:07.227836 23672 solver.cpp:347] Iteration 10000, Testing net (#0)
I1002 00:42:07.396452 23672 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:42:07.505162 23672 solver.cpp:415]     Test net output #0: error_blob = 0.12485 (* 1 = 0.12485 loss)
I1002 00:42:07.505182 23672 solver.cpp:332] Optimization Done.
I1002 00:42:07.505185 23672 caffe.cpp:215] Optimization Done.
I1002 00:42:07.564677 23693 caffe.cpp:184] Using GPUs 0
I1002 00:42:08.121832 23693 solver.cpp:54] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "fixed"
momentum: 0.9
solver_mode: GPU
device_id: 0
net: "model/NNScore/nnscore_model_1.prototxt"
I1002 00:42:08.121863 23693 solver.cpp:97] Creating training net from net file: model/NNScore/nnscore_model_1.prototxt
I1002 00:42:08.122032 23693 net.cpp:339] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_layer
I1002 00:42:08.122079 23693 net.cpp:50] Initializing net from parameters: 
name: "model/NNScore/nnscore_model_1.prototxt"
state {
  phase: TRAIN
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TRAIN
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.1.train"
    batch_size: 20000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1002 00:42:08.122153 23693 layer_factory.hpp:76] Creating layer data_layer
I1002 00:42:08.135428 23693 net.cpp:110] Creating Layer data_layer
I1002 00:42:08.135463 23693 net.cpp:433] data_layer -> data_blob
I1002 00:42:08.135495 23693 net.cpp:433] data_layer -> label_blob
I1002 00:42:08.136085 23697 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.1.train
I1002 00:42:08.819108 23693 data_layer.cpp:45] output data size: 20000,61,1,1
I1002 00:42:08.824007 23693 net.cpp:155] Setting up data_layer
I1002 00:42:08.824048 23693 net.cpp:163] Top shape: 20000 61 1 1 (1220000)
I1002 00:42:08.824051 23693 net.cpp:163] Top shape: 20000 (20000)
I1002 00:42:08.824057 23693 layer_factory.hpp:76] Creating layer hidden_sum_layer
I1002 00:42:08.824079 23693 net.cpp:110] Creating Layer hidden_sum_layer
I1002 00:42:08.824082 23693 net.cpp:477] hidden_sum_layer <- data_blob
I1002 00:42:08.824092 23693 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I1002 00:42:08.824461 23693 net.cpp:155] Setting up hidden_sum_layer
I1002 00:42:08.824470 23693 net.cpp:163] Top shape: 20000 10 (200000)
I1002 00:42:08.824496 23693 layer_factory.hpp:76] Creating layer hidden_act_layer
I1002 00:42:08.824504 23693 net.cpp:110] Creating Layer hidden_act_layer
I1002 00:42:08.824506 23693 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I1002 00:42:08.824509 23693 net.cpp:433] hidden_act_layer -> hidden_act_blob
I1002 00:42:12.046514 23693 net.cpp:155] Setting up hidden_act_layer
I1002 00:42:12.046545 23693 net.cpp:163] Top shape: 20000 10 (200000)
I1002 00:42:12.046550 23693 layer_factory.hpp:76] Creating layer output_sum_layer
I1002 00:42:12.046558 23693 net.cpp:110] Creating Layer output_sum_layer
I1002 00:42:12.046561 23693 net.cpp:477] output_sum_layer <- hidden_act_blob
I1002 00:42:12.046566 23693 net.cpp:433] output_sum_layer -> output_sum_blob
I1002 00:42:12.046654 23693 net.cpp:155] Setting up output_sum_layer
I1002 00:42:12.046660 23693 net.cpp:163] Top shape: 20000 1 (20000)
I1002 00:42:12.046677 23693 layer_factory.hpp:76] Creating layer output_act_layer
I1002 00:42:12.046682 23693 net.cpp:110] Creating Layer output_act_layer
I1002 00:42:12.046685 23693 net.cpp:477] output_act_layer <- output_sum_blob
I1002 00:42:12.046689 23693 net.cpp:433] output_act_layer -> output_act_blob
I1002 00:42:12.046751 23693 net.cpp:155] Setting up output_act_layer
I1002 00:42:12.046769 23693 net.cpp:163] Top shape: 20000 1 (20000)
I1002 00:42:12.046783 23693 layer_factory.hpp:76] Creating layer error_layer
I1002 00:42:12.046788 23693 net.cpp:110] Creating Layer error_layer
I1002 00:42:12.046792 23693 net.cpp:477] error_layer <- output_act_blob
I1002 00:42:12.046793 23693 net.cpp:477] error_layer <- label_blob
I1002 00:42:12.046797 23693 net.cpp:433] error_layer -> error_blob
I1002 00:42:12.046823 23693 net.cpp:155] Setting up error_layer
I1002 00:42:12.046826 23693 net.cpp:163] Top shape: (1)
I1002 00:42:12.046828 23693 net.cpp:168]     with loss weight 1
I1002 00:42:12.046844 23693 net.cpp:236] error_layer needs backward computation.
I1002 00:42:12.046847 23693 net.cpp:236] output_act_layer needs backward computation.
I1002 00:42:12.046849 23693 net.cpp:236] output_sum_layer needs backward computation.
I1002 00:42:12.046851 23693 net.cpp:236] hidden_act_layer needs backward computation.
I1002 00:42:12.046854 23693 net.cpp:236] hidden_sum_layer needs backward computation.
I1002 00:42:12.046855 23693 net.cpp:240] data_layer does not need backward computation.
I1002 00:42:12.046857 23693 net.cpp:283] This network produces output error_blob
I1002 00:42:12.046862 23693 net.cpp:297] Network initialization done.
I1002 00:42:12.046864 23693 net.cpp:298] Memory required for data: 6720004
I1002 00:42:12.046998 23693 solver.cpp:187] Creating test net (#0) specified by net file: model/NNScore/nnscore_model_1.prototxt
I1002 00:42:12.047020 23693 net.cpp:339] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_layer
I1002 00:42:12.047051 23693 net.cpp:50] Initializing net from parameters: 
name: "model/NNScore/nnscore_model_1.prototxt"
state {
  phase: TEST
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TEST
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.1.test"
    batch_size: 2000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1002 00:42:12.047070 23693 layer_factory.hpp:76] Creating layer data_layer
I1002 00:42:12.048280 23693 net.cpp:110] Creating Layer data_layer
I1002 00:42:12.048296 23693 net.cpp:433] data_layer -> data_blob
I1002 00:42:12.048301 23693 net.cpp:433] data_layer -> label_blob
I1002 00:42:12.048867 23699 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.1.test
I1002 00:42:12.048949 23693 data_layer.cpp:45] output data size: 2000,61,1,1
I1002 00:42:12.050343 23693 net.cpp:155] Setting up data_layer
I1002 00:42:12.050354 23693 net.cpp:163] Top shape: 2000 61 1 1 (122000)
I1002 00:42:12.050357 23693 net.cpp:163] Top shape: 2000 (2000)
I1002 00:42:12.050360 23693 layer_factory.hpp:76] Creating layer hidden_sum_layer
I1002 00:42:12.050369 23693 net.cpp:110] Creating Layer hidden_sum_layer
I1002 00:42:12.050374 23693 net.cpp:477] hidden_sum_layer <- data_blob
I1002 00:42:12.050382 23693 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I1002 00:42:12.050510 23693 net.cpp:155] Setting up hidden_sum_layer
I1002 00:42:12.050516 23693 net.cpp:163] Top shape: 2000 10 (20000)
I1002 00:42:12.050524 23693 layer_factory.hpp:76] Creating layer hidden_act_layer
I1002 00:42:12.050531 23693 net.cpp:110] Creating Layer hidden_act_layer
I1002 00:42:12.050536 23693 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I1002 00:42:12.050557 23693 net.cpp:433] hidden_act_layer -> hidden_act_blob
I1002 00:42:12.050747 23693 net.cpp:155] Setting up hidden_act_layer
I1002 00:42:12.050756 23693 net.cpp:163] Top shape: 2000 10 (20000)
I1002 00:42:12.050762 23693 layer_factory.hpp:76] Creating layer output_sum_layer
I1002 00:42:12.050768 23693 net.cpp:110] Creating Layer output_sum_layer
I1002 00:42:12.050772 23693 net.cpp:477] output_sum_layer <- hidden_act_blob
I1002 00:42:12.050778 23693 net.cpp:433] output_sum_layer -> output_sum_blob
I1002 00:42:12.050868 23693 net.cpp:155] Setting up output_sum_layer
I1002 00:42:12.050876 23693 net.cpp:163] Top shape: 2000 1 (2000)
I1002 00:42:12.050884 23693 layer_factory.hpp:76] Creating layer output_act_layer
I1002 00:42:12.050891 23693 net.cpp:110] Creating Layer output_act_layer
I1002 00:42:12.050895 23693 net.cpp:477] output_act_layer <- output_sum_blob
I1002 00:42:12.050901 23693 net.cpp:433] output_act_layer -> output_act_blob
I1002 00:42:12.050976 23693 net.cpp:155] Setting up output_act_layer
I1002 00:42:12.050986 23693 net.cpp:163] Top shape: 2000 1 (2000)
I1002 00:42:12.050989 23693 layer_factory.hpp:76] Creating layer error_layer
I1002 00:42:12.050997 23693 net.cpp:110] Creating Layer error_layer
I1002 00:42:12.051000 23693 net.cpp:477] error_layer <- output_act_blob
I1002 00:42:12.051005 23693 net.cpp:477] error_layer <- label_blob
I1002 00:42:12.051012 23693 net.cpp:433] error_layer -> error_blob
I1002 00:42:12.051045 23693 net.cpp:155] Setting up error_layer
I1002 00:42:12.051051 23693 net.cpp:163] Top shape: (1)
I1002 00:42:12.051056 23693 net.cpp:168]     with loss weight 1
I1002 00:42:12.051066 23693 net.cpp:236] error_layer needs backward computation.
I1002 00:42:12.051071 23693 net.cpp:236] output_act_layer needs backward computation.
I1002 00:42:12.051074 23693 net.cpp:236] output_sum_layer needs backward computation.
I1002 00:42:12.051077 23693 net.cpp:236] hidden_act_layer needs backward computation.
I1002 00:42:12.051081 23693 net.cpp:236] hidden_sum_layer needs backward computation.
I1002 00:42:12.051085 23693 net.cpp:240] data_layer does not need backward computation.
I1002 00:42:12.051090 23693 net.cpp:283] This network produces output error_blob
I1002 00:42:12.051096 23693 net.cpp:297] Network initialization done.
I1002 00:42:12.051100 23693 net.cpp:298] Memory required for data: 672004
I1002 00:42:12.051128 23693 solver.cpp:66] Solver scaffolding done.
I1002 00:42:12.051247 23693 caffe.cpp:212] Starting Optimization
I1002 00:42:12.051256 23693 solver.cpp:294] Solving model/NNScore/nnscore_model_1.prototxt
I1002 00:42:12.051260 23693 solver.cpp:295] Learning Rate Policy: fixed
I1002 00:42:12.051472 23693 solver.cpp:347] Iteration 0, Testing net (#0)
I1002 00:42:12.051537 23693 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:42:12.317428 23693 solver.cpp:415]     Test net output #0: error_blob = 0.128301 (* 1 = 0.128301 loss)
I1002 00:42:12.318662 23693 solver.cpp:243] Iteration 0, loss = 0.126016
I1002 00:42:12.318677 23693 solver.cpp:259]     Train net output #0: error_blob = 0.126016 (* 1 = 0.126016 loss)
I1002 00:42:12.318689 23693 solver.cpp:590] Iteration 0, lr = 0.01
I1002 00:42:14.789862 23693 solver.cpp:243] Iteration 100, loss = 0.119569
I1002 00:42:14.789896 23693 solver.cpp:259]     Train net output #0: error_blob = 0.119569 (* 1 = 0.119569 loss)
I1002 00:42:14.789903 23693 solver.cpp:590] Iteration 100, lr = 0.01
I1002 00:42:17.302466 23693 solver.cpp:243] Iteration 200, loss = 0.121737
I1002 00:42:17.302498 23693 solver.cpp:259]     Train net output #0: error_blob = 0.121737 (* 1 = 0.121737 loss)
I1002 00:42:17.302506 23693 solver.cpp:590] Iteration 200, lr = 0.01
I1002 00:42:19.910966 23693 solver.cpp:243] Iteration 300, loss = 0.120361
I1002 00:42:19.911013 23693 solver.cpp:259]     Train net output #0: error_blob = 0.120361 (* 1 = 0.120361 loss)
I1002 00:42:19.911021 23693 solver.cpp:590] Iteration 300, lr = 0.01
I1002 00:42:22.414269 23693 solver.cpp:243] Iteration 400, loss = 0.121246
I1002 00:42:22.414335 23693 solver.cpp:259]     Train net output #0: error_blob = 0.121246 (* 1 = 0.121246 loss)
I1002 00:42:22.414345 23693 solver.cpp:590] Iteration 400, lr = 0.01
I1002 00:42:24.894459 23693 solver.cpp:243] Iteration 500, loss = 0.121338
I1002 00:42:24.894507 23693 solver.cpp:259]     Train net output #0: error_blob = 0.121338 (* 1 = 0.121338 loss)
I1002 00:42:24.894515 23693 solver.cpp:590] Iteration 500, lr = 0.01
I1002 00:42:27.404835 23693 solver.cpp:243] Iteration 600, loss = 0.121132
I1002 00:42:27.404876 23693 solver.cpp:259]     Train net output #0: error_blob = 0.121132 (* 1 = 0.121132 loss)
I1002 00:42:27.404882 23693 solver.cpp:590] Iteration 600, lr = 0.01
I1002 00:42:29.922495 23693 solver.cpp:243] Iteration 700, loss = 0.120894
I1002 00:42:29.922540 23693 solver.cpp:259]     Train net output #0: error_blob = 0.120894 (* 1 = 0.120894 loss)
I1002 00:42:29.922547 23693 solver.cpp:590] Iteration 700, lr = 0.01
I1002 00:42:32.457393 23693 solver.cpp:243] Iteration 800, loss = 0.121305
I1002 00:42:32.457433 23693 solver.cpp:259]     Train net output #0: error_blob = 0.121305 (* 1 = 0.121305 loss)
I1002 00:42:32.457438 23693 solver.cpp:590] Iteration 800, lr = 0.01
I1002 00:42:34.975038 23693 solver.cpp:243] Iteration 900, loss = 0.121807
I1002 00:42:34.975085 23693 solver.cpp:259]     Train net output #0: error_blob = 0.121807 (* 1 = 0.121807 loss)
I1002 00:42:34.975092 23693 solver.cpp:590] Iteration 900, lr = 0.01
I1002 00:42:35.024447 23693 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:42:37.387202 23693 solver.cpp:347] Iteration 1000, Testing net (#0)
I1002 00:42:37.782793 23693 solver.cpp:415]     Test net output #0: error_blob = 0.117528 (* 1 = 0.117528 loss)
I1002 00:42:37.783610 23693 solver.cpp:243] Iteration 1000, loss = 0.119983
I1002 00:42:37.783638 23693 solver.cpp:259]     Train net output #0: error_blob = 0.119983 (* 1 = 0.119983 loss)
I1002 00:42:37.783644 23693 solver.cpp:590] Iteration 1000, lr = 0.01
I1002 00:42:40.240473 23693 solver.cpp:243] Iteration 1100, loss = 0.121564
I1002 00:42:40.240533 23693 solver.cpp:259]     Train net output #0: error_blob = 0.121564 (* 1 = 0.121564 loss)
I1002 00:42:40.240542 23693 solver.cpp:590] Iteration 1100, lr = 0.01
I1002 00:42:42.764953 23693 solver.cpp:243] Iteration 1200, loss = 0.118875
I1002 00:42:42.765002 23693 solver.cpp:259]     Train net output #0: error_blob = 0.118875 (* 1 = 0.118875 loss)
I1002 00:42:42.765012 23693 solver.cpp:590] Iteration 1200, lr = 0.01
I1002 00:42:45.290433 23693 solver.cpp:243] Iteration 1300, loss = 0.121634
I1002 00:42:45.290483 23693 solver.cpp:259]     Train net output #0: error_blob = 0.121634 (* 1 = 0.121634 loss)
I1002 00:42:45.290490 23693 solver.cpp:590] Iteration 1300, lr = 0.01
I1002 00:42:47.815798 23693 solver.cpp:243] Iteration 1400, loss = 0.119584
I1002 00:42:47.815839 23693 solver.cpp:259]     Train net output #0: error_blob = 0.119584 (* 1 = 0.119584 loss)
I1002 00:42:47.815843 23693 solver.cpp:590] Iteration 1400, lr = 0.01
I1002 00:42:50.368535 23693 solver.cpp:243] Iteration 1500, loss = 0.120819
I1002 00:42:50.368579 23693 solver.cpp:259]     Train net output #0: error_blob = 0.120819 (* 1 = 0.120819 loss)
I1002 00:42:50.368587 23693 solver.cpp:590] Iteration 1500, lr = 0.01
I1002 00:42:52.916015 23693 solver.cpp:243] Iteration 1600, loss = 0.120406
I1002 00:42:52.916061 23693 solver.cpp:259]     Train net output #0: error_blob = 0.120406 (* 1 = 0.120406 loss)
I1002 00:42:52.916069 23693 solver.cpp:590] Iteration 1600, lr = 0.01
I1002 00:42:55.462508 23693 solver.cpp:243] Iteration 1700, loss = 0.121175
I1002 00:42:55.462549 23693 solver.cpp:259]     Train net output #0: error_blob = 0.121175 (* 1 = 0.121175 loss)
I1002 00:42:55.462556 23693 solver.cpp:590] Iteration 1700, lr = 0.01
I1002 00:42:58.024710 23693 solver.cpp:243] Iteration 1800, loss = 0.119849
I1002 00:42:58.024741 23693 solver.cpp:259]     Train net output #0: error_blob = 0.119849 (* 1 = 0.119849 loss)
I1002 00:42:58.024747 23693 solver.cpp:590] Iteration 1800, lr = 0.01
I1002 00:42:58.214582 23693 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:43:00.509662 23693 solver.cpp:243] Iteration 1900, loss = 0.120652
I1002 00:43:00.509711 23693 solver.cpp:259]     Train net output #0: error_blob = 0.120652 (* 1 = 0.120652 loss)
I1002 00:43:00.509718 23693 solver.cpp:590] Iteration 1900, lr = 0.01
I1002 00:43:03.024533 23693 solver.cpp:347] Iteration 2000, Testing net (#0)
I1002 00:43:03.363525 23693 solver.cpp:415]     Test net output #0: error_blob = 0.117325 (* 1 = 0.117325 loss)
I1002 00:43:03.364178 23693 solver.cpp:243] Iteration 2000, loss = 0.121447
I1002 00:43:03.364235 23693 solver.cpp:259]     Train net output #0: error_blob = 0.121447 (* 1 = 0.121447 loss)
I1002 00:43:03.364245 23693 solver.cpp:590] Iteration 2000, lr = 0.01
I1002 00:43:05.834583 23693 solver.cpp:243] Iteration 2100, loss = 0.118618
I1002 00:43:05.834622 23693 solver.cpp:259]     Train net output #0: error_blob = 0.118618 (* 1 = 0.118618 loss)
I1002 00:43:05.834630 23693 solver.cpp:590] Iteration 2100, lr = 0.01
I1002 00:43:08.360785 23693 solver.cpp:243] Iteration 2200, loss = 0.121275
I1002 00:43:08.360957 23693 solver.cpp:259]     Train net output #0: error_blob = 0.121275 (* 1 = 0.121275 loss)
I1002 00:43:08.360966 23693 solver.cpp:590] Iteration 2200, lr = 0.01
I1002 00:43:10.879171 23693 solver.cpp:243] Iteration 2300, loss = 0.117655
I1002 00:43:10.879215 23693 solver.cpp:259]     Train net output #0: error_blob = 0.117655 (* 1 = 0.117655 loss)
I1002 00:43:10.879220 23693 solver.cpp:590] Iteration 2300, lr = 0.01
I1002 00:43:13.389106 23693 solver.cpp:243] Iteration 2400, loss = 0.121238
I1002 00:43:13.389153 23693 solver.cpp:259]     Train net output #0: error_blob = 0.121238 (* 1 = 0.121238 loss)
I1002 00:43:13.389160 23693 solver.cpp:590] Iteration 2400, lr = 0.01
I1002 00:43:15.971933 23693 solver.cpp:243] Iteration 2500, loss = 0.118781
I1002 00:43:15.971971 23693 solver.cpp:259]     Train net output #0: error_blob = 0.118781 (* 1 = 0.118781 loss)
I1002 00:43:15.971977 23693 solver.cpp:590] Iteration 2500, lr = 0.01
I1002 00:43:18.526682 23693 solver.cpp:243] Iteration 2600, loss = 0.120449
I1002 00:43:18.526731 23693 solver.cpp:259]     Train net output #0: error_blob = 0.120449 (* 1 = 0.120449 loss)
I1002 00:43:18.526738 23693 solver.cpp:590] Iteration 2600, lr = 0.01
I1002 00:43:21.073148 23693 solver.cpp:243] Iteration 2700, loss = 0.119398
I1002 00:43:21.073180 23693 solver.cpp:259]     Train net output #0: error_blob = 0.119398 (* 1 = 0.119398 loss)
I1002 00:43:21.073185 23693 solver.cpp:590] Iteration 2700, lr = 0.01
I1002 00:43:21.417057 23693 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:43:23.591375 23693 solver.cpp:243] Iteration 2800, loss = 0.120562
I1002 00:43:23.591413 23693 solver.cpp:259]     Train net output #0: error_blob = 0.120562 (* 1 = 0.120562 loss)
I1002 00:43:23.591423 23693 solver.cpp:590] Iteration 2800, lr = 0.01
I1002 00:43:26.101317 23693 solver.cpp:243] Iteration 2900, loss = 0.118901
I1002 00:43:26.101357 23693 solver.cpp:259]     Train net output #0: error_blob = 0.118901 (* 1 = 0.118901 loss)
I1002 00:43:26.101364 23693 solver.cpp:590] Iteration 2900, lr = 0.01
I1002 00:43:28.630187 23693 solver.cpp:347] Iteration 3000, Testing net (#0)
I1002 00:43:28.900145 23693 solver.cpp:415]     Test net output #0: error_blob = 0.117769 (* 1 = 0.117769 loss)
I1002 00:43:28.900765 23693 solver.cpp:243] Iteration 3000, loss = 0.117203
I1002 00:43:28.900782 23693 solver.cpp:259]     Train net output #0: error_blob = 0.117203 (* 1 = 0.117203 loss)
I1002 00:43:28.900792 23693 solver.cpp:590] Iteration 3000, lr = 0.01
I1002 00:43:31.376585 23693 solver.cpp:243] Iteration 3100, loss = 0.120162
I1002 00:43:31.376617 23693 solver.cpp:259]     Train net output #0: error_blob = 0.120162 (* 1 = 0.120162 loss)
I1002 00:43:31.376624 23693 solver.cpp:590] Iteration 3100, lr = 0.01
I1002 00:43:33.930677 23693 solver.cpp:243] Iteration 3200, loss = 0.11673
I1002 00:43:33.930711 23693 solver.cpp:259]     Train net output #0: error_blob = 0.11673 (* 1 = 0.11673 loss)
I1002 00:43:33.930717 23693 solver.cpp:590] Iteration 3200, lr = 0.01
I1002 00:43:36.447947 23693 solver.cpp:243] Iteration 3300, loss = 0.119824
I1002 00:43:36.447978 23693 solver.cpp:259]     Train net output #0: error_blob = 0.119824 (* 1 = 0.119824 loss)
I1002 00:43:36.447984 23693 solver.cpp:590] Iteration 3300, lr = 0.01
I1002 00:43:38.956535 23693 solver.cpp:243] Iteration 3400, loss = 0.114107
I1002 00:43:38.956675 23693 solver.cpp:259]     Train net output #0: error_blob = 0.114107 (* 1 = 0.114107 loss)
I1002 00:43:38.956683 23693 solver.cpp:590] Iteration 3400, lr = 0.01
I1002 00:43:41.437453 23693 solver.cpp:243] Iteration 3500, loss = 0.119209
I1002 00:43:41.437485 23693 solver.cpp:259]     Train net output #0: error_blob = 0.119209 (* 1 = 0.119209 loss)
I1002 00:43:41.437490 23693 solver.cpp:590] Iteration 3500, lr = 0.01
I1002 00:43:43.928073 23693 solver.cpp:243] Iteration 3600, loss = 0.114698
I1002 00:43:43.928103 23693 solver.cpp:259]     Train net output #0: error_blob = 0.114698 (* 1 = 0.114698 loss)
I1002 00:43:43.928108 23693 solver.cpp:590] Iteration 3600, lr = 0.01
I1002 00:43:44.413506 23693 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:43:46.406069 23693 solver.cpp:243] Iteration 3700, loss = 0.118776
I1002 00:43:46.406100 23693 solver.cpp:259]     Train net output #0: error_blob = 0.118776 (* 1 = 0.118776 loss)
I1002 00:43:46.406106 23693 solver.cpp:590] Iteration 3700, lr = 0.01
I1002 00:43:48.923952 23693 solver.cpp:243] Iteration 3800, loss = 0.120963
I1002 00:43:48.923993 23693 solver.cpp:259]     Train net output #0: error_blob = 0.120963 (* 1 = 0.120963 loss)
I1002 00:43:48.924000 23693 solver.cpp:590] Iteration 3800, lr = 0.01
I1002 00:43:51.453670 23693 solver.cpp:243] Iteration 3900, loss = 0.118761
I1002 00:43:51.453699 23693 solver.cpp:259]     Train net output #0: error_blob = 0.118761 (* 1 = 0.118761 loss)
I1002 00:43:51.453706 23693 solver.cpp:590] Iteration 3900, lr = 0.01
I1002 00:43:53.943588 23693 solver.cpp:347] Iteration 4000, Testing net (#0)
I1002 00:43:54.219038 23693 solver.cpp:415]     Test net output #0: error_blob = 0.116157 (* 1 = 0.116157 loss)
I1002 00:43:54.219657 23693 solver.cpp:243] Iteration 4000, loss = 0.117276
I1002 00:43:54.219672 23693 solver.cpp:259]     Train net output #0: error_blob = 0.117276 (* 1 = 0.117276 loss)
I1002 00:43:54.219677 23693 solver.cpp:590] Iteration 4000, lr = 0.01
I1002 00:43:56.724613 23693 solver.cpp:243] Iteration 4100, loss = 0.116492
I1002 00:43:56.724655 23693 solver.cpp:259]     Train net output #0: error_blob = 0.116492 (* 1 = 0.116492 loss)
I1002 00:43:56.724660 23693 solver.cpp:590] Iteration 4100, lr = 0.01
I1002 00:43:59.241562 23693 solver.cpp:243] Iteration 4200, loss = 0.116689
I1002 00:43:59.241595 23693 solver.cpp:259]     Train net output #0: error_blob = 0.116689 (* 1 = 0.116689 loss)
I1002 00:43:59.241600 23693 solver.cpp:590] Iteration 4200, lr = 0.01
I1002 00:44:01.739222 23693 solver.cpp:243] Iteration 4300, loss = 0.115822
I1002 00:44:01.739264 23693 solver.cpp:259]     Train net output #0: error_blob = 0.115822 (* 1 = 0.115822 loss)
I1002 00:44:01.739270 23693 solver.cpp:590] Iteration 4300, lr = 0.01
I1002 00:44:04.209455 23693 solver.cpp:243] Iteration 4400, loss = 0.11859
I1002 00:44:04.209488 23693 solver.cpp:259]     Train net output #0: error_blob = 0.11859 (* 1 = 0.11859 loss)
I1002 00:44:04.209494 23693 solver.cpp:590] Iteration 4400, lr = 0.01
I1002 00:44:06.715379 23693 solver.cpp:243] Iteration 4500, loss = 0.113279
I1002 00:44:06.715412 23693 solver.cpp:259]     Train net output #0: error_blob = 0.113279 (* 1 = 0.113279 loss)
I1002 00:44:06.715418 23693 solver.cpp:590] Iteration 4500, lr = 0.01
I1002 00:44:07.366118 23693 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:44:09.225831 23693 solver.cpp:243] Iteration 4600, loss = 0.122565
I1002 00:44:09.225901 23693 solver.cpp:259]     Train net output #0: error_blob = 0.122565 (* 1 = 0.122565 loss)
I1002 00:44:09.225909 23693 solver.cpp:590] Iteration 4600, lr = 0.01
I1002 00:44:11.762337 23693 solver.cpp:243] Iteration 4700, loss = 0.113466
I1002 00:44:11.762372 23693 solver.cpp:259]     Train net output #0: error_blob = 0.113466 (* 1 = 0.113466 loss)
I1002 00:44:11.762378 23693 solver.cpp:590] Iteration 4700, lr = 0.01
I1002 00:44:14.261358 23693 solver.cpp:243] Iteration 4800, loss = 0.118035
I1002 00:44:14.261389 23693 solver.cpp:259]     Train net output #0: error_blob = 0.118035 (* 1 = 0.118035 loss)
I1002 00:44:14.261394 23693 solver.cpp:590] Iteration 4800, lr = 0.01
I1002 00:44:16.816030 23693 solver.cpp:243] Iteration 4900, loss = 0.116173
I1002 00:44:16.816061 23693 solver.cpp:259]     Train net output #0: error_blob = 0.116173 (* 1 = 0.116173 loss)
I1002 00:44:16.816066 23693 solver.cpp:590] Iteration 4900, lr = 0.01
I1002 00:44:19.282187 23693 solver.cpp:347] Iteration 5000, Testing net (#0)
I1002 00:44:19.574612 23693 solver.cpp:415]     Test net output #0: error_blob = 0.116729 (* 1 = 0.116729 loss)
I1002 00:44:19.575242 23693 solver.cpp:243] Iteration 5000, loss = 0.120175
I1002 00:44:19.575258 23693 solver.cpp:259]     Train net output #0: error_blob = 0.120175 (* 1 = 0.120175 loss)
I1002 00:44:19.575263 23693 solver.cpp:590] Iteration 5000, lr = 0.01
I1002 00:44:22.126672 23693 solver.cpp:243] Iteration 5100, loss = 0.117232
I1002 00:44:22.126703 23693 solver.cpp:259]     Train net output #0: error_blob = 0.117232 (* 1 = 0.117232 loss)
I1002 00:44:22.126708 23693 solver.cpp:590] Iteration 5100, lr = 0.01
I1002 00:44:24.632911 23693 solver.cpp:243] Iteration 5200, loss = 0.115801
I1002 00:44:24.632942 23693 solver.cpp:259]     Train net output #0: error_blob = 0.115801 (* 1 = 0.115801 loss)
I1002 00:44:24.632947 23693 solver.cpp:590] Iteration 5200, lr = 0.01
I1002 00:44:27.176453 23693 solver.cpp:243] Iteration 5300, loss = 0.116071
I1002 00:44:27.176496 23693 solver.cpp:259]     Train net output #0: error_blob = 0.116071 (* 1 = 0.116071 loss)
I1002 00:44:27.176503 23693 solver.cpp:590] Iteration 5300, lr = 0.01
I1002 00:44:29.710777 23693 solver.cpp:243] Iteration 5400, loss = 0.113749
I1002 00:44:29.710810 23693 solver.cpp:259]     Train net output #0: error_blob = 0.113749 (* 1 = 0.113749 loss)
I1002 00:44:29.710815 23693 solver.cpp:590] Iteration 5400, lr = 0.01
I1002 00:44:30.520273 23693 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:44:32.243729 23693 solver.cpp:243] Iteration 5500, loss = 0.117497
I1002 00:44:32.243763 23693 solver.cpp:259]     Train net output #0: error_blob = 0.117497 (* 1 = 0.117497 loss)
I1002 00:44:32.243772 23693 solver.cpp:590] Iteration 5500, lr = 0.01
I1002 00:44:34.794981 23693 solver.cpp:243] Iteration 5600, loss = 0.111478
I1002 00:44:34.795017 23693 solver.cpp:259]     Train net output #0: error_blob = 0.111478 (* 1 = 0.111478 loss)
I1002 00:44:34.795023 23693 solver.cpp:590] Iteration 5600, lr = 0.01
I1002 00:44:37.315579 23693 solver.cpp:243] Iteration 5700, loss = 0.11804
I1002 00:44:37.315614 23693 solver.cpp:259]     Train net output #0: error_blob = 0.11804 (* 1 = 0.11804 loss)
I1002 00:44:37.315624 23693 solver.cpp:590] Iteration 5700, lr = 0.01
I1002 00:44:39.828066 23693 solver.cpp:243] Iteration 5800, loss = 0.119416
I1002 00:44:39.828485 23693 solver.cpp:259]     Train net output #0: error_blob = 0.119416 (* 1 = 0.119416 loss)
I1002 00:44:39.828503 23693 solver.cpp:590] Iteration 5800, lr = 0.01
I1002 00:44:42.344876 23693 solver.cpp:243] Iteration 5900, loss = 0.117459
I1002 00:44:42.344908 23693 solver.cpp:259]     Train net output #0: error_blob = 0.117459 (* 1 = 0.117459 loss)
I1002 00:44:42.344914 23693 solver.cpp:590] Iteration 5900, lr = 0.01
I1002 00:44:44.817628 23693 solver.cpp:347] Iteration 6000, Testing net (#0)
I1002 00:44:45.093607 23693 solver.cpp:415]     Test net output #0: error_blob = 0.115052 (* 1 = 0.115052 loss)
I1002 00:44:45.094310 23693 solver.cpp:243] Iteration 6000, loss = 0.113717
I1002 00:44:45.094336 23693 solver.cpp:259]     Train net output #0: error_blob = 0.113717 (* 1 = 0.113717 loss)
I1002 00:44:45.094341 23693 solver.cpp:590] Iteration 6000, lr = 0.01
I1002 00:44:47.598392 23693 solver.cpp:243] Iteration 6100, loss = 0.118527
I1002 00:44:47.598431 23693 solver.cpp:259]     Train net output #0: error_blob = 0.118527 (* 1 = 0.118527 loss)
I1002 00:44:47.598441 23693 solver.cpp:590] Iteration 6100, lr = 0.01
I1002 00:44:50.118150 23693 solver.cpp:243] Iteration 6200, loss = 0.115903
I1002 00:44:50.118192 23693 solver.cpp:259]     Train net output #0: error_blob = 0.115903 (* 1 = 0.115903 loss)
I1002 00:44:50.118198 23693 solver.cpp:590] Iteration 6200, lr = 0.01
I1002 00:44:52.662509 23693 solver.cpp:243] Iteration 6300, loss = 0.114019
I1002 00:44:52.662551 23693 solver.cpp:259]     Train net output #0: error_blob = 0.114019 (* 1 = 0.114019 loss)
I1002 00:44:52.662557 23693 solver.cpp:590] Iteration 6300, lr = 0.01
I1002 00:44:53.625267 23693 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:44:55.197140 23693 solver.cpp:243] Iteration 6400, loss = 0.115031
I1002 00:44:55.197170 23693 solver.cpp:259]     Train net output #0: error_blob = 0.115031 (* 1 = 0.115031 loss)
I1002 00:44:55.197175 23693 solver.cpp:590] Iteration 6400, lr = 0.01
I1002 00:44:57.717893 23693 solver.cpp:243] Iteration 6500, loss = 0.11269
I1002 00:44:57.717936 23693 solver.cpp:259]     Train net output #0: error_blob = 0.11269 (* 1 = 0.11269 loss)
I1002 00:44:57.717942 23693 solver.cpp:590] Iteration 6500, lr = 0.01
I1002 00:45:00.249446 23693 solver.cpp:243] Iteration 6600, loss = 0.117947
I1002 00:45:00.249478 23693 solver.cpp:259]     Train net output #0: error_blob = 0.117947 (* 1 = 0.117947 loss)
I1002 00:45:00.249483 23693 solver.cpp:590] Iteration 6600, lr = 0.01
I1002 00:45:02.774888 23693 solver.cpp:243] Iteration 6700, loss = 0.11117
I1002 00:45:02.774929 23693 solver.cpp:259]     Train net output #0: error_blob = 0.11117 (* 1 = 0.11117 loss)
I1002 00:45:02.774935 23693 solver.cpp:590] Iteration 6700, lr = 0.01
I1002 00:45:05.283063 23693 solver.cpp:243] Iteration 6800, loss = 0.117031
I1002 00:45:05.283095 23693 solver.cpp:259]     Train net output #0: error_blob = 0.117031 (* 1 = 0.117031 loss)
I1002 00:45:05.283102 23693 solver.cpp:590] Iteration 6800, lr = 0.01
I1002 00:45:07.802222 23693 solver.cpp:243] Iteration 6900, loss = 0.112904
I1002 00:45:07.802270 23693 solver.cpp:259]     Train net output #0: error_blob = 0.112904 (* 1 = 0.112904 loss)
I1002 00:45:07.802279 23693 solver.cpp:590] Iteration 6900, lr = 0.01
I1002 00:45:10.296347 23693 solver.cpp:347] Iteration 7000, Testing net (#0)
I1002 00:45:10.594305 23693 solver.cpp:415]     Test net output #0: error_blob = 0.113984 (* 1 = 0.113984 loss)
I1002 00:45:10.594997 23693 solver.cpp:243] Iteration 7000, loss = 0.116922
I1002 00:45:10.595011 23693 solver.cpp:259]     Train net output #0: error_blob = 0.116922 (* 1 = 0.116922 loss)
I1002 00:45:10.595021 23693 solver.cpp:590] Iteration 7000, lr = 0.01
I1002 00:45:13.079886 23693 solver.cpp:243] Iteration 7100, loss = 0.11622
I1002 00:45:13.079923 23693 solver.cpp:259]     Train net output #0: error_blob = 0.11622 (* 1 = 0.11622 loss)
I1002 00:45:13.079931 23693 solver.cpp:590] Iteration 7100, lr = 0.01
I1002 00:45:15.661532 23693 solver.cpp:243] Iteration 7200, loss = 0.116372
I1002 00:45:15.661578 23693 solver.cpp:259]     Train net output #0: error_blob = 0.116372 (* 1 = 0.116372 loss)
I1002 00:45:15.661587 23693 solver.cpp:590] Iteration 7200, lr = 0.01
I1002 00:45:16.778992 23693 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:45:18.199764 23693 solver.cpp:243] Iteration 7300, loss = 0.114621
I1002 00:45:18.199792 23693 solver.cpp:259]     Train net output #0: error_blob = 0.114621 (* 1 = 0.114621 loss)
I1002 00:45:18.199797 23693 solver.cpp:590] Iteration 7300, lr = 0.01
I1002 00:45:20.736734 23693 solver.cpp:243] Iteration 7400, loss = 0.113265
I1002 00:45:20.736775 23693 solver.cpp:259]     Train net output #0: error_blob = 0.113265 (* 1 = 0.113265 loss)
I1002 00:45:20.736780 23693 solver.cpp:590] Iteration 7400, lr = 0.01
I1002 00:45:23.255856 23693 solver.cpp:243] Iteration 7500, loss = 0.120845
I1002 00:45:23.255889 23693 solver.cpp:259]     Train net output #0: error_blob = 0.120845 (* 1 = 0.120845 loss)
I1002 00:45:23.255894 23693 solver.cpp:590] Iteration 7500, lr = 0.01
I1002 00:45:25.779444 23693 solver.cpp:243] Iteration 7600, loss = 0.112456
I1002 00:45:25.779486 23693 solver.cpp:259]     Train net output #0: error_blob = 0.112456 (* 1 = 0.112456 loss)
I1002 00:45:25.779494 23693 solver.cpp:590] Iteration 7600, lr = 0.01
I1002 00:45:28.302956 23693 solver.cpp:243] Iteration 7700, loss = 0.116102
I1002 00:45:28.303005 23693 solver.cpp:259]     Train net output #0: error_blob = 0.116102 (* 1 = 0.116102 loss)
I1002 00:45:28.303012 23693 solver.cpp:590] Iteration 7700, lr = 0.01
I1002 00:45:30.837118 23693 solver.cpp:243] Iteration 7800, loss = 0.111145
I1002 00:45:30.837167 23693 solver.cpp:259]     Train net output #0: error_blob = 0.111145 (* 1 = 0.111145 loss)
I1002 00:45:30.837174 23693 solver.cpp:590] Iteration 7800, lr = 0.01
I1002 00:45:33.410233 23693 solver.cpp:243] Iteration 7900, loss = 0.116347
I1002 00:45:33.410274 23693 solver.cpp:259]     Train net output #0: error_blob = 0.116347 (* 1 = 0.116347 loss)
I1002 00:45:33.410282 23693 solver.cpp:590] Iteration 7900, lr = 0.01
I1002 00:45:35.897312 23693 solver.cpp:347] Iteration 8000, Testing net (#0)
I1002 00:45:36.188231 23693 solver.cpp:415]     Test net output #0: error_blob = 0.115617 (* 1 = 0.115617 loss)
I1002 00:45:36.188926 23693 solver.cpp:243] Iteration 8000, loss = 0.113701
I1002 00:45:36.188952 23693 solver.cpp:259]     Train net output #0: error_blob = 0.113701 (* 1 = 0.113701 loss)
I1002 00:45:36.188959 23693 solver.cpp:590] Iteration 8000, lr = 0.01
I1002 00:45:38.674964 23693 solver.cpp:243] Iteration 8100, loss = 0.116353
I1002 00:45:38.674998 23693 solver.cpp:259]     Train net output #0: error_blob = 0.116353 (* 1 = 0.116353 loss)
I1002 00:45:38.675003 23693 solver.cpp:590] Iteration 8100, lr = 0.01
I1002 00:45:39.936075 23693 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:45:41.179844 23693 solver.cpp:243] Iteration 8200, loss = 0.112602
I1002 00:45:41.180868 23693 solver.cpp:259]     Train net output #0: error_blob = 0.112602 (* 1 = 0.112602 loss)
I1002 00:45:41.180877 23693 solver.cpp:590] Iteration 8200, lr = 0.01
I1002 00:45:43.702039 23693 solver.cpp:243] Iteration 8300, loss = 0.114341
I1002 00:45:43.702080 23693 solver.cpp:259]     Train net output #0: error_blob = 0.114341 (* 1 = 0.114341 loss)
I1002 00:45:43.702085 23693 solver.cpp:590] Iteration 8300, lr = 0.01
I1002 00:45:46.208762 23693 solver.cpp:243] Iteration 8400, loss = 0.11445
I1002 00:45:46.208792 23693 solver.cpp:259]     Train net output #0: error_blob = 0.11445 (* 1 = 0.11445 loss)
I1002 00:45:46.208798 23693 solver.cpp:590] Iteration 8400, lr = 0.01
I1002 00:45:48.720341 23693 solver.cpp:243] Iteration 8500, loss = 0.113242
I1002 00:45:48.720382 23693 solver.cpp:259]     Train net output #0: error_blob = 0.113242 (* 1 = 0.113242 loss)
I1002 00:45:48.720388 23693 solver.cpp:590] Iteration 8500, lr = 0.01
I1002 00:45:51.219264 23693 solver.cpp:243] Iteration 8600, loss = 0.114889
I1002 00:45:51.219296 23693 solver.cpp:259]     Train net output #0: error_blob = 0.114889 (* 1 = 0.114889 loss)
I1002 00:45:51.219302 23693 solver.cpp:590] Iteration 8600, lr = 0.01
I1002 00:45:53.714730 23693 solver.cpp:243] Iteration 8700, loss = 0.111676
I1002 00:45:53.714763 23693 solver.cpp:259]     Train net output #0: error_blob = 0.111676 (* 1 = 0.111676 loss)
I1002 00:45:53.714768 23693 solver.cpp:590] Iteration 8700, lr = 0.01
I1002 00:45:56.236138 23693 solver.cpp:243] Iteration 8800, loss = 0.117757
I1002 00:45:56.236168 23693 solver.cpp:259]     Train net output #0: error_blob = 0.117757 (* 1 = 0.117757 loss)
I1002 00:45:56.236176 23693 solver.cpp:590] Iteration 8800, lr = 0.01
I1002 00:45:58.762528 23693 solver.cpp:243] Iteration 8900, loss = 0.119816
I1002 00:45:58.762564 23693 solver.cpp:259]     Train net output #0: error_blob = 0.119816 (* 1 = 0.119816 loss)
I1002 00:45:58.762573 23693 solver.cpp:590] Iteration 8900, lr = 0.01
I1002 00:46:01.239362 23693 solver.cpp:347] Iteration 9000, Testing net (#0)
I1002 00:46:01.508792 23693 solver.cpp:415]     Test net output #0: error_blob = 0.112777 (* 1 = 0.112777 loss)
I1002 00:46:01.509418 23693 solver.cpp:243] Iteration 9000, loss = 0.116038
I1002 00:46:01.509431 23693 solver.cpp:259]     Train net output #0: error_blob = 0.116038 (* 1 = 0.116038 loss)
I1002 00:46:01.509436 23693 solver.cpp:590] Iteration 9000, lr = 0.01
I1002 00:46:02.868355 23693 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:46:03.985343 23693 solver.cpp:243] Iteration 9100, loss = 0.115973
I1002 00:46:03.985375 23693 solver.cpp:259]     Train net output #0: error_blob = 0.115973 (* 1 = 0.115973 loss)
I1002 00:46:03.985381 23693 solver.cpp:590] Iteration 9100, lr = 0.01
I1002 00:46:06.476825 23693 solver.cpp:243] Iteration 9200, loss = 0.116147
I1002 00:46:06.476866 23693 solver.cpp:259]     Train net output #0: error_blob = 0.116147 (* 1 = 0.116147 loss)
I1002 00:46:06.476871 23693 solver.cpp:590] Iteration 9200, lr = 0.01
I1002 00:46:08.912320 23693 solver.cpp:243] Iteration 9300, loss = 0.113292
I1002 00:46:08.912363 23693 solver.cpp:259]     Train net output #0: error_blob = 0.113292 (* 1 = 0.113292 loss)
I1002 00:46:08.912369 23693 solver.cpp:590] Iteration 9300, lr = 0.01
I1002 00:46:11.379312 23693 solver.cpp:243] Iteration 9400, loss = 0.11886
I1002 00:46:11.380352 23693 solver.cpp:259]     Train net output #0: error_blob = 0.11886 (* 1 = 0.11886 loss)
I1002 00:46:11.380363 23693 solver.cpp:590] Iteration 9400, lr = 0.01
I1002 00:46:13.846910 23693 solver.cpp:243] Iteration 9500, loss = 0.114888
I1002 00:46:13.846945 23693 solver.cpp:259]     Train net output #0: error_blob = 0.114888 (* 1 = 0.114888 loss)
I1002 00:46:13.846951 23693 solver.cpp:590] Iteration 9500, lr = 0.01
I1002 00:46:16.338202 23693 solver.cpp:243] Iteration 9600, loss = 0.112187
I1002 00:46:16.338235 23693 solver.cpp:259]     Train net output #0: error_blob = 0.112187 (* 1 = 0.112187 loss)
I1002 00:46:16.338244 23693 solver.cpp:590] Iteration 9600, lr = 0.01
I1002 00:46:18.873210 23693 solver.cpp:243] Iteration 9700, loss = 0.118411
I1002 00:46:18.873245 23693 solver.cpp:259]     Train net output #0: error_blob = 0.118411 (* 1 = 0.118411 loss)
I1002 00:46:18.873252 23693 solver.cpp:590] Iteration 9700, lr = 0.01
I1002 00:46:21.407409 23693 solver.cpp:243] Iteration 9800, loss = 0.111121
I1002 00:46:21.407444 23693 solver.cpp:259]     Train net output #0: error_blob = 0.111121 (* 1 = 0.111121 loss)
I1002 00:46:21.407452 23693 solver.cpp:590] Iteration 9800, lr = 0.01
I1002 00:46:23.929191 23693 solver.cpp:243] Iteration 9900, loss = 0.116664
I1002 00:46:23.929229 23693 solver.cpp:259]     Train net output #0: error_blob = 0.116664 (* 1 = 0.116664 loss)
I1002 00:46:23.929235 23693 solver.cpp:590] Iteration 9900, lr = 0.01
I1002 00:46:26.395393 23693 solver.cpp:468] Snapshotting to binary proto file _iter_10000.caffemodel
I1002 00:46:26.396240 23693 solver.cpp:753] Snapshotting solver state to binary proto file _iter_10000.solverstate
I1002 00:46:26.419154 23693 solver.cpp:327] Iteration 10000, loss = 0.110236
I1002 00:46:26.419181 23693 solver.cpp:347] Iteration 10000, Testing net (#0)
I1002 00:46:26.589077 23693 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:46:26.696441 23693 solver.cpp:415]     Test net output #0: error_blob = 0.113643 (* 1 = 0.113643 loss)
I1002 00:46:26.696461 23693 solver.cpp:332] Optimization Done.
I1002 00:46:26.696465 23693 caffe.cpp:215] Optimization Done.
I1002 00:46:26.763272 23704 caffe.cpp:184] Using GPUs 0
I1002 00:46:27.325091 23704 solver.cpp:54] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "fixed"
momentum: 0.9
solver_mode: GPU
device_id: 0
net: "model/NNScore/nnscore_model_2.prototxt"
I1002 00:46:27.325122 23704 solver.cpp:97] Creating training net from net file: model/NNScore/nnscore_model_2.prototxt
I1002 00:46:27.325271 23704 net.cpp:339] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_layer
I1002 00:46:27.325309 23704 net.cpp:50] Initializing net from parameters: 
name: "model/NNScore/nnscore_model_2.prototxt"
state {
  phase: TRAIN
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TRAIN
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.2.train"
    batch_size: 20000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1002 00:46:27.325346 23704 layer_factory.hpp:76] Creating layer data_layer
I1002 00:46:27.338541 23704 net.cpp:110] Creating Layer data_layer
I1002 00:46:27.338572 23704 net.cpp:433] data_layer -> data_blob
I1002 00:46:27.338603 23704 net.cpp:433] data_layer -> label_blob
I1002 00:46:27.339213 23708 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.2.train
I1002 00:46:28.021807 23704 data_layer.cpp:45] output data size: 20000,61,1,1
I1002 00:46:28.026754 23704 net.cpp:155] Setting up data_layer
I1002 00:46:28.026785 23704 net.cpp:163] Top shape: 20000 61 1 1 (1220000)
I1002 00:46:28.026789 23704 net.cpp:163] Top shape: 20000 (20000)
I1002 00:46:28.026795 23704 layer_factory.hpp:76] Creating layer hidden_sum_layer
I1002 00:46:28.026806 23704 net.cpp:110] Creating Layer hidden_sum_layer
I1002 00:46:28.026810 23704 net.cpp:477] hidden_sum_layer <- data_blob
I1002 00:46:28.026819 23704 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I1002 00:46:28.027169 23704 net.cpp:155] Setting up hidden_sum_layer
I1002 00:46:28.027176 23704 net.cpp:163] Top shape: 20000 10 (200000)
I1002 00:46:28.027199 23704 layer_factory.hpp:76] Creating layer hidden_act_layer
I1002 00:46:28.027215 23704 net.cpp:110] Creating Layer hidden_act_layer
I1002 00:46:28.027218 23704 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I1002 00:46:28.027221 23704 net.cpp:433] hidden_act_layer -> hidden_act_blob
I1002 00:46:31.236904 23704 net.cpp:155] Setting up hidden_act_layer
I1002 00:46:31.236927 23704 net.cpp:163] Top shape: 20000 10 (200000)
I1002 00:46:31.236932 23704 layer_factory.hpp:76] Creating layer output_sum_layer
I1002 00:46:31.236940 23704 net.cpp:110] Creating Layer output_sum_layer
I1002 00:46:31.236943 23704 net.cpp:477] output_sum_layer <- hidden_act_blob
I1002 00:46:31.236948 23704 net.cpp:433] output_sum_layer -> output_sum_blob
I1002 00:46:31.237031 23704 net.cpp:155] Setting up output_sum_layer
I1002 00:46:31.237037 23704 net.cpp:163] Top shape: 20000 1 (20000)
I1002 00:46:31.237043 23704 layer_factory.hpp:76] Creating layer output_act_layer
I1002 00:46:31.237048 23704 net.cpp:110] Creating Layer output_act_layer
I1002 00:46:31.237051 23704 net.cpp:477] output_act_layer <- output_sum_blob
I1002 00:46:31.237054 23704 net.cpp:433] output_act_layer -> output_act_blob
I1002 00:46:31.237112 23704 net.cpp:155] Setting up output_act_layer
I1002 00:46:31.237130 23704 net.cpp:163] Top shape: 20000 1 (20000)
I1002 00:46:31.237133 23704 layer_factory.hpp:76] Creating layer error_layer
I1002 00:46:31.237138 23704 net.cpp:110] Creating Layer error_layer
I1002 00:46:31.237140 23704 net.cpp:477] error_layer <- output_act_blob
I1002 00:46:31.237144 23704 net.cpp:477] error_layer <- label_blob
I1002 00:46:31.237148 23704 net.cpp:433] error_layer -> error_blob
I1002 00:46:31.237172 23704 net.cpp:155] Setting up error_layer
I1002 00:46:31.237176 23704 net.cpp:163] Top shape: (1)
I1002 00:46:31.237179 23704 net.cpp:168]     with loss weight 1
I1002 00:46:31.237195 23704 net.cpp:236] error_layer needs backward computation.
I1002 00:46:31.237196 23704 net.cpp:236] output_act_layer needs backward computation.
I1002 00:46:31.237198 23704 net.cpp:236] output_sum_layer needs backward computation.
I1002 00:46:31.237200 23704 net.cpp:236] hidden_act_layer needs backward computation.
I1002 00:46:31.237202 23704 net.cpp:236] hidden_sum_layer needs backward computation.
I1002 00:46:31.237205 23704 net.cpp:240] data_layer does not need backward computation.
I1002 00:46:31.237207 23704 net.cpp:283] This network produces output error_blob
I1002 00:46:31.237212 23704 net.cpp:297] Network initialization done.
I1002 00:46:31.237215 23704 net.cpp:298] Memory required for data: 6720004
I1002 00:46:31.237367 23704 solver.cpp:187] Creating test net (#0) specified by net file: model/NNScore/nnscore_model_2.prototxt
I1002 00:46:31.237382 23704 net.cpp:339] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_layer
I1002 00:46:31.237423 23704 net.cpp:50] Initializing net from parameters: 
name: "model/NNScore/nnscore_model_2.prototxt"
state {
  phase: TEST
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TEST
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.2.test"
    batch_size: 2000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1002 00:46:31.237454 23704 layer_factory.hpp:76] Creating layer data_layer
I1002 00:46:31.238664 23704 net.cpp:110] Creating Layer data_layer
I1002 00:46:31.238682 23704 net.cpp:433] data_layer -> data_blob
I1002 00:46:31.238688 23704 net.cpp:433] data_layer -> label_blob
I1002 00:46:31.239229 23710 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.2.test
I1002 00:46:31.239294 23704 data_layer.cpp:45] output data size: 2000,61,1,1
I1002 00:46:31.240797 23704 net.cpp:155] Setting up data_layer
I1002 00:46:31.240814 23704 net.cpp:163] Top shape: 2000 61 1 1 (122000)
I1002 00:46:31.240820 23704 net.cpp:163] Top shape: 2000 (2000)
I1002 00:46:31.240826 23704 layer_factory.hpp:76] Creating layer hidden_sum_layer
I1002 00:46:31.240839 23704 net.cpp:110] Creating Layer hidden_sum_layer
I1002 00:46:31.240844 23704 net.cpp:477] hidden_sum_layer <- data_blob
I1002 00:46:31.240850 23704 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I1002 00:46:31.240979 23704 net.cpp:155] Setting up hidden_sum_layer
I1002 00:46:31.240988 23704 net.cpp:163] Top shape: 2000 10 (20000)
I1002 00:46:31.240998 23704 layer_factory.hpp:76] Creating layer hidden_act_layer
I1002 00:46:31.241006 23704 net.cpp:110] Creating Layer hidden_act_layer
I1002 00:46:31.241014 23704 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I1002 00:46:31.241032 23704 net.cpp:433] hidden_act_layer -> hidden_act_blob
I1002 00:46:31.241240 23704 net.cpp:155] Setting up hidden_act_layer
I1002 00:46:31.241248 23704 net.cpp:163] Top shape: 2000 10 (20000)
I1002 00:46:31.241253 23704 layer_factory.hpp:76] Creating layer output_sum_layer
I1002 00:46:31.241260 23704 net.cpp:110] Creating Layer output_sum_layer
I1002 00:46:31.241263 23704 net.cpp:477] output_sum_layer <- hidden_act_blob
I1002 00:46:31.241269 23704 net.cpp:433] output_sum_layer -> output_sum_blob
I1002 00:46:31.241338 23704 net.cpp:155] Setting up output_sum_layer
I1002 00:46:31.241344 23704 net.cpp:163] Top shape: 2000 1 (2000)
I1002 00:46:31.241353 23704 layer_factory.hpp:76] Creating layer output_act_layer
I1002 00:46:31.241359 23704 net.cpp:110] Creating Layer output_act_layer
I1002 00:46:31.241364 23704 net.cpp:477] output_act_layer <- output_sum_blob
I1002 00:46:31.241369 23704 net.cpp:433] output_act_layer -> output_act_blob
I1002 00:46:31.241426 23704 net.cpp:155] Setting up output_act_layer
I1002 00:46:31.241433 23704 net.cpp:163] Top shape: 2000 1 (2000)
I1002 00:46:31.241437 23704 layer_factory.hpp:76] Creating layer error_layer
I1002 00:46:31.241443 23704 net.cpp:110] Creating Layer error_layer
I1002 00:46:31.241447 23704 net.cpp:477] error_layer <- output_act_blob
I1002 00:46:31.241451 23704 net.cpp:477] error_layer <- label_blob
I1002 00:46:31.241456 23704 net.cpp:433] error_layer -> error_blob
I1002 00:46:31.241487 23704 net.cpp:155] Setting up error_layer
I1002 00:46:31.241492 23704 net.cpp:163] Top shape: (1)
I1002 00:46:31.241495 23704 net.cpp:168]     with loss weight 1
I1002 00:46:31.241508 23704 net.cpp:236] error_layer needs backward computation.
I1002 00:46:31.241511 23704 net.cpp:236] output_act_layer needs backward computation.
I1002 00:46:31.241515 23704 net.cpp:236] output_sum_layer needs backward computation.
I1002 00:46:31.241519 23704 net.cpp:236] hidden_act_layer needs backward computation.
I1002 00:46:31.241523 23704 net.cpp:236] hidden_sum_layer needs backward computation.
I1002 00:46:31.241526 23704 net.cpp:240] data_layer does not need backward computation.
I1002 00:46:31.241529 23704 net.cpp:283] This network produces output error_blob
I1002 00:46:31.241538 23704 net.cpp:297] Network initialization done.
I1002 00:46:31.241540 23704 net.cpp:298] Memory required for data: 672004
I1002 00:46:31.241566 23704 solver.cpp:66] Solver scaffolding done.
I1002 00:46:31.241665 23704 caffe.cpp:212] Starting Optimization
I1002 00:46:31.241674 23704 solver.cpp:294] Solving model/NNScore/nnscore_model_2.prototxt
I1002 00:46:31.241679 23704 solver.cpp:295] Learning Rate Policy: fixed
I1002 00:46:31.241863 23704 solver.cpp:347] Iteration 0, Testing net (#0)
I1002 00:46:31.241966 23704 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:46:31.520433 23704 solver.cpp:415]     Test net output #0: error_blob = 0.147149 (* 1 = 0.147149 loss)
I1002 00:46:31.521778 23704 solver.cpp:243] Iteration 0, loss = 0.142363
I1002 00:46:31.521796 23704 solver.cpp:259]     Train net output #0: error_blob = 0.142363 (* 1 = 0.142363 loss)
I1002 00:46:31.521812 23704 solver.cpp:590] Iteration 0, lr = 0.01
I1002 00:46:33.946154 23704 solver.cpp:243] Iteration 100, loss = 0.12343
I1002 00:46:33.946202 23704 solver.cpp:259]     Train net output #0: error_blob = 0.12343 (* 1 = 0.12343 loss)
I1002 00:46:33.946210 23704 solver.cpp:590] Iteration 100, lr = 0.01
I1002 00:46:36.463227 23704 solver.cpp:243] Iteration 200, loss = 0.121122
I1002 00:46:36.463268 23704 solver.cpp:259]     Train net output #0: error_blob = 0.121122 (* 1 = 0.121122 loss)
I1002 00:46:36.463274 23704 solver.cpp:590] Iteration 200, lr = 0.01
I1002 00:46:38.983319 23704 solver.cpp:243] Iteration 300, loss = 0.121304
I1002 00:46:38.983358 23704 solver.cpp:259]     Train net output #0: error_blob = 0.121304 (* 1 = 0.121304 loss)
I1002 00:46:38.983364 23704 solver.cpp:590] Iteration 300, lr = 0.01
I1002 00:46:41.458312 23704 solver.cpp:243] Iteration 400, loss = 0.120261
I1002 00:46:41.458385 23704 solver.cpp:259]     Train net output #0: error_blob = 0.120261 (* 1 = 0.120261 loss)
I1002 00:46:41.458394 23704 solver.cpp:590] Iteration 400, lr = 0.01
I1002 00:46:44.026232 23704 solver.cpp:243] Iteration 500, loss = 0.121394
I1002 00:46:44.026275 23704 solver.cpp:259]     Train net output #0: error_blob = 0.121394 (* 1 = 0.121394 loss)
I1002 00:46:44.026281 23704 solver.cpp:590] Iteration 500, lr = 0.01
I1002 00:46:46.515022 23704 solver.cpp:243] Iteration 600, loss = 0.120043
I1002 00:46:46.515064 23704 solver.cpp:259]     Train net output #0: error_blob = 0.120043 (* 1 = 0.120043 loss)
I1002 00:46:46.515069 23704 solver.cpp:590] Iteration 600, lr = 0.01
I1002 00:46:49.033783 23704 solver.cpp:243] Iteration 700, loss = 0.120608
I1002 00:46:49.033830 23704 solver.cpp:259]     Train net output #0: error_blob = 0.120608 (* 1 = 0.120608 loss)
I1002 00:46:49.033838 23704 solver.cpp:590] Iteration 700, lr = 0.01
I1002 00:46:51.565130 23704 solver.cpp:243] Iteration 800, loss = 0.119802
I1002 00:46:51.565181 23704 solver.cpp:259]     Train net output #0: error_blob = 0.119802 (* 1 = 0.119802 loss)
I1002 00:46:51.565191 23704 solver.cpp:590] Iteration 800, lr = 0.01
I1002 00:46:54.084987 23704 solver.cpp:243] Iteration 900, loss = 0.118604
I1002 00:46:54.085032 23704 solver.cpp:259]     Train net output #0: error_blob = 0.118604 (* 1 = 0.118604 loss)
I1002 00:46:54.085041 23704 solver.cpp:590] Iteration 900, lr = 0.01
I1002 00:46:54.134575 23704 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:46:56.585235 23704 solver.cpp:347] Iteration 1000, Testing net (#0)
I1002 00:46:56.858364 23704 solver.cpp:415]     Test net output #0: error_blob = 0.125148 (* 1 = 0.125148 loss)
I1002 00:46:56.859125 23704 solver.cpp:243] Iteration 1000, loss = 0.121454
I1002 00:46:56.859163 23704 solver.cpp:259]     Train net output #0: error_blob = 0.121454 (* 1 = 0.121454 loss)
I1002 00:46:56.859182 23704 solver.cpp:590] Iteration 1000, lr = 0.01
I1002 00:46:59.334820 23704 solver.cpp:243] Iteration 1100, loss = 0.120164
I1002 00:46:59.334864 23704 solver.cpp:259]     Train net output #0: error_blob = 0.120164 (* 1 = 0.120164 loss)
I1002 00:46:59.334869 23704 solver.cpp:590] Iteration 1100, lr = 0.01
I1002 00:47:01.800355 23704 solver.cpp:243] Iteration 1200, loss = 0.11996
I1002 00:47:01.800403 23704 solver.cpp:259]     Train net output #0: error_blob = 0.11996 (* 1 = 0.11996 loss)
I1002 00:47:01.800412 23704 solver.cpp:590] Iteration 1200, lr = 0.01
I1002 00:47:04.277555 23704 solver.cpp:243] Iteration 1300, loss = 0.12078
I1002 00:47:04.277590 23704 solver.cpp:259]     Train net output #0: error_blob = 0.12078 (* 1 = 0.12078 loss)
I1002 00:47:04.277598 23704 solver.cpp:590] Iteration 1300, lr = 0.01
I1002 00:47:06.782399 23704 solver.cpp:243] Iteration 1400, loss = 0.118333
I1002 00:47:06.782441 23704 solver.cpp:259]     Train net output #0: error_blob = 0.118333 (* 1 = 0.118333 loss)
I1002 00:47:06.782448 23704 solver.cpp:590] Iteration 1400, lr = 0.01
I1002 00:47:09.295999 23704 solver.cpp:243] Iteration 1500, loss = 0.120382
I1002 00:47:09.296030 23704 solver.cpp:259]     Train net output #0: error_blob = 0.120382 (* 1 = 0.120382 loss)
I1002 00:47:09.296036 23704 solver.cpp:590] Iteration 1500, lr = 0.01
I1002 00:47:11.796398 23704 solver.cpp:243] Iteration 1600, loss = 0.11956
I1002 00:47:11.796439 23704 solver.cpp:259]     Train net output #0: error_blob = 0.11956 (* 1 = 0.11956 loss)
I1002 00:47:11.796445 23704 solver.cpp:590] Iteration 1600, lr = 0.01
I1002 00:47:14.297117 23704 solver.cpp:243] Iteration 1700, loss = 0.120829
I1002 00:47:14.297157 23704 solver.cpp:259]     Train net output #0: error_blob = 0.120829 (* 1 = 0.120829 loss)
I1002 00:47:14.297164 23704 solver.cpp:590] Iteration 1700, lr = 0.01
I1002 00:47:16.842983 23704 solver.cpp:243] Iteration 1800, loss = 0.121566
I1002 00:47:16.843024 23704 solver.cpp:259]     Train net output #0: error_blob = 0.121566 (* 1 = 0.121566 loss)
I1002 00:47:16.843030 23704 solver.cpp:590] Iteration 1800, lr = 0.01
I1002 00:47:17.046689 23704 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:47:19.363673 23704 solver.cpp:243] Iteration 1900, loss = 0.116815
I1002 00:47:19.363720 23704 solver.cpp:259]     Train net output #0: error_blob = 0.116815 (* 1 = 0.116815 loss)
I1002 00:47:19.363729 23704 solver.cpp:590] Iteration 1900, lr = 0.01
I1002 00:47:21.841054 23704 solver.cpp:347] Iteration 2000, Testing net (#0)
I1002 00:47:22.152027 23704 solver.cpp:415]     Test net output #0: error_blob = 0.124929 (* 1 = 0.124929 loss)
I1002 00:47:22.152729 23704 solver.cpp:243] Iteration 2000, loss = 0.120966
I1002 00:47:22.152767 23704 solver.cpp:259]     Train net output #0: error_blob = 0.120966 (* 1 = 0.120966 loss)
I1002 00:47:22.152778 23704 solver.cpp:590] Iteration 2000, lr = 0.01
I1002 00:47:24.586117 23704 solver.cpp:243] Iteration 2100, loss = 0.119225
I1002 00:47:24.586156 23704 solver.cpp:259]     Train net output #0: error_blob = 0.119225 (* 1 = 0.119225 loss)
I1002 00:47:24.586163 23704 solver.cpp:590] Iteration 2100, lr = 0.01
I1002 00:47:27.062311 23704 solver.cpp:243] Iteration 2200, loss = 0.118683
I1002 00:47:27.062446 23704 solver.cpp:259]     Train net output #0: error_blob = 0.118683 (* 1 = 0.118683 loss)
I1002 00:47:27.062466 23704 solver.cpp:590] Iteration 2200, lr = 0.01
I1002 00:47:29.515123 23704 solver.cpp:243] Iteration 2300, loss = 0.121054
I1002 00:47:29.515166 23704 solver.cpp:259]     Train net output #0: error_blob = 0.121054 (* 1 = 0.121054 loss)
I1002 00:47:29.515172 23704 solver.cpp:590] Iteration 2300, lr = 0.01
I1002 00:47:31.987316 23704 solver.cpp:243] Iteration 2400, loss = 0.117642
I1002 00:47:31.987357 23704 solver.cpp:259]     Train net output #0: error_blob = 0.117642 (* 1 = 0.117642 loss)
I1002 00:47:31.987364 23704 solver.cpp:590] Iteration 2400, lr = 0.01
I1002 00:47:34.477597 23704 solver.cpp:243] Iteration 2500, loss = 0.119242
I1002 00:47:34.477638 23704 solver.cpp:259]     Train net output #0: error_blob = 0.119242 (* 1 = 0.119242 loss)
I1002 00:47:34.477643 23704 solver.cpp:590] Iteration 2500, lr = 0.01
I1002 00:47:36.943334 23704 solver.cpp:243] Iteration 2600, loss = 0.118039
I1002 00:47:36.943375 23704 solver.cpp:259]     Train net output #0: error_blob = 0.118039 (* 1 = 0.118039 loss)
I1002 00:47:36.943382 23704 solver.cpp:590] Iteration 2600, lr = 0.01
I1002 00:47:39.427548 23704 solver.cpp:243] Iteration 2700, loss = 0.119608
I1002 00:47:39.427577 23704 solver.cpp:259]     Train net output #0: error_blob = 0.119608 (* 1 = 0.119608 loss)
I1002 00:47:39.427582 23704 solver.cpp:590] Iteration 2700, lr = 0.01
I1002 00:47:39.767362 23704 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:47:41.899087 23704 solver.cpp:243] Iteration 2800, loss = 0.120396
I1002 00:47:41.899128 23704 solver.cpp:259]     Train net output #0: error_blob = 0.120396 (* 1 = 0.120396 loss)
I1002 00:47:41.899133 23704 solver.cpp:590] Iteration 2800, lr = 0.01
I1002 00:47:44.398077 23704 solver.cpp:243] Iteration 2900, loss = 0.116071
I1002 00:47:44.398108 23704 solver.cpp:259]     Train net output #0: error_blob = 0.116071 (* 1 = 0.116071 loss)
I1002 00:47:44.398113 23704 solver.cpp:590] Iteration 2900, lr = 0.01
I1002 00:47:46.922216 23704 solver.cpp:347] Iteration 3000, Testing net (#0)
I1002 00:47:47.212119 23704 solver.cpp:415]     Test net output #0: error_blob = 0.12122 (* 1 = 0.12122 loss)
I1002 00:47:47.212802 23704 solver.cpp:243] Iteration 3000, loss = 0.11831
I1002 00:47:47.212837 23704 solver.cpp:259]     Train net output #0: error_blob = 0.11831 (* 1 = 0.11831 loss)
I1002 00:47:47.212847 23704 solver.cpp:590] Iteration 3000, lr = 0.01
I1002 00:47:49.685962 23704 solver.cpp:243] Iteration 3100, loss = 0.117018
I1002 00:47:49.685993 23704 solver.cpp:259]     Train net output #0: error_blob = 0.117018 (* 1 = 0.117018 loss)
I1002 00:47:49.685999 23704 solver.cpp:590] Iteration 3100, lr = 0.01
I1002 00:47:52.175940 23704 solver.cpp:243] Iteration 3200, loss = 0.116699
I1002 00:47:52.175982 23704 solver.cpp:259]     Train net output #0: error_blob = 0.116699 (* 1 = 0.116699 loss)
I1002 00:47:52.175988 23704 solver.cpp:590] Iteration 3200, lr = 0.01
I1002 00:47:54.657569 23704 solver.cpp:243] Iteration 3300, loss = 0.118752
I1002 00:47:54.657608 23704 solver.cpp:259]     Train net output #0: error_blob = 0.118752 (* 1 = 0.118752 loss)
I1002 00:47:54.657614 23704 solver.cpp:590] Iteration 3300, lr = 0.01
I1002 00:47:57.118574 23704 solver.cpp:243] Iteration 3400, loss = 0.116297
I1002 00:47:57.119570 23704 solver.cpp:259]     Train net output #0: error_blob = 0.116297 (* 1 = 0.116297 loss)
I1002 00:47:57.119576 23704 solver.cpp:590] Iteration 3400, lr = 0.01
I1002 00:47:59.593857 23704 solver.cpp:243] Iteration 3500, loss = 0.117754
I1002 00:47:59.593896 23704 solver.cpp:259]     Train net output #0: error_blob = 0.117754 (* 1 = 0.117754 loss)
I1002 00:47:59.593901 23704 solver.cpp:590] Iteration 3500, lr = 0.01
I1002 00:48:02.082190 23704 solver.cpp:243] Iteration 3600, loss = 0.117021
I1002 00:48:02.082229 23704 solver.cpp:259]     Train net output #0: error_blob = 0.117021 (* 1 = 0.117021 loss)
I1002 00:48:02.082234 23704 solver.cpp:590] Iteration 3600, lr = 0.01
I1002 00:48:02.574717 23704 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:48:04.545869 23704 solver.cpp:243] Iteration 3700, loss = 0.114942
I1002 00:48:04.545912 23704 solver.cpp:259]     Train net output #0: error_blob = 0.114942 (* 1 = 0.114942 loss)
I1002 00:48:04.545917 23704 solver.cpp:590] Iteration 3700, lr = 0.01
I1002 00:48:07.020623 23704 solver.cpp:243] Iteration 3800, loss = 0.117684
I1002 00:48:07.020654 23704 solver.cpp:259]     Train net output #0: error_blob = 0.117684 (* 1 = 0.117684 loss)
I1002 00:48:07.020659 23704 solver.cpp:590] Iteration 3800, lr = 0.01
I1002 00:48:09.528869 23704 solver.cpp:243] Iteration 3900, loss = 0.115636
I1002 00:48:09.528910 23704 solver.cpp:259]     Train net output #0: error_blob = 0.115636 (* 1 = 0.115636 loss)
I1002 00:48:09.528914 23704 solver.cpp:590] Iteration 3900, lr = 0.01
I1002 00:48:11.993592 23704 solver.cpp:347] Iteration 4000, Testing net (#0)
I1002 00:48:12.270455 23704 solver.cpp:415]     Test net output #0: error_blob = 0.121569 (* 1 = 0.121569 loss)
I1002 00:48:12.271106 23704 solver.cpp:243] Iteration 4000, loss = 0.118421
I1002 00:48:12.271121 23704 solver.cpp:259]     Train net output #0: error_blob = 0.118421 (* 1 = 0.118421 loss)
I1002 00:48:12.271131 23704 solver.cpp:590] Iteration 4000, lr = 0.01
I1002 00:48:14.759484 23704 solver.cpp:243] Iteration 4100, loss = 0.116486
I1002 00:48:14.759516 23704 solver.cpp:259]     Train net output #0: error_blob = 0.116486 (* 1 = 0.116486 loss)
I1002 00:48:14.759521 23704 solver.cpp:590] Iteration 4100, lr = 0.01
I1002 00:48:17.252238 23704 solver.cpp:243] Iteration 4200, loss = 0.114176
I1002 00:48:17.252270 23704 solver.cpp:259]     Train net output #0: error_blob = 0.114176 (* 1 = 0.114176 loss)
I1002 00:48:17.252276 23704 solver.cpp:590] Iteration 4200, lr = 0.01
I1002 00:48:19.756086 23704 solver.cpp:243] Iteration 4300, loss = 0.118507
I1002 00:48:19.756117 23704 solver.cpp:259]     Train net output #0: error_blob = 0.118507 (* 1 = 0.118507 loss)
I1002 00:48:19.756125 23704 solver.cpp:590] Iteration 4300, lr = 0.01
I1002 00:48:22.268895 23704 solver.cpp:243] Iteration 4400, loss = 0.114474
I1002 00:48:22.268926 23704 solver.cpp:259]     Train net output #0: error_blob = 0.114474 (* 1 = 0.114474 loss)
I1002 00:48:22.268932 23704 solver.cpp:590] Iteration 4400, lr = 0.01
I1002 00:48:24.764926 23704 solver.cpp:243] Iteration 4500, loss = 0.115773
I1002 00:48:24.764958 23704 solver.cpp:259]     Train net output #0: error_blob = 0.115773 (* 1 = 0.115773 loss)
I1002 00:48:24.764966 23704 solver.cpp:590] Iteration 4500, lr = 0.01
I1002 00:48:25.415971 23704 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:48:27.275959 23704 solver.cpp:243] Iteration 4600, loss = 0.118493
I1002 00:48:27.276024 23704 solver.cpp:259]     Train net output #0: error_blob = 0.118493 (* 1 = 0.118493 loss)
I1002 00:48:27.276032 23704 solver.cpp:590] Iteration 4600, lr = 0.01
I1002 00:48:29.755571 23704 solver.cpp:243] Iteration 4700, loss = 0.113966
I1002 00:48:29.755604 23704 solver.cpp:259]     Train net output #0: error_blob = 0.113966 (* 1 = 0.113966 loss)
I1002 00:48:29.755611 23704 solver.cpp:590] Iteration 4700, lr = 0.01
I1002 00:48:32.223645 23704 solver.cpp:243] Iteration 4800, loss = 0.117492
I1002 00:48:32.223677 23704 solver.cpp:259]     Train net output #0: error_blob = 0.117492 (* 1 = 0.117492 loss)
I1002 00:48:32.223685 23704 solver.cpp:590] Iteration 4800, lr = 0.01
I1002 00:48:34.712594 23704 solver.cpp:243] Iteration 4900, loss = 0.114755
I1002 00:48:34.712625 23704 solver.cpp:259]     Train net output #0: error_blob = 0.114755 (* 1 = 0.114755 loss)
I1002 00:48:34.712630 23704 solver.cpp:590] Iteration 4900, lr = 0.01
I1002 00:48:37.173861 23704 solver.cpp:347] Iteration 5000, Testing net (#0)
I1002 00:48:37.530104 23704 solver.cpp:415]     Test net output #0: error_blob = 0.125575 (* 1 = 0.125575 loss)
I1002 00:48:37.530757 23704 solver.cpp:243] Iteration 5000, loss = 0.119331
I1002 00:48:37.530768 23704 solver.cpp:259]     Train net output #0: error_blob = 0.119331 (* 1 = 0.119331 loss)
I1002 00:48:37.530773 23704 solver.cpp:590] Iteration 5000, lr = 0.01
I1002 00:48:40.096355 23704 solver.cpp:243] Iteration 5100, loss = 0.116788
I1002 00:48:40.096385 23704 solver.cpp:259]     Train net output #0: error_blob = 0.116788 (* 1 = 0.116788 loss)
I1002 00:48:40.096390 23704 solver.cpp:590] Iteration 5100, lr = 0.01
I1002 00:48:42.603133 23704 solver.cpp:243] Iteration 5200, loss = 0.114359
I1002 00:48:42.603165 23704 solver.cpp:259]     Train net output #0: error_blob = 0.114359 (* 1 = 0.114359 loss)
I1002 00:48:42.603173 23704 solver.cpp:590] Iteration 5200, lr = 0.01
I1002 00:48:45.103415 23704 solver.cpp:243] Iteration 5300, loss = 0.119354
I1002 00:48:45.103446 23704 solver.cpp:259]     Train net output #0: error_blob = 0.119354 (* 1 = 0.119354 loss)
I1002 00:48:45.103453 23704 solver.cpp:590] Iteration 5300, lr = 0.01
I1002 00:48:47.596012 23704 solver.cpp:243] Iteration 5400, loss = 0.114191
I1002 00:48:47.596041 23704 solver.cpp:259]     Train net output #0: error_blob = 0.114191 (* 1 = 0.114191 loss)
I1002 00:48:47.596046 23704 solver.cpp:590] Iteration 5400, lr = 0.01
I1002 00:48:48.393420 23704 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:48:50.084431 23704 solver.cpp:243] Iteration 5500, loss = 0.113613
I1002 00:48:50.084461 23704 solver.cpp:259]     Train net output #0: error_blob = 0.113613 (* 1 = 0.113613 loss)
I1002 00:48:50.084466 23704 solver.cpp:590] Iteration 5500, lr = 0.01
I1002 00:48:52.599972 23704 solver.cpp:243] Iteration 5600, loss = 0.118234
I1002 00:48:52.600002 23704 solver.cpp:259]     Train net output #0: error_blob = 0.118234 (* 1 = 0.118234 loss)
I1002 00:48:52.600006 23704 solver.cpp:590] Iteration 5600, lr = 0.01
I1002 00:48:55.132058 23704 solver.cpp:243] Iteration 5700, loss = 0.119002
I1002 00:48:55.132087 23704 solver.cpp:259]     Train net output #0: error_blob = 0.119002 (* 1 = 0.119002 loss)
I1002 00:48:55.132092 23704 solver.cpp:590] Iteration 5700, lr = 0.01
I1002 00:48:57.681325 23704 solver.cpp:243] Iteration 5800, loss = 0.119634
I1002 00:48:57.681452 23704 solver.cpp:259]     Train net output #0: error_blob = 0.119634 (* 1 = 0.119634 loss)
I1002 00:48:57.681473 23704 solver.cpp:590] Iteration 5800, lr = 0.01
I1002 00:49:00.143023 23704 solver.cpp:243] Iteration 5900, loss = 0.116767
I1002 00:49:00.143055 23704 solver.cpp:259]     Train net output #0: error_blob = 0.116767 (* 1 = 0.116767 loss)
I1002 00:49:00.143064 23704 solver.cpp:590] Iteration 5900, lr = 0.01
I1002 00:49:02.622508 23704 solver.cpp:347] Iteration 6000, Testing net (#0)
I1002 00:49:02.932950 23704 solver.cpp:415]     Test net output #0: error_blob = 0.118461 (* 1 = 0.118461 loss)
I1002 00:49:02.933564 23704 solver.cpp:243] Iteration 6000, loss = 0.113808
I1002 00:49:02.933576 23704 solver.cpp:259]     Train net output #0: error_blob = 0.113808 (* 1 = 0.113808 loss)
I1002 00:49:02.933581 23704 solver.cpp:590] Iteration 6000, lr = 0.01
I1002 00:49:05.371424 23704 solver.cpp:243] Iteration 6100, loss = 0.11825
I1002 00:49:05.371454 23704 solver.cpp:259]     Train net output #0: error_blob = 0.11825 (* 1 = 0.11825 loss)
I1002 00:49:05.371460 23704 solver.cpp:590] Iteration 6100, lr = 0.01
I1002 00:49:07.843639 23704 solver.cpp:243] Iteration 6200, loss = 0.112786
I1002 00:49:07.843672 23704 solver.cpp:259]     Train net output #0: error_blob = 0.112786 (* 1 = 0.112786 loss)
I1002 00:49:07.843677 23704 solver.cpp:590] Iteration 6200, lr = 0.01
I1002 00:49:10.315326 23704 solver.cpp:243] Iteration 6300, loss = 0.118773
I1002 00:49:10.315366 23704 solver.cpp:259]     Train net output #0: error_blob = 0.118773 (* 1 = 0.118773 loss)
I1002 00:49:10.315371 23704 solver.cpp:590] Iteration 6300, lr = 0.01
I1002 00:49:11.247681 23704 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:49:12.799002 23704 solver.cpp:243] Iteration 6400, loss = 0.117638
I1002 00:49:12.799044 23704 solver.cpp:259]     Train net output #0: error_blob = 0.117638 (* 1 = 0.117638 loss)
I1002 00:49:12.799049 23704 solver.cpp:590] Iteration 6400, lr = 0.01
I1002 00:49:15.304018 23704 solver.cpp:243] Iteration 6500, loss = 0.114399
I1002 00:49:15.304047 23704 solver.cpp:259]     Train net output #0: error_blob = 0.114399 (* 1 = 0.114399 loss)
I1002 00:49:15.304052 23704 solver.cpp:590] Iteration 6500, lr = 0.01
I1002 00:49:17.835517 23704 solver.cpp:243] Iteration 6600, loss = 0.117894
I1002 00:49:17.835548 23704 solver.cpp:259]     Train net output #0: error_blob = 0.117894 (* 1 = 0.117894 loss)
I1002 00:49:17.835553 23704 solver.cpp:590] Iteration 6600, lr = 0.01
I1002 00:49:20.337126 23704 solver.cpp:243] Iteration 6700, loss = 0.113547
I1002 00:49:20.337167 23704 solver.cpp:259]     Train net output #0: error_blob = 0.113547 (* 1 = 0.113547 loss)
I1002 00:49:20.337172 23704 solver.cpp:590] Iteration 6700, lr = 0.01
I1002 00:49:22.800060 23704 solver.cpp:243] Iteration 6800, loss = 0.118258
I1002 00:49:22.800098 23704 solver.cpp:259]     Train net output #0: error_blob = 0.118258 (* 1 = 0.118258 loss)
I1002 00:49:22.800103 23704 solver.cpp:590] Iteration 6800, lr = 0.01
I1002 00:49:25.328227 23704 solver.cpp:243] Iteration 6900, loss = 0.119197
I1002 00:49:25.328268 23704 solver.cpp:259]     Train net output #0: error_blob = 0.119197 (* 1 = 0.119197 loss)
I1002 00:49:25.328274 23704 solver.cpp:590] Iteration 6900, lr = 0.01
I1002 00:49:27.811848 23704 solver.cpp:347] Iteration 7000, Testing net (#0)
I1002 00:49:28.151846 23704 solver.cpp:415]     Test net output #0: error_blob = 0.118813 (* 1 = 0.118813 loss)
I1002 00:49:28.152499 23704 solver.cpp:243] Iteration 7000, loss = 0.112511
I1002 00:49:28.152510 23704 solver.cpp:259]     Train net output #0: error_blob = 0.112511 (* 1 = 0.112511 loss)
I1002 00:49:28.152516 23704 solver.cpp:590] Iteration 7000, lr = 0.01
I1002 00:49:30.587019 23704 solver.cpp:243] Iteration 7100, loss = 0.117199
I1002 00:49:30.587060 23704 solver.cpp:259]     Train net output #0: error_blob = 0.117199 (* 1 = 0.117199 loss)
I1002 00:49:30.587065 23704 solver.cpp:590] Iteration 7100, lr = 0.01
I1002 00:49:33.051796 23704 solver.cpp:243] Iteration 7200, loss = 0.118193
I1002 00:49:33.051827 23704 solver.cpp:259]     Train net output #0: error_blob = 0.118193 (* 1 = 0.118193 loss)
I1002 00:49:33.051834 23704 solver.cpp:590] Iteration 7200, lr = 0.01
I1002 00:49:34.137648 23704 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:49:35.527315 23704 solver.cpp:243] Iteration 7300, loss = 0.115288
I1002 00:49:35.527348 23704 solver.cpp:259]     Train net output #0: error_blob = 0.115288 (* 1 = 0.115288 loss)
I1002 00:49:35.527356 23704 solver.cpp:590] Iteration 7300, lr = 0.01
I1002 00:49:38.054683 23704 solver.cpp:243] Iteration 7400, loss = 0.116668
I1002 00:49:38.054716 23704 solver.cpp:259]     Train net output #0: error_blob = 0.116668 (* 1 = 0.116668 loss)
I1002 00:49:38.054723 23704 solver.cpp:590] Iteration 7400, lr = 0.01
I1002 00:49:40.525981 23704 solver.cpp:243] Iteration 7500, loss = 0.115188
I1002 00:49:40.526015 23704 solver.cpp:259]     Train net output #0: error_blob = 0.115188 (* 1 = 0.115188 loss)
I1002 00:49:40.526021 23704 solver.cpp:590] Iteration 7500, lr = 0.01
I1002 00:49:43.053894 23704 solver.cpp:243] Iteration 7600, loss = 0.116583
I1002 00:49:43.053927 23704 solver.cpp:259]     Train net output #0: error_blob = 0.116583 (* 1 = 0.116583 loss)
I1002 00:49:43.053936 23704 solver.cpp:590] Iteration 7600, lr = 0.01
I1002 00:49:45.559232 23704 solver.cpp:243] Iteration 7700, loss = 0.114172
I1002 00:49:45.559263 23704 solver.cpp:259]     Train net output #0: error_blob = 0.114172 (* 1 = 0.114172 loss)
I1002 00:49:45.559268 23704 solver.cpp:590] Iteration 7700, lr = 0.01
I1002 00:49:48.029063 23704 solver.cpp:243] Iteration 7800, loss = 0.114464
I1002 00:49:48.029093 23704 solver.cpp:259]     Train net output #0: error_blob = 0.114464 (* 1 = 0.114464 loss)
I1002 00:49:48.029098 23704 solver.cpp:590] Iteration 7800, lr = 0.01
I1002 00:49:50.517397 23704 solver.cpp:243] Iteration 7900, loss = 0.117736
I1002 00:49:50.517427 23704 solver.cpp:259]     Train net output #0: error_blob = 0.117736 (* 1 = 0.117736 loss)
I1002 00:49:50.517432 23704 solver.cpp:590] Iteration 7900, lr = 0.01
I1002 00:49:52.944176 23704 solver.cpp:347] Iteration 8000, Testing net (#0)
I1002 00:49:53.212404 23704 solver.cpp:415]     Test net output #0: error_blob = 0.119261 (* 1 = 0.119261 loss)
I1002 00:49:53.213018 23704 solver.cpp:243] Iteration 8000, loss = 0.111848
I1002 00:49:53.213032 23704 solver.cpp:259]     Train net output #0: error_blob = 0.111848 (* 1 = 0.111848 loss)
I1002 00:49:53.213037 23704 solver.cpp:590] Iteration 8000, lr = 0.01
I1002 00:49:55.655114 23704 solver.cpp:243] Iteration 8100, loss = 0.117121
I1002 00:49:55.655153 23704 solver.cpp:259]     Train net output #0: error_blob = 0.117121 (* 1 = 0.117121 loss)
I1002 00:49:55.655158 23704 solver.cpp:590] Iteration 8100, lr = 0.01
I1002 00:49:56.897449 23704 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:49:58.145473 23704 solver.cpp:243] Iteration 8200, loss = 0.112849
I1002 00:49:58.145576 23704 solver.cpp:259]     Train net output #0: error_blob = 0.112849 (* 1 = 0.112849 loss)
I1002 00:49:58.145581 23704 solver.cpp:590] Iteration 8200, lr = 0.01
I1002 00:50:00.635303 23704 solver.cpp:243] Iteration 8300, loss = 0.113832
I1002 00:50:00.635335 23704 solver.cpp:259]     Train net output #0: error_blob = 0.113832 (* 1 = 0.113832 loss)
I1002 00:50:00.635341 23704 solver.cpp:590] Iteration 8300, lr = 0.01
I1002 00:50:03.169718 23704 solver.cpp:243] Iteration 8400, loss = 0.117418
I1002 00:50:03.169747 23704 solver.cpp:259]     Train net output #0: error_blob = 0.117418 (* 1 = 0.117418 loss)
I1002 00:50:03.169752 23704 solver.cpp:590] Iteration 8400, lr = 0.01
I1002 00:50:05.644446 23704 solver.cpp:243] Iteration 8500, loss = 0.111962
I1002 00:50:05.644476 23704 solver.cpp:259]     Train net output #0: error_blob = 0.111962 (* 1 = 0.111962 loss)
I1002 00:50:05.644481 23704 solver.cpp:590] Iteration 8500, lr = 0.01
I1002 00:50:08.121984 23704 solver.cpp:243] Iteration 8600, loss = 0.1189
I1002 00:50:08.122014 23704 solver.cpp:259]     Train net output #0: error_blob = 0.1189 (* 1 = 0.1189 loss)
I1002 00:50:08.122020 23704 solver.cpp:590] Iteration 8600, lr = 0.01
I1002 00:50:10.631384 23704 solver.cpp:243] Iteration 8700, loss = 0.117571
I1002 00:50:10.631414 23704 solver.cpp:259]     Train net output #0: error_blob = 0.117571 (* 1 = 0.117571 loss)
I1002 00:50:10.631420 23704 solver.cpp:590] Iteration 8700, lr = 0.01
I1002 00:50:13.110935 23704 solver.cpp:243] Iteration 8800, loss = 0.114827
I1002 00:50:13.110967 23704 solver.cpp:259]     Train net output #0: error_blob = 0.114827 (* 1 = 0.114827 loss)
I1002 00:50:13.110975 23704 solver.cpp:590] Iteration 8800, lr = 0.01
I1002 00:50:15.635964 23704 solver.cpp:243] Iteration 8900, loss = 0.117561
I1002 00:50:15.635996 23704 solver.cpp:259]     Train net output #0: error_blob = 0.117561 (* 1 = 0.117561 loss)
I1002 00:50:15.636001 23704 solver.cpp:590] Iteration 8900, lr = 0.01
I1002 00:50:18.099787 23704 solver.cpp:347] Iteration 9000, Testing net (#0)
I1002 00:50:18.386661 23704 solver.cpp:415]     Test net output #0: error_blob = 0.125492 (* 1 = 0.125492 loss)
I1002 00:50:18.387382 23704 solver.cpp:243] Iteration 9000, loss = 0.113786
I1002 00:50:18.387400 23704 solver.cpp:259]     Train net output #0: error_blob = 0.113786 (* 1 = 0.113786 loss)
I1002 00:50:18.387408 23704 solver.cpp:590] Iteration 9000, lr = 0.01
I1002 00:50:19.746687 23704 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:50:20.826807 23704 solver.cpp:243] Iteration 9100, loss = 0.117024
I1002 00:50:20.826838 23704 solver.cpp:259]     Train net output #0: error_blob = 0.117024 (* 1 = 0.117024 loss)
I1002 00:50:20.826843 23704 solver.cpp:590] Iteration 9100, lr = 0.01
I1002 00:50:23.326234 23704 solver.cpp:243] Iteration 9200, loss = 0.116483
I1002 00:50:23.326277 23704 solver.cpp:259]     Train net output #0: error_blob = 0.116483 (* 1 = 0.116483 loss)
I1002 00:50:23.326282 23704 solver.cpp:590] Iteration 9200, lr = 0.01
I1002 00:50:25.804591 23704 solver.cpp:243] Iteration 9300, loss = 0.112053
I1002 00:50:25.804631 23704 solver.cpp:259]     Train net output #0: error_blob = 0.112053 (* 1 = 0.112053 loss)
I1002 00:50:25.804636 23704 solver.cpp:590] Iteration 9300, lr = 0.01
I1002 00:50:28.313030 23704 solver.cpp:243] Iteration 9400, loss = 0.11773
I1002 00:50:28.313140 23704 solver.cpp:259]     Train net output #0: error_blob = 0.11773 (* 1 = 0.11773 loss)
I1002 00:50:28.313148 23704 solver.cpp:590] Iteration 9400, lr = 0.01
I1002 00:50:30.794749 23704 solver.cpp:243] Iteration 9500, loss = 0.11717
I1002 00:50:30.794790 23704 solver.cpp:259]     Train net output #0: error_blob = 0.11717 (* 1 = 0.11717 loss)
I1002 00:50:30.794795 23704 solver.cpp:590] Iteration 9500, lr = 0.01
I1002 00:50:33.263036 23704 solver.cpp:243] Iteration 9600, loss = 0.117052
I1002 00:50:33.263066 23704 solver.cpp:259]     Train net output #0: error_blob = 0.117052 (* 1 = 0.117052 loss)
I1002 00:50:33.263070 23704 solver.cpp:590] Iteration 9600, lr = 0.01
I1002 00:50:35.743604 23704 solver.cpp:243] Iteration 9700, loss = 0.119743
I1002 00:50:35.743646 23704 solver.cpp:259]     Train net output #0: error_blob = 0.119743 (* 1 = 0.119743 loss)
I1002 00:50:35.743652 23704 solver.cpp:590] Iteration 9700, lr = 0.01
I1002 00:50:38.237478 23704 solver.cpp:243] Iteration 9800, loss = 0.111867
I1002 00:50:38.237509 23704 solver.cpp:259]     Train net output #0: error_blob = 0.111867 (* 1 = 0.111867 loss)
I1002 00:50:38.237514 23704 solver.cpp:590] Iteration 9800, lr = 0.01
I1002 00:50:40.691237 23704 solver.cpp:243] Iteration 9900, loss = 0.118903
I1002 00:50:40.691278 23704 solver.cpp:259]     Train net output #0: error_blob = 0.118903 (* 1 = 0.118903 loss)
I1002 00:50:40.691283 23704 solver.cpp:590] Iteration 9900, lr = 0.01
I1002 00:50:43.160960 23704 solver.cpp:468] Snapshotting to binary proto file _iter_10000.caffemodel
I1002 00:50:43.162753 23704 solver.cpp:753] Snapshotting solver state to binary proto file _iter_10000.solverstate
I1002 00:50:43.185726 23704 solver.cpp:327] Iteration 10000, loss = 0.113942
I1002 00:50:43.185763 23704 solver.cpp:347] Iteration 10000, Testing net (#0)
I1002 00:50:43.372838 23704 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:50:43.480790 23704 solver.cpp:415]     Test net output #0: error_blob = 0.115705 (* 1 = 0.115705 loss)
I1002 00:50:43.480808 23704 solver.cpp:332] Optimization Done.
I1002 00:50:43.480811 23704 caffe.cpp:215] Optimization Done.
I1002 00:50:43.550107 23713 caffe.cpp:184] Using GPUs 0
I1002 00:50:44.110399 23713 solver.cpp:54] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "fixed"
momentum: 0.9
solver_mode: GPU
device_id: 0
net: "model/NNScore/nnscore_model_3.prototxt"
I1002 00:50:44.110430 23713 solver.cpp:97] Creating training net from net file: model/NNScore/nnscore_model_3.prototxt
I1002 00:50:44.110597 23713 net.cpp:339] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_layer
I1002 00:50:44.110644 23713 net.cpp:50] Initializing net from parameters: 
name: "model/NNScore/nnscore_model_3.prototxt"
state {
  phase: TRAIN
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TRAIN
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.3.train"
    batch_size: 20000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1002 00:50:44.110719 23713 layer_factory.hpp:76] Creating layer data_layer
I1002 00:50:44.123906 23713 net.cpp:110] Creating Layer data_layer
I1002 00:50:44.123937 23713 net.cpp:433] data_layer -> data_blob
I1002 00:50:44.123960 23713 net.cpp:433] data_layer -> label_blob
I1002 00:50:44.124565 23717 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.3.train
I1002 00:50:44.807699 23713 data_layer.cpp:45] output data size: 20000,61,1,1
I1002 00:50:44.812681 23713 net.cpp:155] Setting up data_layer
I1002 00:50:44.812724 23713 net.cpp:163] Top shape: 20000 61 1 1 (1220000)
I1002 00:50:44.812728 23713 net.cpp:163] Top shape: 20000 (20000)
I1002 00:50:44.812733 23713 layer_factory.hpp:76] Creating layer hidden_sum_layer
I1002 00:50:44.812744 23713 net.cpp:110] Creating Layer hidden_sum_layer
I1002 00:50:44.812748 23713 net.cpp:477] hidden_sum_layer <- data_blob
I1002 00:50:44.812757 23713 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I1002 00:50:44.813132 23713 net.cpp:155] Setting up hidden_sum_layer
I1002 00:50:44.813139 23713 net.cpp:163] Top shape: 20000 10 (200000)
I1002 00:50:44.813160 23713 layer_factory.hpp:76] Creating layer hidden_act_layer
I1002 00:50:44.813169 23713 net.cpp:110] Creating Layer hidden_act_layer
I1002 00:50:44.813170 23713 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I1002 00:50:44.813172 23713 net.cpp:433] hidden_act_layer -> hidden_act_blob
I1002 00:50:48.029914 23713 net.cpp:155] Setting up hidden_act_layer
I1002 00:50:48.029952 23713 net.cpp:163] Top shape: 20000 10 (200000)
I1002 00:50:48.029958 23713 layer_factory.hpp:76] Creating layer output_sum_layer
I1002 00:50:48.029971 23713 net.cpp:110] Creating Layer output_sum_layer
I1002 00:50:48.029975 23713 net.cpp:477] output_sum_layer <- hidden_act_blob
I1002 00:50:48.029981 23713 net.cpp:433] output_sum_layer -> output_sum_blob
I1002 00:50:48.030081 23713 net.cpp:155] Setting up output_sum_layer
I1002 00:50:48.030086 23713 net.cpp:163] Top shape: 20000 1 (20000)
I1002 00:50:48.030102 23713 layer_factory.hpp:76] Creating layer output_act_layer
I1002 00:50:48.030107 23713 net.cpp:110] Creating Layer output_act_layer
I1002 00:50:48.030109 23713 net.cpp:477] output_act_layer <- output_sum_blob
I1002 00:50:48.030112 23713 net.cpp:433] output_act_layer -> output_act_blob
I1002 00:50:48.030174 23713 net.cpp:155] Setting up output_act_layer
I1002 00:50:48.030194 23713 net.cpp:163] Top shape: 20000 1 (20000)
I1002 00:50:48.030205 23713 layer_factory.hpp:76] Creating layer error_layer
I1002 00:50:48.030211 23713 net.cpp:110] Creating Layer error_layer
I1002 00:50:48.030213 23713 net.cpp:477] error_layer <- output_act_blob
I1002 00:50:48.030216 23713 net.cpp:477] error_layer <- label_blob
I1002 00:50:48.030220 23713 net.cpp:433] error_layer -> error_blob
I1002 00:50:48.030242 23713 net.cpp:155] Setting up error_layer
I1002 00:50:48.030246 23713 net.cpp:163] Top shape: (1)
I1002 00:50:48.030256 23713 net.cpp:168]     with loss weight 1
I1002 00:50:48.030283 23713 net.cpp:236] error_layer needs backward computation.
I1002 00:50:48.030285 23713 net.cpp:236] output_act_layer needs backward computation.
I1002 00:50:48.030287 23713 net.cpp:236] output_sum_layer needs backward computation.
I1002 00:50:48.030288 23713 net.cpp:236] hidden_act_layer needs backward computation.
I1002 00:50:48.030290 23713 net.cpp:236] hidden_sum_layer needs backward computation.
I1002 00:50:48.030292 23713 net.cpp:240] data_layer does not need backward computation.
I1002 00:50:48.030294 23713 net.cpp:283] This network produces output error_blob
I1002 00:50:48.030299 23713 net.cpp:297] Network initialization done.
I1002 00:50:48.030302 23713 net.cpp:298] Memory required for data: 6720004
I1002 00:50:48.030426 23713 solver.cpp:187] Creating test net (#0) specified by net file: model/NNScore/nnscore_model_3.prototxt
I1002 00:50:48.030448 23713 net.cpp:339] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_layer
I1002 00:50:48.030488 23713 net.cpp:50] Initializing net from parameters: 
name: "model/NNScore/nnscore_model_3.prototxt"
state {
  phase: TEST
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TEST
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.3.test"
    batch_size: 2000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1002 00:50:48.030519 23713 layer_factory.hpp:76] Creating layer data_layer
I1002 00:50:48.031728 23713 net.cpp:110] Creating Layer data_layer
I1002 00:50:48.031744 23713 net.cpp:433] data_layer -> data_blob
I1002 00:50:48.031749 23713 net.cpp:433] data_layer -> label_blob
I1002 00:50:48.032290 23719 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.3.test
I1002 00:50:48.032354 23713 data_layer.cpp:45] output data size: 2000,61,1,1
I1002 00:50:48.033741 23713 net.cpp:155] Setting up data_layer
I1002 00:50:48.033756 23713 net.cpp:163] Top shape: 2000 61 1 1 (122000)
I1002 00:50:48.033758 23713 net.cpp:163] Top shape: 2000 (2000)
I1002 00:50:48.033761 23713 layer_factory.hpp:76] Creating layer hidden_sum_layer
I1002 00:50:48.033769 23713 net.cpp:110] Creating Layer hidden_sum_layer
I1002 00:50:48.033771 23713 net.cpp:477] hidden_sum_layer <- data_blob
I1002 00:50:48.033776 23713 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I1002 00:50:48.033905 23713 net.cpp:155] Setting up hidden_sum_layer
I1002 00:50:48.033910 23713 net.cpp:163] Top shape: 2000 10 (20000)
I1002 00:50:48.033917 23713 layer_factory.hpp:76] Creating layer hidden_act_layer
I1002 00:50:48.033922 23713 net.cpp:110] Creating Layer hidden_act_layer
I1002 00:50:48.033924 23713 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I1002 00:50:48.033939 23713 net.cpp:433] hidden_act_layer -> hidden_act_blob
I1002 00:50:48.034119 23713 net.cpp:155] Setting up hidden_act_layer
I1002 00:50:48.034127 23713 net.cpp:163] Top shape: 2000 10 (20000)
I1002 00:50:48.034131 23713 layer_factory.hpp:76] Creating layer output_sum_layer
I1002 00:50:48.034134 23713 net.cpp:110] Creating Layer output_sum_layer
I1002 00:50:48.034137 23713 net.cpp:477] output_sum_layer <- hidden_act_blob
I1002 00:50:48.034140 23713 net.cpp:433] output_sum_layer -> output_sum_blob
I1002 00:50:48.034199 23713 net.cpp:155] Setting up output_sum_layer
I1002 00:50:48.034204 23713 net.cpp:163] Top shape: 2000 1 (2000)
I1002 00:50:48.034210 23713 layer_factory.hpp:76] Creating layer output_act_layer
I1002 00:50:48.034214 23713 net.cpp:110] Creating Layer output_act_layer
I1002 00:50:48.034215 23713 net.cpp:477] output_act_layer <- output_sum_blob
I1002 00:50:48.034219 23713 net.cpp:433] output_act_layer -> output_act_blob
I1002 00:50:48.034268 23713 net.cpp:155] Setting up output_act_layer
I1002 00:50:48.034272 23713 net.cpp:163] Top shape: 2000 1 (2000)
I1002 00:50:48.034274 23713 layer_factory.hpp:76] Creating layer error_layer
I1002 00:50:48.034278 23713 net.cpp:110] Creating Layer error_layer
I1002 00:50:48.034281 23713 net.cpp:477] error_layer <- output_act_blob
I1002 00:50:48.034283 23713 net.cpp:477] error_layer <- label_blob
I1002 00:50:48.034286 23713 net.cpp:433] error_layer -> error_blob
I1002 00:50:48.034306 23713 net.cpp:155] Setting up error_layer
I1002 00:50:48.034309 23713 net.cpp:163] Top shape: (1)
I1002 00:50:48.034312 23713 net.cpp:168]     with loss weight 1
I1002 00:50:48.034318 23713 net.cpp:236] error_layer needs backward computation.
I1002 00:50:48.034320 23713 net.cpp:236] output_act_layer needs backward computation.
I1002 00:50:48.034322 23713 net.cpp:236] output_sum_layer needs backward computation.
I1002 00:50:48.034324 23713 net.cpp:236] hidden_act_layer needs backward computation.
I1002 00:50:48.034327 23713 net.cpp:236] hidden_sum_layer needs backward computation.
I1002 00:50:48.034329 23713 net.cpp:240] data_layer does not need backward computation.
I1002 00:50:48.034332 23713 net.cpp:283] This network produces output error_blob
I1002 00:50:48.034335 23713 net.cpp:297] Network initialization done.
I1002 00:50:48.034337 23713 net.cpp:298] Memory required for data: 672004
I1002 00:50:48.034356 23713 solver.cpp:66] Solver scaffolding done.
I1002 00:50:48.034447 23713 caffe.cpp:212] Starting Optimization
I1002 00:50:48.034454 23713 solver.cpp:294] Solving model/NNScore/nnscore_model_3.prototxt
I1002 00:50:48.034456 23713 solver.cpp:295] Learning Rate Policy: fixed
I1002 00:50:48.034597 23713 solver.cpp:347] Iteration 0, Testing net (#0)
I1002 00:50:48.034667 23713 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:50:48.324048 23713 solver.cpp:415]     Test net output #0: error_blob = 0.125775 (* 1 = 0.125775 loss)
I1002 00:50:48.325351 23713 solver.cpp:243] Iteration 0, loss = 0.125229
I1002 00:50:48.325367 23713 solver.cpp:259]     Train net output #0: error_blob = 0.125229 (* 1 = 0.125229 loss)
I1002 00:50:48.325379 23713 solver.cpp:590] Iteration 0, lr = 0.01
I1002 00:50:50.820353 23713 solver.cpp:243] Iteration 100, loss = 0.12238
I1002 00:50:50.820384 23713 solver.cpp:259]     Train net output #0: error_blob = 0.12238 (* 1 = 0.12238 loss)
I1002 00:50:50.820390 23713 solver.cpp:590] Iteration 100, lr = 0.01
I1002 00:50:53.309010 23713 solver.cpp:243] Iteration 200, loss = 0.122326
I1002 00:50:53.309039 23713 solver.cpp:259]     Train net output #0: error_blob = 0.122326 (* 1 = 0.122326 loss)
I1002 00:50:53.309044 23713 solver.cpp:590] Iteration 200, lr = 0.01
I1002 00:50:55.842102 23713 solver.cpp:243] Iteration 300, loss = 0.121766
I1002 00:50:55.842133 23713 solver.cpp:259]     Train net output #0: error_blob = 0.121766 (* 1 = 0.121766 loss)
I1002 00:50:55.842139 23713 solver.cpp:590] Iteration 300, lr = 0.01
I1002 00:50:58.353458 23713 solver.cpp:243] Iteration 400, loss = 0.122017
I1002 00:50:58.353512 23713 solver.cpp:259]     Train net output #0: error_blob = 0.122017 (* 1 = 0.122017 loss)
I1002 00:50:58.353519 23713 solver.cpp:590] Iteration 400, lr = 0.01
I1002 00:51:00.893564 23713 solver.cpp:243] Iteration 500, loss = 0.121133
I1002 00:51:00.893597 23713 solver.cpp:259]     Train net output #0: error_blob = 0.121133 (* 1 = 0.121133 loss)
I1002 00:51:00.893605 23713 solver.cpp:590] Iteration 500, lr = 0.01
I1002 00:51:03.461745 23713 solver.cpp:243] Iteration 600, loss = 0.121503
I1002 00:51:03.461776 23713 solver.cpp:259]     Train net output #0: error_blob = 0.121503 (* 1 = 0.121503 loss)
I1002 00:51:03.461781 23713 solver.cpp:590] Iteration 600, lr = 0.01
I1002 00:51:05.954884 23713 solver.cpp:243] Iteration 700, loss = 0.121681
I1002 00:51:05.954924 23713 solver.cpp:259]     Train net output #0: error_blob = 0.121681 (* 1 = 0.121681 loss)
I1002 00:51:05.954931 23713 solver.cpp:590] Iteration 700, lr = 0.01
I1002 00:51:08.460301 23713 solver.cpp:243] Iteration 800, loss = 0.121257
I1002 00:51:08.460332 23713 solver.cpp:259]     Train net output #0: error_blob = 0.121257 (* 1 = 0.121257 loss)
I1002 00:51:08.460337 23713 solver.cpp:590] Iteration 800, lr = 0.01
I1002 00:51:10.972513 23713 solver.cpp:243] Iteration 900, loss = 0.121077
I1002 00:51:10.972544 23713 solver.cpp:259]     Train net output #0: error_blob = 0.121077 (* 1 = 0.121077 loss)
I1002 00:51:10.972548 23713 solver.cpp:590] Iteration 900, lr = 0.01
I1002 00:51:11.022074 23713 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:51:13.420928 23713 solver.cpp:347] Iteration 1000, Testing net (#0)
I1002 00:51:13.695462 23713 solver.cpp:415]     Test net output #0: error_blob = 0.116938 (* 1 = 0.116938 loss)
I1002 00:51:13.696249 23713 solver.cpp:243] Iteration 1000, loss = 0.120778
I1002 00:51:13.696287 23713 solver.cpp:259]     Train net output #0: error_blob = 0.120778 (* 1 = 0.120778 loss)
I1002 00:51:13.696297 23713 solver.cpp:590] Iteration 1000, lr = 0.01
I1002 00:51:16.209301 23713 solver.cpp:243] Iteration 1100, loss = 0.120751
I1002 00:51:16.209343 23713 solver.cpp:259]     Train net output #0: error_blob = 0.120751 (* 1 = 0.120751 loss)
I1002 00:51:16.209349 23713 solver.cpp:590] Iteration 1100, lr = 0.01
I1002 00:51:18.739372 23713 solver.cpp:243] Iteration 1200, loss = 0.120336
I1002 00:51:18.739404 23713 solver.cpp:259]     Train net output #0: error_blob = 0.120336 (* 1 = 0.120336 loss)
I1002 00:51:18.739408 23713 solver.cpp:590] Iteration 1200, lr = 0.01
I1002 00:51:21.265996 23713 solver.cpp:243] Iteration 1300, loss = 0.120585
I1002 00:51:21.266026 23713 solver.cpp:259]     Train net output #0: error_blob = 0.120585 (* 1 = 0.120585 loss)
I1002 00:51:21.266031 23713 solver.cpp:590] Iteration 1300, lr = 0.01
I1002 00:51:23.796185 23713 solver.cpp:243] Iteration 1400, loss = 0.12049
I1002 00:51:23.796217 23713 solver.cpp:259]     Train net output #0: error_blob = 0.12049 (* 1 = 0.12049 loss)
I1002 00:51:23.796222 23713 solver.cpp:590] Iteration 1400, lr = 0.01
I1002 00:51:26.346268 23713 solver.cpp:243] Iteration 1500, loss = 0.119794
I1002 00:51:26.346302 23713 solver.cpp:259]     Train net output #0: error_blob = 0.119794 (* 1 = 0.119794 loss)
I1002 00:51:26.346307 23713 solver.cpp:590] Iteration 1500, lr = 0.01
I1002 00:51:28.899269 23713 solver.cpp:243] Iteration 1600, loss = 0.122317
I1002 00:51:28.899302 23713 solver.cpp:259]     Train net output #0: error_blob = 0.122317 (* 1 = 0.122317 loss)
I1002 00:51:28.899305 23713 solver.cpp:590] Iteration 1600, lr = 0.01
I1002 00:51:31.445592 23713 solver.cpp:243] Iteration 1700, loss = 0.120664
I1002 00:51:31.445626 23713 solver.cpp:259]     Train net output #0: error_blob = 0.120664 (* 1 = 0.120664 loss)
I1002 00:51:31.445632 23713 solver.cpp:590] Iteration 1700, lr = 0.01
I1002 00:51:33.953869 23713 solver.cpp:243] Iteration 1800, loss = 0.120816
I1002 00:51:33.953899 23713 solver.cpp:259]     Train net output #0: error_blob = 0.120816 (* 1 = 0.120816 loss)
I1002 00:51:33.953904 23713 solver.cpp:590] Iteration 1800, lr = 0.01
I1002 00:51:34.155014 23713 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:51:36.487885 23713 solver.cpp:243] Iteration 1900, loss = 0.120592
I1002 00:51:36.487915 23713 solver.cpp:259]     Train net output #0: error_blob = 0.120592 (* 1 = 0.120592 loss)
I1002 00:51:36.487920 23713 solver.cpp:590] Iteration 1900, lr = 0.01
I1002 00:51:38.998489 23713 solver.cpp:347] Iteration 2000, Testing net (#0)
I1002 00:51:39.296744 23713 solver.cpp:415]     Test net output #0: error_blob = 0.1158 (* 1 = 0.1158 loss)
I1002 00:51:39.297380 23713 solver.cpp:243] Iteration 2000, loss = 0.120647
I1002 00:51:39.297392 23713 solver.cpp:259]     Train net output #0: error_blob = 0.120647 (* 1 = 0.120647 loss)
I1002 00:51:39.297399 23713 solver.cpp:590] Iteration 2000, lr = 0.01
I1002 00:51:41.773763 23713 solver.cpp:243] Iteration 2100, loss = 0.120594
I1002 00:51:41.773793 23713 solver.cpp:259]     Train net output #0: error_blob = 0.120594 (* 1 = 0.120594 loss)
I1002 00:51:41.773798 23713 solver.cpp:590] Iteration 2100, lr = 0.01
I1002 00:51:44.291198 23713 solver.cpp:243] Iteration 2200, loss = 0.118669
I1002 00:51:44.291307 23713 solver.cpp:259]     Train net output #0: error_blob = 0.118669 (* 1 = 0.118669 loss)
I1002 00:51:44.291313 23713 solver.cpp:590] Iteration 2200, lr = 0.01
I1002 00:51:46.792050 23713 solver.cpp:243] Iteration 2300, loss = 0.120586
I1002 00:51:46.792091 23713 solver.cpp:259]     Train net output #0: error_blob = 0.120586 (* 1 = 0.120586 loss)
I1002 00:51:46.792098 23713 solver.cpp:590] Iteration 2300, lr = 0.01
I1002 00:51:49.290248 23713 solver.cpp:243] Iteration 2400, loss = 0.120957
I1002 00:51:49.290289 23713 solver.cpp:259]     Train net output #0: error_blob = 0.120957 (* 1 = 0.120957 loss)
I1002 00:51:49.290293 23713 solver.cpp:590] Iteration 2400, lr = 0.01
I1002 00:51:51.826059 23713 solver.cpp:243] Iteration 2500, loss = 0.11996
I1002 00:51:51.826091 23713 solver.cpp:259]     Train net output #0: error_blob = 0.11996 (* 1 = 0.11996 loss)
I1002 00:51:51.826095 23713 solver.cpp:590] Iteration 2500, lr = 0.01
I1002 00:51:54.372827 23713 solver.cpp:243] Iteration 2600, loss = 0.12057
I1002 00:51:54.372859 23713 solver.cpp:259]     Train net output #0: error_blob = 0.12057 (* 1 = 0.12057 loss)
I1002 00:51:54.372864 23713 solver.cpp:590] Iteration 2600, lr = 0.01
I1002 00:51:56.919461 23713 solver.cpp:243] Iteration 2700, loss = 0.120413
I1002 00:51:56.919492 23713 solver.cpp:259]     Train net output #0: error_blob = 0.120413 (* 1 = 0.120413 loss)
I1002 00:51:56.919497 23713 solver.cpp:590] Iteration 2700, lr = 0.01
I1002 00:51:57.276406 23713 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:51:59.456078 23713 solver.cpp:243] Iteration 2800, loss = 0.12073
I1002 00:51:59.456118 23713 solver.cpp:259]     Train net output #0: error_blob = 0.12073 (* 1 = 0.12073 loss)
I1002 00:51:59.456125 23713 solver.cpp:590] Iteration 2800, lr = 0.01
I1002 00:52:01.947832 23713 solver.cpp:243] Iteration 2900, loss = 0.119623
I1002 00:52:01.947862 23713 solver.cpp:259]     Train net output #0: error_blob = 0.119623 (* 1 = 0.119623 loss)
I1002 00:52:01.947867 23713 solver.cpp:590] Iteration 2900, lr = 0.01
I1002 00:52:04.440850 23713 solver.cpp:347] Iteration 3000, Testing net (#0)
I1002 00:52:04.719260 23713 solver.cpp:415]     Test net output #0: error_blob = 0.115268 (* 1 = 0.115268 loss)
I1002 00:52:04.719949 23713 solver.cpp:243] Iteration 3000, loss = 0.120132
I1002 00:52:04.719964 23713 solver.cpp:259]     Train net output #0: error_blob = 0.120132 (* 1 = 0.120132 loss)
I1002 00:52:04.719970 23713 solver.cpp:590] Iteration 3000, lr = 0.01
I1002 00:52:07.195626 23713 solver.cpp:243] Iteration 3100, loss = 0.120827
I1002 00:52:07.195667 23713 solver.cpp:259]     Train net output #0: error_blob = 0.120827 (* 1 = 0.120827 loss)
I1002 00:52:07.195674 23713 solver.cpp:590] Iteration 3100, lr = 0.01
I1002 00:52:09.678275 23713 solver.cpp:243] Iteration 3200, loss = 0.118111
I1002 00:52:09.678308 23713 solver.cpp:259]     Train net output #0: error_blob = 0.118111 (* 1 = 0.118111 loss)
I1002 00:52:09.678313 23713 solver.cpp:590] Iteration 3200, lr = 0.01
I1002 00:52:12.226660 23713 solver.cpp:243] Iteration 3300, loss = 0.119673
I1002 00:52:12.226692 23713 solver.cpp:259]     Train net output #0: error_blob = 0.119673 (* 1 = 0.119673 loss)
I1002 00:52:12.226698 23713 solver.cpp:590] Iteration 3300, lr = 0.01
I1002 00:52:14.779500 23713 solver.cpp:243] Iteration 3400, loss = 0.119936
I1002 00:52:14.780498 23713 solver.cpp:259]     Train net output #0: error_blob = 0.119936 (* 1 = 0.119936 loss)
I1002 00:52:14.780510 23713 solver.cpp:590] Iteration 3400, lr = 0.01
I1002 00:52:17.270756 23713 solver.cpp:243] Iteration 3500, loss = 0.118255
I1002 00:52:17.270798 23713 solver.cpp:259]     Train net output #0: error_blob = 0.118255 (* 1 = 0.118255 loss)
I1002 00:52:17.270803 23713 solver.cpp:590] Iteration 3500, lr = 0.01
I1002 00:52:19.870684 23713 solver.cpp:243] Iteration 3600, loss = 0.118145
I1002 00:52:19.870714 23713 solver.cpp:259]     Train net output #0: error_blob = 0.118145 (* 1 = 0.118145 loss)
I1002 00:52:19.870719 23713 solver.cpp:590] Iteration 3600, lr = 0.01
I1002 00:52:20.355625 23713 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:52:22.366204 23713 solver.cpp:243] Iteration 3700, loss = 0.120481
I1002 00:52:22.366245 23713 solver.cpp:259]     Train net output #0: error_blob = 0.120481 (* 1 = 0.120481 loss)
I1002 00:52:22.366250 23713 solver.cpp:590] Iteration 3700, lr = 0.01
I1002 00:52:24.846899 23713 solver.cpp:243] Iteration 3800, loss = 0.11879
I1002 00:52:24.846930 23713 solver.cpp:259]     Train net output #0: error_blob = 0.11879 (* 1 = 0.11879 loss)
I1002 00:52:24.846935 23713 solver.cpp:590] Iteration 3800, lr = 0.01
I1002 00:52:27.384380 23713 solver.cpp:243] Iteration 3900, loss = 0.119797
I1002 00:52:27.384423 23713 solver.cpp:259]     Train net output #0: error_blob = 0.119797 (* 1 = 0.119797 loss)
I1002 00:52:27.384428 23713 solver.cpp:590] Iteration 3900, lr = 0.01
I1002 00:52:29.893329 23713 solver.cpp:347] Iteration 4000, Testing net (#0)
I1002 00:52:30.178769 23713 solver.cpp:415]     Test net output #0: error_blob = 0.11804 (* 1 = 0.11804 loss)
I1002 00:52:30.179388 23713 solver.cpp:243] Iteration 4000, loss = 0.118178
I1002 00:52:30.179401 23713 solver.cpp:259]     Train net output #0: error_blob = 0.118178 (* 1 = 0.118178 loss)
I1002 00:52:30.179407 23713 solver.cpp:590] Iteration 4000, lr = 0.01
I1002 00:52:32.747243 23713 solver.cpp:243] Iteration 4100, loss = 0.121946
I1002 00:52:32.747277 23713 solver.cpp:259]     Train net output #0: error_blob = 0.121946 (* 1 = 0.121946 loss)
I1002 00:52:32.747284 23713 solver.cpp:590] Iteration 4100, lr = 0.01
I1002 00:52:35.317502 23713 solver.cpp:243] Iteration 4200, loss = 0.117891
I1002 00:52:35.317533 23713 solver.cpp:259]     Train net output #0: error_blob = 0.117891 (* 1 = 0.117891 loss)
I1002 00:52:35.317538 23713 solver.cpp:590] Iteration 4200, lr = 0.01
I1002 00:52:37.828369 23713 solver.cpp:243] Iteration 4300, loss = 0.117604
I1002 00:52:37.828400 23713 solver.cpp:259]     Train net output #0: error_blob = 0.117604 (* 1 = 0.117604 loss)
I1002 00:52:37.828405 23713 solver.cpp:590] Iteration 4300, lr = 0.01
I1002 00:52:40.404606 23713 solver.cpp:243] Iteration 4400, loss = 0.119894
I1002 00:52:40.404639 23713 solver.cpp:259]     Train net output #0: error_blob = 0.119894 (* 1 = 0.119894 loss)
I1002 00:52:40.404645 23713 solver.cpp:590] Iteration 4400, lr = 0.01
I1002 00:52:42.965389 23713 solver.cpp:243] Iteration 4500, loss = 0.120116
I1002 00:52:42.965421 23713 solver.cpp:259]     Train net output #0: error_blob = 0.120116 (* 1 = 0.120116 loss)
I1002 00:52:42.965426 23713 solver.cpp:590] Iteration 4500, lr = 0.01
I1002 00:52:43.609042 23713 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:52:45.478662 23713 solver.cpp:243] Iteration 4600, loss = 0.11741
I1002 00:52:45.478723 23713 solver.cpp:259]     Train net output #0: error_blob = 0.11741 (* 1 = 0.11741 loss)
I1002 00:52:45.478727 23713 solver.cpp:590] Iteration 4600, lr = 0.01
I1002 00:52:47.997728 23713 solver.cpp:243] Iteration 4700, loss = 0.121753
I1002 00:52:47.997758 23713 solver.cpp:259]     Train net output #0: error_blob = 0.121753 (* 1 = 0.121753 loss)
I1002 00:52:47.997762 23713 solver.cpp:590] Iteration 4700, lr = 0.01
I1002 00:52:50.461611 23713 solver.cpp:243] Iteration 4800, loss = 0.119296
I1002 00:52:50.461642 23713 solver.cpp:259]     Train net output #0: error_blob = 0.119296 (* 1 = 0.119296 loss)
I1002 00:52:50.461645 23713 solver.cpp:590] Iteration 4800, lr = 0.01
I1002 00:52:53.008743 23713 solver.cpp:243] Iteration 4900, loss = 0.116572
I1002 00:52:53.008770 23713 solver.cpp:259]     Train net output #0: error_blob = 0.116572 (* 1 = 0.116572 loss)
I1002 00:52:53.008775 23713 solver.cpp:590] Iteration 4900, lr = 0.01
I1002 00:52:55.513264 23713 solver.cpp:347] Iteration 5000, Testing net (#0)
I1002 00:52:55.844271 23713 solver.cpp:415]     Test net output #0: error_blob = 0.120273 (* 1 = 0.120273 loss)
I1002 00:52:55.844890 23713 solver.cpp:243] Iteration 5000, loss = 0.116684
I1002 00:52:55.844902 23713 solver.cpp:259]     Train net output #0: error_blob = 0.116684 (* 1 = 0.116684 loss)
I1002 00:52:55.844908 23713 solver.cpp:590] Iteration 5000, lr = 0.01
I1002 00:52:58.362903 23713 solver.cpp:243] Iteration 5100, loss = 0.120239
I1002 00:52:58.362936 23713 solver.cpp:259]     Train net output #0: error_blob = 0.120239 (* 1 = 0.120239 loss)
I1002 00:52:58.362939 23713 solver.cpp:590] Iteration 5100, lr = 0.01
I1002 00:53:00.898491 23713 solver.cpp:243] Iteration 5200, loss = 0.118103
I1002 00:53:00.898522 23713 solver.cpp:259]     Train net output #0: error_blob = 0.118103 (* 1 = 0.118103 loss)
I1002 00:53:00.898529 23713 solver.cpp:590] Iteration 5200, lr = 0.01
I1002 00:53:03.366561 23713 solver.cpp:243] Iteration 5300, loss = 0.115965
I1002 00:53:03.366592 23713 solver.cpp:259]     Train net output #0: error_blob = 0.115965 (* 1 = 0.115965 loss)
I1002 00:53:03.366597 23713 solver.cpp:590] Iteration 5300, lr = 0.01
I1002 00:53:05.841102 23713 solver.cpp:243] Iteration 5400, loss = 0.119413
I1002 00:53:05.841142 23713 solver.cpp:259]     Train net output #0: error_blob = 0.119413 (* 1 = 0.119413 loss)
I1002 00:53:05.841148 23713 solver.cpp:590] Iteration 5400, lr = 0.01
I1002 00:53:06.633698 23713 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:53:08.309278 23713 solver.cpp:243] Iteration 5500, loss = 0.120982
I1002 00:53:08.309309 23713 solver.cpp:259]     Train net output #0: error_blob = 0.120982 (* 1 = 0.120982 loss)
I1002 00:53:08.309314 23713 solver.cpp:590] Iteration 5500, lr = 0.01
I1002 00:53:10.802656 23713 solver.cpp:243] Iteration 5600, loss = 0.118494
I1002 00:53:10.802685 23713 solver.cpp:259]     Train net output #0: error_blob = 0.118494 (* 1 = 0.118494 loss)
I1002 00:53:10.802690 23713 solver.cpp:590] Iteration 5600, lr = 0.01
I1002 00:53:13.327385 23713 solver.cpp:243] Iteration 5700, loss = 0.118867
I1002 00:53:13.327419 23713 solver.cpp:259]     Train net output #0: error_blob = 0.118867 (* 1 = 0.118867 loss)
I1002 00:53:13.327425 23713 solver.cpp:590] Iteration 5700, lr = 0.01
I1002 00:53:15.870748 23713 solver.cpp:243] Iteration 5800, loss = 0.11972
I1002 00:53:15.871855 23713 solver.cpp:259]     Train net output #0: error_blob = 0.11972 (* 1 = 0.11972 loss)
I1002 00:53:15.871873 23713 solver.cpp:590] Iteration 5800, lr = 0.01
I1002 00:53:18.423699 23713 solver.cpp:243] Iteration 5900, loss = 0.115838
I1002 00:53:18.423739 23713 solver.cpp:259]     Train net output #0: error_blob = 0.115838 (* 1 = 0.115838 loss)
I1002 00:53:18.423748 23713 solver.cpp:590] Iteration 5900, lr = 0.01
I1002 00:53:20.961765 23713 solver.cpp:347] Iteration 6000, Testing net (#0)
I1002 00:53:21.254040 23713 solver.cpp:415]     Test net output #0: error_blob = 0.112461 (* 1 = 0.112461 loss)
I1002 00:53:21.254714 23713 solver.cpp:243] Iteration 6000, loss = 0.115446
I1002 00:53:21.254732 23713 solver.cpp:259]     Train net output #0: error_blob = 0.115446 (* 1 = 0.115446 loss)
I1002 00:53:21.254740 23713 solver.cpp:590] Iteration 6000, lr = 0.01
I1002 00:53:23.717886 23713 solver.cpp:243] Iteration 6100, loss = 0.119137
I1002 00:53:23.717926 23713 solver.cpp:259]     Train net output #0: error_blob = 0.119137 (* 1 = 0.119137 loss)
I1002 00:53:23.717936 23713 solver.cpp:590] Iteration 6100, lr = 0.01
I1002 00:53:26.281316 23713 solver.cpp:243] Iteration 6200, loss = 0.118529
I1002 00:53:26.281365 23713 solver.cpp:259]     Train net output #0: error_blob = 0.118529 (* 1 = 0.118529 loss)
I1002 00:53:26.281373 23713 solver.cpp:590] Iteration 6200, lr = 0.01
I1002 00:53:28.872370 23713 solver.cpp:243] Iteration 6300, loss = 0.115042
I1002 00:53:28.872405 23713 solver.cpp:259]     Train net output #0: error_blob = 0.115042 (* 1 = 0.115042 loss)
I1002 00:53:28.872412 23713 solver.cpp:590] Iteration 6300, lr = 0.01
I1002 00:53:29.845573 23713 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:53:31.461719 23713 solver.cpp:243] Iteration 6400, loss = 0.11759
I1002 00:53:31.461750 23713 solver.cpp:259]     Train net output #0: error_blob = 0.11759 (* 1 = 0.11759 loss)
I1002 00:53:31.461757 23713 solver.cpp:590] Iteration 6400, lr = 0.01
I1002 00:53:33.990870 23713 solver.cpp:243] Iteration 6500, loss = 0.12047
I1002 00:53:33.990902 23713 solver.cpp:259]     Train net output #0: error_blob = 0.12047 (* 1 = 0.12047 loss)
I1002 00:53:33.990908 23713 solver.cpp:590] Iteration 6500, lr = 0.01
I1002 00:53:36.513283 23713 solver.cpp:243] Iteration 6600, loss = 0.115734
I1002 00:53:36.513315 23713 solver.cpp:259]     Train net output #0: error_blob = 0.115734 (* 1 = 0.115734 loss)
I1002 00:53:36.513321 23713 solver.cpp:590] Iteration 6600, lr = 0.01
I1002 00:53:39.082245 23713 solver.cpp:243] Iteration 6700, loss = 0.116765
I1002 00:53:39.082281 23713 solver.cpp:259]     Train net output #0: error_blob = 0.116765 (* 1 = 0.116765 loss)
I1002 00:53:39.082288 23713 solver.cpp:590] Iteration 6700, lr = 0.01
I1002 00:53:41.614573 23713 solver.cpp:243] Iteration 6800, loss = 0.119969
I1002 00:53:41.614601 23713 solver.cpp:259]     Train net output #0: error_blob = 0.119969 (* 1 = 0.119969 loss)
I1002 00:53:41.614608 23713 solver.cpp:590] Iteration 6800, lr = 0.01
I1002 00:53:44.177621 23713 solver.cpp:243] Iteration 6900, loss = 0.117084
I1002 00:53:44.177669 23713 solver.cpp:259]     Train net output #0: error_blob = 0.117084 (* 1 = 0.117084 loss)
I1002 00:53:44.177677 23713 solver.cpp:590] Iteration 6900, lr = 0.01
I1002 00:53:46.737443 23713 solver.cpp:347] Iteration 7000, Testing net (#0)
I1002 00:53:47.009140 23713 solver.cpp:415]     Test net output #0: error_blob = 0.109783 (* 1 = 0.109783 loss)
I1002 00:53:47.009791 23713 solver.cpp:243] Iteration 7000, loss = 0.116293
I1002 00:53:47.009809 23713 solver.cpp:259]     Train net output #0: error_blob = 0.116293 (* 1 = 0.116293 loss)
I1002 00:53:47.009814 23713 solver.cpp:590] Iteration 7000, lr = 0.01
I1002 00:53:49.562556 23713 solver.cpp:243] Iteration 7100, loss = 0.119078
I1002 00:53:49.562594 23713 solver.cpp:259]     Train net output #0: error_blob = 0.119078 (* 1 = 0.119078 loss)
I1002 00:53:49.562602 23713 solver.cpp:590] Iteration 7100, lr = 0.01
I1002 00:53:52.143210 23713 solver.cpp:243] Iteration 7200, loss = 0.118816
I1002 00:53:52.143247 23713 solver.cpp:259]     Train net output #0: error_blob = 0.118816 (* 1 = 0.118816 loss)
I1002 00:53:52.143255 23713 solver.cpp:590] Iteration 7200, lr = 0.01
I1002 00:53:53.292984 23713 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:53:54.716279 23713 solver.cpp:243] Iteration 7300, loss = 0.118519
I1002 00:53:54.716327 23713 solver.cpp:259]     Train net output #0: error_blob = 0.118519 (* 1 = 0.118519 loss)
I1002 00:53:54.716336 23713 solver.cpp:590] Iteration 7300, lr = 0.01
I1002 00:53:57.254807 23713 solver.cpp:243] Iteration 7400, loss = 0.116844
I1002 00:53:57.254844 23713 solver.cpp:259]     Train net output #0: error_blob = 0.116844 (* 1 = 0.116844 loss)
I1002 00:53:57.254853 23713 solver.cpp:590] Iteration 7400, lr = 0.01
I1002 00:53:59.855345 23713 solver.cpp:243] Iteration 7500, loss = 0.118952
I1002 00:53:59.855389 23713 solver.cpp:259]     Train net output #0: error_blob = 0.118952 (* 1 = 0.118952 loss)
I1002 00:53:59.855398 23713 solver.cpp:590] Iteration 7500, lr = 0.01
I1002 00:54:02.384169 23713 solver.cpp:243] Iteration 7600, loss = 0.115161
I1002 00:54:02.384213 23713 solver.cpp:259]     Train net output #0: error_blob = 0.115161 (* 1 = 0.115161 loss)
I1002 00:54:02.384219 23713 solver.cpp:590] Iteration 7600, lr = 0.01
I1002 00:54:04.914438 23713 solver.cpp:243] Iteration 7700, loss = 0.118601
I1002 00:54:04.914469 23713 solver.cpp:259]     Train net output #0: error_blob = 0.118601 (* 1 = 0.118601 loss)
I1002 00:54:04.914474 23713 solver.cpp:590] Iteration 7700, lr = 0.01
I1002 00:54:07.486546 23713 solver.cpp:243] Iteration 7800, loss = 0.118474
I1002 00:54:07.486582 23713 solver.cpp:259]     Train net output #0: error_blob = 0.118474 (* 1 = 0.118474 loss)
I1002 00:54:07.486591 23713 solver.cpp:590] Iteration 7800, lr = 0.01
I1002 00:54:10.042201 23713 solver.cpp:243] Iteration 7900, loss = 0.117885
I1002 00:54:10.042239 23713 solver.cpp:259]     Train net output #0: error_blob = 0.117885 (* 1 = 0.117885 loss)
I1002 00:54:10.042248 23713 solver.cpp:590] Iteration 7900, lr = 0.01
I1002 00:54:12.551764 23713 solver.cpp:347] Iteration 8000, Testing net (#0)
I1002 00:54:12.824728 23713 solver.cpp:415]     Test net output #0: error_blob = 0.109971 (* 1 = 0.109971 loss)
I1002 00:54:12.825345 23713 solver.cpp:243] Iteration 8000, loss = 0.113058
I1002 00:54:12.825356 23713 solver.cpp:259]     Train net output #0: error_blob = 0.113058 (* 1 = 0.113058 loss)
I1002 00:54:12.825359 23713 solver.cpp:590] Iteration 8000, lr = 0.01
I1002 00:54:15.390080 23713 solver.cpp:243] Iteration 8100, loss = 0.117041
I1002 00:54:15.390110 23713 solver.cpp:259]     Train net output #0: error_blob = 0.117041 (* 1 = 0.117041 loss)
I1002 00:54:15.390115 23713 solver.cpp:590] Iteration 8100, lr = 0.01
I1002 00:54:16.651926 23713 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:54:17.924271 23713 solver.cpp:243] Iteration 8200, loss = 0.118686
I1002 00:54:17.925290 23713 solver.cpp:259]     Train net output #0: error_blob = 0.118686 (* 1 = 0.118686 loss)
I1002 00:54:17.925298 23713 solver.cpp:590] Iteration 8200, lr = 0.01
I1002 00:54:20.433022 23713 solver.cpp:243] Iteration 8300, loss = 0.11396
I1002 00:54:20.433051 23713 solver.cpp:259]     Train net output #0: error_blob = 0.11396 (* 1 = 0.11396 loss)
I1002 00:54:20.433056 23713 solver.cpp:590] Iteration 8300, lr = 0.01
I1002 00:54:22.943641 23713 solver.cpp:243] Iteration 8400, loss = 0.11577
I1002 00:54:22.943682 23713 solver.cpp:259]     Train net output #0: error_blob = 0.11577 (* 1 = 0.11577 loss)
I1002 00:54:22.943687 23713 solver.cpp:590] Iteration 8400, lr = 0.01
I1002 00:54:25.478906 23713 solver.cpp:243] Iteration 8500, loss = 0.11762
I1002 00:54:25.478938 23713 solver.cpp:259]     Train net output #0: error_blob = 0.11762 (* 1 = 0.11762 loss)
I1002 00:54:25.478945 23713 solver.cpp:590] Iteration 8500, lr = 0.01
I1002 00:54:28.003002 23713 solver.cpp:243] Iteration 8600, loss = 0.11661
I1002 00:54:28.003033 23713 solver.cpp:259]     Train net output #0: error_blob = 0.11661 (* 1 = 0.11661 loss)
I1002 00:54:28.003038 23713 solver.cpp:590] Iteration 8600, lr = 0.01
I1002 00:54:30.545398 23713 solver.cpp:243] Iteration 8700, loss = 0.113801
I1002 00:54:30.545428 23713 solver.cpp:259]     Train net output #0: error_blob = 0.113801 (* 1 = 0.113801 loss)
I1002 00:54:30.545433 23713 solver.cpp:590] Iteration 8700, lr = 0.01
I1002 00:54:33.064167 23713 solver.cpp:243] Iteration 8800, loss = 0.118926
I1002 00:54:33.064198 23713 solver.cpp:259]     Train net output #0: error_blob = 0.118926 (* 1 = 0.118926 loss)
I1002 00:54:33.064203 23713 solver.cpp:590] Iteration 8800, lr = 0.01
I1002 00:54:35.575729 23713 solver.cpp:243] Iteration 8900, loss = 0.117751
I1002 00:54:35.575762 23713 solver.cpp:259]     Train net output #0: error_blob = 0.117751 (* 1 = 0.117751 loss)
I1002 00:54:35.575767 23713 solver.cpp:590] Iteration 8900, lr = 0.01
I1002 00:54:38.053359 23713 solver.cpp:347] Iteration 9000, Testing net (#0)
I1002 00:54:38.347785 23713 solver.cpp:415]     Test net output #0: error_blob = 0.109604 (* 1 = 0.109604 loss)
I1002 00:54:38.348402 23713 solver.cpp:243] Iteration 9000, loss = 0.113211
I1002 00:54:38.348415 23713 solver.cpp:259]     Train net output #0: error_blob = 0.113211 (* 1 = 0.113211 loss)
I1002 00:54:38.348419 23713 solver.cpp:590] Iteration 9000, lr = 0.01
I1002 00:54:39.749905 23713 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:54:40.855048 23713 solver.cpp:243] Iteration 9100, loss = 0.11752
I1002 00:54:40.855080 23713 solver.cpp:259]     Train net output #0: error_blob = 0.11752 (* 1 = 0.11752 loss)
I1002 00:54:40.855087 23713 solver.cpp:590] Iteration 9100, lr = 0.01
I1002 00:54:43.433326 23713 solver.cpp:243] Iteration 9200, loss = 0.11876
I1002 00:54:43.433357 23713 solver.cpp:259]     Train net output #0: error_blob = 0.11876 (* 1 = 0.11876 loss)
I1002 00:54:43.433362 23713 solver.cpp:590] Iteration 9200, lr = 0.01
I1002 00:54:45.934074 23713 solver.cpp:243] Iteration 9300, loss = 0.115855
I1002 00:54:45.934104 23713 solver.cpp:259]     Train net output #0: error_blob = 0.115855 (* 1 = 0.115855 loss)
I1002 00:54:45.934109 23713 solver.cpp:590] Iteration 9300, lr = 0.01
I1002 00:54:48.484540 23713 solver.cpp:243] Iteration 9400, loss = 0.114435
I1002 00:54:48.485582 23713 solver.cpp:259]     Train net output #0: error_blob = 0.114435 (* 1 = 0.114435 loss)
I1002 00:54:48.485590 23713 solver.cpp:590] Iteration 9400, lr = 0.01
I1002 00:54:51.013651 23713 solver.cpp:243] Iteration 9500, loss = 0.119031
I1002 00:54:51.013681 23713 solver.cpp:259]     Train net output #0: error_blob = 0.119031 (* 1 = 0.119031 loss)
I1002 00:54:51.013686 23713 solver.cpp:590] Iteration 9500, lr = 0.01
I1002 00:54:53.538339 23713 solver.cpp:243] Iteration 9600, loss = 0.118525
I1002 00:54:53.538370 23713 solver.cpp:259]     Train net output #0: error_blob = 0.118525 (* 1 = 0.118525 loss)
I1002 00:54:53.538374 23713 solver.cpp:590] Iteration 9600, lr = 0.01
I1002 00:54:56.081147 23713 solver.cpp:243] Iteration 9700, loss = 0.123091
I1002 00:54:56.081178 23713 solver.cpp:259]     Train net output #0: error_blob = 0.123091 (* 1 = 0.123091 loss)
I1002 00:54:56.081183 23713 solver.cpp:590] Iteration 9700, lr = 0.01
I1002 00:54:58.605060 23713 solver.cpp:243] Iteration 9800, loss = 0.115948
I1002 00:54:58.605090 23713 solver.cpp:259]     Train net output #0: error_blob = 0.115948 (* 1 = 0.115948 loss)
I1002 00:54:58.605095 23713 solver.cpp:590] Iteration 9800, lr = 0.01
I1002 00:55:01.081581 23713 solver.cpp:243] Iteration 9900, loss = 0.118492
I1002 00:55:01.081615 23713 solver.cpp:259]     Train net output #0: error_blob = 0.118492 (* 1 = 0.118492 loss)
I1002 00:55:01.081621 23713 solver.cpp:590] Iteration 9900, lr = 0.01
I1002 00:55:03.539124 23713 solver.cpp:468] Snapshotting to binary proto file _iter_10000.caffemodel
I1002 00:55:03.540880 23713 solver.cpp:753] Snapshotting solver state to binary proto file _iter_10000.solverstate
I1002 00:55:03.563554 23713 solver.cpp:327] Iteration 10000, loss = 0.116237
I1002 00:55:03.563580 23713 solver.cpp:347] Iteration 10000, Testing net (#0)
I1002 00:55:03.729378 23713 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:55:03.833199 23713 solver.cpp:415]     Test net output #0: error_blob = 0.109106 (* 1 = 0.109106 loss)
I1002 00:55:03.833231 23713 solver.cpp:332] Optimization Done.
I1002 00:55:03.833236 23713 caffe.cpp:215] Optimization Done.
I1002 00:55:03.893671 23724 caffe.cpp:184] Using GPUs 0
I1002 00:55:04.452817 23724 solver.cpp:54] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "fixed"
momentum: 0.9
solver_mode: GPU
device_id: 0
net: "model/NNScore/nnscore_model_4.prototxt"
I1002 00:55:04.452848 23724 solver.cpp:97] Creating training net from net file: model/NNScore/nnscore_model_4.prototxt
I1002 00:55:04.453017 23724 net.cpp:339] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_layer
I1002 00:55:04.453063 23724 net.cpp:50] Initializing net from parameters: 
name: "model/NNScore/nnscore_model_4.prototxt"
state {
  phase: TRAIN
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TRAIN
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.4.train"
    batch_size: 20000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1002 00:55:04.453126 23724 layer_factory.hpp:76] Creating layer data_layer
I1002 00:55:04.466018 23724 net.cpp:110] Creating Layer data_layer
I1002 00:55:04.466048 23724 net.cpp:433] data_layer -> data_blob
I1002 00:55:04.466083 23724 net.cpp:433] data_layer -> label_blob
I1002 00:55:04.466677 23728 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.4.train
I1002 00:55:05.149425 23724 data_layer.cpp:45] output data size: 20000,61,1,1
I1002 00:55:05.154417 23724 net.cpp:155] Setting up data_layer
I1002 00:55:05.154458 23724 net.cpp:163] Top shape: 20000 61 1 1 (1220000)
I1002 00:55:05.154463 23724 net.cpp:163] Top shape: 20000 (20000)
I1002 00:55:05.154479 23724 layer_factory.hpp:76] Creating layer hidden_sum_layer
I1002 00:55:05.154491 23724 net.cpp:110] Creating Layer hidden_sum_layer
I1002 00:55:05.154495 23724 net.cpp:477] hidden_sum_layer <- data_blob
I1002 00:55:05.154503 23724 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I1002 00:55:05.154881 23724 net.cpp:155] Setting up hidden_sum_layer
I1002 00:55:05.154888 23724 net.cpp:163] Top shape: 20000 10 (200000)
I1002 00:55:05.154911 23724 layer_factory.hpp:76] Creating layer hidden_act_layer
I1002 00:55:05.154927 23724 net.cpp:110] Creating Layer hidden_act_layer
I1002 00:55:05.154930 23724 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I1002 00:55:05.154933 23724 net.cpp:433] hidden_act_layer -> hidden_act_blob
I1002 00:55:08.389164 23724 net.cpp:155] Setting up hidden_act_layer
I1002 00:55:08.389195 23724 net.cpp:163] Top shape: 20000 10 (200000)
I1002 00:55:08.389200 23724 layer_factory.hpp:76] Creating layer output_sum_layer
I1002 00:55:08.389211 23724 net.cpp:110] Creating Layer output_sum_layer
I1002 00:55:08.389214 23724 net.cpp:477] output_sum_layer <- hidden_act_blob
I1002 00:55:08.389219 23724 net.cpp:433] output_sum_layer -> output_sum_blob
I1002 00:55:08.389309 23724 net.cpp:155] Setting up output_sum_layer
I1002 00:55:08.389314 23724 net.cpp:163] Top shape: 20000 1 (20000)
I1002 00:55:08.389330 23724 layer_factory.hpp:76] Creating layer output_act_layer
I1002 00:55:08.389336 23724 net.cpp:110] Creating Layer output_act_layer
I1002 00:55:08.389338 23724 net.cpp:477] output_act_layer <- output_sum_blob
I1002 00:55:08.389341 23724 net.cpp:433] output_act_layer -> output_act_blob
I1002 00:55:08.389405 23724 net.cpp:155] Setting up output_act_layer
I1002 00:55:08.389422 23724 net.cpp:163] Top shape: 20000 1 (20000)
I1002 00:55:08.389436 23724 layer_factory.hpp:76] Creating layer error_layer
I1002 00:55:08.389441 23724 net.cpp:110] Creating Layer error_layer
I1002 00:55:08.389442 23724 net.cpp:477] error_layer <- output_act_blob
I1002 00:55:08.389446 23724 net.cpp:477] error_layer <- label_blob
I1002 00:55:08.389448 23724 net.cpp:433] error_layer -> error_blob
I1002 00:55:08.389472 23724 net.cpp:155] Setting up error_layer
I1002 00:55:08.389477 23724 net.cpp:163] Top shape: (1)
I1002 00:55:08.389478 23724 net.cpp:168]     with loss weight 1
I1002 00:55:08.389495 23724 net.cpp:236] error_layer needs backward computation.
I1002 00:55:08.389497 23724 net.cpp:236] output_act_layer needs backward computation.
I1002 00:55:08.389499 23724 net.cpp:236] output_sum_layer needs backward computation.
I1002 00:55:08.389502 23724 net.cpp:236] hidden_act_layer needs backward computation.
I1002 00:55:08.389503 23724 net.cpp:236] hidden_sum_layer needs backward computation.
I1002 00:55:08.389505 23724 net.cpp:240] data_layer does not need backward computation.
I1002 00:55:08.389508 23724 net.cpp:283] This network produces output error_blob
I1002 00:55:08.389513 23724 net.cpp:297] Network initialization done.
I1002 00:55:08.389514 23724 net.cpp:298] Memory required for data: 6720004
I1002 00:55:08.389646 23724 solver.cpp:187] Creating test net (#0) specified by net file: model/NNScore/nnscore_model_4.prototxt
I1002 00:55:08.389667 23724 net.cpp:339] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_layer
I1002 00:55:08.389698 23724 net.cpp:50] Initializing net from parameters: 
name: "model/NNScore/nnscore_model_4.prototxt"
state {
  phase: TEST
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TEST
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.4.test"
    batch_size: 2000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1002 00:55:08.389739 23724 layer_factory.hpp:76] Creating layer data_layer
I1002 00:55:08.390986 23724 net.cpp:110] Creating Layer data_layer
I1002 00:55:08.391002 23724 net.cpp:433] data_layer -> data_blob
I1002 00:55:08.391006 23724 net.cpp:433] data_layer -> label_blob
I1002 00:55:08.391695 23730 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.4.test
I1002 00:55:08.391762 23724 data_layer.cpp:45] output data size: 2000,61,1,1
I1002 00:55:08.393158 23724 net.cpp:155] Setting up data_layer
I1002 00:55:08.393170 23724 net.cpp:163] Top shape: 2000 61 1 1 (122000)
I1002 00:55:08.393173 23724 net.cpp:163] Top shape: 2000 (2000)
I1002 00:55:08.393177 23724 layer_factory.hpp:76] Creating layer hidden_sum_layer
I1002 00:55:08.393183 23724 net.cpp:110] Creating Layer hidden_sum_layer
I1002 00:55:08.393185 23724 net.cpp:477] hidden_sum_layer <- data_blob
I1002 00:55:08.393189 23724 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I1002 00:55:08.393317 23724 net.cpp:155] Setting up hidden_sum_layer
I1002 00:55:08.393323 23724 net.cpp:163] Top shape: 2000 10 (20000)
I1002 00:55:08.393331 23724 layer_factory.hpp:76] Creating layer hidden_act_layer
I1002 00:55:08.393335 23724 net.cpp:110] Creating Layer hidden_act_layer
I1002 00:55:08.393337 23724 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I1002 00:55:08.393352 23724 net.cpp:433] hidden_act_layer -> hidden_act_blob
I1002 00:55:08.393532 23724 net.cpp:155] Setting up hidden_act_layer
I1002 00:55:08.393539 23724 net.cpp:163] Top shape: 2000 10 (20000)
I1002 00:55:08.393542 23724 layer_factory.hpp:76] Creating layer output_sum_layer
I1002 00:55:08.393546 23724 net.cpp:110] Creating Layer output_sum_layer
I1002 00:55:08.393548 23724 net.cpp:477] output_sum_layer <- hidden_act_blob
I1002 00:55:08.393553 23724 net.cpp:433] output_sum_layer -> output_sum_blob
I1002 00:55:08.393610 23724 net.cpp:155] Setting up output_sum_layer
I1002 00:55:08.393615 23724 net.cpp:163] Top shape: 2000 1 (2000)
I1002 00:55:08.393620 23724 layer_factory.hpp:76] Creating layer output_act_layer
I1002 00:55:08.393625 23724 net.cpp:110] Creating Layer output_act_layer
I1002 00:55:08.393626 23724 net.cpp:477] output_act_layer <- output_sum_blob
I1002 00:55:08.393630 23724 net.cpp:433] output_act_layer -> output_act_blob
I1002 00:55:08.393678 23724 net.cpp:155] Setting up output_act_layer
I1002 00:55:08.393682 23724 net.cpp:163] Top shape: 2000 1 (2000)
I1002 00:55:08.393684 23724 layer_factory.hpp:76] Creating layer error_layer
I1002 00:55:08.393688 23724 net.cpp:110] Creating Layer error_layer
I1002 00:55:08.393689 23724 net.cpp:477] error_layer <- output_act_blob
I1002 00:55:08.393692 23724 net.cpp:477] error_layer <- label_blob
I1002 00:55:08.393695 23724 net.cpp:433] error_layer -> error_blob
I1002 00:55:08.393714 23724 net.cpp:155] Setting up error_layer
I1002 00:55:08.393718 23724 net.cpp:163] Top shape: (1)
I1002 00:55:08.393719 23724 net.cpp:168]     with loss weight 1
I1002 00:55:08.393728 23724 net.cpp:236] error_layer needs backward computation.
I1002 00:55:08.393729 23724 net.cpp:236] output_act_layer needs backward computation.
I1002 00:55:08.393731 23724 net.cpp:236] output_sum_layer needs backward computation.
I1002 00:55:08.393733 23724 net.cpp:236] hidden_act_layer needs backward computation.
I1002 00:55:08.393735 23724 net.cpp:236] hidden_sum_layer needs backward computation.
I1002 00:55:08.393738 23724 net.cpp:240] data_layer does not need backward computation.
I1002 00:55:08.393739 23724 net.cpp:283] This network produces output error_blob
I1002 00:55:08.393744 23724 net.cpp:297] Network initialization done.
I1002 00:55:08.393745 23724 net.cpp:298] Memory required for data: 672004
I1002 00:55:08.393765 23724 solver.cpp:66] Solver scaffolding done.
I1002 00:55:08.393857 23724 caffe.cpp:212] Starting Optimization
I1002 00:55:08.393863 23724 solver.cpp:294] Solving model/NNScore/nnscore_model_4.prototxt
I1002 00:55:08.393865 23724 solver.cpp:295] Learning Rate Policy: fixed
I1002 00:55:08.394003 23724 solver.cpp:347] Iteration 0, Testing net (#0)
I1002 00:55:08.394053 23724 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:55:08.660341 23724 solver.cpp:415]     Test net output #0: error_blob = 0.128905 (* 1 = 0.128905 loss)
I1002 00:55:08.661646 23724 solver.cpp:243] Iteration 0, loss = 0.128237
I1002 00:55:08.661659 23724 solver.cpp:259]     Train net output #0: error_blob = 0.128237 (* 1 = 0.128237 loss)
I1002 00:55:08.661669 23724 solver.cpp:590] Iteration 0, lr = 0.01
I1002 00:55:11.168699 23724 solver.cpp:243] Iteration 100, loss = 0.121812
I1002 00:55:11.168730 23724 solver.cpp:259]     Train net output #0: error_blob = 0.121812 (* 1 = 0.121812 loss)
I1002 00:55:11.168735 23724 solver.cpp:590] Iteration 100, lr = 0.01
I1002 00:55:13.661320 23724 solver.cpp:243] Iteration 200, loss = 0.118906
I1002 00:55:13.661360 23724 solver.cpp:259]     Train net output #0: error_blob = 0.118906 (* 1 = 0.118906 loss)
I1002 00:55:13.661365 23724 solver.cpp:590] Iteration 200, lr = 0.01
I1002 00:55:16.178324 23724 solver.cpp:243] Iteration 300, loss = 0.121059
I1002 00:55:16.178366 23724 solver.cpp:259]     Train net output #0: error_blob = 0.121059 (* 1 = 0.121059 loss)
I1002 00:55:16.178370 23724 solver.cpp:590] Iteration 300, lr = 0.01
I1002 00:55:18.728443 23724 solver.cpp:243] Iteration 400, loss = 0.120419
I1002 00:55:18.728531 23724 solver.cpp:259]     Train net output #0: error_blob = 0.120419 (* 1 = 0.120419 loss)
I1002 00:55:18.728539 23724 solver.cpp:590] Iteration 400, lr = 0.01
I1002 00:55:21.215312 23724 solver.cpp:243] Iteration 500, loss = 0.120095
I1002 00:55:21.215354 23724 solver.cpp:259]     Train net output #0: error_blob = 0.120095 (* 1 = 0.120095 loss)
I1002 00:55:21.215360 23724 solver.cpp:590] Iteration 500, lr = 0.01
I1002 00:55:23.731492 23724 solver.cpp:243] Iteration 600, loss = 0.119189
I1002 00:55:23.731528 23724 solver.cpp:259]     Train net output #0: error_blob = 0.119189 (* 1 = 0.119189 loss)
I1002 00:55:23.731535 23724 solver.cpp:590] Iteration 600, lr = 0.01
I1002 00:55:26.258908 23724 solver.cpp:243] Iteration 700, loss = 0.119152
I1002 00:55:26.258949 23724 solver.cpp:259]     Train net output #0: error_blob = 0.119152 (* 1 = 0.119152 loss)
I1002 00:55:26.258954 23724 solver.cpp:590] Iteration 700, lr = 0.01
I1002 00:55:28.759480 23724 solver.cpp:243] Iteration 800, loss = 0.119201
I1002 00:55:28.759521 23724 solver.cpp:259]     Train net output #0: error_blob = 0.119201 (* 1 = 0.119201 loss)
I1002 00:55:28.759526 23724 solver.cpp:590] Iteration 800, lr = 0.01
I1002 00:55:31.239830 23724 solver.cpp:243] Iteration 900, loss = 0.120801
I1002 00:55:31.239866 23724 solver.cpp:259]     Train net output #0: error_blob = 0.120801 (* 1 = 0.120801 loss)
I1002 00:55:31.239876 23724 solver.cpp:590] Iteration 900, lr = 0.01
I1002 00:55:31.288803 23724 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:55:33.710532 23724 solver.cpp:347] Iteration 1000, Testing net (#0)
I1002 00:55:34.012370 23724 solver.cpp:415]     Test net output #0: error_blob = 0.116536 (* 1 = 0.116536 loss)
I1002 00:55:34.013070 23724 solver.cpp:243] Iteration 1000, loss = 0.119544
I1002 00:55:34.013082 23724 solver.cpp:259]     Train net output #0: error_blob = 0.119544 (* 1 = 0.119544 loss)
I1002 00:55:34.013087 23724 solver.cpp:590] Iteration 1000, lr = 0.01
I1002 00:55:36.507006 23724 solver.cpp:243] Iteration 1100, loss = 0.116372
I1002 00:55:36.507043 23724 solver.cpp:259]     Train net output #0: error_blob = 0.116372 (* 1 = 0.116372 loss)
I1002 00:55:36.507050 23724 solver.cpp:590] Iteration 1100, lr = 0.01
I1002 00:55:39.012048 23724 solver.cpp:243] Iteration 1200, loss = 0.119742
I1002 00:55:39.012095 23724 solver.cpp:259]     Train net output #0: error_blob = 0.119742 (* 1 = 0.119742 loss)
I1002 00:55:39.012102 23724 solver.cpp:590] Iteration 1200, lr = 0.01
I1002 00:55:41.493938 23724 solver.cpp:243] Iteration 1300, loss = 0.119347
I1002 00:55:41.493968 23724 solver.cpp:259]     Train net output #0: error_blob = 0.119347 (* 1 = 0.119347 loss)
I1002 00:55:41.493973 23724 solver.cpp:590] Iteration 1300, lr = 0.01
I1002 00:55:43.987471 23724 solver.cpp:243] Iteration 1400, loss = 0.119484
I1002 00:55:43.987501 23724 solver.cpp:259]     Train net output #0: error_blob = 0.119484 (* 1 = 0.119484 loss)
I1002 00:55:43.987506 23724 solver.cpp:590] Iteration 1400, lr = 0.01
I1002 00:55:46.540719 23724 solver.cpp:243] Iteration 1500, loss = 0.118188
I1002 00:55:46.540756 23724 solver.cpp:259]     Train net output #0: error_blob = 0.118188 (* 1 = 0.118188 loss)
I1002 00:55:46.540763 23724 solver.cpp:590] Iteration 1500, lr = 0.01
I1002 00:55:49.069470 23724 solver.cpp:243] Iteration 1600, loss = 0.11719
I1002 00:55:49.069500 23724 solver.cpp:259]     Train net output #0: error_blob = 0.11719 (* 1 = 0.11719 loss)
I1002 00:55:49.069505 23724 solver.cpp:590] Iteration 1600, lr = 0.01
I1002 00:55:51.582671 23724 solver.cpp:243] Iteration 1700, loss = 0.118584
I1002 00:55:51.582708 23724 solver.cpp:259]     Train net output #0: error_blob = 0.118584 (* 1 = 0.118584 loss)
I1002 00:55:51.582717 23724 solver.cpp:590] Iteration 1700, lr = 0.01
I1002 00:55:54.077061 23724 solver.cpp:243] Iteration 1800, loss = 0.119323
I1002 00:55:54.077091 23724 solver.cpp:259]     Train net output #0: error_blob = 0.119323 (* 1 = 0.119323 loss)
I1002 00:55:54.077097 23724 solver.cpp:590] Iteration 1800, lr = 0.01
I1002 00:55:54.273211 23724 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:55:56.579710 23724 solver.cpp:243] Iteration 1900, loss = 0.117369
I1002 00:55:56.579741 23724 solver.cpp:259]     Train net output #0: error_blob = 0.117369 (* 1 = 0.117369 loss)
I1002 00:55:56.579746 23724 solver.cpp:590] Iteration 1900, lr = 0.01
I1002 00:55:59.053175 23724 solver.cpp:347] Iteration 2000, Testing net (#0)
I1002 00:55:59.325667 23724 solver.cpp:415]     Test net output #0: error_blob = 0.117106 (* 1 = 0.117106 loss)
I1002 00:55:59.326339 23724 solver.cpp:243] Iteration 2000, loss = 0.117945
I1002 00:55:59.326376 23724 solver.cpp:259]     Train net output #0: error_blob = 0.117945 (* 1 = 0.117945 loss)
I1002 00:55:59.326383 23724 solver.cpp:590] Iteration 2000, lr = 0.01
I1002 00:56:01.813256 23724 solver.cpp:243] Iteration 2100, loss = 0.118155
I1002 00:56:01.813292 23724 solver.cpp:259]     Train net output #0: error_blob = 0.118155 (* 1 = 0.118155 loss)
I1002 00:56:01.813299 23724 solver.cpp:590] Iteration 2100, lr = 0.01
I1002 00:56:04.326522 23724 solver.cpp:243] Iteration 2200, loss = 0.118569
I1002 00:56:04.326928 23724 solver.cpp:259]     Train net output #0: error_blob = 0.118569 (* 1 = 0.118569 loss)
I1002 00:56:04.326937 23724 solver.cpp:590] Iteration 2200, lr = 0.01
I1002 00:56:06.777086 23724 solver.cpp:243] Iteration 2300, loss = 0.118288
I1002 00:56:06.777118 23724 solver.cpp:259]     Train net output #0: error_blob = 0.118288 (* 1 = 0.118288 loss)
I1002 00:56:06.777124 23724 solver.cpp:590] Iteration 2300, lr = 0.01
I1002 00:56:09.206531 23724 solver.cpp:243] Iteration 2400, loss = 0.11592
I1002 00:56:09.206559 23724 solver.cpp:259]     Train net output #0: error_blob = 0.11592 (* 1 = 0.11592 loss)
I1002 00:56:09.206565 23724 solver.cpp:590] Iteration 2400, lr = 0.01
I1002 00:56:11.645786 23724 solver.cpp:243] Iteration 2500, loss = 0.116484
I1002 00:56:11.645828 23724 solver.cpp:259]     Train net output #0: error_blob = 0.116484 (* 1 = 0.116484 loss)
I1002 00:56:11.645833 23724 solver.cpp:590] Iteration 2500, lr = 0.01
I1002 00:56:14.095052 23724 solver.cpp:243] Iteration 2600, loss = 0.118582
I1002 00:56:14.095093 23724 solver.cpp:259]     Train net output #0: error_blob = 0.118582 (* 1 = 0.118582 loss)
I1002 00:56:14.095099 23724 solver.cpp:590] Iteration 2600, lr = 0.01
I1002 00:56:16.583253 23724 solver.cpp:243] Iteration 2700, loss = 0.1197
I1002 00:56:16.583283 23724 solver.cpp:259]     Train net output #0: error_blob = 0.1197 (* 1 = 0.1197 loss)
I1002 00:56:16.583289 23724 solver.cpp:590] Iteration 2700, lr = 0.01
I1002 00:56:16.937924 23724 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:56:19.105696 23724 solver.cpp:243] Iteration 2800, loss = 0.116515
I1002 00:56:19.105731 23724 solver.cpp:259]     Train net output #0: error_blob = 0.116515 (* 1 = 0.116515 loss)
I1002 00:56:19.105737 23724 solver.cpp:590] Iteration 2800, lr = 0.01
I1002 00:56:21.616121 23724 solver.cpp:243] Iteration 2900, loss = 0.115654
I1002 00:56:21.616163 23724 solver.cpp:259]     Train net output #0: error_blob = 0.115654 (* 1 = 0.115654 loss)
I1002 00:56:21.616168 23724 solver.cpp:590] Iteration 2900, lr = 0.01
I1002 00:56:24.051338 23724 solver.cpp:347] Iteration 3000, Testing net (#0)
I1002 00:56:24.354534 23724 solver.cpp:415]     Test net output #0: error_blob = 0.113482 (* 1 = 0.113482 loss)
I1002 00:56:24.355159 23724 solver.cpp:243] Iteration 3000, loss = 0.117501
I1002 00:56:24.355171 23724 solver.cpp:259]     Train net output #0: error_blob = 0.117501 (* 1 = 0.117501 loss)
I1002 00:56:24.355176 23724 solver.cpp:590] Iteration 3000, lr = 0.01
I1002 00:56:26.826012 23724 solver.cpp:243] Iteration 3100, loss = 0.118401
I1002 00:56:26.826056 23724 solver.cpp:259]     Train net output #0: error_blob = 0.118401 (* 1 = 0.118401 loss)
I1002 00:56:26.826061 23724 solver.cpp:590] Iteration 3100, lr = 0.01
I1002 00:56:29.307407 23724 solver.cpp:243] Iteration 3200, loss = 0.118803
I1002 00:56:29.307440 23724 solver.cpp:259]     Train net output #0: error_blob = 0.118803 (* 1 = 0.118803 loss)
I1002 00:56:29.307446 23724 solver.cpp:590] Iteration 3200, lr = 0.01
I1002 00:56:31.814716 23724 solver.cpp:243] Iteration 3300, loss = 0.115101
I1002 00:56:31.814751 23724 solver.cpp:259]     Train net output #0: error_blob = 0.115101 (* 1 = 0.115101 loss)
I1002 00:56:31.814757 23724 solver.cpp:590] Iteration 3300, lr = 0.01
I1002 00:56:34.298338 23724 solver.cpp:243] Iteration 3400, loss = 0.1147
I1002 00:56:34.298372 23724 solver.cpp:259]     Train net output #0: error_blob = 0.1147 (* 1 = 0.1147 loss)
I1002 00:56:34.298379 23724 solver.cpp:590] Iteration 3400, lr = 0.01
I1002 00:56:36.800427 23724 solver.cpp:243] Iteration 3500, loss = 0.117805
I1002 00:56:36.801688 23724 solver.cpp:259]     Train net output #0: error_blob = 0.117805 (* 1 = 0.117805 loss)
I1002 00:56:36.801698 23724 solver.cpp:590] Iteration 3500, lr = 0.01
I1002 00:56:39.240591 23724 solver.cpp:243] Iteration 3600, loss = 0.120184
I1002 00:56:39.240622 23724 solver.cpp:259]     Train net output #0: error_blob = 0.120184 (* 1 = 0.120184 loss)
I1002 00:56:39.240628 23724 solver.cpp:590] Iteration 3600, lr = 0.01
I1002 00:56:39.731290 23724 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:56:41.712750 23724 solver.cpp:243] Iteration 3700, loss = 0.11529
I1002 00:56:41.712784 23724 solver.cpp:259]     Train net output #0: error_blob = 0.11529 (* 1 = 0.11529 loss)
I1002 00:56:41.712790 23724 solver.cpp:590] Iteration 3700, lr = 0.01
I1002 00:56:44.232869 23724 solver.cpp:243] Iteration 3800, loss = 0.116358
I1002 00:56:44.232899 23724 solver.cpp:259]     Train net output #0: error_blob = 0.116358 (* 1 = 0.116358 loss)
I1002 00:56:44.232905 23724 solver.cpp:590] Iteration 3800, lr = 0.01
I1002 00:56:46.708350 23724 solver.cpp:243] Iteration 3900, loss = 0.11698
I1002 00:56:46.708384 23724 solver.cpp:259]     Train net output #0: error_blob = 0.11698 (* 1 = 0.11698 loss)
I1002 00:56:46.708389 23724 solver.cpp:590] Iteration 3900, lr = 0.01
I1002 00:56:49.192015 23724 solver.cpp:347] Iteration 4000, Testing net (#0)
I1002 00:56:49.462975 23724 solver.cpp:415]     Test net output #0: error_blob = 0.112166 (* 1 = 0.112166 loss)
I1002 00:56:49.463594 23724 solver.cpp:243] Iteration 4000, loss = 0.119225
I1002 00:56:49.463608 23724 solver.cpp:259]     Train net output #0: error_blob = 0.119225 (* 1 = 0.119225 loss)
I1002 00:56:49.463616 23724 solver.cpp:590] Iteration 4000, lr = 0.01
I1002 00:56:51.927613 23724 solver.cpp:243] Iteration 4100, loss = 0.116237
I1002 00:56:51.927646 23724 solver.cpp:259]     Train net output #0: error_blob = 0.116237 (* 1 = 0.116237 loss)
I1002 00:56:51.927654 23724 solver.cpp:590] Iteration 4100, lr = 0.01
I1002 00:56:54.418767 23724 solver.cpp:243] Iteration 4200, loss = 0.115582
I1002 00:56:54.418800 23724 solver.cpp:259]     Train net output #0: error_blob = 0.115582 (* 1 = 0.115582 loss)
I1002 00:56:54.418807 23724 solver.cpp:590] Iteration 4200, lr = 0.01
I1002 00:56:56.883790 23724 solver.cpp:243] Iteration 4300, loss = 0.113773
I1002 00:56:56.883821 23724 solver.cpp:259]     Train net output #0: error_blob = 0.113773 (* 1 = 0.113773 loss)
I1002 00:56:56.883826 23724 solver.cpp:590] Iteration 4300, lr = 0.01
I1002 00:56:59.346516 23724 solver.cpp:243] Iteration 4400, loss = 0.116831
I1002 00:56:59.346549 23724 solver.cpp:259]     Train net output #0: error_blob = 0.116831 (* 1 = 0.116831 loss)
I1002 00:56:59.346554 23724 solver.cpp:590] Iteration 4400, lr = 0.01
I1002 00:57:01.814615 23724 solver.cpp:243] Iteration 4500, loss = 0.118235
I1002 00:57:01.814657 23724 solver.cpp:259]     Train net output #0: error_blob = 0.118235 (* 1 = 0.118235 loss)
I1002 00:57:01.814663 23724 solver.cpp:590] Iteration 4500, lr = 0.01
I1002 00:57:02.453269 23724 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:57:04.295073 23724 solver.cpp:243] Iteration 4600, loss = 0.115442
I1002 00:57:04.295105 23724 solver.cpp:259]     Train net output #0: error_blob = 0.115442 (* 1 = 0.115442 loss)
I1002 00:57:04.295111 23724 solver.cpp:590] Iteration 4600, lr = 0.01
I1002 00:57:06.780390 23724 solver.cpp:243] Iteration 4700, loss = 0.111197
I1002 00:57:06.780424 23724 solver.cpp:259]     Train net output #0: error_blob = 0.111197 (* 1 = 0.111197 loss)
I1002 00:57:06.780432 23724 solver.cpp:590] Iteration 4700, lr = 0.01
I1002 00:57:09.252640 23724 solver.cpp:243] Iteration 4800, loss = 0.115374
I1002 00:57:09.252770 23724 solver.cpp:259]     Train net output #0: error_blob = 0.115374 (* 1 = 0.115374 loss)
I1002 00:57:09.252778 23724 solver.cpp:590] Iteration 4800, lr = 0.01
I1002 00:57:11.726065 23724 solver.cpp:243] Iteration 4900, loss = 0.117957
I1002 00:57:11.726096 23724 solver.cpp:259]     Train net output #0: error_blob = 0.117957 (* 1 = 0.117957 loss)
I1002 00:57:11.726102 23724 solver.cpp:590] Iteration 4900, lr = 0.01
I1002 00:57:14.190260 23724 solver.cpp:347] Iteration 5000, Testing net (#0)
I1002 00:57:14.473418 23724 solver.cpp:415]     Test net output #0: error_blob = 0.110013 (* 1 = 0.110013 loss)
I1002 00:57:14.474110 23724 solver.cpp:243] Iteration 5000, loss = 0.115431
I1002 00:57:14.474149 23724 solver.cpp:259]     Train net output #0: error_blob = 0.115431 (* 1 = 0.115431 loss)
I1002 00:57:14.474156 23724 solver.cpp:590] Iteration 5000, lr = 0.01
I1002 00:57:16.919297 23724 solver.cpp:243] Iteration 5100, loss = 0.113505
I1002 00:57:16.919340 23724 solver.cpp:259]     Train net output #0: error_blob = 0.113505 (* 1 = 0.113505 loss)
I1002 00:57:16.919347 23724 solver.cpp:590] Iteration 5100, lr = 0.01
I1002 00:57:19.416060 23724 solver.cpp:243] Iteration 5200, loss = 0.112665
I1002 00:57:19.416095 23724 solver.cpp:259]     Train net output #0: error_blob = 0.112665 (* 1 = 0.112665 loss)
I1002 00:57:19.416101 23724 solver.cpp:590] Iteration 5200, lr = 0.01
I1002 00:57:21.892355 23724 solver.cpp:243] Iteration 5300, loss = 0.116094
I1002 00:57:21.892388 23724 solver.cpp:259]     Train net output #0: error_blob = 0.116094 (* 1 = 0.116094 loss)
I1002 00:57:21.892393 23724 solver.cpp:590] Iteration 5300, lr = 0.01
I1002 00:57:24.343516 23724 solver.cpp:243] Iteration 5400, loss = 0.119105
I1002 00:57:24.343550 23724 solver.cpp:259]     Train net output #0: error_blob = 0.119105 (* 1 = 0.119105 loss)
I1002 00:57:24.343556 23724 solver.cpp:590] Iteration 5400, lr = 0.01
I1002 00:57:25.139178 23724 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:57:26.844766 23724 solver.cpp:243] Iteration 5500, loss = 0.11454
I1002 00:57:26.844799 23724 solver.cpp:259]     Train net output #0: error_blob = 0.11454 (* 1 = 0.11454 loss)
I1002 00:57:26.844805 23724 solver.cpp:590] Iteration 5500, lr = 0.01
I1002 00:57:29.352215 23724 solver.cpp:243] Iteration 5600, loss = 0.115631
I1002 00:57:29.352248 23724 solver.cpp:259]     Train net output #0: error_blob = 0.115631 (* 1 = 0.115631 loss)
I1002 00:57:29.352255 23724 solver.cpp:590] Iteration 5600, lr = 0.01
I1002 00:57:31.845027 23724 solver.cpp:243] Iteration 5700, loss = 0.115658
I1002 00:57:31.845060 23724 solver.cpp:259]     Train net output #0: error_blob = 0.115658 (* 1 = 0.115658 loss)
I1002 00:57:31.845067 23724 solver.cpp:590] Iteration 5700, lr = 0.01
I1002 00:57:34.327612 23724 solver.cpp:243] Iteration 5800, loss = 0.117919
I1002 00:57:34.327644 23724 solver.cpp:259]     Train net output #0: error_blob = 0.117919 (* 1 = 0.117919 loss)
I1002 00:57:34.327651 23724 solver.cpp:590] Iteration 5800, lr = 0.01
I1002 00:57:36.845754 23724 solver.cpp:243] Iteration 5900, loss = 0.115858
I1002 00:57:36.845788 23724 solver.cpp:259]     Train net output #0: error_blob = 0.115858 (* 1 = 0.115858 loss)
I1002 00:57:36.845793 23724 solver.cpp:590] Iteration 5900, lr = 0.01
I1002 00:57:39.325906 23724 solver.cpp:347] Iteration 6000, Testing net (#0)
I1002 00:57:39.616320 23724 solver.cpp:415]     Test net output #0: error_blob = 0.112379 (* 1 = 0.112379 loss)
I1002 00:57:39.617048 23724 solver.cpp:243] Iteration 6000, loss = 0.115148
I1002 00:57:39.617085 23724 solver.cpp:259]     Train net output #0: error_blob = 0.115148 (* 1 = 0.115148 loss)
I1002 00:57:39.617095 23724 solver.cpp:590] Iteration 6000, lr = 0.01
I1002 00:57:42.106364 23724 solver.cpp:243] Iteration 6100, loss = 0.113938
I1002 00:57:42.106396 23724 solver.cpp:259]     Train net output #0: error_blob = 0.113938 (* 1 = 0.113938 loss)
I1002 00:57:42.106401 23724 solver.cpp:590] Iteration 6100, lr = 0.01
I1002 00:57:44.522989 23724 solver.cpp:243] Iteration 6200, loss = 0.116686
I1002 00:57:44.523022 23724 solver.cpp:259]     Train net output #0: error_blob = 0.116686 (* 1 = 0.116686 loss)
I1002 00:57:44.523028 23724 solver.cpp:590] Iteration 6200, lr = 0.01
I1002 00:57:47.003345 23724 solver.cpp:243] Iteration 6300, loss = 0.117811
I1002 00:57:47.003381 23724 solver.cpp:259]     Train net output #0: error_blob = 0.117811 (* 1 = 0.117811 loss)
I1002 00:57:47.003388 23724 solver.cpp:590] Iteration 6300, lr = 0.01
I1002 00:57:47.919458 23724 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:57:49.435470 23724 solver.cpp:243] Iteration 6400, loss = 0.120472
I1002 00:57:49.435506 23724 solver.cpp:259]     Train net output #0: error_blob = 0.120472 (* 1 = 0.120472 loss)
I1002 00:57:49.435514 23724 solver.cpp:590] Iteration 6400, lr = 0.01
I1002 00:57:51.891809 23724 solver.cpp:243] Iteration 6500, loss = 0.111816
I1002 00:57:51.891844 23724 solver.cpp:259]     Train net output #0: error_blob = 0.111816 (* 1 = 0.111816 loss)
I1002 00:57:51.891851 23724 solver.cpp:590] Iteration 6500, lr = 0.01
I1002 00:57:54.436058 23724 solver.cpp:243] Iteration 6600, loss = 0.115122
I1002 00:57:54.436092 23724 solver.cpp:259]     Train net output #0: error_blob = 0.115122 (* 1 = 0.115122 loss)
I1002 00:57:54.436100 23724 solver.cpp:590] Iteration 6600, lr = 0.01
I1002 00:57:56.968250 23724 solver.cpp:243] Iteration 6700, loss = 0.118429
I1002 00:57:56.968286 23724 solver.cpp:259]     Train net output #0: error_blob = 0.118429 (* 1 = 0.118429 loss)
I1002 00:57:56.968293 23724 solver.cpp:590] Iteration 6700, lr = 0.01
I1002 00:57:59.487462 23724 solver.cpp:243] Iteration 6800, loss = 0.115671
I1002 00:57:59.487493 23724 solver.cpp:259]     Train net output #0: error_blob = 0.115671 (* 1 = 0.115671 loss)
I1002 00:57:59.487499 23724 solver.cpp:590] Iteration 6800, lr = 0.01
I1002 00:58:01.959131 23724 solver.cpp:243] Iteration 6900, loss = 0.11426
I1002 00:58:01.959163 23724 solver.cpp:259]     Train net output #0: error_blob = 0.11426 (* 1 = 0.11426 loss)
I1002 00:58:01.959168 23724 solver.cpp:590] Iteration 6900, lr = 0.01
I1002 00:58:04.413661 23724 solver.cpp:347] Iteration 7000, Testing net (#0)
I1002 00:58:04.717635 23724 solver.cpp:415]     Test net output #0: error_blob = 0.114968 (* 1 = 0.114968 loss)
I1002 00:58:04.718252 23724 solver.cpp:243] Iteration 7000, loss = 0.115426
I1002 00:58:04.718263 23724 solver.cpp:259]     Train net output #0: error_blob = 0.115426 (* 1 = 0.115426 loss)
I1002 00:58:04.718277 23724 solver.cpp:590] Iteration 7000, lr = 0.01
I1002 00:58:07.240597 23724 solver.cpp:243] Iteration 7100, loss = 0.115231
I1002 00:58:07.240636 23724 solver.cpp:259]     Train net output #0: error_blob = 0.115231 (* 1 = 0.115231 loss)
I1002 00:58:07.240641 23724 solver.cpp:590] Iteration 7100, lr = 0.01
I1002 00:58:09.709267 23724 solver.cpp:243] Iteration 7200, loss = 0.116068
I1002 00:58:09.710382 23724 solver.cpp:259]     Train net output #0: error_blob = 0.116068 (* 1 = 0.116068 loss)
I1002 00:58:09.710391 23724 solver.cpp:590] Iteration 7200, lr = 0.01
I1002 00:58:10.794512 23724 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:58:12.235111 23724 solver.cpp:243] Iteration 7300, loss = 0.122592
I1002 00:58:12.235148 23724 solver.cpp:259]     Train net output #0: error_blob = 0.122592 (* 1 = 0.122592 loss)
I1002 00:58:12.235154 23724 solver.cpp:590] Iteration 7300, lr = 0.01
I1002 00:58:14.771217 23724 solver.cpp:243] Iteration 7400, loss = 0.11106
I1002 00:58:14.771252 23724 solver.cpp:259]     Train net output #0: error_blob = 0.11106 (* 1 = 0.11106 loss)
I1002 00:58:14.771260 23724 solver.cpp:590] Iteration 7400, lr = 0.01
I1002 00:58:17.309478 23724 solver.cpp:243] Iteration 7500, loss = 0.115048
I1002 00:58:17.309515 23724 solver.cpp:259]     Train net output #0: error_blob = 0.115048 (* 1 = 0.115048 loss)
I1002 00:58:17.309521 23724 solver.cpp:590] Iteration 7500, lr = 0.01
I1002 00:58:19.844538 23724 solver.cpp:243] Iteration 7600, loss = 0.115313
I1002 00:58:19.844573 23724 solver.cpp:259]     Train net output #0: error_blob = 0.115313 (* 1 = 0.115313 loss)
I1002 00:58:19.844580 23724 solver.cpp:590] Iteration 7600, lr = 0.01
I1002 00:58:22.395618 23724 solver.cpp:243] Iteration 7700, loss = 0.11672
I1002 00:58:22.395653 23724 solver.cpp:259]     Train net output #0: error_blob = 0.11672 (* 1 = 0.11672 loss)
I1002 00:58:22.395660 23724 solver.cpp:590] Iteration 7700, lr = 0.01
I1002 00:58:24.879407 23724 solver.cpp:243] Iteration 7800, loss = 0.115571
I1002 00:58:24.879439 23724 solver.cpp:259]     Train net output #0: error_blob = 0.115571 (* 1 = 0.115571 loss)
I1002 00:58:24.879443 23724 solver.cpp:590] Iteration 7800, lr = 0.01
I1002 00:58:27.377689 23724 solver.cpp:243] Iteration 7900, loss = 0.112841
I1002 00:58:27.377724 23724 solver.cpp:259]     Train net output #0: error_blob = 0.112841 (* 1 = 0.112841 loss)
I1002 00:58:27.377732 23724 solver.cpp:590] Iteration 7900, lr = 0.01
I1002 00:58:29.879099 23724 solver.cpp:347] Iteration 8000, Testing net (#0)
I1002 00:58:30.166898 23724 solver.cpp:415]     Test net output #0: error_blob = 0.114209 (* 1 = 0.114209 loss)
I1002 00:58:30.167520 23724 solver.cpp:243] Iteration 8000, loss = 0.113986
I1002 00:58:30.167534 23724 solver.cpp:259]     Train net output #0: error_blob = 0.113986 (* 1 = 0.113986 loss)
I1002 00:58:30.167551 23724 solver.cpp:590] Iteration 8000, lr = 0.01
I1002 00:58:32.611007 23724 solver.cpp:243] Iteration 8100, loss = 0.118796
I1002 00:58:32.611042 23724 solver.cpp:259]     Train net output #0: error_blob = 0.118796 (* 1 = 0.118796 loss)
I1002 00:58:32.611048 23724 solver.cpp:590] Iteration 8100, lr = 0.01
I1002 00:58:33.841328 23724 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:58:35.086849 23724 solver.cpp:243] Iteration 8200, loss = 0.116696
I1002 00:58:35.086884 23724 solver.cpp:259]     Train net output #0: error_blob = 0.116696 (* 1 = 0.116696 loss)
I1002 00:58:35.086889 23724 solver.cpp:590] Iteration 8200, lr = 0.01
I1002 00:58:37.621518 23724 solver.cpp:243] Iteration 8300, loss = 0.111162
I1002 00:58:37.621553 23724 solver.cpp:259]     Train net output #0: error_blob = 0.111162 (* 1 = 0.111162 loss)
I1002 00:58:37.621561 23724 solver.cpp:590] Iteration 8300, lr = 0.01
I1002 00:58:40.127403 23724 solver.cpp:243] Iteration 8400, loss = 0.115898
I1002 00:58:40.129096 23724 solver.cpp:259]     Train net output #0: error_blob = 0.115898 (* 1 = 0.115898 loss)
I1002 00:58:40.129104 23724 solver.cpp:590] Iteration 8400, lr = 0.01
I1002 00:58:42.634291 23724 solver.cpp:243] Iteration 8500, loss = 0.116046
I1002 00:58:42.634333 23724 solver.cpp:259]     Train net output #0: error_blob = 0.116046 (* 1 = 0.116046 loss)
I1002 00:58:42.634340 23724 solver.cpp:590] Iteration 8500, lr = 0.01
I1002 00:58:45.144981 23724 solver.cpp:243] Iteration 8600, loss = 0.114869
I1002 00:58:45.145031 23724 solver.cpp:259]     Train net output #0: error_blob = 0.114869 (* 1 = 0.114869 loss)
I1002 00:58:45.145040 23724 solver.cpp:590] Iteration 8600, lr = 0.01
I1002 00:58:47.646970 23724 solver.cpp:243] Iteration 8700, loss = 0.114221
I1002 00:58:47.647011 23724 solver.cpp:259]     Train net output #0: error_blob = 0.114221 (* 1 = 0.114221 loss)
I1002 00:58:47.647028 23724 solver.cpp:590] Iteration 8700, lr = 0.01
I1002 00:58:50.151631 23724 solver.cpp:243] Iteration 8800, loss = 0.114099
I1002 00:58:50.151674 23724 solver.cpp:259]     Train net output #0: error_blob = 0.114099 (* 1 = 0.114099 loss)
I1002 00:58:50.151679 23724 solver.cpp:590] Iteration 8800, lr = 0.01
I1002 00:58:52.610043 23724 solver.cpp:243] Iteration 8900, loss = 0.116547
I1002 00:58:52.610085 23724 solver.cpp:259]     Train net output #0: error_blob = 0.116547 (* 1 = 0.116547 loss)
I1002 00:58:52.610090 23724 solver.cpp:590] Iteration 8900, lr = 0.01
I1002 00:58:55.089092 23724 solver.cpp:347] Iteration 9000, Testing net (#0)
I1002 00:58:55.368350 23724 solver.cpp:415]     Test net output #0: error_blob = 0.113214 (* 1 = 0.113214 loss)
I1002 00:58:55.369084 23724 solver.cpp:243] Iteration 9000, loss = 0.114885
I1002 00:58:55.369101 23724 solver.cpp:259]     Train net output #0: error_blob = 0.114885 (* 1 = 0.114885 loss)
I1002 00:58:55.369107 23724 solver.cpp:590] Iteration 9000, lr = 0.01
I1002 00:58:56.711904 23724 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:58:57.823549 23724 solver.cpp:243] Iteration 9100, loss = 0.11383
I1002 00:58:57.823580 23724 solver.cpp:259]     Train net output #0: error_blob = 0.11383 (* 1 = 0.11383 loss)
I1002 00:58:57.823586 23724 solver.cpp:590] Iteration 9100, lr = 0.01
I1002 00:59:00.309468 23724 solver.cpp:243] Iteration 9200, loss = 0.117684
I1002 00:59:00.309509 23724 solver.cpp:259]     Train net output #0: error_blob = 0.117684 (* 1 = 0.117684 loss)
I1002 00:59:00.309514 23724 solver.cpp:590] Iteration 9200, lr = 0.01
I1002 00:59:02.796049 23724 solver.cpp:243] Iteration 9300, loss = 0.12215
I1002 00:59:02.796089 23724 solver.cpp:259]     Train net output #0: error_blob = 0.12215 (* 1 = 0.12215 loss)
I1002 00:59:02.796097 23724 solver.cpp:590] Iteration 9300, lr = 0.01
I1002 00:59:05.331434 23724 solver.cpp:243] Iteration 9400, loss = 0.119441
I1002 00:59:05.331480 23724 solver.cpp:259]     Train net output #0: error_blob = 0.119441 (* 1 = 0.119441 loss)
I1002 00:59:05.331487 23724 solver.cpp:590] Iteration 9400, lr = 0.01
I1002 00:59:07.852196 23724 solver.cpp:243] Iteration 9500, loss = 0.118501
I1002 00:59:07.852232 23724 solver.cpp:259]     Train net output #0: error_blob = 0.118501 (* 1 = 0.118501 loss)
I1002 00:59:07.852239 23724 solver.cpp:590] Iteration 9500, lr = 0.01
I1002 00:59:10.368053 23724 solver.cpp:243] Iteration 9600, loss = 0.116446
I1002 00:59:10.368191 23724 solver.cpp:259]     Train net output #0: error_blob = 0.116446 (* 1 = 0.116446 loss)
I1002 00:59:10.368198 23724 solver.cpp:590] Iteration 9600, lr = 0.01
I1002 00:59:12.882055 23724 solver.cpp:243] Iteration 9700, loss = 0.118591
I1002 00:59:12.882096 23724 solver.cpp:259]     Train net output #0: error_blob = 0.118591 (* 1 = 0.118591 loss)
I1002 00:59:12.882102 23724 solver.cpp:590] Iteration 9700, lr = 0.01
I1002 00:59:15.369453 23724 solver.cpp:243] Iteration 9800, loss = 0.120457
I1002 00:59:15.369494 23724 solver.cpp:259]     Train net output #0: error_blob = 0.120457 (* 1 = 0.120457 loss)
I1002 00:59:15.369500 23724 solver.cpp:590] Iteration 9800, lr = 0.01
I1002 00:59:17.854553 23724 solver.cpp:243] Iteration 9900, loss = 0.121225
I1002 00:59:17.854593 23724 solver.cpp:259]     Train net output #0: error_blob = 0.121225 (* 1 = 0.121225 loss)
I1002 00:59:17.854599 23724 solver.cpp:590] Iteration 9900, lr = 0.01
I1002 00:59:20.318791 23724 solver.cpp:468] Snapshotting to binary proto file _iter_10000.caffemodel
I1002 00:59:20.319634 23724 solver.cpp:753] Snapshotting solver state to binary proto file _iter_10000.solverstate
I1002 00:59:20.344349 23724 solver.cpp:327] Iteration 10000, loss = 0.121235
I1002 00:59:20.344383 23724 solver.cpp:347] Iteration 10000, Testing net (#0)
I1002 00:59:20.540858 23724 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:59:20.643960 23724 solver.cpp:415]     Test net output #0: error_blob = 0.120641 (* 1 = 0.120641 loss)
I1002 00:59:20.643982 23724 solver.cpp:332] Optimization Done.
I1002 00:59:20.643985 23724 caffe.cpp:215] Optimization Done.
I1002 00:59:20.704964 23733 caffe.cpp:184] Using GPUs 0
I1002 00:59:21.261178 23733 solver.cpp:54] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "fixed"
momentum: 0.9
solver_mode: GPU
device_id: 0
net: "model/NNScore/nnscore_model_5.prototxt"
I1002 00:59:21.261214 23733 solver.cpp:97] Creating training net from net file: model/NNScore/nnscore_model_5.prototxt
I1002 00:59:21.261375 23733 net.cpp:339] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_layer
I1002 00:59:21.261418 23733 net.cpp:50] Initializing net from parameters: 
name: "model/NNScore/nnscore_model_5.prototxt"
state {
  phase: TRAIN
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TRAIN
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.5.train"
    batch_size: 20000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1002 00:59:21.261469 23733 layer_factory.hpp:76] Creating layer data_layer
I1002 00:59:21.274731 23733 net.cpp:110] Creating Layer data_layer
I1002 00:59:21.274752 23733 net.cpp:433] data_layer -> data_blob
I1002 00:59:21.274791 23733 net.cpp:433] data_layer -> label_blob
I1002 00:59:21.275357 23738 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.5.train
I1002 00:59:21.962398 23733 data_layer.cpp:45] output data size: 20000,61,1,1
I1002 00:59:21.967306 23733 net.cpp:155] Setting up data_layer
I1002 00:59:21.967341 23733 net.cpp:163] Top shape: 20000 61 1 1 (1220000)
I1002 00:59:21.967356 23733 net.cpp:163] Top shape: 20000 (20000)
I1002 00:59:21.967365 23733 layer_factory.hpp:76] Creating layer hidden_sum_layer
I1002 00:59:21.967380 23733 net.cpp:110] Creating Layer hidden_sum_layer
I1002 00:59:21.967387 23733 net.cpp:477] hidden_sum_layer <- data_blob
I1002 00:59:21.967401 23733 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I1002 00:59:21.967767 23733 net.cpp:155] Setting up hidden_sum_layer
I1002 00:59:21.967775 23733 net.cpp:163] Top shape: 20000 10 (200000)
I1002 00:59:21.967800 23733 layer_factory.hpp:76] Creating layer hidden_act_layer
I1002 00:59:21.967813 23733 net.cpp:110] Creating Layer hidden_act_layer
I1002 00:59:21.967818 23733 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I1002 00:59:21.967823 23733 net.cpp:433] hidden_act_layer -> hidden_act_blob
I1002 00:59:25.187551 23733 net.cpp:155] Setting up hidden_act_layer
I1002 00:59:25.187573 23733 net.cpp:163] Top shape: 20000 10 (200000)
I1002 00:59:25.187579 23733 layer_factory.hpp:76] Creating layer output_sum_layer
I1002 00:59:25.187590 23733 net.cpp:110] Creating Layer output_sum_layer
I1002 00:59:25.187595 23733 net.cpp:477] output_sum_layer <- hidden_act_blob
I1002 00:59:25.187602 23733 net.cpp:433] output_sum_layer -> output_sum_blob
I1002 00:59:25.187687 23733 net.cpp:155] Setting up output_sum_layer
I1002 00:59:25.187695 23733 net.cpp:163] Top shape: 20000 1 (20000)
I1002 00:59:25.187705 23733 layer_factory.hpp:76] Creating layer output_act_layer
I1002 00:59:25.187713 23733 net.cpp:110] Creating Layer output_act_layer
I1002 00:59:25.187719 23733 net.cpp:477] output_act_layer <- output_sum_blob
I1002 00:59:25.187724 23733 net.cpp:433] output_act_layer -> output_act_blob
I1002 00:59:25.187783 23733 net.cpp:155] Setting up output_act_layer
I1002 00:59:25.187803 23733 net.cpp:163] Top shape: 20000 1 (20000)
I1002 00:59:25.187809 23733 layer_factory.hpp:76] Creating layer error_layer
I1002 00:59:25.187818 23733 net.cpp:110] Creating Layer error_layer
I1002 00:59:25.187821 23733 net.cpp:477] error_layer <- output_act_blob
I1002 00:59:25.187825 23733 net.cpp:477] error_layer <- label_blob
I1002 00:59:25.187831 23733 net.cpp:433] error_layer -> error_blob
I1002 00:59:25.187860 23733 net.cpp:155] Setting up error_layer
I1002 00:59:25.187867 23733 net.cpp:163] Top shape: (1)
I1002 00:59:25.187870 23733 net.cpp:168]     with loss weight 1
I1002 00:59:25.187891 23733 net.cpp:236] error_layer needs backward computation.
I1002 00:59:25.187896 23733 net.cpp:236] output_act_layer needs backward computation.
I1002 00:59:25.187898 23733 net.cpp:236] output_sum_layer needs backward computation.
I1002 00:59:25.187902 23733 net.cpp:236] hidden_act_layer needs backward computation.
I1002 00:59:25.187906 23733 net.cpp:236] hidden_sum_layer needs backward computation.
I1002 00:59:25.187911 23733 net.cpp:240] data_layer does not need backward computation.
I1002 00:59:25.187913 23733 net.cpp:283] This network produces output error_blob
I1002 00:59:25.187921 23733 net.cpp:297] Network initialization done.
I1002 00:59:25.187923 23733 net.cpp:298] Memory required for data: 6720004
I1002 00:59:25.188062 23733 solver.cpp:187] Creating test net (#0) specified by net file: model/NNScore/nnscore_model_5.prototxt
I1002 00:59:25.188082 23733 net.cpp:339] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_layer
I1002 00:59:25.188128 23733 net.cpp:50] Initializing net from parameters: 
name: "model/NNScore/nnscore_model_5.prototxt"
state {
  phase: TEST
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TEST
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.5.test"
    batch_size: 2000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1002 00:59:25.188158 23733 layer_factory.hpp:76] Creating layer data_layer
I1002 00:59:25.189416 23733 net.cpp:110] Creating Layer data_layer
I1002 00:59:25.189435 23733 net.cpp:433] data_layer -> data_blob
I1002 00:59:25.189443 23733 net.cpp:433] data_layer -> label_blob
I1002 00:59:25.190001 23740 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.5.test
I1002 00:59:25.190065 23733 data_layer.cpp:45] output data size: 2000,61,1,1
I1002 00:59:25.191436 23733 net.cpp:155] Setting up data_layer
I1002 00:59:25.191448 23733 net.cpp:163] Top shape: 2000 61 1 1 (122000)
I1002 00:59:25.191453 23733 net.cpp:163] Top shape: 2000 (2000)
I1002 00:59:25.191458 23733 layer_factory.hpp:76] Creating layer hidden_sum_layer
I1002 00:59:25.191469 23733 net.cpp:110] Creating Layer hidden_sum_layer
I1002 00:59:25.191473 23733 net.cpp:477] hidden_sum_layer <- data_blob
I1002 00:59:25.191479 23733 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I1002 00:59:25.191598 23733 net.cpp:155] Setting up hidden_sum_layer
I1002 00:59:25.191606 23733 net.cpp:163] Top shape: 2000 10 (20000)
I1002 00:59:25.191618 23733 layer_factory.hpp:76] Creating layer hidden_act_layer
I1002 00:59:25.191628 23733 net.cpp:110] Creating Layer hidden_act_layer
I1002 00:59:25.191633 23733 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I1002 00:59:25.191650 23733 net.cpp:433] hidden_act_layer -> hidden_act_blob
I1002 00:59:25.191836 23733 net.cpp:155] Setting up hidden_act_layer
I1002 00:59:25.191844 23733 net.cpp:163] Top shape: 2000 10 (20000)
I1002 00:59:25.191848 23733 layer_factory.hpp:76] Creating layer output_sum_layer
I1002 00:59:25.191855 23733 net.cpp:110] Creating Layer output_sum_layer
I1002 00:59:25.191859 23733 net.cpp:477] output_sum_layer <- hidden_act_blob
I1002 00:59:25.191865 23733 net.cpp:433] output_sum_layer -> output_sum_blob
I1002 00:59:25.191933 23733 net.cpp:155] Setting up output_sum_layer
I1002 00:59:25.191941 23733 net.cpp:163] Top shape: 2000 1 (2000)
I1002 00:59:25.191948 23733 layer_factory.hpp:76] Creating layer output_act_layer
I1002 00:59:25.191956 23733 net.cpp:110] Creating Layer output_act_layer
I1002 00:59:25.191961 23733 net.cpp:477] output_act_layer <- output_sum_blob
I1002 00:59:25.191965 23733 net.cpp:433] output_act_layer -> output_act_blob
I1002 00:59:25.192020 23733 net.cpp:155] Setting up output_act_layer
I1002 00:59:25.192026 23733 net.cpp:163] Top shape: 2000 1 (2000)
I1002 00:59:25.192029 23733 layer_factory.hpp:76] Creating layer error_layer
I1002 00:59:25.192035 23733 net.cpp:110] Creating Layer error_layer
I1002 00:59:25.192039 23733 net.cpp:477] error_layer <- output_act_blob
I1002 00:59:25.192044 23733 net.cpp:477] error_layer <- label_blob
I1002 00:59:25.192049 23733 net.cpp:433] error_layer -> error_blob
I1002 00:59:25.192076 23733 net.cpp:155] Setting up error_layer
I1002 00:59:25.192082 23733 net.cpp:163] Top shape: (1)
I1002 00:59:25.192085 23733 net.cpp:168]     with loss weight 1
I1002 00:59:25.192098 23733 net.cpp:236] error_layer needs backward computation.
I1002 00:59:25.192102 23733 net.cpp:236] output_act_layer needs backward computation.
I1002 00:59:25.192106 23733 net.cpp:236] output_sum_layer needs backward computation.
I1002 00:59:25.192109 23733 net.cpp:236] hidden_act_layer needs backward computation.
I1002 00:59:25.192113 23733 net.cpp:236] hidden_sum_layer needs backward computation.
I1002 00:59:25.192117 23733 net.cpp:240] data_layer does not need backward computation.
I1002 00:59:25.192122 23733 net.cpp:283] This network produces output error_blob
I1002 00:59:25.192131 23733 net.cpp:297] Network initialization done.
I1002 00:59:25.192133 23733 net.cpp:298] Memory required for data: 672004
I1002 00:59:25.192155 23733 solver.cpp:66] Solver scaffolding done.
I1002 00:59:25.192248 23733 caffe.cpp:212] Starting Optimization
I1002 00:59:25.192258 23733 solver.cpp:294] Solving model/NNScore/nnscore_model_5.prototxt
I1002 00:59:25.192262 23733 solver.cpp:295] Learning Rate Policy: fixed
I1002 00:59:25.192443 23733 solver.cpp:347] Iteration 0, Testing net (#0)
I1002 00:59:25.192555 23733 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:59:25.460108 23733 solver.cpp:415]     Test net output #0: error_blob = 0.126685 (* 1 = 0.126685 loss)
I1002 00:59:25.461396 23733 solver.cpp:243] Iteration 0, loss = 0.130309
I1002 00:59:25.461410 23733 solver.cpp:259]     Train net output #0: error_blob = 0.130309 (* 1 = 0.130309 loss)
I1002 00:59:25.461421 23733 solver.cpp:590] Iteration 0, lr = 0.01
I1002 00:59:27.911011 23733 solver.cpp:243] Iteration 100, loss = 0.123921
I1002 00:59:27.911062 23733 solver.cpp:259]     Train net output #0: error_blob = 0.123921 (* 1 = 0.123921 loss)
I1002 00:59:27.911069 23733 solver.cpp:590] Iteration 100, lr = 0.01
I1002 00:59:30.426828 23733 solver.cpp:243] Iteration 200, loss = 0.122944
I1002 00:59:30.426877 23733 solver.cpp:259]     Train net output #0: error_blob = 0.122944 (* 1 = 0.122944 loss)
I1002 00:59:30.426884 23733 solver.cpp:590] Iteration 200, lr = 0.01
I1002 00:59:32.918104 23733 solver.cpp:243] Iteration 300, loss = 0.122509
I1002 00:59:32.918148 23733 solver.cpp:259]     Train net output #0: error_blob = 0.122509 (* 1 = 0.122509 loss)
I1002 00:59:32.918153 23733 solver.cpp:590] Iteration 300, lr = 0.01
I1002 00:59:35.392482 23733 solver.cpp:243] Iteration 400, loss = 0.122068
I1002 00:59:35.392570 23733 solver.cpp:259]     Train net output #0: error_blob = 0.122068 (* 1 = 0.122068 loss)
I1002 00:59:35.392580 23733 solver.cpp:590] Iteration 400, lr = 0.01
I1002 00:59:37.912547 23733 solver.cpp:243] Iteration 500, loss = 0.12098
I1002 00:59:37.912583 23733 solver.cpp:259]     Train net output #0: error_blob = 0.12098 (* 1 = 0.12098 loss)
I1002 00:59:37.912590 23733 solver.cpp:590] Iteration 500, lr = 0.01
I1002 00:59:40.430605 23733 solver.cpp:243] Iteration 600, loss = 0.121113
I1002 00:59:40.430654 23733 solver.cpp:259]     Train net output #0: error_blob = 0.121113 (* 1 = 0.121113 loss)
I1002 00:59:40.430660 23733 solver.cpp:590] Iteration 600, lr = 0.01
I1002 00:59:42.934645 23733 solver.cpp:243] Iteration 700, loss = 0.120872
I1002 00:59:42.934684 23733 solver.cpp:259]     Train net output #0: error_blob = 0.120872 (* 1 = 0.120872 loss)
I1002 00:59:42.934690 23733 solver.cpp:590] Iteration 700, lr = 0.01
I1002 00:59:45.418848 23733 solver.cpp:243] Iteration 800, loss = 0.120272
I1002 00:59:45.418889 23733 solver.cpp:259]     Train net output #0: error_blob = 0.120272 (* 1 = 0.120272 loss)
I1002 00:59:45.418895 23733 solver.cpp:590] Iteration 800, lr = 0.01
I1002 00:59:47.938172 23733 solver.cpp:243] Iteration 900, loss = 0.119669
I1002 00:59:47.938211 23733 solver.cpp:259]     Train net output #0: error_blob = 0.119669 (* 1 = 0.119669 loss)
I1002 00:59:47.938220 23733 solver.cpp:590] Iteration 900, lr = 0.01
I1002 00:59:47.988262 23733 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 00:59:50.407886 23733 solver.cpp:347] Iteration 1000, Testing net (#0)
I1002 00:59:50.697819 23733 solver.cpp:415]     Test net output #0: error_blob = 0.122018 (* 1 = 0.122018 loss)
I1002 00:59:50.698513 23733 solver.cpp:243] Iteration 1000, loss = 0.120996
I1002 00:59:50.698529 23733 solver.cpp:259]     Train net output #0: error_blob = 0.120996 (* 1 = 0.120996 loss)
I1002 00:59:50.698535 23733 solver.cpp:590] Iteration 1000, lr = 0.01
I1002 00:59:53.150883 23733 solver.cpp:243] Iteration 1100, loss = 0.120717
I1002 00:59:53.152688 23733 solver.cpp:259]     Train net output #0: error_blob = 0.120717 (* 1 = 0.120717 loss)
I1002 00:59:53.152698 23733 solver.cpp:590] Iteration 1100, lr = 0.01
I1002 00:59:55.663549 23733 solver.cpp:243] Iteration 1200, loss = 0.119993
I1002 00:59:55.663590 23733 solver.cpp:259]     Train net output #0: error_blob = 0.119993 (* 1 = 0.119993 loss)
I1002 00:59:55.663595 23733 solver.cpp:590] Iteration 1200, lr = 0.01
I1002 00:59:58.169716 23733 solver.cpp:243] Iteration 1300, loss = 0.118326
I1002 00:59:58.169756 23733 solver.cpp:259]     Train net output #0: error_blob = 0.118326 (* 1 = 0.118326 loss)
I1002 00:59:58.169764 23733 solver.cpp:590] Iteration 1300, lr = 0.01
I1002 01:00:00.701184 23733 solver.cpp:243] Iteration 1400, loss = 0.119667
I1002 01:00:00.701233 23733 solver.cpp:259]     Train net output #0: error_blob = 0.119667 (* 1 = 0.119667 loss)
I1002 01:00:00.701241 23733 solver.cpp:590] Iteration 1400, lr = 0.01
I1002 01:00:03.224401 23733 solver.cpp:243] Iteration 1500, loss = 0.120767
I1002 01:00:03.224452 23733 solver.cpp:259]     Train net output #0: error_blob = 0.120767 (* 1 = 0.120767 loss)
I1002 01:00:03.224460 23733 solver.cpp:590] Iteration 1500, lr = 0.01
I1002 01:00:05.750303 23733 solver.cpp:243] Iteration 1600, loss = 0.118893
I1002 01:00:05.750334 23733 solver.cpp:259]     Train net output #0: error_blob = 0.118893 (* 1 = 0.118893 loss)
I1002 01:00:05.750340 23733 solver.cpp:590] Iteration 1600, lr = 0.01
I1002 01:00:08.269021 23733 solver.cpp:243] Iteration 1700, loss = 0.118652
I1002 01:00:08.269062 23733 solver.cpp:259]     Train net output #0: error_blob = 0.118652 (* 1 = 0.118652 loss)
I1002 01:00:08.269068 23733 solver.cpp:590] Iteration 1700, lr = 0.01
I1002 01:00:10.753736 23733 solver.cpp:243] Iteration 1800, loss = 0.120055
I1002 01:00:10.753785 23733 solver.cpp:259]     Train net output #0: error_blob = 0.120055 (* 1 = 0.120055 loss)
I1002 01:00:10.753793 23733 solver.cpp:590] Iteration 1800, lr = 0.01
I1002 01:00:10.954151 23733 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 01:00:13.267843 23733 solver.cpp:243] Iteration 1900, loss = 0.11933
I1002 01:00:13.267875 23733 solver.cpp:259]     Train net output #0: error_blob = 0.11933 (* 1 = 0.11933 loss)
I1002 01:00:13.267880 23733 solver.cpp:590] Iteration 1900, lr = 0.01
I1002 01:00:15.712131 23733 solver.cpp:347] Iteration 2000, Testing net (#0)
I1002 01:00:15.982424 23733 solver.cpp:415]     Test net output #0: error_blob = 0.121331 (* 1 = 0.121331 loss)
I1002 01:00:15.983099 23733 solver.cpp:243] Iteration 2000, loss = 0.117655
I1002 01:00:15.983116 23733 solver.cpp:259]     Train net output #0: error_blob = 0.117655 (* 1 = 0.117655 loss)
I1002 01:00:15.983122 23733 solver.cpp:590] Iteration 2000, lr = 0.01
I1002 01:00:18.440299 23733 solver.cpp:243] Iteration 2100, loss = 0.118338
I1002 01:00:18.440330 23733 solver.cpp:259]     Train net output #0: error_blob = 0.118338 (* 1 = 0.118338 loss)
I1002 01:00:18.440335 23733 solver.cpp:590] Iteration 2100, lr = 0.01
I1002 01:00:20.920608 23733 solver.cpp:243] Iteration 2200, loss = 0.118887
I1002 01:00:20.920636 23733 solver.cpp:259]     Train net output #0: error_blob = 0.118887 (* 1 = 0.118887 loss)
I1002 01:00:20.920641 23733 solver.cpp:590] Iteration 2200, lr = 0.01
I1002 01:00:23.425930 23733 solver.cpp:243] Iteration 2300, loss = 0.119252
I1002 01:00:23.426033 23733 solver.cpp:259]     Train net output #0: error_blob = 0.119252 (* 1 = 0.119252 loss)
I1002 01:00:23.426039 23733 solver.cpp:590] Iteration 2300, lr = 0.01
I1002 01:00:25.899268 23733 solver.cpp:243] Iteration 2400, loss = 0.116714
I1002 01:00:25.899299 23733 solver.cpp:259]     Train net output #0: error_blob = 0.116714 (* 1 = 0.116714 loss)
I1002 01:00:25.899303 23733 solver.cpp:590] Iteration 2400, lr = 0.01
I1002 01:00:28.337018 23733 solver.cpp:243] Iteration 2500, loss = 0.118831
I1002 01:00:28.337050 23733 solver.cpp:259]     Train net output #0: error_blob = 0.118831 (* 1 = 0.118831 loss)
I1002 01:00:28.337055 23733 solver.cpp:590] Iteration 2500, lr = 0.01
I1002 01:00:30.800588 23733 solver.cpp:243] Iteration 2600, loss = 0.1188
I1002 01:00:30.800617 23733 solver.cpp:259]     Train net output #0: error_blob = 0.1188 (* 1 = 0.1188 loss)
I1002 01:00:30.800623 23733 solver.cpp:590] Iteration 2600, lr = 0.01
I1002 01:00:33.260025 23733 solver.cpp:243] Iteration 2700, loss = 0.116886
I1002 01:00:33.260056 23733 solver.cpp:259]     Train net output #0: error_blob = 0.116886 (* 1 = 0.116886 loss)
I1002 01:00:33.260061 23733 solver.cpp:590] Iteration 2700, lr = 0.01
I1002 01:00:33.608408 23733 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 01:00:35.716251 23733 solver.cpp:243] Iteration 2800, loss = 0.114867
I1002 01:00:35.716282 23733 solver.cpp:259]     Train net output #0: error_blob = 0.114867 (* 1 = 0.114867 loss)
I1002 01:00:35.716287 23733 solver.cpp:590] Iteration 2800, lr = 0.01
I1002 01:00:38.178138 23733 solver.cpp:243] Iteration 2900, loss = 0.11835
I1002 01:00:38.178179 23733 solver.cpp:259]     Train net output #0: error_blob = 0.11835 (* 1 = 0.11835 loss)
I1002 01:00:38.178184 23733 solver.cpp:590] Iteration 2900, lr = 0.01
I1002 01:00:40.634995 23733 solver.cpp:347] Iteration 3000, Testing net (#0)
I1002 01:00:40.908299 23733 solver.cpp:415]     Test net output #0: error_blob = 0.121466 (* 1 = 0.121466 loss)
I1002 01:00:40.908956 23733 solver.cpp:243] Iteration 3000, loss = 0.118835
I1002 01:00:40.908972 23733 solver.cpp:259]     Train net output #0: error_blob = 0.118835 (* 1 = 0.118835 loss)
I1002 01:00:40.908979 23733 solver.cpp:590] Iteration 3000, lr = 0.01
I1002 01:00:43.356017 23733 solver.cpp:243] Iteration 3100, loss = 0.116221
I1002 01:00:43.356047 23733 solver.cpp:259]     Train net output #0: error_blob = 0.116221 (* 1 = 0.116221 loss)
I1002 01:00:43.356052 23733 solver.cpp:590] Iteration 3100, lr = 0.01
I1002 01:00:45.870976 23733 solver.cpp:243] Iteration 3200, loss = 0.119297
I1002 01:00:45.871026 23733 solver.cpp:259]     Train net output #0: error_blob = 0.119297 (* 1 = 0.119297 loss)
I1002 01:00:45.871033 23733 solver.cpp:590] Iteration 3200, lr = 0.01
I1002 01:00:48.403527 23733 solver.cpp:243] Iteration 3300, loss = 0.118992
I1002 01:00:48.403560 23733 solver.cpp:259]     Train net output #0: error_blob = 0.118992 (* 1 = 0.118992 loss)
I1002 01:00:48.403565 23733 solver.cpp:590] Iteration 3300, lr = 0.01
I1002 01:00:50.868296 23733 solver.cpp:243] Iteration 3400, loss = 0.117265
I1002 01:00:50.868327 23733 solver.cpp:259]     Train net output #0: error_blob = 0.117265 (* 1 = 0.117265 loss)
I1002 01:00:50.868332 23733 solver.cpp:590] Iteration 3400, lr = 0.01
I1002 01:00:53.341277 23733 solver.cpp:243] Iteration 3500, loss = 0.115276
I1002 01:00:53.341307 23733 solver.cpp:259]     Train net output #0: error_blob = 0.115276 (* 1 = 0.115276 loss)
I1002 01:00:53.341313 23733 solver.cpp:590] Iteration 3500, lr = 0.01
I1002 01:00:55.824748 23733 solver.cpp:243] Iteration 3600, loss = 0.117902
I1002 01:00:55.824874 23733 solver.cpp:259]     Train net output #0: error_blob = 0.117902 (* 1 = 0.117902 loss)
I1002 01:00:55.824882 23733 solver.cpp:590] Iteration 3600, lr = 0.01
I1002 01:00:56.315755 23733 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 01:00:58.314000 23733 solver.cpp:243] Iteration 3700, loss = 0.120599
I1002 01:00:58.314043 23733 solver.cpp:259]     Train net output #0: error_blob = 0.120599 (* 1 = 0.120599 loss)
I1002 01:00:58.314049 23733 solver.cpp:590] Iteration 3700, lr = 0.01
I1002 01:01:00.792153 23733 solver.cpp:243] Iteration 3800, loss = 0.116867
I1002 01:01:00.792202 23733 solver.cpp:259]     Train net output #0: error_blob = 0.116867 (* 1 = 0.116867 loss)
I1002 01:01:00.792212 23733 solver.cpp:590] Iteration 3800, lr = 0.01
I1002 01:01:03.325952 23733 solver.cpp:243] Iteration 3900, loss = 0.11515
I1002 01:01:03.325999 23733 solver.cpp:259]     Train net output #0: error_blob = 0.11515 (* 1 = 0.11515 loss)
I1002 01:01:03.326007 23733 solver.cpp:590] Iteration 3900, lr = 0.01
I1002 01:01:05.799350 23733 solver.cpp:347] Iteration 4000, Testing net (#0)
I1002 01:01:06.099278 23733 solver.cpp:415]     Test net output #0: error_blob = 0.12089 (* 1 = 0.12089 loss)
I1002 01:01:06.099992 23733 solver.cpp:243] Iteration 4000, loss = 0.11798
I1002 01:01:06.100009 23733 solver.cpp:259]     Train net output #0: error_blob = 0.11798 (* 1 = 0.11798 loss)
I1002 01:01:06.100016 23733 solver.cpp:590] Iteration 4000, lr = 0.01
I1002 01:01:08.583639 23733 solver.cpp:243] Iteration 4100, loss = 0.117992
I1002 01:01:08.583672 23733 solver.cpp:259]     Train net output #0: error_blob = 0.117992 (* 1 = 0.117992 loss)
I1002 01:01:08.583677 23733 solver.cpp:590] Iteration 4100, lr = 0.01
I1002 01:01:11.036311 23733 solver.cpp:243] Iteration 4200, loss = 0.116439
I1002 01:01:11.036345 23733 solver.cpp:259]     Train net output #0: error_blob = 0.116439 (* 1 = 0.116439 loss)
I1002 01:01:11.036350 23733 solver.cpp:590] Iteration 4200, lr = 0.01
I1002 01:01:13.558912 23733 solver.cpp:243] Iteration 4300, loss = 0.113894
I1002 01:01:13.558943 23733 solver.cpp:259]     Train net output #0: error_blob = 0.113894 (* 1 = 0.113894 loss)
I1002 01:01:13.558949 23733 solver.cpp:590] Iteration 4300, lr = 0.01
I1002 01:01:16.076035 23733 solver.cpp:243] Iteration 4400, loss = 0.117372
I1002 01:01:16.076064 23733 solver.cpp:259]     Train net output #0: error_blob = 0.117372 (* 1 = 0.117372 loss)
I1002 01:01:16.076069 23733 solver.cpp:590] Iteration 4400, lr = 0.01
I1002 01:01:18.565420 23733 solver.cpp:243] Iteration 4500, loss = 0.118509
I1002 01:01:18.565451 23733 solver.cpp:259]     Train net output #0: error_blob = 0.118509 (* 1 = 0.118509 loss)
I1002 01:01:18.565456 23733 solver.cpp:590] Iteration 4500, lr = 0.01
I1002 01:01:19.212255 23733 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 01:01:21.048696 23733 solver.cpp:243] Iteration 4600, loss = 0.115688
I1002 01:01:21.048727 23733 solver.cpp:259]     Train net output #0: error_blob = 0.115688 (* 1 = 0.115688 loss)
I1002 01:01:21.048733 23733 solver.cpp:590] Iteration 4600, lr = 0.01
I1002 01:01:23.545630 23733 solver.cpp:243] Iteration 4700, loss = 0.115917
I1002 01:01:23.545678 23733 solver.cpp:259]     Train net output #0: error_blob = 0.115917 (* 1 = 0.115917 loss)
I1002 01:01:23.545686 23733 solver.cpp:590] Iteration 4700, lr = 0.01
I1002 01:01:26.047459 23733 solver.cpp:243] Iteration 4800, loss = 0.118372
I1002 01:01:26.048494 23733 solver.cpp:259]     Train net output #0: error_blob = 0.118372 (* 1 = 0.118372 loss)
I1002 01:01:26.048506 23733 solver.cpp:590] Iteration 4800, lr = 0.01
I1002 01:01:28.575160 23733 solver.cpp:243] Iteration 4900, loss = 0.117157
I1002 01:01:28.575191 23733 solver.cpp:259]     Train net output #0: error_blob = 0.117157 (* 1 = 0.117157 loss)
I1002 01:01:28.575196 23733 solver.cpp:590] Iteration 4900, lr = 0.01
I1002 01:01:31.038980 23733 solver.cpp:347] Iteration 5000, Testing net (#0)
I1002 01:01:31.381587 23733 solver.cpp:415]     Test net output #0: error_blob = 0.117934 (* 1 = 0.117934 loss)
I1002 01:01:31.382243 23733 solver.cpp:243] Iteration 5000, loss = 0.113855
I1002 01:01:31.382266 23733 solver.cpp:259]     Train net output #0: error_blob = 0.113855 (* 1 = 0.113855 loss)
I1002 01:01:31.382274 23733 solver.cpp:590] Iteration 5000, lr = 0.01
I1002 01:01:33.924121 23733 solver.cpp:243] Iteration 5100, loss = 0.116301
I1002 01:01:33.924160 23733 solver.cpp:259]     Train net output #0: error_blob = 0.116301 (* 1 = 0.116301 loss)
I1002 01:01:33.924166 23733 solver.cpp:590] Iteration 5100, lr = 0.01
I1002 01:01:36.422122 23733 solver.cpp:243] Iteration 5200, loss = 0.118468
I1002 01:01:36.422163 23733 solver.cpp:259]     Train net output #0: error_blob = 0.118468 (* 1 = 0.118468 loss)
I1002 01:01:36.422169 23733 solver.cpp:590] Iteration 5200, lr = 0.01
I1002 01:01:38.896129 23733 solver.cpp:243] Iteration 5300, loss = 0.116614
I1002 01:01:38.896167 23733 solver.cpp:259]     Train net output #0: error_blob = 0.116614 (* 1 = 0.116614 loss)
I1002 01:01:38.896173 23733 solver.cpp:590] Iteration 5300, lr = 0.01
I1002 01:01:41.387899 23733 solver.cpp:243] Iteration 5400, loss = 0.117015
I1002 01:01:41.387940 23733 solver.cpp:259]     Train net output #0: error_blob = 0.117015 (* 1 = 0.117015 loss)
I1002 01:01:41.387945 23733 solver.cpp:590] Iteration 5400, lr = 0.01
I1002 01:01:42.165285 23733 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 01:01:43.860255 23733 solver.cpp:243] Iteration 5500, loss = 0.117101
I1002 01:01:43.860285 23733 solver.cpp:259]     Train net output #0: error_blob = 0.117101 (* 1 = 0.117101 loss)
I1002 01:01:43.860290 23733 solver.cpp:590] Iteration 5500, lr = 0.01
I1002 01:01:46.296859 23733 solver.cpp:243] Iteration 5600, loss = 0.117445
I1002 01:01:46.296888 23733 solver.cpp:259]     Train net output #0: error_blob = 0.117445 (* 1 = 0.117445 loss)
I1002 01:01:46.296893 23733 solver.cpp:590] Iteration 5600, lr = 0.01
I1002 01:01:48.805119 23733 solver.cpp:243] Iteration 5700, loss = 0.115218
I1002 01:01:48.805148 23733 solver.cpp:259]     Train net output #0: error_blob = 0.115218 (* 1 = 0.115218 loss)
I1002 01:01:48.805153 23733 solver.cpp:590] Iteration 5700, lr = 0.01
I1002 01:01:51.320200 23733 solver.cpp:243] Iteration 5800, loss = 0.114407
I1002 01:01:51.320230 23733 solver.cpp:259]     Train net output #0: error_blob = 0.114407 (* 1 = 0.114407 loss)
I1002 01:01:51.320235 23733 solver.cpp:590] Iteration 5800, lr = 0.01
I1002 01:01:53.795588 23733 solver.cpp:243] Iteration 5900, loss = 0.117924
I1002 01:01:53.795619 23733 solver.cpp:259]     Train net output #0: error_blob = 0.117924 (* 1 = 0.117924 loss)
I1002 01:01:53.795624 23733 solver.cpp:590] Iteration 5900, lr = 0.01
I1002 01:01:56.244338 23733 solver.cpp:347] Iteration 6000, Testing net (#0)
I1002 01:01:56.548595 23733 solver.cpp:415]     Test net output #0: error_blob = 0.117287 (* 1 = 0.117287 loss)
I1002 01:01:56.549237 23733 solver.cpp:243] Iteration 6000, loss = 0.11778
I1002 01:01:56.549250 23733 solver.cpp:259]     Train net output #0: error_blob = 0.11778 (* 1 = 0.11778 loss)
I1002 01:01:56.549254 23733 solver.cpp:590] Iteration 6000, lr = 0.01
I1002 01:01:59.031500 23733 solver.cpp:243] Iteration 6100, loss = 0.114926
I1002 01:01:59.031532 23733 solver.cpp:259]     Train net output #0: error_blob = 0.114926 (* 1 = 0.114926 loss)
I1002 01:01:59.031536 23733 solver.cpp:590] Iteration 6100, lr = 0.01
I1002 01:02:01.552186 23733 solver.cpp:243] Iteration 6200, loss = 0.115067
I1002 01:02:01.552218 23733 solver.cpp:259]     Train net output #0: error_blob = 0.115067 (* 1 = 0.115067 loss)
I1002 01:02:01.552224 23733 solver.cpp:590] Iteration 6200, lr = 0.01
I1002 01:02:04.051133 23733 solver.cpp:243] Iteration 6300, loss = 0.118377
I1002 01:02:04.051167 23733 solver.cpp:259]     Train net output #0: error_blob = 0.118377 (* 1 = 0.118377 loss)
I1002 01:02:04.051172 23733 solver.cpp:590] Iteration 6300, lr = 0.01
I1002 01:02:04.998447 23733 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 01:02:06.548323 23733 solver.cpp:243] Iteration 6400, loss = 0.118346
I1002 01:02:06.548353 23733 solver.cpp:259]     Train net output #0: error_blob = 0.118346 (* 1 = 0.118346 loss)
I1002 01:02:06.548358 23733 solver.cpp:590] Iteration 6400, lr = 0.01
I1002 01:02:09.034947 23733 solver.cpp:243] Iteration 6500, loss = 0.113991
I1002 01:02:09.034978 23733 solver.cpp:259]     Train net output #0: error_blob = 0.113991 (* 1 = 0.113991 loss)
I1002 01:02:09.034984 23733 solver.cpp:590] Iteration 6500, lr = 0.01
I1002 01:02:11.525122 23733 solver.cpp:243] Iteration 6600, loss = 0.117139
I1002 01:02:11.525154 23733 solver.cpp:259]     Train net output #0: error_blob = 0.117139 (* 1 = 0.117139 loss)
I1002 01:02:11.525161 23733 solver.cpp:590] Iteration 6600, lr = 0.01
I1002 01:02:14.013141 23733 solver.cpp:243] Iteration 6700, loss = 0.117292
I1002 01:02:14.013172 23733 solver.cpp:259]     Train net output #0: error_blob = 0.117292 (* 1 = 0.117292 loss)
I1002 01:02:14.013176 23733 solver.cpp:590] Iteration 6700, lr = 0.01
I1002 01:02:16.502828 23733 solver.cpp:243] Iteration 6800, loss = 0.11886
I1002 01:02:16.502859 23733 solver.cpp:259]     Train net output #0: error_blob = 0.11886 (* 1 = 0.11886 loss)
I1002 01:02:16.502864 23733 solver.cpp:590] Iteration 6800, lr = 0.01
I1002 01:02:19.016659 23733 solver.cpp:243] Iteration 6900, loss = 0.116653
I1002 01:02:19.016688 23733 solver.cpp:259]     Train net output #0: error_blob = 0.116653 (* 1 = 0.116653 loss)
I1002 01:02:19.016693 23733 solver.cpp:590] Iteration 6900, lr = 0.01
I1002 01:02:21.477046 23733 solver.cpp:347] Iteration 7000, Testing net (#0)
I1002 01:02:21.809648 23733 solver.cpp:415]     Test net output #0: error_blob = 0.115399 (* 1 = 0.115399 loss)
I1002 01:02:21.810282 23733 solver.cpp:243] Iteration 7000, loss = 0.115229
I1002 01:02:21.810295 23733 solver.cpp:259]     Train net output #0: error_blob = 0.115229 (* 1 = 0.115229 loss)
I1002 01:02:21.810302 23733 solver.cpp:590] Iteration 7000, lr = 0.01
I1002 01:02:24.249944 23733 solver.cpp:243] Iteration 7100, loss = 0.117486
I1002 01:02:24.249974 23733 solver.cpp:259]     Train net output #0: error_blob = 0.117486 (* 1 = 0.117486 loss)
I1002 01:02:24.249979 23733 solver.cpp:590] Iteration 7100, lr = 0.01
I1002 01:02:26.736891 23733 solver.cpp:243] Iteration 7200, loss = 0.121836
I1002 01:02:26.736986 23733 solver.cpp:259]     Train net output #0: error_blob = 0.121836 (* 1 = 0.121836 loss)
I1002 01:02:26.736992 23733 solver.cpp:590] Iteration 7200, lr = 0.01
I1002 01:02:27.807361 23733 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 01:02:29.218808 23733 solver.cpp:243] Iteration 7300, loss = 0.114962
I1002 01:02:29.218840 23733 solver.cpp:259]     Train net output #0: error_blob = 0.114962 (* 1 = 0.114962 loss)
I1002 01:02:29.218845 23733 solver.cpp:590] Iteration 7300, lr = 0.01
I1002 01:02:31.735517 23733 solver.cpp:243] Iteration 7400, loss = 0.117847
I1002 01:02:31.735548 23733 solver.cpp:259]     Train net output #0: error_blob = 0.117847 (* 1 = 0.117847 loss)
I1002 01:02:31.735553 23733 solver.cpp:590] Iteration 7400, lr = 0.01
I1002 01:02:34.249882 23733 solver.cpp:243] Iteration 7500, loss = 0.11764
I1002 01:02:34.249913 23733 solver.cpp:259]     Train net output #0: error_blob = 0.11764 (* 1 = 0.11764 loss)
I1002 01:02:34.249919 23733 solver.cpp:590] Iteration 7500, lr = 0.01
I1002 01:02:36.747280 23733 solver.cpp:243] Iteration 7600, loss = 0.114541
I1002 01:02:36.747309 23733 solver.cpp:259]     Train net output #0: error_blob = 0.114541 (* 1 = 0.114541 loss)
I1002 01:02:36.747315 23733 solver.cpp:590] Iteration 7600, lr = 0.01
I1002 01:02:39.237058 23733 solver.cpp:243] Iteration 7700, loss = 0.114374
I1002 01:02:39.237090 23733 solver.cpp:259]     Train net output #0: error_blob = 0.114374 (* 1 = 0.114374 loss)
I1002 01:02:39.237098 23733 solver.cpp:590] Iteration 7700, lr = 0.01
I1002 01:02:41.699697 23733 solver.cpp:243] Iteration 7800, loss = 0.118092
I1002 01:02:41.699728 23733 solver.cpp:259]     Train net output #0: error_blob = 0.118092 (* 1 = 0.118092 loss)
I1002 01:02:41.699733 23733 solver.cpp:590] Iteration 7800, lr = 0.01
I1002 01:02:44.160739 23733 solver.cpp:243] Iteration 7900, loss = 0.116354
I1002 01:02:44.160773 23733 solver.cpp:259]     Train net output #0: error_blob = 0.116354 (* 1 = 0.116354 loss)
I1002 01:02:44.160779 23733 solver.cpp:590] Iteration 7900, lr = 0.01
I1002 01:02:46.603953 23733 solver.cpp:347] Iteration 8000, Testing net (#0)
I1002 01:02:46.874167 23733 solver.cpp:415]     Test net output #0: error_blob = 0.117177 (* 1 = 0.117177 loss)
I1002 01:02:46.874888 23733 solver.cpp:243] Iteration 8000, loss = 0.112911
I1002 01:02:46.874902 23733 solver.cpp:259]     Train net output #0: error_blob = 0.112911 (* 1 = 0.112911 loss)
I1002 01:02:46.874909 23733 solver.cpp:590] Iteration 8000, lr = 0.01
I1002 01:02:49.418406 23733 solver.cpp:243] Iteration 8100, loss = 0.115177
I1002 01:02:49.418437 23733 solver.cpp:259]     Train net output #0: error_blob = 0.115177 (* 1 = 0.115177 loss)
I1002 01:02:49.418442 23733 solver.cpp:590] Iteration 8100, lr = 0.01
I1002 01:02:50.663578 23733 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 01:02:51.900692 23733 solver.cpp:243] Iteration 8200, loss = 0.116931
I1002 01:02:51.900722 23733 solver.cpp:259]     Train net output #0: error_blob = 0.116931 (* 1 = 0.116931 loss)
I1002 01:02:51.900727 23733 solver.cpp:590] Iteration 8200, lr = 0.01
I1002 01:02:54.380795 23733 solver.cpp:243] Iteration 8300, loss = 0.115609
I1002 01:02:54.380825 23733 solver.cpp:259]     Train net output #0: error_blob = 0.115609 (* 1 = 0.115609 loss)
I1002 01:02:54.380828 23733 solver.cpp:590] Iteration 8300, lr = 0.01
I1002 01:02:56.860600 23733 solver.cpp:243] Iteration 8400, loss = 0.115264
I1002 01:02:56.861650 23733 solver.cpp:259]     Train net output #0: error_blob = 0.115264 (* 1 = 0.115264 loss)
I1002 01:02:56.861659 23733 solver.cpp:590] Iteration 8400, lr = 0.01
I1002 01:02:59.335697 23733 solver.cpp:243] Iteration 8500, loss = 0.117462
I1002 01:02:59.335729 23733 solver.cpp:259]     Train net output #0: error_blob = 0.117462 (* 1 = 0.117462 loss)
I1002 01:02:59.335736 23733 solver.cpp:590] Iteration 8500, lr = 0.01
I1002 01:03:01.797366 23733 solver.cpp:243] Iteration 8600, loss = 0.117062
I1002 01:03:01.797407 23733 solver.cpp:259]     Train net output #0: error_blob = 0.117062 (* 1 = 0.117062 loss)
I1002 01:03:01.797412 23733 solver.cpp:590] Iteration 8600, lr = 0.01
I1002 01:03:04.279129 23733 solver.cpp:243] Iteration 8700, loss = 0.115684
I1002 01:03:04.279170 23733 solver.cpp:259]     Train net output #0: error_blob = 0.115684 (* 1 = 0.115684 loss)
I1002 01:03:04.279175 23733 solver.cpp:590] Iteration 8700, lr = 0.01
I1002 01:03:06.770854 23733 solver.cpp:243] Iteration 8800, loss = 0.113904
I1002 01:03:06.770884 23733 solver.cpp:259]     Train net output #0: error_blob = 0.113904 (* 1 = 0.113904 loss)
I1002 01:03:06.770889 23733 solver.cpp:590] Iteration 8800, lr = 0.01
I1002 01:03:09.228423 23733 solver.cpp:243] Iteration 8900, loss = 0.115736
I1002 01:03:09.228453 23733 solver.cpp:259]     Train net output #0: error_blob = 0.115736 (* 1 = 0.115736 loss)
I1002 01:03:09.228458 23733 solver.cpp:590] Iteration 8900, lr = 0.01
I1002 01:03:11.670680 23733 solver.cpp:347] Iteration 9000, Testing net (#0)
I1002 01:03:11.949596 23733 solver.cpp:415]     Test net output #0: error_blob = 0.114938 (* 1 = 0.114938 loss)
I1002 01:03:11.950206 23733 solver.cpp:243] Iteration 9000, loss = 0.117533
I1002 01:03:11.950215 23733 solver.cpp:259]     Train net output #0: error_blob = 0.117533 (* 1 = 0.117533 loss)
I1002 01:03:11.950222 23733 solver.cpp:590] Iteration 9000, lr = 0.01
I1002 01:03:13.314992 23733 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 01:03:14.415606 23733 solver.cpp:243] Iteration 9100, loss = 0.117467
I1002 01:03:14.415637 23733 solver.cpp:259]     Train net output #0: error_blob = 0.117467 (* 1 = 0.117467 loss)
I1002 01:03:14.415643 23733 solver.cpp:590] Iteration 9100, lr = 0.01
I1002 01:03:16.884460 23733 solver.cpp:243] Iteration 9200, loss = 0.114183
I1002 01:03:16.884502 23733 solver.cpp:259]     Train net output #0: error_blob = 0.114183 (* 1 = 0.114183 loss)
I1002 01:03:16.884507 23733 solver.cpp:590] Iteration 9200, lr = 0.01
I1002 01:03:19.391005 23733 solver.cpp:243] Iteration 9300, loss = 0.117776
I1002 01:03:19.391047 23733 solver.cpp:259]     Train net output #0: error_blob = 0.117776 (* 1 = 0.117776 loss)
I1002 01:03:19.391052 23733 solver.cpp:590] Iteration 9300, lr = 0.01
I1002 01:03:21.882761 23733 solver.cpp:243] Iteration 9400, loss = 0.116215
I1002 01:03:21.882791 23733 solver.cpp:259]     Train net output #0: error_blob = 0.116215 (* 1 = 0.116215 loss)
I1002 01:03:21.882797 23733 solver.cpp:590] Iteration 9400, lr = 0.01
I1002 01:03:24.363384 23733 solver.cpp:243] Iteration 9500, loss = 0.113169
I1002 01:03:24.363414 23733 solver.cpp:259]     Train net output #0: error_blob = 0.113169 (* 1 = 0.113169 loss)
I1002 01:03:24.363418 23733 solver.cpp:590] Iteration 9500, lr = 0.01
I1002 01:03:26.841441 23733 solver.cpp:243] Iteration 9600, loss = 0.113623
I1002 01:03:26.841482 23733 solver.cpp:259]     Train net output #0: error_blob = 0.113623 (* 1 = 0.113623 loss)
I1002 01:03:26.841488 23733 solver.cpp:590] Iteration 9600, lr = 0.01
I1002 01:03:29.288599 23733 solver.cpp:243] Iteration 9700, loss = 0.11703
I1002 01:03:29.289656 23733 solver.cpp:259]     Train net output #0: error_blob = 0.11703 (* 1 = 0.11703 loss)
I1002 01:03:29.289664 23733 solver.cpp:590] Iteration 9700, lr = 0.01
I1002 01:03:31.759822 23733 solver.cpp:243] Iteration 9800, loss = 0.116613
I1002 01:03:31.759853 23733 solver.cpp:259]     Train net output #0: error_blob = 0.116613 (* 1 = 0.116613 loss)
I1002 01:03:31.759860 23733 solver.cpp:590] Iteration 9800, lr = 0.01
I1002 01:03:34.271919 23733 solver.cpp:243] Iteration 9900, loss = 0.113413
I1002 01:03:34.271952 23733 solver.cpp:259]     Train net output #0: error_blob = 0.113413 (* 1 = 0.113413 loss)
I1002 01:03:34.271958 23733 solver.cpp:590] Iteration 9900, lr = 0.01
I1002 01:03:36.746791 23733 solver.cpp:468] Snapshotting to binary proto file _iter_10000.caffemodel
I1002 01:03:36.748535 23733 solver.cpp:753] Snapshotting solver state to binary proto file _iter_10000.solverstate
I1002 01:03:36.771813 23733 solver.cpp:327] Iteration 10000, loss = 0.115247
I1002 01:03:36.771838 23733 solver.cpp:347] Iteration 10000, Testing net (#0)
I1002 01:03:37.015256 23733 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 01:03:37.173166 23733 solver.cpp:415]     Test net output #0: error_blob = 0.117076 (* 1 = 0.117076 loss)
I1002 01:03:37.173193 23733 solver.cpp:332] Optimization Done.
I1002 01:03:37.173197 23733 caffe.cpp:215] Optimization Done.
I1002 01:03:37.237520 23744 caffe.cpp:184] Using GPUs 0
I1002 01:03:37.795091 23744 solver.cpp:54] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "fixed"
momentum: 0.9
solver_mode: GPU
device_id: 0
net: "model/NNScore/nnscore_model_6.prototxt"
I1002 01:03:37.795123 23744 solver.cpp:97] Creating training net from net file: model/NNScore/nnscore_model_6.prototxt
I1002 01:03:37.795274 23744 net.cpp:339] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_layer
I1002 01:03:37.795311 23744 net.cpp:50] Initializing net from parameters: 
name: "model/NNScore/nnscore_model_6.prototxt"
state {
  phase: TRAIN
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TRAIN
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.6.train"
    batch_size: 20000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1002 01:03:37.795348 23744 layer_factory.hpp:76] Creating layer data_layer
I1002 01:03:37.808609 23744 net.cpp:110] Creating Layer data_layer
I1002 01:03:37.808640 23744 net.cpp:433] data_layer -> data_blob
I1002 01:03:37.808663 23744 net.cpp:433] data_layer -> label_blob
I1002 01:03:37.809281 23748 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.6.train
I1002 01:03:38.493721 23744 data_layer.cpp:45] output data size: 20000,61,1,1
I1002 01:03:38.498672 23744 net.cpp:155] Setting up data_layer
I1002 01:03:38.498713 23744 net.cpp:163] Top shape: 20000 61 1 1 (1220000)
I1002 01:03:38.498718 23744 net.cpp:163] Top shape: 20000 (20000)
I1002 01:03:38.498733 23744 layer_factory.hpp:76] Creating layer hidden_sum_layer
I1002 01:03:38.498745 23744 net.cpp:110] Creating Layer hidden_sum_layer
I1002 01:03:38.498749 23744 net.cpp:477] hidden_sum_layer <- data_blob
I1002 01:03:38.498757 23744 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I1002 01:03:38.499114 23744 net.cpp:155] Setting up hidden_sum_layer
I1002 01:03:38.499121 23744 net.cpp:163] Top shape: 20000 10 (200000)
I1002 01:03:38.499142 23744 layer_factory.hpp:76] Creating layer hidden_act_layer
I1002 01:03:38.499160 23744 net.cpp:110] Creating Layer hidden_act_layer
I1002 01:03:38.499162 23744 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I1002 01:03:38.499166 23744 net.cpp:433] hidden_act_layer -> hidden_act_blob
I1002 01:03:41.725293 23744 net.cpp:155] Setting up hidden_act_layer
I1002 01:03:41.725319 23744 net.cpp:163] Top shape: 20000 10 (200000)
I1002 01:03:41.725325 23744 layer_factory.hpp:76] Creating layer output_sum_layer
I1002 01:03:41.725338 23744 net.cpp:110] Creating Layer output_sum_layer
I1002 01:03:41.725342 23744 net.cpp:477] output_sum_layer <- hidden_act_blob
I1002 01:03:41.725358 23744 net.cpp:433] output_sum_layer -> output_sum_blob
I1002 01:03:41.725457 23744 net.cpp:155] Setting up output_sum_layer
I1002 01:03:41.725462 23744 net.cpp:163] Top shape: 20000 1 (20000)
I1002 01:03:41.725487 23744 layer_factory.hpp:76] Creating layer output_act_layer
I1002 01:03:41.725492 23744 net.cpp:110] Creating Layer output_act_layer
I1002 01:03:41.725494 23744 net.cpp:477] output_act_layer <- output_sum_blob
I1002 01:03:41.725497 23744 net.cpp:433] output_act_layer -> output_act_blob
I1002 01:03:41.725580 23744 net.cpp:155] Setting up output_act_layer
I1002 01:03:41.725596 23744 net.cpp:163] Top shape: 20000 1 (20000)
I1002 01:03:41.725600 23744 layer_factory.hpp:76] Creating layer error_layer
I1002 01:03:41.725605 23744 net.cpp:110] Creating Layer error_layer
I1002 01:03:41.725606 23744 net.cpp:477] error_layer <- output_act_blob
I1002 01:03:41.725610 23744 net.cpp:477] error_layer <- label_blob
I1002 01:03:41.725612 23744 net.cpp:433] error_layer -> error_blob
I1002 01:03:41.725646 23744 net.cpp:155] Setting up error_layer
I1002 01:03:41.725649 23744 net.cpp:163] Top shape: (1)
I1002 01:03:41.725651 23744 net.cpp:168]     with loss weight 1
I1002 01:03:41.725668 23744 net.cpp:236] error_layer needs backward computation.
I1002 01:03:41.725683 23744 net.cpp:236] output_act_layer needs backward computation.
I1002 01:03:41.725685 23744 net.cpp:236] output_sum_layer needs backward computation.
I1002 01:03:41.725687 23744 net.cpp:236] hidden_act_layer needs backward computation.
I1002 01:03:41.725689 23744 net.cpp:236] hidden_sum_layer needs backward computation.
I1002 01:03:41.725692 23744 net.cpp:240] data_layer does not need backward computation.
I1002 01:03:41.725693 23744 net.cpp:283] This network produces output error_blob
I1002 01:03:41.725714 23744 net.cpp:297] Network initialization done.
I1002 01:03:41.725716 23744 net.cpp:298] Memory required for data: 6720004
I1002 01:03:41.725849 23744 solver.cpp:187] Creating test net (#0) specified by net file: model/NNScore/nnscore_model_6.prototxt
I1002 01:03:41.725860 23744 net.cpp:339] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_layer
I1002 01:03:41.725911 23744 net.cpp:50] Initializing net from parameters: 
name: "model/NNScore/nnscore_model_6.prototxt"
state {
  phase: TEST
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TEST
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.6.test"
    batch_size: 2000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1002 01:03:41.725951 23744 layer_factory.hpp:76] Creating layer data_layer
I1002 01:03:41.727224 23744 net.cpp:110] Creating Layer data_layer
I1002 01:03:41.727233 23744 net.cpp:433] data_layer -> data_blob
I1002 01:03:41.727238 23744 net.cpp:433] data_layer -> label_blob
I1002 01:03:41.727965 23750 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.6.test
I1002 01:03:41.728049 23744 data_layer.cpp:45] output data size: 2000,61,1,1
I1002 01:03:41.729480 23744 net.cpp:155] Setting up data_layer
I1002 01:03:41.729493 23744 net.cpp:163] Top shape: 2000 61 1 1 (122000)
I1002 01:03:41.729497 23744 net.cpp:163] Top shape: 2000 (2000)
I1002 01:03:41.729501 23744 layer_factory.hpp:76] Creating layer hidden_sum_layer
I1002 01:03:41.729511 23744 net.cpp:110] Creating Layer hidden_sum_layer
I1002 01:03:41.729512 23744 net.cpp:477] hidden_sum_layer <- data_blob
I1002 01:03:41.729517 23744 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I1002 01:03:41.729674 23744 net.cpp:155] Setting up hidden_sum_layer
I1002 01:03:41.729681 23744 net.cpp:163] Top shape: 2000 10 (20000)
I1002 01:03:41.729688 23744 layer_factory.hpp:76] Creating layer hidden_act_layer
I1002 01:03:41.729693 23744 net.cpp:110] Creating Layer hidden_act_layer
I1002 01:03:41.729696 23744 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I1002 01:03:41.729709 23744 net.cpp:433] hidden_act_layer -> hidden_act_blob
I1002 01:03:41.729890 23744 net.cpp:155] Setting up hidden_act_layer
I1002 01:03:41.729897 23744 net.cpp:163] Top shape: 2000 10 (20000)
I1002 01:03:41.729899 23744 layer_factory.hpp:76] Creating layer output_sum_layer
I1002 01:03:41.729904 23744 net.cpp:110] Creating Layer output_sum_layer
I1002 01:03:41.729907 23744 net.cpp:477] output_sum_layer <- hidden_act_blob
I1002 01:03:41.729910 23744 net.cpp:433] output_sum_layer -> output_sum_blob
I1002 01:03:41.729967 23744 net.cpp:155] Setting up output_sum_layer
I1002 01:03:41.729972 23744 net.cpp:163] Top shape: 2000 1 (2000)
I1002 01:03:41.729979 23744 layer_factory.hpp:76] Creating layer output_act_layer
I1002 01:03:41.729981 23744 net.cpp:110] Creating Layer output_act_layer
I1002 01:03:41.729984 23744 net.cpp:477] output_act_layer <- output_sum_blob
I1002 01:03:41.729986 23744 net.cpp:433] output_act_layer -> output_act_blob
I1002 01:03:41.730033 23744 net.cpp:155] Setting up output_act_layer
I1002 01:03:41.730037 23744 net.cpp:163] Top shape: 2000 1 (2000)
I1002 01:03:41.730041 23744 layer_factory.hpp:76] Creating layer error_layer
I1002 01:03:41.730044 23744 net.cpp:110] Creating Layer error_layer
I1002 01:03:41.730046 23744 net.cpp:477] error_layer <- output_act_blob
I1002 01:03:41.730048 23744 net.cpp:477] error_layer <- label_blob
I1002 01:03:41.730051 23744 net.cpp:433] error_layer -> error_blob
I1002 01:03:41.730070 23744 net.cpp:155] Setting up error_layer
I1002 01:03:41.730073 23744 net.cpp:163] Top shape: (1)
I1002 01:03:41.730075 23744 net.cpp:168]     with loss weight 1
I1002 01:03:41.730083 23744 net.cpp:236] error_layer needs backward computation.
I1002 01:03:41.730085 23744 net.cpp:236] output_act_layer needs backward computation.
I1002 01:03:41.730087 23744 net.cpp:236] output_sum_layer needs backward computation.
I1002 01:03:41.730089 23744 net.cpp:236] hidden_act_layer needs backward computation.
I1002 01:03:41.730092 23744 net.cpp:236] hidden_sum_layer needs backward computation.
I1002 01:03:41.730093 23744 net.cpp:240] data_layer does not need backward computation.
I1002 01:03:41.730095 23744 net.cpp:283] This network produces output error_blob
I1002 01:03:41.730100 23744 net.cpp:297] Network initialization done.
I1002 01:03:41.730101 23744 net.cpp:298] Memory required for data: 672004
I1002 01:03:41.730121 23744 solver.cpp:66] Solver scaffolding done.
I1002 01:03:41.730211 23744 caffe.cpp:212] Starting Optimization
I1002 01:03:41.730216 23744 solver.cpp:294] Solving model/NNScore/nnscore_model_6.prototxt
I1002 01:03:41.730218 23744 solver.cpp:295] Learning Rate Policy: fixed
I1002 01:03:41.730356 23744 solver.cpp:347] Iteration 0, Testing net (#0)
I1002 01:03:41.730427 23744 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 01:03:41.996080 23744 solver.cpp:415]     Test net output #0: error_blob = 0.128908 (* 1 = 0.128908 loss)
I1002 01:03:41.997409 23744 solver.cpp:243] Iteration 0, loss = 0.128576
I1002 01:03:41.997426 23744 solver.cpp:259]     Train net output #0: error_blob = 0.128576 (* 1 = 0.128576 loss)
I1002 01:03:41.997436 23744 solver.cpp:590] Iteration 0, lr = 0.01
I1002 01:03:44.622202 23744 solver.cpp:243] Iteration 100, loss = 0.116621
I1002 01:03:44.622241 23744 solver.cpp:259]     Train net output #0: error_blob = 0.116621 (* 1 = 0.116621 loss)
I1002 01:03:44.622251 23744 solver.cpp:590] Iteration 100, lr = 0.01
I1002 01:03:47.127276 23744 solver.cpp:243] Iteration 200, loss = 0.114208
I1002 01:03:47.127316 23744 solver.cpp:259]     Train net output #0: error_blob = 0.114208 (* 1 = 0.114208 loss)
I1002 01:03:47.127336 23744 solver.cpp:590] Iteration 200, lr = 0.01
I1002 01:03:49.596127 23744 solver.cpp:243] Iteration 300, loss = 0.116175
I1002 01:03:49.596165 23744 solver.cpp:259]     Train net output #0: error_blob = 0.116175 (* 1 = 0.116175 loss)
I1002 01:03:49.596184 23744 solver.cpp:590] Iteration 300, lr = 0.01
I1002 01:03:52.093937 23744 solver.cpp:243] Iteration 400, loss = 0.117018
I1002 01:03:52.093991 23744 solver.cpp:259]     Train net output #0: error_blob = 0.117018 (* 1 = 0.117018 loss)
I1002 01:03:52.093998 23744 solver.cpp:590] Iteration 400, lr = 0.01
I1002 01:03:54.638743 23744 solver.cpp:243] Iteration 500, loss = 0.115798
I1002 01:03:54.638784 23744 solver.cpp:259]     Train net output #0: error_blob = 0.115798 (* 1 = 0.115798 loss)
I1002 01:03:54.638792 23744 solver.cpp:590] Iteration 500, lr = 0.01
I1002 01:03:57.139827 23744 solver.cpp:243] Iteration 600, loss = 0.112993
I1002 01:03:57.139876 23744 solver.cpp:259]     Train net output #0: error_blob = 0.112993 (* 1 = 0.112993 loss)
I1002 01:03:57.139883 23744 solver.cpp:590] Iteration 600, lr = 0.01
I1002 01:03:59.663873 23744 solver.cpp:243] Iteration 700, loss = 0.113032
I1002 01:03:59.663913 23744 solver.cpp:259]     Train net output #0: error_blob = 0.113032 (* 1 = 0.113032 loss)
I1002 01:03:59.663918 23744 solver.cpp:590] Iteration 700, lr = 0.01
I1002 01:04:02.158452 23744 solver.cpp:243] Iteration 800, loss = 0.116204
I1002 01:04:02.158495 23744 solver.cpp:259]     Train net output #0: error_blob = 0.116204 (* 1 = 0.116204 loss)
I1002 01:04:02.158500 23744 solver.cpp:590] Iteration 800, lr = 0.01
I1002 01:04:04.631328 23744 solver.cpp:243] Iteration 900, loss = 0.116112
I1002 01:04:04.631378 23744 solver.cpp:259]     Train net output #0: error_blob = 0.116112 (* 1 = 0.116112 loss)
I1002 01:04:04.631386 23744 solver.cpp:590] Iteration 900, lr = 0.01
I1002 01:04:04.680903 23744 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 01:04:07.062692 23744 solver.cpp:347] Iteration 1000, Testing net (#0)
I1002 01:04:07.350661 23744 solver.cpp:415]     Test net output #0: error_blob = 0.118931 (* 1 = 0.118931 loss)
I1002 01:04:07.352910 23744 solver.cpp:243] Iteration 1000, loss = 0.11302
I1002 01:04:07.352952 23744 solver.cpp:259]     Train net output #0: error_blob = 0.11302 (* 1 = 0.11302 loss)
I1002 01:04:07.352962 23744 solver.cpp:590] Iteration 1000, lr = 0.01
I1002 01:04:09.822825 23744 solver.cpp:243] Iteration 1100, loss = 0.113249
I1002 01:04:09.822857 23744 solver.cpp:259]     Train net output #0: error_blob = 0.113249 (* 1 = 0.113249 loss)
I1002 01:04:09.822865 23744 solver.cpp:590] Iteration 1100, lr = 0.01
I1002 01:04:12.316157 23744 solver.cpp:243] Iteration 1200, loss = 0.116353
I1002 01:04:12.316207 23744 solver.cpp:259]     Train net output #0: error_blob = 0.116353 (* 1 = 0.116353 loss)
I1002 01:04:12.316215 23744 solver.cpp:590] Iteration 1200, lr = 0.01
I1002 01:04:14.859655 23744 solver.cpp:243] Iteration 1300, loss = 0.116644
I1002 01:04:14.859704 23744 solver.cpp:259]     Train net output #0: error_blob = 0.116644 (* 1 = 0.116644 loss)
I1002 01:04:14.859714 23744 solver.cpp:590] Iteration 1300, lr = 0.01
I1002 01:04:17.403990 23744 solver.cpp:243] Iteration 1400, loss = 0.110777
I1002 01:04:17.404032 23744 solver.cpp:259]     Train net output #0: error_blob = 0.110777 (* 1 = 0.110777 loss)
I1002 01:04:17.404037 23744 solver.cpp:590] Iteration 1400, lr = 0.01
I1002 01:04:19.913113 23744 solver.cpp:243] Iteration 1500, loss = 0.110568
I1002 01:04:19.913153 23744 solver.cpp:259]     Train net output #0: error_blob = 0.110568 (* 1 = 0.110568 loss)
I1002 01:04:19.913158 23744 solver.cpp:590] Iteration 1500, lr = 0.01
I1002 01:04:22.438454 23744 solver.cpp:243] Iteration 1600, loss = 0.115649
I1002 01:04:22.438484 23744 solver.cpp:259]     Train net output #0: error_blob = 0.115649 (* 1 = 0.115649 loss)
I1002 01:04:22.438489 23744 solver.cpp:590] Iteration 1600, lr = 0.01
I1002 01:04:24.967964 23744 solver.cpp:243] Iteration 1700, loss = 0.117318
I1002 01:04:24.968006 23744 solver.cpp:259]     Train net output #0: error_blob = 0.117318 (* 1 = 0.117318 loss)
I1002 01:04:24.968011 23744 solver.cpp:590] Iteration 1700, lr = 0.01
I1002 01:04:27.476972 23744 solver.cpp:243] Iteration 1800, loss = 0.110548
I1002 01:04:27.477005 23744 solver.cpp:259]     Train net output #0: error_blob = 0.110548 (* 1 = 0.110548 loss)
I1002 01:04:27.477010 23744 solver.cpp:590] Iteration 1800, lr = 0.01
I1002 01:04:27.677788 23744 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 01:04:29.967335 23744 solver.cpp:243] Iteration 1900, loss = 0.111504
I1002 01:04:29.967366 23744 solver.cpp:259]     Train net output #0: error_blob = 0.111504 (* 1 = 0.111504 loss)
I1002 01:04:29.967371 23744 solver.cpp:590] Iteration 1900, lr = 0.01
I1002 01:04:32.407239 23744 solver.cpp:347] Iteration 2000, Testing net (#0)
I1002 01:04:32.701776 23744 solver.cpp:415]     Test net output #0: error_blob = 0.118075 (* 1 = 0.118075 loss)
I1002 01:04:32.702445 23744 solver.cpp:243] Iteration 2000, loss = 0.113358
I1002 01:04:32.702462 23744 solver.cpp:259]     Train net output #0: error_blob = 0.113358 (* 1 = 0.113358 loss)
I1002 01:04:32.702469 23744 solver.cpp:590] Iteration 2000, lr = 0.01
I1002 01:04:35.202918 23744 solver.cpp:243] Iteration 2100, loss = 0.115296
I1002 01:04:35.202949 23744 solver.cpp:259]     Train net output #0: error_blob = 0.115296 (* 1 = 0.115296 loss)
I1002 01:04:35.202955 23744 solver.cpp:590] Iteration 2100, lr = 0.01
I1002 01:04:37.689097 23744 solver.cpp:243] Iteration 2200, loss = 0.115149
I1002 01:04:37.689275 23744 solver.cpp:259]     Train net output #0: error_blob = 0.115149 (* 1 = 0.115149 loss)
I1002 01:04:37.689295 23744 solver.cpp:590] Iteration 2200, lr = 0.01
I1002 01:04:40.242400 23744 solver.cpp:243] Iteration 2300, loss = 0.111938
I1002 01:04:40.242437 23744 solver.cpp:259]     Train net output #0: error_blob = 0.111938 (* 1 = 0.111938 loss)
I1002 01:04:40.242444 23744 solver.cpp:590] Iteration 2300, lr = 0.01
I1002 01:04:42.784975 23744 solver.cpp:243] Iteration 2400, loss = 0.116243
I1002 01:04:42.785007 23744 solver.cpp:259]     Train net output #0: error_blob = 0.116243 (* 1 = 0.116243 loss)
I1002 01:04:42.785014 23744 solver.cpp:590] Iteration 2400, lr = 0.01
I1002 01:04:45.332875 23744 solver.cpp:243] Iteration 2500, loss = 0.114855
I1002 01:04:45.332913 23744 solver.cpp:259]     Train net output #0: error_blob = 0.114855 (* 1 = 0.114855 loss)
I1002 01:04:45.332918 23744 solver.cpp:590] Iteration 2500, lr = 0.01
I1002 01:04:47.859354 23744 solver.cpp:243] Iteration 2600, loss = 0.1161
I1002 01:04:47.859396 23744 solver.cpp:259]     Train net output #0: error_blob = 0.1161 (* 1 = 0.1161 loss)
I1002 01:04:47.859401 23744 solver.cpp:590] Iteration 2600, lr = 0.01
I1002 01:04:50.368779 23744 solver.cpp:243] Iteration 2700, loss = 0.110941
I1002 01:04:50.368825 23744 solver.cpp:259]     Train net output #0: error_blob = 0.110941 (* 1 = 0.110941 loss)
I1002 01:04:50.368834 23744 solver.cpp:590] Iteration 2700, lr = 0.01
I1002 01:04:50.715651 23744 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 01:04:52.877430 23744 solver.cpp:243] Iteration 2800, loss = 0.11175
I1002 01:04:52.877471 23744 solver.cpp:259]     Train net output #0: error_blob = 0.11175 (* 1 = 0.11175 loss)
I1002 01:04:52.877478 23744 solver.cpp:590] Iteration 2800, lr = 0.01
I1002 01:04:55.404132 23744 solver.cpp:243] Iteration 2900, loss = 0.115977
I1002 01:04:55.404165 23744 solver.cpp:259]     Train net output #0: error_blob = 0.115977 (* 1 = 0.115977 loss)
I1002 01:04:55.404170 23744 solver.cpp:590] Iteration 2900, lr = 0.01
I1002 01:04:57.920680 23744 solver.cpp:347] Iteration 3000, Testing net (#0)
I1002 01:04:58.204017 23744 solver.cpp:415]     Test net output #0: error_blob = 0.117439 (* 1 = 0.117439 loss)
I1002 01:04:58.204713 23744 solver.cpp:243] Iteration 3000, loss = 0.114817
I1002 01:04:58.204732 23744 solver.cpp:259]     Train net output #0: error_blob = 0.114817 (* 1 = 0.114817 loss)
I1002 01:04:58.204751 23744 solver.cpp:590] Iteration 3000, lr = 0.01
I1002 01:05:00.670748 23744 solver.cpp:243] Iteration 3100, loss = 0.113275
I1002 01:05:00.670794 23744 solver.cpp:259]     Train net output #0: error_blob = 0.113275 (* 1 = 0.113275 loss)
I1002 01:05:00.670800 23744 solver.cpp:590] Iteration 3100, lr = 0.01
I1002 01:05:03.202378 23744 solver.cpp:243] Iteration 3200, loss = 0.111704
I1002 01:05:03.202410 23744 solver.cpp:259]     Train net output #0: error_blob = 0.111704 (* 1 = 0.111704 loss)
I1002 01:05:03.202415 23744 solver.cpp:590] Iteration 3200, lr = 0.01
I1002 01:05:05.719617 23744 solver.cpp:243] Iteration 3300, loss = 0.114867
I1002 01:05:05.719651 23744 solver.cpp:259]     Train net output #0: error_blob = 0.114867 (* 1 = 0.114867 loss)
I1002 01:05:05.719655 23744 solver.cpp:590] Iteration 3300, lr = 0.01
I1002 01:05:08.256266 23744 solver.cpp:243] Iteration 3400, loss = 0.114879
I1002 01:05:08.256395 23744 solver.cpp:259]     Train net output #0: error_blob = 0.114879 (* 1 = 0.114879 loss)
I1002 01:05:08.256402 23744 solver.cpp:590] Iteration 3400, lr = 0.01
I1002 01:05:10.767037 23744 solver.cpp:243] Iteration 3500, loss = 0.112521
I1002 01:05:10.767083 23744 solver.cpp:259]     Train net output #0: error_blob = 0.112521 (* 1 = 0.112521 loss)
I1002 01:05:10.767092 23744 solver.cpp:590] Iteration 3500, lr = 0.01
I1002 01:05:13.270110 23744 solver.cpp:243] Iteration 3600, loss = 0.109396
I1002 01:05:13.270150 23744 solver.cpp:259]     Train net output #0: error_blob = 0.109396 (* 1 = 0.109396 loss)
I1002 01:05:13.270155 23744 solver.cpp:590] Iteration 3600, lr = 0.01
I1002 01:05:13.776244 23744 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 01:05:15.826519 23744 solver.cpp:243] Iteration 3700, loss = 0.112781
I1002 01:05:15.826551 23744 solver.cpp:259]     Train net output #0: error_blob = 0.112781 (* 1 = 0.112781 loss)
I1002 01:05:15.826556 23744 solver.cpp:590] Iteration 3700, lr = 0.01
I1002 01:05:18.353396 23744 solver.cpp:243] Iteration 3800, loss = 0.116007
I1002 01:05:18.353445 23744 solver.cpp:259]     Train net output #0: error_blob = 0.116007 (* 1 = 0.116007 loss)
I1002 01:05:18.353452 23744 solver.cpp:590] Iteration 3800, lr = 0.01
I1002 01:05:20.897454 23744 solver.cpp:243] Iteration 3900, loss = 0.113991
I1002 01:05:20.897485 23744 solver.cpp:259]     Train net output #0: error_blob = 0.113991 (* 1 = 0.113991 loss)
I1002 01:05:20.897490 23744 solver.cpp:590] Iteration 3900, lr = 0.01
I1002 01:05:23.416604 23744 solver.cpp:347] Iteration 4000, Testing net (#0)
I1002 01:05:23.707590 23744 solver.cpp:415]     Test net output #0: error_blob = 0.117056 (* 1 = 0.117056 loss)
I1002 01:05:23.708259 23744 solver.cpp:243] Iteration 4000, loss = 0.108792
I1002 01:05:23.708278 23744 solver.cpp:259]     Train net output #0: error_blob = 0.108792 (* 1 = 0.108792 loss)
I1002 01:05:23.708287 23744 solver.cpp:590] Iteration 4000, lr = 0.01
I1002 01:05:26.218153 23744 solver.cpp:243] Iteration 4100, loss = 0.11163
I1002 01:05:26.218183 23744 solver.cpp:259]     Train net output #0: error_blob = 0.11163 (* 1 = 0.11163 loss)
I1002 01:05:26.218188 23744 solver.cpp:590] Iteration 4100, lr = 0.01
I1002 01:05:28.776307 23744 solver.cpp:243] Iteration 4200, loss = 0.112544
I1002 01:05:28.776355 23744 solver.cpp:259]     Train net output #0: error_blob = 0.112544 (* 1 = 0.112544 loss)
I1002 01:05:28.776361 23744 solver.cpp:590] Iteration 4200, lr = 0.01
I1002 01:05:31.334143 23744 solver.cpp:243] Iteration 4300, loss = 0.114157
I1002 01:05:31.334187 23744 solver.cpp:259]     Train net output #0: error_blob = 0.114157 (* 1 = 0.114157 loss)
I1002 01:05:31.334194 23744 solver.cpp:590] Iteration 4300, lr = 0.01
I1002 01:05:33.896455 23744 solver.cpp:243] Iteration 4400, loss = 0.110447
I1002 01:05:33.896499 23744 solver.cpp:259]     Train net output #0: error_blob = 0.110447 (* 1 = 0.110447 loss)
I1002 01:05:33.896519 23744 solver.cpp:590] Iteration 4400, lr = 0.01
I1002 01:05:36.432397 23744 solver.cpp:243] Iteration 4500, loss = 0.110386
I1002 01:05:36.432441 23744 solver.cpp:259]     Train net output #0: error_blob = 0.110386 (* 1 = 0.110386 loss)
I1002 01:05:36.432449 23744 solver.cpp:590] Iteration 4500, lr = 0.01
I1002 01:05:37.095123 23744 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 01:05:38.987761 23744 solver.cpp:243] Iteration 4600, loss = 0.115845
I1002 01:05:38.987869 23744 solver.cpp:259]     Train net output #0: error_blob = 0.115845 (* 1 = 0.115845 loss)
I1002 01:05:38.987875 23744 solver.cpp:590] Iteration 4600, lr = 0.01
I1002 01:05:41.522845 23744 solver.cpp:243] Iteration 4700, loss = 0.114998
I1002 01:05:41.522884 23744 solver.cpp:259]     Train net output #0: error_blob = 0.114998 (* 1 = 0.114998 loss)
I1002 01:05:41.522891 23744 solver.cpp:590] Iteration 4700, lr = 0.01
I1002 01:05:44.079001 23744 solver.cpp:243] Iteration 4800, loss = 0.112551
I1002 01:05:44.079043 23744 solver.cpp:259]     Train net output #0: error_blob = 0.112551 (* 1 = 0.112551 loss)
I1002 01:05:44.079049 23744 solver.cpp:590] Iteration 4800, lr = 0.01
I1002 01:05:46.567215 23744 solver.cpp:243] Iteration 4900, loss = 0.110617
I1002 01:05:46.567248 23744 solver.cpp:259]     Train net output #0: error_blob = 0.110617 (* 1 = 0.110617 loss)
I1002 01:05:46.567255 23744 solver.cpp:590] Iteration 4900, lr = 0.01
I1002 01:05:49.068583 23744 solver.cpp:347] Iteration 5000, Testing net (#0)
I1002 01:05:49.357255 23744 solver.cpp:415]     Test net output #0: error_blob = 0.116639 (* 1 = 0.116639 loss)
I1002 01:05:49.357890 23744 solver.cpp:243] Iteration 5000, loss = 0.113416
I1002 01:05:49.357908 23744 solver.cpp:259]     Train net output #0: error_blob = 0.113416 (* 1 = 0.113416 loss)
I1002 01:05:49.357915 23744 solver.cpp:590] Iteration 5000, lr = 0.01
I1002 01:05:51.950657 23744 solver.cpp:243] Iteration 5100, loss = 0.112598
I1002 01:05:51.950690 23744 solver.cpp:259]     Train net output #0: error_blob = 0.112598 (* 1 = 0.112598 loss)
I1002 01:05:51.950696 23744 solver.cpp:590] Iteration 5100, lr = 0.01
I1002 01:05:54.460314 23744 solver.cpp:243] Iteration 5200, loss = 0.109628
I1002 01:05:54.460348 23744 solver.cpp:259]     Train net output #0: error_blob = 0.109628 (* 1 = 0.109628 loss)
I1002 01:05:54.460356 23744 solver.cpp:590] Iteration 5200, lr = 0.01
I1002 01:05:56.997263 23744 solver.cpp:243] Iteration 5300, loss = 0.107828
I1002 01:05:56.997311 23744 solver.cpp:259]     Train net output #0: error_blob = 0.107828 (* 1 = 0.107828 loss)
I1002 01:05:56.997319 23744 solver.cpp:590] Iteration 5300, lr = 0.01
I1002 01:05:59.519686 23744 solver.cpp:243] Iteration 5400, loss = 0.113461
I1002 01:05:59.519737 23744 solver.cpp:259]     Train net output #0: error_blob = 0.113461 (* 1 = 0.113461 loss)
I1002 01:05:59.519745 23744 solver.cpp:590] Iteration 5400, lr = 0.01
I1002 01:06:00.316113 23744 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 01:06:02.007673 23744 solver.cpp:243] Iteration 5500, loss = 0.11473
I1002 01:06:02.007704 23744 solver.cpp:259]     Train net output #0: error_blob = 0.11473 (* 1 = 0.11473 loss)
I1002 01:06:02.007709 23744 solver.cpp:590] Iteration 5500, lr = 0.01
I1002 01:06:04.499724 23744 solver.cpp:243] Iteration 5600, loss = 0.111428
I1002 01:06:04.499754 23744 solver.cpp:259]     Train net output #0: error_blob = 0.111428 (* 1 = 0.111428 loss)
I1002 01:06:04.499760 23744 solver.cpp:590] Iteration 5600, lr = 0.01
I1002 01:06:07.024693 23744 solver.cpp:243] Iteration 5700, loss = 0.108845
I1002 01:06:07.024724 23744 solver.cpp:259]     Train net output #0: error_blob = 0.108845 (* 1 = 0.108845 loss)
I1002 01:06:07.024729 23744 solver.cpp:590] Iteration 5700, lr = 0.01
I1002 01:06:09.553305 23744 solver.cpp:243] Iteration 5800, loss = 0.109101
I1002 01:06:09.554275 23744 solver.cpp:259]     Train net output #0: error_blob = 0.109101 (* 1 = 0.109101 loss)
I1002 01:06:09.554281 23744 solver.cpp:590] Iteration 5800, lr = 0.01
I1002 01:06:12.085070 23744 solver.cpp:243] Iteration 5900, loss = 0.112899
I1002 01:06:12.085100 23744 solver.cpp:259]     Train net output #0: error_blob = 0.112899 (* 1 = 0.112899 loss)
I1002 01:06:12.085104 23744 solver.cpp:590] Iteration 5900, lr = 0.01
I1002 01:06:14.551297 23744 solver.cpp:347] Iteration 6000, Testing net (#0)
I1002 01:06:14.867745 23744 solver.cpp:415]     Test net output #0: error_blob = 0.116845 (* 1 = 0.116845 loss)
I1002 01:06:14.868402 23744 solver.cpp:243] Iteration 6000, loss = 0.112424
I1002 01:06:14.868418 23744 solver.cpp:259]     Train net output #0: error_blob = 0.112424 (* 1 = 0.112424 loss)
I1002 01:06:14.868424 23744 solver.cpp:590] Iteration 6000, lr = 0.01
I1002 01:06:17.365042 23744 solver.cpp:243] Iteration 6100, loss = 0.114824
I1002 01:06:17.365072 23744 solver.cpp:259]     Train net output #0: error_blob = 0.114824 (* 1 = 0.114824 loss)
I1002 01:06:17.365078 23744 solver.cpp:590] Iteration 6100, lr = 0.01
I1002 01:06:19.830482 23744 solver.cpp:243] Iteration 6200, loss = 0.108168
I1002 01:06:19.830512 23744 solver.cpp:259]     Train net output #0: error_blob = 0.108168 (* 1 = 0.108168 loss)
I1002 01:06:19.830517 23744 solver.cpp:590] Iteration 6200, lr = 0.01
I1002 01:06:22.321934 23744 solver.cpp:243] Iteration 6300, loss = 0.114733
I1002 01:06:22.321965 23744 solver.cpp:259]     Train net output #0: error_blob = 0.114733 (* 1 = 0.114733 loss)
I1002 01:06:22.321969 23744 solver.cpp:590] Iteration 6300, lr = 0.01
I1002 01:06:23.271355 23744 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 01:06:24.840245 23744 solver.cpp:243] Iteration 6400, loss = 0.113229
I1002 01:06:24.840276 23744 solver.cpp:259]     Train net output #0: error_blob = 0.113229 (* 1 = 0.113229 loss)
I1002 01:06:24.840279 23744 solver.cpp:590] Iteration 6400, lr = 0.01
I1002 01:06:27.343749 23744 solver.cpp:243] Iteration 6500, loss = 0.108681
I1002 01:06:27.343780 23744 solver.cpp:259]     Train net output #0: error_blob = 0.108681 (* 1 = 0.108681 loss)
I1002 01:06:27.343785 23744 solver.cpp:590] Iteration 6500, lr = 0.01
I1002 01:06:29.853101 23744 solver.cpp:243] Iteration 6600, loss = 0.109202
I1002 01:06:29.853130 23744 solver.cpp:259]     Train net output #0: error_blob = 0.109202 (* 1 = 0.109202 loss)
I1002 01:06:29.853134 23744 solver.cpp:590] Iteration 6600, lr = 0.01
I1002 01:06:32.356931 23744 solver.cpp:243] Iteration 6700, loss = 0.114063
I1002 01:06:32.356962 23744 solver.cpp:259]     Train net output #0: error_blob = 0.114063 (* 1 = 0.114063 loss)
I1002 01:06:32.356967 23744 solver.cpp:590] Iteration 6700, lr = 0.01
I1002 01:06:34.860375 23744 solver.cpp:243] Iteration 6800, loss = 0.112696
I1002 01:06:34.860405 23744 solver.cpp:259]     Train net output #0: error_blob = 0.112696 (* 1 = 0.112696 loss)
I1002 01:06:34.860409 23744 solver.cpp:590] Iteration 6800, lr = 0.01
I1002 01:06:37.378021 23744 solver.cpp:243] Iteration 6900, loss = 0.11048
I1002 01:06:37.378049 23744 solver.cpp:259]     Train net output #0: error_blob = 0.11048 (* 1 = 0.11048 loss)
I1002 01:06:37.378054 23744 solver.cpp:590] Iteration 6900, lr = 0.01
I1002 01:06:39.856813 23744 solver.cpp:347] Iteration 7000, Testing net (#0)
I1002 01:06:40.177719 23744 solver.cpp:415]     Test net output #0: error_blob = 0.119411 (* 1 = 0.119411 loss)
I1002 01:06:40.178395 23744 solver.cpp:243] Iteration 7000, loss = 0.108307
I1002 01:06:40.178410 23744 solver.cpp:259]     Train net output #0: error_blob = 0.108307 (* 1 = 0.108307 loss)
I1002 01:06:40.178416 23744 solver.cpp:590] Iteration 7000, lr = 0.01
I1002 01:06:42.637899 23744 solver.cpp:243] Iteration 7100, loss = 0.113196
I1002 01:06:42.637930 23744 solver.cpp:259]     Train net output #0: error_blob = 0.113196 (* 1 = 0.113196 loss)
I1002 01:06:42.637935 23744 solver.cpp:590] Iteration 7100, lr = 0.01
I1002 01:06:45.142748 23744 solver.cpp:243] Iteration 7200, loss = 0.112997
I1002 01:06:45.142778 23744 solver.cpp:259]     Train net output #0: error_blob = 0.112997 (* 1 = 0.112997 loss)
I1002 01:06:45.142782 23744 solver.cpp:590] Iteration 7200, lr = 0.01
I1002 01:06:46.232553 23744 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 01:06:47.637905 23744 solver.cpp:243] Iteration 7300, loss = 0.111394
I1002 01:06:47.637936 23744 solver.cpp:259]     Train net output #0: error_blob = 0.111394 (* 1 = 0.111394 loss)
I1002 01:06:47.637941 23744 solver.cpp:590] Iteration 7300, lr = 0.01
I1002 01:06:50.120205 23744 solver.cpp:243] Iteration 7400, loss = 0.108423
I1002 01:06:50.120246 23744 solver.cpp:259]     Train net output #0: error_blob = 0.108423 (* 1 = 0.108423 loss)
I1002 01:06:50.120251 23744 solver.cpp:590] Iteration 7400, lr = 0.01
I1002 01:06:52.626705 23744 solver.cpp:243] Iteration 7500, loss = 0.114534
I1002 01:06:52.626736 23744 solver.cpp:259]     Train net output #0: error_blob = 0.114534 (* 1 = 0.114534 loss)
I1002 01:06:52.626741 23744 solver.cpp:590] Iteration 7500, lr = 0.01
I1002 01:06:55.162760 23744 solver.cpp:243] Iteration 7600, loss = 0.114793
I1002 01:06:55.162793 23744 solver.cpp:259]     Train net output #0: error_blob = 0.114793 (* 1 = 0.114793 loss)
I1002 01:06:55.162801 23744 solver.cpp:590] Iteration 7600, lr = 0.01
I1002 01:06:57.685070 23744 solver.cpp:243] Iteration 7700, loss = 0.113247
I1002 01:06:57.685103 23744 solver.cpp:259]     Train net output #0: error_blob = 0.113247 (* 1 = 0.113247 loss)
I1002 01:06:57.685109 23744 solver.cpp:590] Iteration 7700, lr = 0.01
I1002 01:07:00.196645 23744 solver.cpp:243] Iteration 7800, loss = 0.106128
I1002 01:07:00.196676 23744 solver.cpp:259]     Train net output #0: error_blob = 0.106128 (* 1 = 0.106128 loss)
I1002 01:07:00.196683 23744 solver.cpp:590] Iteration 7800, lr = 0.01
I1002 01:07:02.715793 23744 solver.cpp:243] Iteration 7900, loss = 0.1127
I1002 01:07:02.715823 23744 solver.cpp:259]     Train net output #0: error_blob = 0.1127 (* 1 = 0.1127 loss)
I1002 01:07:02.715827 23744 solver.cpp:590] Iteration 7900, lr = 0.01
I1002 01:07:05.168263 23744 solver.cpp:347] Iteration 8000, Testing net (#0)
I1002 01:07:05.453521 23744 solver.cpp:415]     Test net output #0: error_blob = 0.117846 (* 1 = 0.117846 loss)
I1002 01:07:05.454124 23744 solver.cpp:243] Iteration 8000, loss = 0.115734
I1002 01:07:05.454138 23744 solver.cpp:259]     Train net output #0: error_blob = 0.115734 (* 1 = 0.115734 loss)
I1002 01:07:05.454144 23744 solver.cpp:590] Iteration 8000, lr = 0.01
I1002 01:07:07.917052 23744 solver.cpp:243] Iteration 8100, loss = 0.117574
I1002 01:07:07.917081 23744 solver.cpp:259]     Train net output #0: error_blob = 0.117574 (* 1 = 0.117574 loss)
I1002 01:07:07.917088 23744 solver.cpp:590] Iteration 8100, lr = 0.01
I1002 01:07:09.161624 23744 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 01:07:10.425426 23744 solver.cpp:243] Iteration 8200, loss = 0.11033
I1002 01:07:10.425545 23744 solver.cpp:259]     Train net output #0: error_blob = 0.11033 (* 1 = 0.11033 loss)
I1002 01:07:10.425550 23744 solver.cpp:590] Iteration 8200, lr = 0.01
I1002 01:07:12.928596 23744 solver.cpp:243] Iteration 8300, loss = 0.11413
I1002 01:07:12.928625 23744 solver.cpp:259]     Train net output #0: error_blob = 0.11413 (* 1 = 0.11413 loss)
I1002 01:07:12.928630 23744 solver.cpp:590] Iteration 8300, lr = 0.01
I1002 01:07:15.451948 23744 solver.cpp:243] Iteration 8400, loss = 0.114862
I1002 01:07:15.451980 23744 solver.cpp:259]     Train net output #0: error_blob = 0.114862 (* 1 = 0.114862 loss)
I1002 01:07:15.451984 23744 solver.cpp:590] Iteration 8400, lr = 0.01
I1002 01:07:17.972805 23744 solver.cpp:243] Iteration 8500, loss = 0.116334
I1002 01:07:17.972836 23744 solver.cpp:259]     Train net output #0: error_blob = 0.116334 (* 1 = 0.116334 loss)
I1002 01:07:17.972841 23744 solver.cpp:590] Iteration 8500, lr = 0.01
I1002 01:07:20.467891 23744 solver.cpp:243] Iteration 8600, loss = 0.110476
I1002 01:07:20.467931 23744 solver.cpp:259]     Train net output #0: error_blob = 0.110476 (* 1 = 0.110476 loss)
I1002 01:07:20.467936 23744 solver.cpp:590] Iteration 8600, lr = 0.01
I1002 01:07:22.989120 23744 solver.cpp:243] Iteration 8700, loss = 0.107817
I1002 01:07:22.989152 23744 solver.cpp:259]     Train net output #0: error_blob = 0.107817 (* 1 = 0.107817 loss)
I1002 01:07:22.989156 23744 solver.cpp:590] Iteration 8700, lr = 0.01
I1002 01:07:25.562896 23744 solver.cpp:243] Iteration 8800, loss = 0.112195
I1002 01:07:25.562927 23744 solver.cpp:259]     Train net output #0: error_blob = 0.112195 (* 1 = 0.112195 loss)
I1002 01:07:25.562932 23744 solver.cpp:590] Iteration 8800, lr = 0.01
I1002 01:07:28.055902 23744 solver.cpp:243] Iteration 8900, loss = 0.116837
I1002 01:07:28.055933 23744 solver.cpp:259]     Train net output #0: error_blob = 0.116837 (* 1 = 0.116837 loss)
I1002 01:07:28.055939 23744 solver.cpp:590] Iteration 8900, lr = 0.01
I1002 01:07:30.530344 23744 solver.cpp:347] Iteration 9000, Testing net (#0)
I1002 01:07:30.885958 23744 solver.cpp:415]     Test net output #0: error_blob = 0.121807 (* 1 = 0.121807 loss)
I1002 01:07:30.886605 23744 solver.cpp:243] Iteration 9000, loss = 0.117196
I1002 01:07:30.886620 23744 solver.cpp:259]     Train net output #0: error_blob = 0.117196 (* 1 = 0.117196 loss)
I1002 01:07:30.886626 23744 solver.cpp:590] Iteration 9000, lr = 0.01
I1002 01:07:32.279813 23744 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 01:07:33.401034 23744 solver.cpp:243] Iteration 9100, loss = 0.11027
I1002 01:07:33.401065 23744 solver.cpp:259]     Train net output #0: error_blob = 0.11027 (* 1 = 0.11027 loss)
I1002 01:07:33.401070 23744 solver.cpp:590] Iteration 9100, lr = 0.01
I1002 01:07:35.917563 23744 solver.cpp:243] Iteration 9200, loss = 0.114016
I1002 01:07:35.917595 23744 solver.cpp:259]     Train net output #0: error_blob = 0.114016 (* 1 = 0.114016 loss)
I1002 01:07:35.917599 23744 solver.cpp:590] Iteration 9200, lr = 0.01
I1002 01:07:38.419026 23744 solver.cpp:243] Iteration 9300, loss = 0.116109
I1002 01:07:38.419059 23744 solver.cpp:259]     Train net output #0: error_blob = 0.116109 (* 1 = 0.116109 loss)
I1002 01:07:38.419064 23744 solver.cpp:590] Iteration 9300, lr = 0.01
I1002 01:07:40.940672 23744 solver.cpp:243] Iteration 9400, loss = 0.114149
I1002 01:07:40.940778 23744 solver.cpp:259]     Train net output #0: error_blob = 0.114149 (* 1 = 0.114149 loss)
I1002 01:07:40.940786 23744 solver.cpp:590] Iteration 9400, lr = 0.01
I1002 01:07:43.442348 23744 solver.cpp:243] Iteration 9500, loss = 0.109419
I1002 01:07:43.442379 23744 solver.cpp:259]     Train net output #0: error_blob = 0.109419 (* 1 = 0.109419 loss)
I1002 01:07:43.442384 23744 solver.cpp:590] Iteration 9500, lr = 0.01
I1002 01:07:45.964835 23744 solver.cpp:243] Iteration 9600, loss = 0.112072
I1002 01:07:45.964864 23744 solver.cpp:259]     Train net output #0: error_blob = 0.112072 (* 1 = 0.112072 loss)
I1002 01:07:45.964869 23744 solver.cpp:590] Iteration 9600, lr = 0.01
I1002 01:07:48.466914 23744 solver.cpp:243] Iteration 9700, loss = 0.11495
I1002 01:07:48.466954 23744 solver.cpp:259]     Train net output #0: error_blob = 0.11495 (* 1 = 0.11495 loss)
I1002 01:07:48.466959 23744 solver.cpp:590] Iteration 9700, lr = 0.01
I1002 01:07:50.962622 23744 solver.cpp:243] Iteration 9800, loss = 0.115024
I1002 01:07:50.962652 23744 solver.cpp:259]     Train net output #0: error_blob = 0.115024 (* 1 = 0.115024 loss)
I1002 01:07:50.962657 23744 solver.cpp:590] Iteration 9800, lr = 0.01
I1002 01:07:53.521955 23744 solver.cpp:243] Iteration 9900, loss = 0.110114
I1002 01:07:53.521988 23744 solver.cpp:259]     Train net output #0: error_blob = 0.110114 (* 1 = 0.110114 loss)
I1002 01:07:53.521993 23744 solver.cpp:590] Iteration 9900, lr = 0.01
I1002 01:07:55.996587 23744 solver.cpp:468] Snapshotting to binary proto file _iter_10000.caffemodel
I1002 01:07:55.997412 23744 solver.cpp:753] Snapshotting solver state to binary proto file _iter_10000.solverstate
I1002 01:07:56.020826 23744 solver.cpp:327] Iteration 10000, loss = 0.110981
I1002 01:07:56.020862 23744 solver.cpp:347] Iteration 10000, Testing net (#0)
I1002 01:07:56.186926 23744 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 01:07:56.293792 23744 solver.cpp:415]     Test net output #0: error_blob = 0.116851 (* 1 = 0.116851 loss)
I1002 01:07:56.293815 23744 solver.cpp:332] Optimization Done.
I1002 01:07:56.293820 23744 caffe.cpp:215] Optimization Done.
I1002 01:07:56.362932 23754 caffe.cpp:184] Using GPUs 0
I1002 01:07:56.920760 23754 solver.cpp:54] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "fixed"
momentum: 0.9
solver_mode: GPU
device_id: 0
net: "model/NNScore/nnscore_model_7.prototxt"
I1002 01:07:56.920789 23754 solver.cpp:97] Creating training net from net file: model/NNScore/nnscore_model_7.prototxt
I1002 01:07:56.920956 23754 net.cpp:339] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_layer
I1002 01:07:56.921000 23754 net.cpp:50] Initializing net from parameters: 
name: "model/NNScore/nnscore_model_7.prototxt"
state {
  phase: TRAIN
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TRAIN
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.7.train"
    batch_size: 20000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1002 01:07:56.921056 23754 layer_factory.hpp:76] Creating layer data_layer
I1002 01:07:56.934419 23754 net.cpp:110] Creating Layer data_layer
I1002 01:07:56.934449 23754 net.cpp:433] data_layer -> data_blob
I1002 01:07:56.934478 23754 net.cpp:433] data_layer -> label_blob
I1002 01:07:56.935036 23758 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.7.train
I1002 01:07:57.619266 23754 data_layer.cpp:45] output data size: 20000,61,1,1
I1002 01:07:57.624246 23754 net.cpp:155] Setting up data_layer
I1002 01:07:57.624292 23754 net.cpp:163] Top shape: 20000 61 1 1 (1220000)
I1002 01:07:57.624299 23754 net.cpp:163] Top shape: 20000 (20000)
I1002 01:07:57.624305 23754 layer_factory.hpp:76] Creating layer hidden_sum_layer
I1002 01:07:57.624320 23754 net.cpp:110] Creating Layer hidden_sum_layer
I1002 01:07:57.624325 23754 net.cpp:477] hidden_sum_layer <- data_blob
I1002 01:07:57.624336 23754 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I1002 01:07:57.624739 23754 net.cpp:155] Setting up hidden_sum_layer
I1002 01:07:57.624747 23754 net.cpp:163] Top shape: 20000 10 (200000)
I1002 01:07:57.624760 23754 layer_factory.hpp:76] Creating layer hidden_act_layer
I1002 01:07:57.624769 23754 net.cpp:110] Creating Layer hidden_act_layer
I1002 01:07:57.624773 23754 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I1002 01:07:57.624778 23754 net.cpp:433] hidden_act_layer -> hidden_act_blob
I1002 01:08:00.819262 23754 net.cpp:155] Setting up hidden_act_layer
I1002 01:08:00.819296 23754 net.cpp:163] Top shape: 20000 10 (200000)
I1002 01:08:00.819301 23754 layer_factory.hpp:76] Creating layer output_sum_layer
I1002 01:08:00.819310 23754 net.cpp:110] Creating Layer output_sum_layer
I1002 01:08:00.819314 23754 net.cpp:477] output_sum_layer <- hidden_act_blob
I1002 01:08:00.819322 23754 net.cpp:433] output_sum_layer -> output_sum_blob
I1002 01:08:00.819442 23754 net.cpp:155] Setting up output_sum_layer
I1002 01:08:00.819458 23754 net.cpp:163] Top shape: 20000 1 (20000)
I1002 01:08:00.819474 23754 layer_factory.hpp:76] Creating layer output_act_layer
I1002 01:08:00.819480 23754 net.cpp:110] Creating Layer output_act_layer
I1002 01:08:00.819483 23754 net.cpp:477] output_act_layer <- output_sum_blob
I1002 01:08:00.819486 23754 net.cpp:433] output_act_layer -> output_act_blob
I1002 01:08:00.819582 23754 net.cpp:155] Setting up output_act_layer
I1002 01:08:00.819604 23754 net.cpp:163] Top shape: 20000 1 (20000)
I1002 01:08:00.819619 23754 layer_factory.hpp:76] Creating layer error_layer
I1002 01:08:00.819627 23754 net.cpp:110] Creating Layer error_layer
I1002 01:08:00.819630 23754 net.cpp:477] error_layer <- output_act_blob
I1002 01:08:00.819634 23754 net.cpp:477] error_layer <- label_blob
I1002 01:08:00.819640 23754 net.cpp:433] error_layer -> error_blob
I1002 01:08:00.819685 23754 net.cpp:155] Setting up error_layer
I1002 01:08:00.819691 23754 net.cpp:163] Top shape: (1)
I1002 01:08:00.819703 23754 net.cpp:168]     with loss weight 1
I1002 01:08:00.819722 23754 net.cpp:236] error_layer needs backward computation.
I1002 01:08:00.819727 23754 net.cpp:236] output_act_layer needs backward computation.
I1002 01:08:00.819731 23754 net.cpp:236] output_sum_layer needs backward computation.
I1002 01:08:00.819739 23754 net.cpp:236] hidden_act_layer needs backward computation.
I1002 01:08:00.819743 23754 net.cpp:236] hidden_sum_layer needs backward computation.
I1002 01:08:00.819749 23754 net.cpp:240] data_layer does not need backward computation.
I1002 01:08:00.819753 23754 net.cpp:283] This network produces output error_blob
I1002 01:08:00.819762 23754 net.cpp:297] Network initialization done.
I1002 01:08:00.819767 23754 net.cpp:298] Memory required for data: 6720004
I1002 01:08:00.819907 23754 solver.cpp:187] Creating test net (#0) specified by net file: model/NNScore/nnscore_model_7.prototxt
I1002 01:08:00.819929 23754 net.cpp:339] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_layer
I1002 01:08:00.819975 23754 net.cpp:50] Initializing net from parameters: 
name: "model/NNScore/nnscore_model_7.prototxt"
state {
  phase: TEST
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TEST
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.7.test"
    batch_size: 2000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1002 01:08:00.820010 23754 layer_factory.hpp:76] Creating layer data_layer
I1002 01:08:00.821274 23754 net.cpp:110] Creating Layer data_layer
I1002 01:08:00.821281 23754 net.cpp:433] data_layer -> data_blob
I1002 01:08:00.821296 23754 net.cpp:433] data_layer -> label_blob
I1002 01:08:00.822000 23760 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.7.test
I1002 01:08:00.822088 23754 data_layer.cpp:45] output data size: 2000,61,1,1
I1002 01:08:00.823429 23754 net.cpp:155] Setting up data_layer
I1002 01:08:00.823451 23754 net.cpp:163] Top shape: 2000 61 1 1 (122000)
I1002 01:08:00.823454 23754 net.cpp:163] Top shape: 2000 (2000)
I1002 01:08:00.823458 23754 layer_factory.hpp:76] Creating layer hidden_sum_layer
I1002 01:08:00.823467 23754 net.cpp:110] Creating Layer hidden_sum_layer
I1002 01:08:00.823470 23754 net.cpp:477] hidden_sum_layer <- data_blob
I1002 01:08:00.823477 23754 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I1002 01:08:00.823601 23754 net.cpp:155] Setting up hidden_sum_layer
I1002 01:08:00.823606 23754 net.cpp:163] Top shape: 2000 10 (20000)
I1002 01:08:00.823614 23754 layer_factory.hpp:76] Creating layer hidden_act_layer
I1002 01:08:00.823622 23754 net.cpp:110] Creating Layer hidden_act_layer
I1002 01:08:00.823627 23754 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I1002 01:08:00.823647 23754 net.cpp:433] hidden_act_layer -> hidden_act_blob
I1002 01:08:00.823824 23754 net.cpp:155] Setting up hidden_act_layer
I1002 01:08:00.823832 23754 net.cpp:163] Top shape: 2000 10 (20000)
I1002 01:08:00.823835 23754 layer_factory.hpp:76] Creating layer output_sum_layer
I1002 01:08:00.823842 23754 net.cpp:110] Creating Layer output_sum_layer
I1002 01:08:00.823845 23754 net.cpp:477] output_sum_layer <- hidden_act_blob
I1002 01:08:00.823850 23754 net.cpp:433] output_sum_layer -> output_sum_blob
I1002 01:08:00.823918 23754 net.cpp:155] Setting up output_sum_layer
I1002 01:08:00.823925 23754 net.cpp:163] Top shape: 2000 1 (2000)
I1002 01:08:00.823931 23754 layer_factory.hpp:76] Creating layer output_act_layer
I1002 01:08:00.823940 23754 net.cpp:110] Creating Layer output_act_layer
I1002 01:08:00.823945 23754 net.cpp:477] output_act_layer <- output_sum_blob
I1002 01:08:00.823951 23754 net.cpp:433] output_act_layer -> output_act_blob
I1002 01:08:00.824008 23754 net.cpp:155] Setting up output_act_layer
I1002 01:08:00.824014 23754 net.cpp:163] Top shape: 2000 1 (2000)
I1002 01:08:00.824018 23754 layer_factory.hpp:76] Creating layer error_layer
I1002 01:08:00.824023 23754 net.cpp:110] Creating Layer error_layer
I1002 01:08:00.824026 23754 net.cpp:477] error_layer <- output_act_blob
I1002 01:08:00.824031 23754 net.cpp:477] error_layer <- label_blob
I1002 01:08:00.824036 23754 net.cpp:433] error_layer -> error_blob
I1002 01:08:00.824062 23754 net.cpp:155] Setting up error_layer
I1002 01:08:00.824067 23754 net.cpp:163] Top shape: (1)
I1002 01:08:00.824070 23754 net.cpp:168]     with loss weight 1
I1002 01:08:00.824082 23754 net.cpp:236] error_layer needs backward computation.
I1002 01:08:00.824086 23754 net.cpp:236] output_act_layer needs backward computation.
I1002 01:08:00.824090 23754 net.cpp:236] output_sum_layer needs backward computation.
I1002 01:08:00.824092 23754 net.cpp:236] hidden_act_layer needs backward computation.
I1002 01:08:00.824096 23754 net.cpp:236] hidden_sum_layer needs backward computation.
I1002 01:08:00.824100 23754 net.cpp:240] data_layer does not need backward computation.
I1002 01:08:00.824103 23754 net.cpp:283] This network produces output error_blob
I1002 01:08:00.824111 23754 net.cpp:297] Network initialization done.
I1002 01:08:00.824115 23754 net.cpp:298] Memory required for data: 672004
I1002 01:08:00.824138 23754 solver.cpp:66] Solver scaffolding done.
I1002 01:08:00.824239 23754 caffe.cpp:212] Starting Optimization
I1002 01:08:00.824246 23754 solver.cpp:294] Solving model/NNScore/nnscore_model_7.prototxt
I1002 01:08:00.824249 23754 solver.cpp:295] Learning Rate Policy: fixed
I1002 01:08:00.824458 23754 solver.cpp:347] Iteration 0, Testing net (#0)
I1002 01:08:00.824532 23754 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 01:08:01.089320 23754 solver.cpp:415]     Test net output #0: error_blob = 0.125223 (* 1 = 0.125223 loss)
I1002 01:08:01.090749 23754 solver.cpp:243] Iteration 0, loss = 0.124874
I1002 01:08:01.090767 23754 solver.cpp:259]     Train net output #0: error_blob = 0.124874 (* 1 = 0.124874 loss)
I1002 01:08:01.090781 23754 solver.cpp:590] Iteration 0, lr = 0.01
I1002 01:08:03.544039 23754 solver.cpp:243] Iteration 100, loss = 0.121641
I1002 01:08:03.544078 23754 solver.cpp:259]     Train net output #0: error_blob = 0.121641 (* 1 = 0.121641 loss)
I1002 01:08:03.544085 23754 solver.cpp:590] Iteration 100, lr = 0.01
I1002 01:08:06.040715 23754 solver.cpp:243] Iteration 200, loss = 0.120353
I1002 01:08:06.040765 23754 solver.cpp:259]     Train net output #0: error_blob = 0.120353 (* 1 = 0.120353 loss)
I1002 01:08:06.040774 23754 solver.cpp:590] Iteration 200, lr = 0.01
I1002 01:08:08.581034 23754 solver.cpp:243] Iteration 300, loss = 0.121256
I1002 01:08:08.581070 23754 solver.cpp:259]     Train net output #0: error_blob = 0.121256 (* 1 = 0.121256 loss)
I1002 01:08:08.581078 23754 solver.cpp:590] Iteration 300, lr = 0.01
I1002 01:08:11.131367 23754 solver.cpp:243] Iteration 400, loss = 0.121252
I1002 01:08:11.131778 23754 solver.cpp:259]     Train net output #0: error_blob = 0.121252 (* 1 = 0.121252 loss)
I1002 01:08:11.131785 23754 solver.cpp:590] Iteration 400, lr = 0.01
I1002 01:08:13.668123 23754 solver.cpp:243] Iteration 500, loss = 0.12004
I1002 01:08:13.668169 23754 solver.cpp:259]     Train net output #0: error_blob = 0.12004 (* 1 = 0.12004 loss)
I1002 01:08:13.668174 23754 solver.cpp:590] Iteration 500, lr = 0.01
I1002 01:08:16.218564 23754 solver.cpp:243] Iteration 600, loss = 0.119404
I1002 01:08:16.218611 23754 solver.cpp:259]     Train net output #0: error_blob = 0.119404 (* 1 = 0.119404 loss)
I1002 01:08:16.218618 23754 solver.cpp:590] Iteration 600, lr = 0.01
I1002 01:08:18.726265 23754 solver.cpp:243] Iteration 700, loss = 0.120631
I1002 01:08:18.726306 23754 solver.cpp:259]     Train net output #0: error_blob = 0.120631 (* 1 = 0.120631 loss)
I1002 01:08:18.726312 23754 solver.cpp:590] Iteration 700, lr = 0.01
I1002 01:08:21.201309 23754 solver.cpp:243] Iteration 800, loss = 0.121202
I1002 01:08:21.201350 23754 solver.cpp:259]     Train net output #0: error_blob = 0.121202 (* 1 = 0.121202 loss)
I1002 01:08:21.201356 23754 solver.cpp:590] Iteration 800, lr = 0.01
I1002 01:08:23.687350 23754 solver.cpp:243] Iteration 900, loss = 0.119655
I1002 01:08:23.687382 23754 solver.cpp:259]     Train net output #0: error_blob = 0.119655 (* 1 = 0.119655 loss)
I1002 01:08:23.687387 23754 solver.cpp:590] Iteration 900, lr = 0.01
I1002 01:08:23.737375 23754 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 01:08:26.148746 23754 solver.cpp:347] Iteration 1000, Testing net (#0)
I1002 01:08:26.426431 23754 solver.cpp:415]     Test net output #0: error_blob = 0.120986 (* 1 = 0.120986 loss)
I1002 01:08:26.428035 23754 solver.cpp:243] Iteration 1000, loss = 0.118703
I1002 01:08:26.428050 23754 solver.cpp:259]     Train net output #0: error_blob = 0.118703 (* 1 = 0.118703 loss)
I1002 01:08:26.428056 23754 solver.cpp:590] Iteration 1000, lr = 0.01
I1002 01:08:28.986748 23754 solver.cpp:243] Iteration 1100, loss = 0.120587
I1002 01:08:28.986784 23754 solver.cpp:259]     Train net output #0: error_blob = 0.120587 (* 1 = 0.120587 loss)
I1002 01:08:28.986793 23754 solver.cpp:590] Iteration 1100, lr = 0.01
I1002 01:08:31.552461 23754 solver.cpp:243] Iteration 1200, loss = 0.121226
I1002 01:08:31.552510 23754 solver.cpp:259]     Train net output #0: error_blob = 0.121226 (* 1 = 0.121226 loss)
I1002 01:08:31.552518 23754 solver.cpp:590] Iteration 1200, lr = 0.01
I1002 01:08:34.116967 23754 solver.cpp:243] Iteration 1300, loss = 0.117863
I1002 01:08:34.117003 23754 solver.cpp:259]     Train net output #0: error_blob = 0.117863 (* 1 = 0.117863 loss)
I1002 01:08:34.117012 23754 solver.cpp:590] Iteration 1300, lr = 0.01
I1002 01:08:36.637323 23754 solver.cpp:243] Iteration 1400, loss = 0.117079
I1002 01:08:36.637359 23754 solver.cpp:259]     Train net output #0: error_blob = 0.117079 (* 1 = 0.117079 loss)
I1002 01:08:36.637367 23754 solver.cpp:590] Iteration 1400, lr = 0.01
I1002 01:08:39.156606 23754 solver.cpp:243] Iteration 1500, loss = 0.119258
I1002 01:08:39.156643 23754 solver.cpp:259]     Train net output #0: error_blob = 0.119258 (* 1 = 0.119258 loss)
I1002 01:08:39.156651 23754 solver.cpp:590] Iteration 1500, lr = 0.01
I1002 01:08:41.620772 23754 solver.cpp:243] Iteration 1600, loss = 0.119845
I1002 01:08:41.620812 23754 solver.cpp:259]     Train net output #0: error_blob = 0.119845 (* 1 = 0.119845 loss)
I1002 01:08:41.620818 23754 solver.cpp:590] Iteration 1600, lr = 0.01
I1002 01:08:44.111767 23754 solver.cpp:243] Iteration 1700, loss = 0.116854
I1002 01:08:44.111799 23754 solver.cpp:259]     Train net output #0: error_blob = 0.116854 (* 1 = 0.116854 loss)
I1002 01:08:44.111804 23754 solver.cpp:590] Iteration 1700, lr = 0.01
I1002 01:08:46.618424 23754 solver.cpp:243] Iteration 1800, loss = 0.115932
I1002 01:08:46.618458 23754 solver.cpp:259]     Train net output #0: error_blob = 0.115932 (* 1 = 0.115932 loss)
I1002 01:08:46.618463 23754 solver.cpp:590] Iteration 1800, lr = 0.01
I1002 01:08:46.815747 23754 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 01:08:49.120579 23754 solver.cpp:243] Iteration 1900, loss = 0.118252
I1002 01:08:49.120609 23754 solver.cpp:259]     Train net output #0: error_blob = 0.118252 (* 1 = 0.118252 loss)
I1002 01:08:49.120615 23754 solver.cpp:590] Iteration 1900, lr = 0.01
I1002 01:08:51.598760 23754 solver.cpp:347] Iteration 2000, Testing net (#0)
I1002 01:08:51.976955 23754 solver.cpp:415]     Test net output #0: error_blob = 0.122804 (* 1 = 0.122804 loss)
I1002 01:08:51.977591 23754 solver.cpp:243] Iteration 2000, loss = 0.119246
I1002 01:08:51.977607 23754 solver.cpp:259]     Train net output #0: error_blob = 0.119246 (* 1 = 0.119246 loss)
I1002 01:08:51.977612 23754 solver.cpp:590] Iteration 2000, lr = 0.01
I1002 01:08:54.598116 23754 solver.cpp:243] Iteration 2100, loss = 0.11582
I1002 01:08:54.598148 23754 solver.cpp:259]     Train net output #0: error_blob = 0.11582 (* 1 = 0.11582 loss)
I1002 01:08:54.598155 23754 solver.cpp:590] Iteration 2100, lr = 0.01
I1002 01:08:57.103925 23754 solver.cpp:243] Iteration 2200, loss = 0.114159
I1002 01:08:57.105425 23754 solver.cpp:259]     Train net output #0: error_blob = 0.114159 (* 1 = 0.114159 loss)
I1002 01:08:57.105433 23754 solver.cpp:590] Iteration 2200, lr = 0.01
I1002 01:08:59.617636 23754 solver.cpp:243] Iteration 2300, loss = 0.117258
I1002 01:08:59.617668 23754 solver.cpp:259]     Train net output #0: error_blob = 0.117258 (* 1 = 0.117258 loss)
I1002 01:08:59.617673 23754 solver.cpp:590] Iteration 2300, lr = 0.01
I1002 01:09:02.064870 23754 solver.cpp:243] Iteration 2400, loss = 0.119159
I1002 01:09:02.064913 23754 solver.cpp:259]     Train net output #0: error_blob = 0.119159 (* 1 = 0.119159 loss)
I1002 01:09:02.064918 23754 solver.cpp:590] Iteration 2400, lr = 0.01
I1002 01:09:04.534785 23754 solver.cpp:243] Iteration 2500, loss = 0.116554
I1002 01:09:04.534826 23754 solver.cpp:259]     Train net output #0: error_blob = 0.116554 (* 1 = 0.116554 loss)
I1002 01:09:04.534832 23754 solver.cpp:590] Iteration 2500, lr = 0.01
I1002 01:09:07.050626 23754 solver.cpp:243] Iteration 2600, loss = 0.118465
I1002 01:09:07.050657 23754 solver.cpp:259]     Train net output #0: error_blob = 0.118465 (* 1 = 0.118465 loss)
I1002 01:09:07.050662 23754 solver.cpp:590] Iteration 2600, lr = 0.01
I1002 01:09:09.549718 23754 solver.cpp:243] Iteration 2700, loss = 0.116923
I1002 01:09:09.549751 23754 solver.cpp:259]     Train net output #0: error_blob = 0.116923 (* 1 = 0.116923 loss)
I1002 01:09:09.549757 23754 solver.cpp:590] Iteration 2700, lr = 0.01
I1002 01:09:09.905511 23754 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 01:09:12.010097 23754 solver.cpp:243] Iteration 2800, loss = 0.119637
I1002 01:09:12.010126 23754 solver.cpp:259]     Train net output #0: error_blob = 0.119637 (* 1 = 0.119637 loss)
I1002 01:09:12.010133 23754 solver.cpp:590] Iteration 2800, lr = 0.01
I1002 01:09:14.482578 23754 solver.cpp:243] Iteration 2900, loss = 0.116097
I1002 01:09:14.482609 23754 solver.cpp:259]     Train net output #0: error_blob = 0.116097 (* 1 = 0.116097 loss)
I1002 01:09:14.482614 23754 solver.cpp:590] Iteration 2900, lr = 0.01
I1002 01:09:16.941691 23754 solver.cpp:347] Iteration 3000, Testing net (#0)
I1002 01:09:17.227236 23754 solver.cpp:415]     Test net output #0: error_blob = 0.120352 (* 1 = 0.120352 loss)
I1002 01:09:17.227903 23754 solver.cpp:243] Iteration 3000, loss = 0.115052
I1002 01:09:17.227918 23754 solver.cpp:259]     Train net output #0: error_blob = 0.115052 (* 1 = 0.115052 loss)
I1002 01:09:17.227928 23754 solver.cpp:590] Iteration 3000, lr = 0.01
I1002 01:09:19.703214 23754 solver.cpp:243] Iteration 3100, loss = 0.117133
I1002 01:09:19.703246 23754 solver.cpp:259]     Train net output #0: error_blob = 0.117133 (* 1 = 0.117133 loss)
I1002 01:09:19.703254 23754 solver.cpp:590] Iteration 3100, lr = 0.01
I1002 01:09:22.191195 23754 solver.cpp:243] Iteration 3200, loss = 0.120538
I1002 01:09:22.191228 23754 solver.cpp:259]     Train net output #0: error_blob = 0.120538 (* 1 = 0.120538 loss)
I1002 01:09:22.191236 23754 solver.cpp:590] Iteration 3200, lr = 0.01
I1002 01:09:24.697077 23754 solver.cpp:243] Iteration 3300, loss = 0.119177
I1002 01:09:24.697110 23754 solver.cpp:259]     Train net output #0: error_blob = 0.119177 (* 1 = 0.119177 loss)
I1002 01:09:24.697118 23754 solver.cpp:590] Iteration 3300, lr = 0.01
I1002 01:09:27.219647 23754 solver.cpp:243] Iteration 3400, loss = 0.112798
I1002 01:09:27.220108 23754 solver.cpp:259]     Train net output #0: error_blob = 0.112798 (* 1 = 0.112798 loss)
I1002 01:09:27.220120 23754 solver.cpp:590] Iteration 3400, lr = 0.01
I1002 01:09:29.713515 23754 solver.cpp:243] Iteration 3500, loss = 0.117791
I1002 01:09:29.713546 23754 solver.cpp:259]     Train net output #0: error_blob = 0.117791 (* 1 = 0.117791 loss)
I1002 01:09:29.713553 23754 solver.cpp:590] Iteration 3500, lr = 0.01
I1002 01:09:32.225801 23754 solver.cpp:243] Iteration 3600, loss = 0.117877
I1002 01:09:32.225837 23754 solver.cpp:259]     Train net output #0: error_blob = 0.117877 (* 1 = 0.117877 loss)
I1002 01:09:32.225844 23754 solver.cpp:590] Iteration 3600, lr = 0.01
I1002 01:09:32.722064 23754 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 01:09:34.733925 23754 solver.cpp:243] Iteration 3700, loss = 0.11573
I1002 01:09:34.733966 23754 solver.cpp:259]     Train net output #0: error_blob = 0.11573 (* 1 = 0.11573 loss)
I1002 01:09:34.733973 23754 solver.cpp:590] Iteration 3700, lr = 0.01
I1002 01:09:37.215426 23754 solver.cpp:243] Iteration 3800, loss = 0.113081
I1002 01:09:37.215457 23754 solver.cpp:259]     Train net output #0: error_blob = 0.113081 (* 1 = 0.113081 loss)
I1002 01:09:37.215464 23754 solver.cpp:590] Iteration 3800, lr = 0.01
I1002 01:09:39.704190 23754 solver.cpp:243] Iteration 3900, loss = 0.116062
I1002 01:09:39.704231 23754 solver.cpp:259]     Train net output #0: error_blob = 0.116062 (* 1 = 0.116062 loss)
I1002 01:09:39.704238 23754 solver.cpp:590] Iteration 3900, lr = 0.01
I1002 01:09:42.171980 23754 solver.cpp:347] Iteration 4000, Testing net (#0)
I1002 01:09:42.498009 23754 solver.cpp:415]     Test net output #0: error_blob = 0.121501 (* 1 = 0.121501 loss)
I1002 01:09:42.498621 23754 solver.cpp:243] Iteration 4000, loss = 0.117975
I1002 01:09:42.498632 23754 solver.cpp:259]     Train net output #0: error_blob = 0.117975 (* 1 = 0.117975 loss)
I1002 01:09:42.498637 23754 solver.cpp:590] Iteration 4000, lr = 0.01
I1002 01:09:44.963044 23754 solver.cpp:243] Iteration 4100, loss = 0.115957
I1002 01:09:44.963085 23754 solver.cpp:259]     Train net output #0: error_blob = 0.115957 (* 1 = 0.115957 loss)
I1002 01:09:44.963090 23754 solver.cpp:590] Iteration 4100, lr = 0.01
I1002 01:09:47.437953 23754 solver.cpp:243] Iteration 4200, loss = 0.112697
I1002 01:09:47.437995 23754 solver.cpp:259]     Train net output #0: error_blob = 0.112697 (* 1 = 0.112697 loss)
I1002 01:09:47.438002 23754 solver.cpp:590] Iteration 4200, lr = 0.01
I1002 01:09:49.929810 23754 solver.cpp:243] Iteration 4300, loss = 0.120723
I1002 01:09:49.929841 23754 solver.cpp:259]     Train net output #0: error_blob = 0.120723 (* 1 = 0.120723 loss)
I1002 01:09:49.929847 23754 solver.cpp:590] Iteration 4300, lr = 0.01
I1002 01:09:52.418102 23754 solver.cpp:243] Iteration 4400, loss = 0.117834
I1002 01:09:52.418133 23754 solver.cpp:259]     Train net output #0: error_blob = 0.117834 (* 1 = 0.117834 loss)
I1002 01:09:52.418138 23754 solver.cpp:590] Iteration 4400, lr = 0.01
I1002 01:09:54.936485 23754 solver.cpp:243] Iteration 4500, loss = 0.117885
I1002 01:09:54.936527 23754 solver.cpp:259]     Train net output #0: error_blob = 0.117885 (* 1 = 0.117885 loss)
I1002 01:09:54.936532 23754 solver.cpp:590] Iteration 4500, lr = 0.01
I1002 01:09:55.593984 23754 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 01:09:57.447829 23754 solver.cpp:243] Iteration 4600, loss = 0.113362
I1002 01:09:57.447919 23754 solver.cpp:259]     Train net output #0: error_blob = 0.113362 (* 1 = 0.113362 loss)
I1002 01:09:57.447929 23754 solver.cpp:590] Iteration 4600, lr = 0.01
I1002 01:09:59.989931 23754 solver.cpp:243] Iteration 4700, loss = 0.115539
I1002 01:09:59.989971 23754 solver.cpp:259]     Train net output #0: error_blob = 0.115539 (* 1 = 0.115539 loss)
I1002 01:09:59.989979 23754 solver.cpp:590] Iteration 4700, lr = 0.01
I1002 01:10:02.490033 23754 solver.cpp:243] Iteration 4800, loss = 0.118327
I1002 01:10:02.490073 23754 solver.cpp:259]     Train net output #0: error_blob = 0.118327 (* 1 = 0.118327 loss)
I1002 01:10:02.490079 23754 solver.cpp:590] Iteration 4800, lr = 0.01
I1002 01:10:04.958664 23754 solver.cpp:243] Iteration 4900, loss = 0.116238
I1002 01:10:04.958708 23754 solver.cpp:259]     Train net output #0: error_blob = 0.116238 (* 1 = 0.116238 loss)
I1002 01:10:04.958712 23754 solver.cpp:590] Iteration 4900, lr = 0.01
I1002 01:10:07.411149 23754 solver.cpp:347] Iteration 5000, Testing net (#0)
I1002 01:10:07.718401 23754 solver.cpp:415]     Test net output #0: error_blob = 0.12033 (* 1 = 0.12033 loss)
I1002 01:10:07.719105 23754 solver.cpp:243] Iteration 5000, loss = 0.110775
I1002 01:10:07.719120 23754 solver.cpp:259]     Train net output #0: error_blob = 0.110775 (* 1 = 0.110775 loss)
I1002 01:10:07.719127 23754 solver.cpp:590] Iteration 5000, lr = 0.01
I1002 01:10:10.151182 23754 solver.cpp:243] Iteration 5100, loss = 0.115004
I1002 01:10:10.151228 23754 solver.cpp:259]     Train net output #0: error_blob = 0.115004 (* 1 = 0.115004 loss)
I1002 01:10:10.151235 23754 solver.cpp:590] Iteration 5100, lr = 0.01
I1002 01:10:12.655771 23754 solver.cpp:243] Iteration 5200, loss = 0.117758
I1002 01:10:12.655812 23754 solver.cpp:259]     Train net output #0: error_blob = 0.117758 (* 1 = 0.117758 loss)
I1002 01:10:12.655817 23754 solver.cpp:590] Iteration 5200, lr = 0.01
I1002 01:10:15.175431 23754 solver.cpp:243] Iteration 5300, loss = 0.116225
I1002 01:10:15.175461 23754 solver.cpp:259]     Train net output #0: error_blob = 0.116225 (* 1 = 0.116225 loss)
I1002 01:10:15.175465 23754 solver.cpp:590] Iteration 5300, lr = 0.01
I1002 01:10:17.703723 23754 solver.cpp:243] Iteration 5400, loss = 0.122472
I1002 01:10:17.703754 23754 solver.cpp:259]     Train net output #0: error_blob = 0.122472 (* 1 = 0.122472 loss)
I1002 01:10:17.703760 23754 solver.cpp:590] Iteration 5400, lr = 0.01
I1002 01:10:18.507805 23754 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 01:10:20.214596 23754 solver.cpp:243] Iteration 5500, loss = 0.114257
I1002 01:10:20.214628 23754 solver.cpp:259]     Train net output #0: error_blob = 0.114257 (* 1 = 0.114257 loss)
I1002 01:10:20.214633 23754 solver.cpp:590] Iteration 5500, lr = 0.01
I1002 01:10:22.703199 23754 solver.cpp:243] Iteration 5600, loss = 0.120058
I1002 01:10:22.703240 23754 solver.cpp:259]     Train net output #0: error_blob = 0.120058 (* 1 = 0.120058 loss)
I1002 01:10:22.703246 23754 solver.cpp:590] Iteration 5600, lr = 0.01
I1002 01:10:25.222604 23754 solver.cpp:243] Iteration 5700, loss = 0.116829
I1002 01:10:25.222636 23754 solver.cpp:259]     Train net output #0: error_blob = 0.116829 (* 1 = 0.116829 loss)
I1002 01:10:25.222641 23754 solver.cpp:590] Iteration 5700, lr = 0.01
I1002 01:10:27.800299 23754 solver.cpp:243] Iteration 5800, loss = 0.113172
I1002 01:10:27.800428 23754 solver.cpp:259]     Train net output #0: error_blob = 0.113172 (* 1 = 0.113172 loss)
I1002 01:10:27.800436 23754 solver.cpp:590] Iteration 5800, lr = 0.01
I1002 01:10:30.326083 23754 solver.cpp:243] Iteration 5900, loss = 0.113992
I1002 01:10:30.326114 23754 solver.cpp:259]     Train net output #0: error_blob = 0.113992 (* 1 = 0.113992 loss)
I1002 01:10:30.326119 23754 solver.cpp:590] Iteration 5900, lr = 0.01
I1002 01:10:32.763607 23754 solver.cpp:347] Iteration 6000, Testing net (#0)
I1002 01:10:33.041169 23754 solver.cpp:415]     Test net output #0: error_blob = 0.120371 (* 1 = 0.120371 loss)
I1002 01:10:33.041846 23754 solver.cpp:243] Iteration 6000, loss = 0.117852
I1002 01:10:33.041862 23754 solver.cpp:259]     Train net output #0: error_blob = 0.117852 (* 1 = 0.117852 loss)
I1002 01:10:33.041870 23754 solver.cpp:590] Iteration 6000, lr = 0.01
I1002 01:10:35.482545 23754 solver.cpp:243] Iteration 6100, loss = 0.116753
I1002 01:10:35.482592 23754 solver.cpp:259]     Train net output #0: error_blob = 0.116753 (* 1 = 0.116753 loss)
I1002 01:10:35.482601 23754 solver.cpp:590] Iteration 6100, lr = 0.01
I1002 01:10:37.939170 23754 solver.cpp:243] Iteration 6200, loss = 0.111244
I1002 01:10:37.939218 23754 solver.cpp:259]     Train net output #0: error_blob = 0.111244 (* 1 = 0.111244 loss)
I1002 01:10:37.939225 23754 solver.cpp:590] Iteration 6200, lr = 0.01
I1002 01:10:40.390125 23754 solver.cpp:243] Iteration 6300, loss = 0.114829
I1002 01:10:40.390166 23754 solver.cpp:259]     Train net output #0: error_blob = 0.114829 (* 1 = 0.114829 loss)
I1002 01:10:40.390172 23754 solver.cpp:590] Iteration 6300, lr = 0.01
I1002 01:10:41.336423 23754 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 01:10:42.901463 23754 solver.cpp:243] Iteration 6400, loss = 0.117815
I1002 01:10:42.901504 23754 solver.cpp:259]     Train net output #0: error_blob = 0.117815 (* 1 = 0.117815 loss)
I1002 01:10:42.901510 23754 solver.cpp:590] Iteration 6400, lr = 0.01
I1002 01:10:45.415305 23754 solver.cpp:243] Iteration 6500, loss = 0.117181
I1002 01:10:45.415354 23754 solver.cpp:259]     Train net output #0: error_blob = 0.117181 (* 1 = 0.117181 loss)
I1002 01:10:45.415361 23754 solver.cpp:590] Iteration 6500, lr = 0.01
I1002 01:10:47.937429 23754 solver.cpp:243] Iteration 6600, loss = 0.114166
I1002 01:10:47.937471 23754 solver.cpp:259]     Train net output #0: error_blob = 0.114166 (* 1 = 0.114166 loss)
I1002 01:10:47.937477 23754 solver.cpp:590] Iteration 6600, lr = 0.01
I1002 01:10:50.448642 23754 solver.cpp:243] Iteration 6700, loss = 0.118371
I1002 01:10:50.448671 23754 solver.cpp:259]     Train net output #0: error_blob = 0.118371 (* 1 = 0.118371 loss)
I1002 01:10:50.448676 23754 solver.cpp:590] Iteration 6700, lr = 0.01
I1002 01:10:52.970710 23754 solver.cpp:243] Iteration 6800, loss = 0.118276
I1002 01:10:52.970748 23754 solver.cpp:259]     Train net output #0: error_blob = 0.118276 (* 1 = 0.118276 loss)
I1002 01:10:52.970755 23754 solver.cpp:590] Iteration 6800, lr = 0.01
I1002 01:10:55.514045 23754 solver.cpp:243] Iteration 6900, loss = 0.116581
I1002 01:10:55.514092 23754 solver.cpp:259]     Train net output #0: error_blob = 0.116581 (* 1 = 0.116581 loss)
I1002 01:10:55.514099 23754 solver.cpp:590] Iteration 6900, lr = 0.01
I1002 01:10:58.042742 23754 solver.cpp:347] Iteration 7000, Testing net (#0)
I1002 01:10:58.324162 23754 solver.cpp:415]     Test net output #0: error_blob = 0.125564 (* 1 = 0.125564 loss)
I1002 01:10:58.324846 23754 solver.cpp:243] Iteration 7000, loss = 0.116877
I1002 01:10:58.324862 23754 solver.cpp:259]     Train net output #0: error_blob = 0.116877 (* 1 = 0.116877 loss)
I1002 01:10:58.324878 23754 solver.cpp:590] Iteration 7000, lr = 0.01
I1002 01:11:00.754781 23754 solver.cpp:243] Iteration 7100, loss = 0.116066
I1002 01:11:00.754811 23754 solver.cpp:259]     Train net output #0: error_blob = 0.116066 (* 1 = 0.116066 loss)
I1002 01:11:00.754815 23754 solver.cpp:590] Iteration 7100, lr = 0.01
I1002 01:11:03.245322 23754 solver.cpp:243] Iteration 7200, loss = 0.116892
I1002 01:11:03.245354 23754 solver.cpp:259]     Train net output #0: error_blob = 0.116892 (* 1 = 0.116892 loss)
I1002 01:11:03.245359 23754 solver.cpp:590] Iteration 7200, lr = 0.01
I1002 01:11:04.344122 23754 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 01:11:05.754806 23754 solver.cpp:243] Iteration 7300, loss = 0.116959
I1002 01:11:05.754835 23754 solver.cpp:259]     Train net output #0: error_blob = 0.116959 (* 1 = 0.116959 loss)
I1002 01:11:05.754840 23754 solver.cpp:590] Iteration 7300, lr = 0.01
I1002 01:11:08.291982 23754 solver.cpp:243] Iteration 7400, loss = 0.115327
I1002 01:11:08.292022 23754 solver.cpp:259]     Train net output #0: error_blob = 0.115327 (* 1 = 0.115327 loss)
I1002 01:11:08.292027 23754 solver.cpp:590] Iteration 7400, lr = 0.01
I1002 01:11:10.804479 23754 solver.cpp:243] Iteration 7500, loss = 0.11873
I1002 01:11:10.804518 23754 solver.cpp:259]     Train net output #0: error_blob = 0.11873 (* 1 = 0.11873 loss)
I1002 01:11:10.804523 23754 solver.cpp:590] Iteration 7500, lr = 0.01
I1002 01:11:13.320901 23754 solver.cpp:243] Iteration 7600, loss = 0.118051
I1002 01:11:13.320935 23754 solver.cpp:259]     Train net output #0: error_blob = 0.118051 (* 1 = 0.118051 loss)
I1002 01:11:13.320943 23754 solver.cpp:590] Iteration 7600, lr = 0.01
I1002 01:11:15.835893 23754 solver.cpp:243] Iteration 7700, loss = 0.115785
I1002 01:11:15.835924 23754 solver.cpp:259]     Train net output #0: error_blob = 0.115785 (* 1 = 0.115785 loss)
I1002 01:11:15.835929 23754 solver.cpp:590] Iteration 7700, lr = 0.01
I1002 01:11:18.302245 23754 solver.cpp:243] Iteration 7800, loss = 0.112457
I1002 01:11:18.302276 23754 solver.cpp:259]     Train net output #0: error_blob = 0.112457 (* 1 = 0.112457 loss)
I1002 01:11:18.302281 23754 solver.cpp:590] Iteration 7800, lr = 0.01
I1002 01:11:20.794082 23754 solver.cpp:243] Iteration 7900, loss = 0.113699
I1002 01:11:20.794114 23754 solver.cpp:259]     Train net output #0: error_blob = 0.113699 (* 1 = 0.113699 loss)
I1002 01:11:20.794119 23754 solver.cpp:590] Iteration 7900, lr = 0.01
I1002 01:11:23.239894 23754 solver.cpp:347] Iteration 8000, Testing net (#0)
I1002 01:11:23.520773 23754 solver.cpp:415]     Test net output #0: error_blob = 0.119236 (* 1 = 0.119236 loss)
I1002 01:11:23.521379 23754 solver.cpp:243] Iteration 8000, loss = 0.117089
I1002 01:11:23.521389 23754 solver.cpp:259]     Train net output #0: error_blob = 0.117089 (* 1 = 0.117089 loss)
I1002 01:11:23.521396 23754 solver.cpp:590] Iteration 8000, lr = 0.01
I1002 01:11:26.015935 23754 solver.cpp:243] Iteration 8100, loss = 0.116387
I1002 01:11:26.015967 23754 solver.cpp:259]     Train net output #0: error_blob = 0.116387 (* 1 = 0.116387 loss)
I1002 01:11:26.015974 23754 solver.cpp:590] Iteration 8100, lr = 0.01
I1002 01:11:27.277508 23754 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 01:11:28.572823 23754 solver.cpp:243] Iteration 8200, loss = 0.112715
I1002 01:11:28.572940 23754 solver.cpp:259]     Train net output #0: error_blob = 0.112715 (* 1 = 0.112715 loss)
I1002 01:11:28.572947 23754 solver.cpp:590] Iteration 8200, lr = 0.01
I1002 01:11:31.063936 23754 solver.cpp:243] Iteration 8300, loss = 0.118158
I1002 01:11:31.063978 23754 solver.cpp:259]     Train net output #0: error_blob = 0.118158 (* 1 = 0.118158 loss)
I1002 01:11:31.063984 23754 solver.cpp:590] Iteration 8300, lr = 0.01
I1002 01:11:33.586419 23754 solver.cpp:243] Iteration 8400, loss = 0.11653
I1002 01:11:33.586462 23754 solver.cpp:259]     Train net output #0: error_blob = 0.11653 (* 1 = 0.11653 loss)
I1002 01:11:33.586467 23754 solver.cpp:590] Iteration 8400, lr = 0.01
I1002 01:11:36.096557 23754 solver.cpp:243] Iteration 8500, loss = 0.119211
I1002 01:11:36.096586 23754 solver.cpp:259]     Train net output #0: error_blob = 0.119211 (* 1 = 0.119211 loss)
I1002 01:11:36.096591 23754 solver.cpp:590] Iteration 8500, lr = 0.01
I1002 01:11:38.582365 23754 solver.cpp:243] Iteration 8600, loss = 0.113301
I1002 01:11:38.582396 23754 solver.cpp:259]     Train net output #0: error_blob = 0.113301 (* 1 = 0.113301 loss)
I1002 01:11:38.582399 23754 solver.cpp:590] Iteration 8600, lr = 0.01
I1002 01:11:41.073909 23754 solver.cpp:243] Iteration 8700, loss = 0.116728
I1002 01:11:41.073941 23754 solver.cpp:259]     Train net output #0: error_blob = 0.116728 (* 1 = 0.116728 loss)
I1002 01:11:41.073948 23754 solver.cpp:590] Iteration 8700, lr = 0.01
I1002 01:11:43.525897 23754 solver.cpp:243] Iteration 8800, loss = 0.11689
I1002 01:11:43.525930 23754 solver.cpp:259]     Train net output #0: error_blob = 0.11689 (* 1 = 0.11689 loss)
I1002 01:11:43.525935 23754 solver.cpp:590] Iteration 8800, lr = 0.01
I1002 01:11:46.005125 23754 solver.cpp:243] Iteration 8900, loss = 0.118861
I1002 01:11:46.005158 23754 solver.cpp:259]     Train net output #0: error_blob = 0.118861 (* 1 = 0.118861 loss)
I1002 01:11:46.005163 23754 solver.cpp:590] Iteration 8900, lr = 0.01
I1002 01:11:48.500239 23754 solver.cpp:347] Iteration 9000, Testing net (#0)
I1002 01:11:48.841717 23754 solver.cpp:415]     Test net output #0: error_blob = 0.12325 (* 1 = 0.12325 loss)
I1002 01:11:48.842326 23754 solver.cpp:243] Iteration 9000, loss = 0.113426
I1002 01:11:48.842339 23754 solver.cpp:259]     Train net output #0: error_blob = 0.113426 (* 1 = 0.113426 loss)
I1002 01:11:48.842342 23754 solver.cpp:590] Iteration 9000, lr = 0.01
I1002 01:11:50.190762 23754 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 01:11:51.295492 23754 solver.cpp:243] Iteration 9100, loss = 0.112722
I1002 01:11:51.295523 23754 solver.cpp:259]     Train net output #0: error_blob = 0.112722 (* 1 = 0.112722 loss)
I1002 01:11:51.295529 23754 solver.cpp:590] Iteration 9100, lr = 0.01
I1002 01:11:53.801192 23754 solver.cpp:243] Iteration 9200, loss = 0.117542
I1002 01:11:53.801224 23754 solver.cpp:259]     Train net output #0: error_blob = 0.117542 (* 1 = 0.117542 loss)
I1002 01:11:53.801230 23754 solver.cpp:590] Iteration 9200, lr = 0.01
I1002 01:11:56.301472 23754 solver.cpp:243] Iteration 9300, loss = 0.116796
I1002 01:11:56.301503 23754 solver.cpp:259]     Train net output #0: error_blob = 0.116796 (* 1 = 0.116796 loss)
I1002 01:11:56.301508 23754 solver.cpp:590] Iteration 9300, lr = 0.01
I1002 01:11:58.803691 23754 solver.cpp:243] Iteration 9400, loss = 0.113145
I1002 01:11:58.804703 23754 solver.cpp:259]     Train net output #0: error_blob = 0.113145 (* 1 = 0.113145 loss)
I1002 01:11:58.804713 23754 solver.cpp:590] Iteration 9400, lr = 0.01
I1002 01:12:01.294111 23754 solver.cpp:243] Iteration 9500, loss = 0.11284
I1002 01:12:01.294150 23754 solver.cpp:259]     Train net output #0: error_blob = 0.11284 (* 1 = 0.11284 loss)
I1002 01:12:01.294155 23754 solver.cpp:590] Iteration 9500, lr = 0.01
I1002 01:12:03.806707 23754 solver.cpp:243] Iteration 9600, loss = 0.117735
I1002 01:12:03.806741 23754 solver.cpp:259]     Train net output #0: error_blob = 0.117735 (* 1 = 0.117735 loss)
I1002 01:12:03.806748 23754 solver.cpp:590] Iteration 9600, lr = 0.01
I1002 01:12:06.308706 23754 solver.cpp:243] Iteration 9700, loss = 0.117834
I1002 01:12:06.308739 23754 solver.cpp:259]     Train net output #0: error_blob = 0.117834 (* 1 = 0.117834 loss)
I1002 01:12:06.308748 23754 solver.cpp:590] Iteration 9700, lr = 0.01
I1002 01:12:08.789368 23754 solver.cpp:243] Iteration 9800, loss = 0.111979
I1002 01:12:08.789402 23754 solver.cpp:259]     Train net output #0: error_blob = 0.111979 (* 1 = 0.111979 loss)
I1002 01:12:08.789408 23754 solver.cpp:590] Iteration 9800, lr = 0.01
I1002 01:12:11.296833 23754 solver.cpp:243] Iteration 9900, loss = 0.115787
I1002 01:12:11.296862 23754 solver.cpp:259]     Train net output #0: error_blob = 0.115787 (* 1 = 0.115787 loss)
I1002 01:12:11.296869 23754 solver.cpp:590] Iteration 9900, lr = 0.01
I1002 01:12:13.747249 23754 solver.cpp:468] Snapshotting to binary proto file _iter_10000.caffemodel
I1002 01:12:13.748962 23754 solver.cpp:753] Snapshotting solver state to binary proto file _iter_10000.solverstate
I1002 01:12:13.772114 23754 solver.cpp:327] Iteration 10000, loss = 0.11791
I1002 01:12:13.772140 23754 solver.cpp:347] Iteration 10000, Testing net (#0)
I1002 01:12:13.949472 23754 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 01:12:14.057608 23754 solver.cpp:415]     Test net output #0: error_blob = 0.119216 (* 1 = 0.119216 loss)
I1002 01:12:14.057628 23754 solver.cpp:332] Optimization Done.
I1002 01:12:14.057631 23754 caffe.cpp:215] Optimization Done.
I1002 01:12:14.121848 23775 caffe.cpp:184] Using GPUs 0
I1002 01:12:14.675578 23775 solver.cpp:54] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "fixed"
momentum: 0.9
solver_mode: GPU
device_id: 0
net: "model/NNScore/nnscore_model_8.prototxt"
I1002 01:12:14.675609 23775 solver.cpp:97] Creating training net from net file: model/NNScore/nnscore_model_8.prototxt
I1002 01:12:14.675782 23775 net.cpp:339] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_layer
I1002 01:12:14.675828 23775 net.cpp:50] Initializing net from parameters: 
name: "model/NNScore/nnscore_model_8.prototxt"
state {
  phase: TRAIN
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TRAIN
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.8.train"
    batch_size: 20000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1002 01:12:14.675906 23775 layer_factory.hpp:76] Creating layer data_layer
I1002 01:12:14.689143 23775 net.cpp:110] Creating Layer data_layer
I1002 01:12:14.689174 23775 net.cpp:433] data_layer -> data_blob
I1002 01:12:14.689206 23775 net.cpp:433] data_layer -> label_blob
I1002 01:12:14.689826 23779 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.8.train
I1002 01:12:15.374620 23775 data_layer.cpp:45] output data size: 20000,61,1,1
I1002 01:12:15.379580 23775 net.cpp:155] Setting up data_layer
I1002 01:12:15.379622 23775 net.cpp:163] Top shape: 20000 61 1 1 (1220000)
I1002 01:12:15.379626 23775 net.cpp:163] Top shape: 20000 (20000)
I1002 01:12:15.379642 23775 layer_factory.hpp:76] Creating layer hidden_sum_layer
I1002 01:12:15.379653 23775 net.cpp:110] Creating Layer hidden_sum_layer
I1002 01:12:15.379657 23775 net.cpp:477] hidden_sum_layer <- data_blob
I1002 01:12:15.379667 23775 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I1002 01:12:15.380028 23775 net.cpp:155] Setting up hidden_sum_layer
I1002 01:12:15.380034 23775 net.cpp:163] Top shape: 20000 10 (200000)
I1002 01:12:15.380056 23775 layer_factory.hpp:76] Creating layer hidden_act_layer
I1002 01:12:15.380074 23775 net.cpp:110] Creating Layer hidden_act_layer
I1002 01:12:15.380076 23775 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I1002 01:12:15.380079 23775 net.cpp:433] hidden_act_layer -> hidden_act_blob
I1002 01:12:18.601126 23775 net.cpp:155] Setting up hidden_act_layer
I1002 01:12:18.601162 23775 net.cpp:163] Top shape: 20000 10 (200000)
I1002 01:12:18.601168 23775 layer_factory.hpp:76] Creating layer output_sum_layer
I1002 01:12:18.601181 23775 net.cpp:110] Creating Layer output_sum_layer
I1002 01:12:18.601193 23775 net.cpp:477] output_sum_layer <- hidden_act_blob
I1002 01:12:18.601202 23775 net.cpp:433] output_sum_layer -> output_sum_blob
I1002 01:12:18.601322 23775 net.cpp:155] Setting up output_sum_layer
I1002 01:12:18.601327 23775 net.cpp:163] Top shape: 20000 1 (20000)
I1002 01:12:18.601347 23775 layer_factory.hpp:76] Creating layer output_act_layer
I1002 01:12:18.601362 23775 net.cpp:110] Creating Layer output_act_layer
I1002 01:12:18.601364 23775 net.cpp:477] output_act_layer <- output_sum_blob
I1002 01:12:18.601367 23775 net.cpp:433] output_act_layer -> output_act_blob
I1002 01:12:18.601449 23775 net.cpp:155] Setting up output_act_layer
I1002 01:12:18.601469 23775 net.cpp:163] Top shape: 20000 1 (20000)
I1002 01:12:18.601482 23775 layer_factory.hpp:76] Creating layer error_layer
I1002 01:12:18.601488 23775 net.cpp:110] Creating Layer error_layer
I1002 01:12:18.601503 23775 net.cpp:477] error_layer <- output_act_blob
I1002 01:12:18.601506 23775 net.cpp:477] error_layer <- label_blob
I1002 01:12:18.601510 23775 net.cpp:433] error_layer -> error_blob
I1002 01:12:18.601943 23775 net.cpp:155] Setting up error_layer
I1002 01:12:18.601946 23775 net.cpp:163] Top shape: (1)
I1002 01:12:18.601948 23775 net.cpp:168]     with loss weight 1
I1002 01:12:18.601964 23775 net.cpp:236] error_layer needs backward computation.
I1002 01:12:18.601968 23775 net.cpp:236] output_act_layer needs backward computation.
I1002 01:12:18.601969 23775 net.cpp:236] output_sum_layer needs backward computation.
I1002 01:12:18.601971 23775 net.cpp:236] hidden_act_layer needs backward computation.
I1002 01:12:18.601974 23775 net.cpp:236] hidden_sum_layer needs backward computation.
I1002 01:12:18.601976 23775 net.cpp:240] data_layer does not need backward computation.
I1002 01:12:18.601979 23775 net.cpp:283] This network produces output error_blob
I1002 01:12:18.601984 23775 net.cpp:297] Network initialization done.
I1002 01:12:18.601985 23775 net.cpp:298] Memory required for data: 6720004
I1002 01:12:18.602111 23775 solver.cpp:187] Creating test net (#0) specified by net file: model/NNScore/nnscore_model_8.prototxt
I1002 01:12:18.602123 23775 net.cpp:339] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_layer
I1002 01:12:18.602155 23775 net.cpp:50] Initializing net from parameters: 
name: "model/NNScore/nnscore_model_8.prototxt"
state {
  phase: TEST
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TEST
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.8.test"
    batch_size: 2000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1002 01:12:18.602176 23775 layer_factory.hpp:76] Creating layer data_layer
I1002 01:12:18.603435 23775 net.cpp:110] Creating Layer data_layer
I1002 01:12:18.603440 23775 net.cpp:433] data_layer -> data_blob
I1002 01:12:18.603446 23775 net.cpp:433] data_layer -> label_blob
I1002 01:12:18.603991 23781 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.8.test
I1002 01:12:18.604055 23775 data_layer.cpp:45] output data size: 2000,61,1,1
I1002 01:12:18.605443 23775 net.cpp:155] Setting up data_layer
I1002 01:12:18.605458 23775 net.cpp:163] Top shape: 2000 61 1 1 (122000)
I1002 01:12:18.605463 23775 net.cpp:163] Top shape: 2000 (2000)
I1002 01:12:18.605468 23775 layer_factory.hpp:76] Creating layer hidden_sum_layer
I1002 01:12:18.605476 23775 net.cpp:110] Creating Layer hidden_sum_layer
I1002 01:12:18.605482 23775 net.cpp:477] hidden_sum_layer <- data_blob
I1002 01:12:18.605489 23775 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I1002 01:12:18.605607 23775 net.cpp:155] Setting up hidden_sum_layer
I1002 01:12:18.605614 23775 net.cpp:163] Top shape: 2000 10 (20000)
I1002 01:12:18.605625 23775 layer_factory.hpp:76] Creating layer hidden_act_layer
I1002 01:12:18.605633 23775 net.cpp:110] Creating Layer hidden_act_layer
I1002 01:12:18.605639 23775 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I1002 01:12:18.605659 23775 net.cpp:433] hidden_act_layer -> hidden_act_blob
I1002 01:12:18.605844 23775 net.cpp:155] Setting up hidden_act_layer
I1002 01:12:18.605852 23775 net.cpp:163] Top shape: 2000 10 (20000)
I1002 01:12:18.605856 23775 layer_factory.hpp:76] Creating layer output_sum_layer
I1002 01:12:18.605862 23775 net.cpp:110] Creating Layer output_sum_layer
I1002 01:12:18.605866 23775 net.cpp:477] output_sum_layer <- hidden_act_blob
I1002 01:12:18.605875 23775 net.cpp:433] output_sum_layer -> output_sum_blob
I1002 01:12:18.605939 23775 net.cpp:155] Setting up output_sum_layer
I1002 01:12:18.605947 23775 net.cpp:163] Top shape: 2000 1 (2000)
I1002 01:12:18.605955 23775 layer_factory.hpp:76] Creating layer output_act_layer
I1002 01:12:18.605962 23775 net.cpp:110] Creating Layer output_act_layer
I1002 01:12:18.605965 23775 net.cpp:477] output_act_layer <- output_sum_blob
I1002 01:12:18.605973 23775 net.cpp:433] output_act_layer -> output_act_blob
I1002 01:12:18.606030 23775 net.cpp:155] Setting up output_act_layer
I1002 01:12:18.606037 23775 net.cpp:163] Top shape: 2000 1 (2000)
I1002 01:12:18.606041 23775 layer_factory.hpp:76] Creating layer error_layer
I1002 01:12:18.606047 23775 net.cpp:110] Creating Layer error_layer
I1002 01:12:18.606052 23775 net.cpp:477] error_layer <- output_act_blob
I1002 01:12:18.606057 23775 net.cpp:477] error_layer <- label_blob
I1002 01:12:18.606062 23775 net.cpp:433] error_layer -> error_blob
I1002 01:12:18.606089 23775 net.cpp:155] Setting up error_layer
I1002 01:12:18.606094 23775 net.cpp:163] Top shape: (1)
I1002 01:12:18.606097 23775 net.cpp:168]     with loss weight 1
I1002 01:12:18.606109 23775 net.cpp:236] error_layer needs backward computation.
I1002 01:12:18.606114 23775 net.cpp:236] output_act_layer needs backward computation.
I1002 01:12:18.606117 23775 net.cpp:236] output_sum_layer needs backward computation.
I1002 01:12:18.606122 23775 net.cpp:236] hidden_act_layer needs backward computation.
I1002 01:12:18.606124 23775 net.cpp:236] hidden_sum_layer needs backward computation.
I1002 01:12:18.606128 23775 net.cpp:240] data_layer does not need backward computation.
I1002 01:12:18.606132 23775 net.cpp:283] This network produces output error_blob
I1002 01:12:18.606138 23775 net.cpp:297] Network initialization done.
I1002 01:12:18.606142 23775 net.cpp:298] Memory required for data: 672004
I1002 01:12:18.606165 23775 solver.cpp:66] Solver scaffolding done.
I1002 01:12:18.606269 23775 caffe.cpp:212] Starting Optimization
I1002 01:12:18.606276 23775 solver.cpp:294] Solving model/NNScore/nnscore_model_8.prototxt
I1002 01:12:18.606281 23775 solver.cpp:295] Learning Rate Policy: fixed
I1002 01:12:18.606497 23775 solver.cpp:347] Iteration 0, Testing net (#0)
I1002 01:12:18.606557 23775 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 01:12:18.870448 23775 solver.cpp:415]     Test net output #0: error_blob = 0.128349 (* 1 = 0.128349 loss)
I1002 01:12:18.871793 23775 solver.cpp:243] Iteration 0, loss = 0.127795
I1002 01:12:18.871812 23775 solver.cpp:259]     Train net output #0: error_blob = 0.127795 (* 1 = 0.127795 loss)
I1002 01:12:18.871825 23775 solver.cpp:590] Iteration 0, lr = 0.01
I1002 01:12:21.357013 23775 solver.cpp:243] Iteration 100, loss = 0.123299
I1002 01:12:21.357044 23775 solver.cpp:259]     Train net output #0: error_blob = 0.123299 (* 1 = 0.123299 loss)
I1002 01:12:21.357049 23775 solver.cpp:590] Iteration 100, lr = 0.01
I1002 01:12:23.874955 23775 solver.cpp:243] Iteration 200, loss = 0.122192
I1002 01:12:23.874985 23775 solver.cpp:259]     Train net output #0: error_blob = 0.122192 (* 1 = 0.122192 loss)
I1002 01:12:23.874990 23775 solver.cpp:590] Iteration 200, lr = 0.01
I1002 01:12:26.380628 23775 solver.cpp:243] Iteration 300, loss = 0.121363
I1002 01:12:26.380668 23775 solver.cpp:259]     Train net output #0: error_blob = 0.121363 (* 1 = 0.121363 loss)
I1002 01:12:26.380674 23775 solver.cpp:590] Iteration 300, lr = 0.01
I1002 01:12:28.875948 23775 solver.cpp:243] Iteration 400, loss = 0.121028
I1002 01:12:28.876016 23775 solver.cpp:259]     Train net output #0: error_blob = 0.121028 (* 1 = 0.121028 loss)
I1002 01:12:28.876021 23775 solver.cpp:590] Iteration 400, lr = 0.01
I1002 01:12:31.391669 23775 solver.cpp:243] Iteration 500, loss = 0.119588
I1002 01:12:31.391698 23775 solver.cpp:259]     Train net output #0: error_blob = 0.119588 (* 1 = 0.119588 loss)
I1002 01:12:31.391703 23775 solver.cpp:590] Iteration 500, lr = 0.01
I1002 01:12:33.881213 23775 solver.cpp:243] Iteration 600, loss = 0.120439
I1002 01:12:33.881243 23775 solver.cpp:259]     Train net output #0: error_blob = 0.120439 (* 1 = 0.120439 loss)
I1002 01:12:33.881247 23775 solver.cpp:590] Iteration 600, lr = 0.01
I1002 01:12:36.380590 23775 solver.cpp:243] Iteration 700, loss = 0.119321
I1002 01:12:36.380620 23775 solver.cpp:259]     Train net output #0: error_blob = 0.119321 (* 1 = 0.119321 loss)
I1002 01:12:36.380625 23775 solver.cpp:590] Iteration 700, lr = 0.01
I1002 01:12:38.879364 23775 solver.cpp:243] Iteration 800, loss = 0.118783
I1002 01:12:38.879395 23775 solver.cpp:259]     Train net output #0: error_blob = 0.118783 (* 1 = 0.118783 loss)
I1002 01:12:38.879400 23775 solver.cpp:590] Iteration 800, lr = 0.01
I1002 01:12:41.379283 23775 solver.cpp:243] Iteration 900, loss = 0.119364
I1002 01:12:41.379317 23775 solver.cpp:259]     Train net output #0: error_blob = 0.119364 (* 1 = 0.119364 loss)
I1002 01:12:41.379322 23775 solver.cpp:590] Iteration 900, lr = 0.01
I1002 01:12:41.428777 23775 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 01:12:43.865734 23775 solver.cpp:347] Iteration 1000, Testing net (#0)
I1002 01:12:44.151433 23775 solver.cpp:415]     Test net output #0: error_blob = 0.120914 (* 1 = 0.120914 loss)
I1002 01:12:44.152145 23775 solver.cpp:243] Iteration 1000, loss = 0.119528
I1002 01:12:44.152160 23775 solver.cpp:259]     Train net output #0: error_blob = 0.119528 (* 1 = 0.119528 loss)
I1002 01:12:44.152164 23775 solver.cpp:590] Iteration 1000, lr = 0.01
I1002 01:12:46.627655 23775 solver.cpp:243] Iteration 1100, loss = 0.117639
I1002 01:12:46.627696 23775 solver.cpp:259]     Train net output #0: error_blob = 0.117639 (* 1 = 0.117639 loss)
I1002 01:12:46.627701 23775 solver.cpp:590] Iteration 1100, lr = 0.01
I1002 01:12:49.106473 23775 solver.cpp:243] Iteration 1200, loss = 0.117128
I1002 01:12:49.106503 23775 solver.cpp:259]     Train net output #0: error_blob = 0.117128 (* 1 = 0.117128 loss)
I1002 01:12:49.106508 23775 solver.cpp:590] Iteration 1200, lr = 0.01
I1002 01:12:51.585315 23775 solver.cpp:243] Iteration 1300, loss = 0.117594
I1002 01:12:51.585346 23775 solver.cpp:259]     Train net output #0: error_blob = 0.117594 (* 1 = 0.117594 loss)
I1002 01:12:51.585351 23775 solver.cpp:590] Iteration 1300, lr = 0.01
I1002 01:12:54.082554 23775 solver.cpp:243] Iteration 1400, loss = 0.119374
I1002 01:12:54.082583 23775 solver.cpp:259]     Train net output #0: error_blob = 0.119374 (* 1 = 0.119374 loss)
I1002 01:12:54.082588 23775 solver.cpp:590] Iteration 1400, lr = 0.01
I1002 01:12:56.534922 23775 solver.cpp:243] Iteration 1500, loss = 0.11761
I1002 01:12:56.534952 23775 solver.cpp:259]     Train net output #0: error_blob = 0.11761 (* 1 = 0.11761 loss)
I1002 01:12:56.534957 23775 solver.cpp:590] Iteration 1500, lr = 0.01
I1002 01:12:59.001972 23775 solver.cpp:243] Iteration 1600, loss = 0.119272
I1002 01:12:59.002004 23775 solver.cpp:259]     Train net output #0: error_blob = 0.119272 (* 1 = 0.119272 loss)
I1002 01:12:59.002009 23775 solver.cpp:590] Iteration 1600, lr = 0.01
I1002 01:13:01.482051 23775 solver.cpp:243] Iteration 1700, loss = 0.117089
I1002 01:13:01.482080 23775 solver.cpp:259]     Train net output #0: error_blob = 0.117089 (* 1 = 0.117089 loss)
I1002 01:13:01.482085 23775 solver.cpp:590] Iteration 1700, lr = 0.01
I1002 01:13:03.972347 23775 solver.cpp:243] Iteration 1800, loss = 0.115377
I1002 01:13:03.972376 23775 solver.cpp:259]     Train net output #0: error_blob = 0.115377 (* 1 = 0.115377 loss)
I1002 01:13:03.972383 23775 solver.cpp:590] Iteration 1800, lr = 0.01
I1002 01:13:04.172505 23775 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 01:13:06.483306 23775 solver.cpp:243] Iteration 1900, loss = 0.12073
I1002 01:13:06.483348 23775 solver.cpp:259]     Train net output #0: error_blob = 0.12073 (* 1 = 0.12073 loss)
I1002 01:13:06.483355 23775 solver.cpp:590] Iteration 1900, lr = 0.01
I1002 01:13:09.006849 23775 solver.cpp:347] Iteration 2000, Testing net (#0)
I1002 01:13:09.285918 23775 solver.cpp:415]     Test net output #0: error_blob = 0.123991 (* 1 = 0.123991 loss)
I1002 01:13:09.286578 23775 solver.cpp:243] Iteration 2000, loss = 0.117209
I1002 01:13:09.286592 23775 solver.cpp:259]     Train net output #0: error_blob = 0.117209 (* 1 = 0.117209 loss)
I1002 01:13:09.286598 23775 solver.cpp:590] Iteration 2000, lr = 0.01
I1002 01:13:11.758962 23775 solver.cpp:243] Iteration 2100, loss = 0.114141
I1002 01:13:11.758991 23775 solver.cpp:259]     Train net output #0: error_blob = 0.114141 (* 1 = 0.114141 loss)
I1002 01:13:11.758996 23775 solver.cpp:590] Iteration 2100, lr = 0.01
I1002 01:13:14.251358 23775 solver.cpp:243] Iteration 2200, loss = 0.115443
I1002 01:13:14.251462 23775 solver.cpp:259]     Train net output #0: error_blob = 0.115443 (* 1 = 0.115443 loss)
I1002 01:13:14.251468 23775 solver.cpp:590] Iteration 2200, lr = 0.01
I1002 01:13:16.765218 23775 solver.cpp:243] Iteration 2300, loss = 0.116369
I1002 01:13:16.765251 23775 solver.cpp:259]     Train net output #0: error_blob = 0.116369 (* 1 = 0.116369 loss)
I1002 01:13:16.765259 23775 solver.cpp:590] Iteration 2300, lr = 0.01
I1002 01:13:19.243842 23775 solver.cpp:243] Iteration 2400, loss = 0.115576
I1002 01:13:19.243872 23775 solver.cpp:259]     Train net output #0: error_blob = 0.115576 (* 1 = 0.115576 loss)
I1002 01:13:19.243877 23775 solver.cpp:590] Iteration 2400, lr = 0.01
I1002 01:13:21.758260 23775 solver.cpp:243] Iteration 2500, loss = 0.114152
I1002 01:13:21.758290 23775 solver.cpp:259]     Train net output #0: error_blob = 0.114152 (* 1 = 0.114152 loss)
I1002 01:13:21.758294 23775 solver.cpp:590] Iteration 2500, lr = 0.01
I1002 01:13:24.245681 23775 solver.cpp:243] Iteration 2600, loss = 0.118968
I1002 01:13:24.245710 23775 solver.cpp:259]     Train net output #0: error_blob = 0.118968 (* 1 = 0.118968 loss)
I1002 01:13:24.245715 23775 solver.cpp:590] Iteration 2600, lr = 0.01
I1002 01:13:26.729276 23775 solver.cpp:243] Iteration 2700, loss = 0.118199
I1002 01:13:26.729306 23775 solver.cpp:259]     Train net output #0: error_blob = 0.118199 (* 1 = 0.118199 loss)
I1002 01:13:26.729311 23775 solver.cpp:590] Iteration 2700, lr = 0.01
I1002 01:13:27.077571 23775 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 01:13:29.199942 23775 solver.cpp:243] Iteration 2800, loss = 0.114299
I1002 01:13:29.199982 23775 solver.cpp:259]     Train net output #0: error_blob = 0.114299 (* 1 = 0.114299 loss)
I1002 01:13:29.199988 23775 solver.cpp:590] Iteration 2800, lr = 0.01
I1002 01:13:31.738013 23775 solver.cpp:243] Iteration 2900, loss = 0.11616
I1002 01:13:31.738042 23775 solver.cpp:259]     Train net output #0: error_blob = 0.11616 (* 1 = 0.11616 loss)
I1002 01:13:31.738047 23775 solver.cpp:590] Iteration 2900, lr = 0.01
I1002 01:13:34.203475 23775 solver.cpp:347] Iteration 3000, Testing net (#0)
I1002 01:13:34.487007 23775 solver.cpp:415]     Test net output #0: error_blob = 0.123526 (* 1 = 0.123526 loss)
I1002 01:13:34.487617 23775 solver.cpp:243] Iteration 3000, loss = 0.116238
I1002 01:13:34.487629 23775 solver.cpp:259]     Train net output #0: error_blob = 0.116238 (* 1 = 0.116238 loss)
I1002 01:13:34.487637 23775 solver.cpp:590] Iteration 3000, lr = 0.01
I1002 01:13:36.989785 23775 solver.cpp:243] Iteration 3100, loss = 0.115428
I1002 01:13:36.989816 23775 solver.cpp:259]     Train net output #0: error_blob = 0.115428 (* 1 = 0.115428 loss)
I1002 01:13:36.989821 23775 solver.cpp:590] Iteration 3100, lr = 0.01
I1002 01:13:39.486140 23775 solver.cpp:243] Iteration 3200, loss = 0.114132
I1002 01:13:39.486170 23775 solver.cpp:259]     Train net output #0: error_blob = 0.114132 (* 1 = 0.114132 loss)
I1002 01:13:39.486174 23775 solver.cpp:590] Iteration 3200, lr = 0.01
I1002 01:13:42.035370 23775 solver.cpp:243] Iteration 3300, loss = 0.117087
I1002 01:13:42.035400 23775 solver.cpp:259]     Train net output #0: error_blob = 0.117087 (* 1 = 0.117087 loss)
I1002 01:13:42.035406 23775 solver.cpp:590] Iteration 3300, lr = 0.01
I1002 01:13:44.535622 23775 solver.cpp:243] Iteration 3400, loss = 0.116629
I1002 01:13:44.535742 23775 solver.cpp:259]     Train net output #0: error_blob = 0.116629 (* 1 = 0.116629 loss)
I1002 01:13:44.535749 23775 solver.cpp:590] Iteration 3400, lr = 0.01
I1002 01:13:47.072399 23775 solver.cpp:243] Iteration 3500, loss = 0.113753
I1002 01:13:47.072430 23775 solver.cpp:259]     Train net output #0: error_blob = 0.113753 (* 1 = 0.113753 loss)
I1002 01:13:47.072434 23775 solver.cpp:590] Iteration 3500, lr = 0.01
I1002 01:13:49.560539 23775 solver.cpp:243] Iteration 3600, loss = 0.119429
I1002 01:13:49.560577 23775 solver.cpp:259]     Train net output #0: error_blob = 0.119429 (* 1 = 0.119429 loss)
I1002 01:13:49.560581 23775 solver.cpp:590] Iteration 3600, lr = 0.01
I1002 01:13:50.052685 23775 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 01:13:52.064277 23775 solver.cpp:243] Iteration 3700, loss = 0.115985
I1002 01:13:52.064306 23775 solver.cpp:259]     Train net output #0: error_blob = 0.115985 (* 1 = 0.115985 loss)
I1002 01:13:52.064311 23775 solver.cpp:590] Iteration 3700, lr = 0.01
I1002 01:13:54.562989 23775 solver.cpp:243] Iteration 3800, loss = 0.114706
I1002 01:13:54.563019 23775 solver.cpp:259]     Train net output #0: error_blob = 0.114706 (* 1 = 0.114706 loss)
I1002 01:13:54.563024 23775 solver.cpp:590] Iteration 3800, lr = 0.01
I1002 01:13:57.055112 23775 solver.cpp:243] Iteration 3900, loss = 0.116319
I1002 01:13:57.055143 23775 solver.cpp:259]     Train net output #0: error_blob = 0.116319 (* 1 = 0.116319 loss)
I1002 01:13:57.055148 23775 solver.cpp:590] Iteration 3900, lr = 0.01
I1002 01:13:59.528213 23775 solver.cpp:347] Iteration 4000, Testing net (#0)
I1002 01:13:59.814061 23775 solver.cpp:415]     Test net output #0: error_blob = 0.123585 (* 1 = 0.123585 loss)
I1002 01:13:59.814781 23775 solver.cpp:243] Iteration 4000, loss = 0.116283
I1002 01:13:59.814820 23775 solver.cpp:259]     Train net output #0: error_blob = 0.116283 (* 1 = 0.116283 loss)
I1002 01:13:59.814828 23775 solver.cpp:590] Iteration 4000, lr = 0.01
I1002 01:14:02.328817 23775 solver.cpp:243] Iteration 4100, loss = 0.112216
I1002 01:14:02.328846 23775 solver.cpp:259]     Train net output #0: error_blob = 0.112216 (* 1 = 0.112216 loss)
I1002 01:14:02.328852 23775 solver.cpp:590] Iteration 4100, lr = 0.01
I1002 01:14:04.785306 23775 solver.cpp:243] Iteration 4200, loss = 0.115498
I1002 01:14:04.785337 23775 solver.cpp:259]     Train net output #0: error_blob = 0.115498 (* 1 = 0.115498 loss)
I1002 01:14:04.785342 23775 solver.cpp:590] Iteration 4200, lr = 0.01
I1002 01:14:07.279394 23775 solver.cpp:243] Iteration 4300, loss = 0.117256
I1002 01:14:07.279422 23775 solver.cpp:259]     Train net output #0: error_blob = 0.117256 (* 1 = 0.117256 loss)
I1002 01:14:07.279428 23775 solver.cpp:590] Iteration 4300, lr = 0.01
I1002 01:14:09.776581 23775 solver.cpp:243] Iteration 4400, loss = 0.117098
I1002 01:14:09.776608 23775 solver.cpp:259]     Train net output #0: error_blob = 0.117098 (* 1 = 0.117098 loss)
I1002 01:14:09.776613 23775 solver.cpp:590] Iteration 4400, lr = 0.01
I1002 01:14:12.266548 23775 solver.cpp:243] Iteration 4500, loss = 0.114614
I1002 01:14:12.266589 23775 solver.cpp:259]     Train net output #0: error_blob = 0.114614 (* 1 = 0.114614 loss)
I1002 01:14:12.266594 23775 solver.cpp:590] Iteration 4500, lr = 0.01
I1002 01:14:12.901228 23775 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 01:14:14.746412 23775 solver.cpp:243] Iteration 4600, loss = 0.117982
I1002 01:14:14.746513 23775 solver.cpp:259]     Train net output #0: error_blob = 0.117982 (* 1 = 0.117982 loss)
I1002 01:14:14.746522 23775 solver.cpp:590] Iteration 4600, lr = 0.01
I1002 01:14:17.305805 23775 solver.cpp:243] Iteration 4700, loss = 0.11587
I1002 01:14:17.305853 23775 solver.cpp:259]     Train net output #0: error_blob = 0.11587 (* 1 = 0.11587 loss)
I1002 01:14:17.305860 23775 solver.cpp:590] Iteration 4700, lr = 0.01
I1002 01:14:19.829860 23775 solver.cpp:243] Iteration 4800, loss = 0.115049
I1002 01:14:19.829890 23775 solver.cpp:259]     Train net output #0: error_blob = 0.115049 (* 1 = 0.115049 loss)
I1002 01:14:19.829896 23775 solver.cpp:590] Iteration 4800, lr = 0.01
I1002 01:14:22.307862 23775 solver.cpp:243] Iteration 4900, loss = 0.115479
I1002 01:14:22.307909 23775 solver.cpp:259]     Train net output #0: error_blob = 0.115479 (* 1 = 0.115479 loss)
I1002 01:14:22.307915 23775 solver.cpp:590] Iteration 4900, lr = 0.01
I1002 01:14:24.771694 23775 solver.cpp:347] Iteration 5000, Testing net (#0)
I1002 01:14:25.047247 23775 solver.cpp:415]     Test net output #0: error_blob = 0.125132 (* 1 = 0.125132 loss)
I1002 01:14:25.047868 23775 solver.cpp:243] Iteration 5000, loss = 0.116667
I1002 01:14:25.047883 23775 solver.cpp:259]     Train net output #0: error_blob = 0.116667 (* 1 = 0.116667 loss)
I1002 01:14:25.047890 23775 solver.cpp:590] Iteration 5000, lr = 0.01
I1002 01:14:27.479076 23775 solver.cpp:243] Iteration 5100, loss = 0.114577
I1002 01:14:27.479109 23775 solver.cpp:259]     Train net output #0: error_blob = 0.114577 (* 1 = 0.114577 loss)
I1002 01:14:27.479115 23775 solver.cpp:590] Iteration 5100, lr = 0.01
I1002 01:14:29.954085 23775 solver.cpp:243] Iteration 5200, loss = 0.11408
I1002 01:14:29.954118 23775 solver.cpp:259]     Train net output #0: error_blob = 0.11408 (* 1 = 0.11408 loss)
I1002 01:14:29.954123 23775 solver.cpp:590] Iteration 5200, lr = 0.01
I1002 01:14:32.410609 23775 solver.cpp:243] Iteration 5300, loss = 0.117152
I1002 01:14:32.410640 23775 solver.cpp:259]     Train net output #0: error_blob = 0.117152 (* 1 = 0.117152 loss)
I1002 01:14:32.410645 23775 solver.cpp:590] Iteration 5300, lr = 0.01
I1002 01:14:34.956168 23775 solver.cpp:243] Iteration 5400, loss = 0.1159
I1002 01:14:34.956197 23775 solver.cpp:259]     Train net output #0: error_blob = 0.1159 (* 1 = 0.1159 loss)
I1002 01:14:34.956202 23775 solver.cpp:590] Iteration 5400, lr = 0.01
I1002 01:14:35.743826 23775 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 01:14:37.431356 23775 solver.cpp:243] Iteration 5500, loss = 0.114211
I1002 01:14:37.431386 23775 solver.cpp:259]     Train net output #0: error_blob = 0.114211 (* 1 = 0.114211 loss)
I1002 01:14:37.431391 23775 solver.cpp:590] Iteration 5500, lr = 0.01
I1002 01:14:39.894189 23775 solver.cpp:243] Iteration 5600, loss = 0.116743
I1002 01:14:39.894219 23775 solver.cpp:259]     Train net output #0: error_blob = 0.116743 (* 1 = 0.116743 loss)
I1002 01:14:39.894224 23775 solver.cpp:590] Iteration 5600, lr = 0.01
I1002 01:14:42.369717 23775 solver.cpp:243] Iteration 5700, loss = 0.116416
I1002 01:14:42.369748 23775 solver.cpp:259]     Train net output #0: error_blob = 0.116416 (* 1 = 0.116416 loss)
I1002 01:14:42.369753 23775 solver.cpp:590] Iteration 5700, lr = 0.01
I1002 01:14:44.855247 23775 solver.cpp:243] Iteration 5800, loss = 0.118102
I1002 01:14:44.855378 23775 solver.cpp:259]     Train net output #0: error_blob = 0.118102 (* 1 = 0.118102 loss)
I1002 01:14:44.855384 23775 solver.cpp:590] Iteration 5800, lr = 0.01
I1002 01:14:47.323866 23775 solver.cpp:243] Iteration 5900, loss = 0.116119
I1002 01:14:47.323899 23775 solver.cpp:259]     Train net output #0: error_blob = 0.116119 (* 1 = 0.116119 loss)
I1002 01:14:47.323906 23775 solver.cpp:590] Iteration 5900, lr = 0.01
I1002 01:14:49.812471 23775 solver.cpp:347] Iteration 6000, Testing net (#0)
I1002 01:14:50.143049 23775 solver.cpp:415]     Test net output #0: error_blob = 0.124379 (* 1 = 0.124379 loss)
I1002 01:14:50.143705 23775 solver.cpp:243] Iteration 6000, loss = 0.116237
I1002 01:14:50.143723 23775 solver.cpp:259]     Train net output #0: error_blob = 0.116237 (* 1 = 0.116237 loss)
I1002 01:14:50.143728 23775 solver.cpp:590] Iteration 6000, lr = 0.01
I1002 01:14:52.563160 23775 solver.cpp:243] Iteration 6100, loss = 0.111966
I1002 01:14:52.563191 23775 solver.cpp:259]     Train net output #0: error_blob = 0.111966 (* 1 = 0.111966 loss)
I1002 01:14:52.563199 23775 solver.cpp:590] Iteration 6100, lr = 0.01
I1002 01:14:55.020793 23775 solver.cpp:243] Iteration 6200, loss = 0.114086
I1002 01:14:55.020826 23775 solver.cpp:259]     Train net output #0: error_blob = 0.114086 (* 1 = 0.114086 loss)
I1002 01:14:55.020833 23775 solver.cpp:590] Iteration 6200, lr = 0.01
I1002 01:14:57.497107 23775 solver.cpp:243] Iteration 6300, loss = 0.116443
I1002 01:14:57.497138 23775 solver.cpp:259]     Train net output #0: error_blob = 0.116443 (* 1 = 0.116443 loss)
I1002 01:14:57.497144 23775 solver.cpp:590] Iteration 6300, lr = 0.01
I1002 01:14:58.422999 23775 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 01:14:59.945472 23775 solver.cpp:243] Iteration 6400, loss = 0.114763
I1002 01:14:59.945503 23775 solver.cpp:259]     Train net output #0: error_blob = 0.114763 (* 1 = 0.114763 loss)
I1002 01:14:59.945511 23775 solver.cpp:590] Iteration 6400, lr = 0.01
I1002 01:15:02.428355 23775 solver.cpp:243] Iteration 6500, loss = 0.113642
I1002 01:15:02.428386 23775 solver.cpp:259]     Train net output #0: error_blob = 0.113642 (* 1 = 0.113642 loss)
I1002 01:15:02.428393 23775 solver.cpp:590] Iteration 6500, lr = 0.01
I1002 01:15:04.863292 23775 solver.cpp:243] Iteration 6600, loss = 0.116299
I1002 01:15:04.863323 23775 solver.cpp:259]     Train net output #0: error_blob = 0.116299 (* 1 = 0.116299 loss)
I1002 01:15:04.863328 23775 solver.cpp:590] Iteration 6600, lr = 0.01
I1002 01:15:07.368263 23775 solver.cpp:243] Iteration 6700, loss = 0.115932
I1002 01:15:07.368294 23775 solver.cpp:259]     Train net output #0: error_blob = 0.115932 (* 1 = 0.115932 loss)
I1002 01:15:07.368298 23775 solver.cpp:590] Iteration 6700, lr = 0.01
I1002 01:15:09.856389 23775 solver.cpp:243] Iteration 6800, loss = 0.112903
I1002 01:15:09.856416 23775 solver.cpp:259]     Train net output #0: error_blob = 0.112903 (* 1 = 0.112903 loss)
I1002 01:15:09.856421 23775 solver.cpp:590] Iteration 6800, lr = 0.01
I1002 01:15:12.285348 23775 solver.cpp:243] Iteration 6900, loss = 0.116237
I1002 01:15:12.285378 23775 solver.cpp:259]     Train net output #0: error_blob = 0.116237 (* 1 = 0.116237 loss)
I1002 01:15:12.285382 23775 solver.cpp:590] Iteration 6900, lr = 0.01
I1002 01:15:14.731303 23775 solver.cpp:347] Iteration 7000, Testing net (#0)
I1002 01:15:15.000154 23775 solver.cpp:415]     Test net output #0: error_blob = 0.12374 (* 1 = 0.12374 loss)
I1002 01:15:15.001833 23775 solver.cpp:243] Iteration 7000, loss = 0.116326
I1002 01:15:15.001844 23775 solver.cpp:259]     Train net output #0: error_blob = 0.116326 (* 1 = 0.116326 loss)
I1002 01:15:15.001848 23775 solver.cpp:590] Iteration 7000, lr = 0.01
I1002 01:15:17.466998 23775 solver.cpp:243] Iteration 7100, loss = 0.113423
I1002 01:15:17.467030 23775 solver.cpp:259]     Train net output #0: error_blob = 0.113423 (* 1 = 0.113423 loss)
I1002 01:15:17.467034 23775 solver.cpp:590] Iteration 7100, lr = 0.01
I1002 01:15:19.952880 23775 solver.cpp:243] Iteration 7200, loss = 0.116347
I1002 01:15:19.952919 23775 solver.cpp:259]     Train net output #0: error_blob = 0.116347 (* 1 = 0.116347 loss)
I1002 01:15:19.952925 23775 solver.cpp:590] Iteration 7200, lr = 0.01
I1002 01:15:21.045675 23775 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 01:15:22.440199 23775 solver.cpp:243] Iteration 7300, loss = 0.116371
I1002 01:15:22.440228 23775 solver.cpp:259]     Train net output #0: error_blob = 0.116371 (* 1 = 0.116371 loss)
I1002 01:15:22.440232 23775 solver.cpp:590] Iteration 7300, lr = 0.01
I1002 01:15:24.930678 23775 solver.cpp:243] Iteration 7400, loss = 0.113552
I1002 01:15:24.930711 23775 solver.cpp:259]     Train net output #0: error_blob = 0.113552 (* 1 = 0.113552 loss)
I1002 01:15:24.930716 23775 solver.cpp:590] Iteration 7400, lr = 0.01
I1002 01:15:27.450109 23775 solver.cpp:243] Iteration 7500, loss = 0.115964
I1002 01:15:27.450141 23775 solver.cpp:259]     Train net output #0: error_blob = 0.115964 (* 1 = 0.115964 loss)
I1002 01:15:27.450147 23775 solver.cpp:590] Iteration 7500, lr = 0.01
I1002 01:15:29.938766 23775 solver.cpp:243] Iteration 7600, loss = 0.116705
I1002 01:15:29.938796 23775 solver.cpp:259]     Train net output #0: error_blob = 0.116705 (* 1 = 0.116705 loss)
I1002 01:15:29.938802 23775 solver.cpp:590] Iteration 7600, lr = 0.01
I1002 01:15:32.393649 23775 solver.cpp:243] Iteration 7700, loss = 0.116477
I1002 01:15:32.393681 23775 solver.cpp:259]     Train net output #0: error_blob = 0.116477 (* 1 = 0.116477 loss)
I1002 01:15:32.393687 23775 solver.cpp:590] Iteration 7700, lr = 0.01
I1002 01:15:34.901953 23775 solver.cpp:243] Iteration 7800, loss = 0.112108
I1002 01:15:34.901985 23775 solver.cpp:259]     Train net output #0: error_blob = 0.112108 (* 1 = 0.112108 loss)
I1002 01:15:34.901993 23775 solver.cpp:590] Iteration 7800, lr = 0.01
I1002 01:15:37.379982 23775 solver.cpp:243] Iteration 7900, loss = 0.116336
I1002 01:15:37.380013 23775 solver.cpp:259]     Train net output #0: error_blob = 0.116336 (* 1 = 0.116336 loss)
I1002 01:15:37.380019 23775 solver.cpp:590] Iteration 7900, lr = 0.01
I1002 01:15:39.810655 23775 solver.cpp:347] Iteration 8000, Testing net (#0)
I1002 01:15:40.204579 23775 solver.cpp:415]     Test net output #0: error_blob = 0.120698 (* 1 = 0.120698 loss)
I1002 01:15:40.205210 23775 solver.cpp:243] Iteration 8000, loss = 0.116558
I1002 01:15:40.205222 23775 solver.cpp:259]     Train net output #0: error_blob = 0.116558 (* 1 = 0.116558 loss)
I1002 01:15:40.205229 23775 solver.cpp:590] Iteration 8000, lr = 0.01
I1002 01:15:42.676937 23775 solver.cpp:243] Iteration 8100, loss = 0.110354
I1002 01:15:42.676967 23775 solver.cpp:259]     Train net output #0: error_blob = 0.110354 (* 1 = 0.110354 loss)
I1002 01:15:42.676971 23775 solver.cpp:590] Iteration 8100, lr = 0.01
I1002 01:15:43.911911 23775 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 01:15:45.173490 23775 solver.cpp:243] Iteration 8200, loss = 0.114088
I1002 01:15:45.173595 23775 solver.cpp:259]     Train net output #0: error_blob = 0.114088 (* 1 = 0.114088 loss)
I1002 01:15:45.173601 23775 solver.cpp:590] Iteration 8200, lr = 0.01
I1002 01:15:47.711451 23775 solver.cpp:243] Iteration 8300, loss = 0.115964
I1002 01:15:47.711482 23775 solver.cpp:259]     Train net output #0: error_blob = 0.115964 (* 1 = 0.115964 loss)
I1002 01:15:47.711488 23775 solver.cpp:590] Iteration 8300, lr = 0.01
I1002 01:15:50.230360 23775 solver.cpp:243] Iteration 8400, loss = 0.113729
I1002 01:15:50.230393 23775 solver.cpp:259]     Train net output #0: error_blob = 0.113729 (* 1 = 0.113729 loss)
I1002 01:15:50.230401 23775 solver.cpp:590] Iteration 8400, lr = 0.01
I1002 01:15:52.734985 23775 solver.cpp:243] Iteration 8500, loss = 0.115601
I1002 01:15:52.735018 23775 solver.cpp:259]     Train net output #0: error_blob = 0.115601 (* 1 = 0.115601 loss)
I1002 01:15:52.735024 23775 solver.cpp:590] Iteration 8500, lr = 0.01
I1002 01:15:55.230432 23775 solver.cpp:243] Iteration 8600, loss = 0.115773
I1002 01:15:55.230461 23775 solver.cpp:259]     Train net output #0: error_blob = 0.115773 (* 1 = 0.115773 loss)
I1002 01:15:55.230468 23775 solver.cpp:590] Iteration 8600, lr = 0.01
I1002 01:15:57.732203 23775 solver.cpp:243] Iteration 8700, loss = 0.117178
I1002 01:15:57.732234 23775 solver.cpp:259]     Train net output #0: error_blob = 0.117178 (* 1 = 0.117178 loss)
I1002 01:15:57.732239 23775 solver.cpp:590] Iteration 8700, lr = 0.01
I1002 01:16:00.229686 23775 solver.cpp:243] Iteration 8800, loss = 0.111873
I1002 01:16:00.229715 23775 solver.cpp:259]     Train net output #0: error_blob = 0.111873 (* 1 = 0.111873 loss)
I1002 01:16:00.229720 23775 solver.cpp:590] Iteration 8800, lr = 0.01
I1002 01:16:02.746842 23775 solver.cpp:243] Iteration 8900, loss = 0.117109
I1002 01:16:02.746872 23775 solver.cpp:259]     Train net output #0: error_blob = 0.117109 (* 1 = 0.117109 loss)
I1002 01:16:02.746877 23775 solver.cpp:590] Iteration 8900, lr = 0.01
I1002 01:16:05.213081 23775 solver.cpp:347] Iteration 9000, Testing net (#0)
I1002 01:16:05.516785 23775 solver.cpp:415]     Test net output #0: error_blob = 0.120629 (* 1 = 0.120629 loss)
I1002 01:16:05.517395 23775 solver.cpp:243] Iteration 9000, loss = 0.116007
I1002 01:16:05.517405 23775 solver.cpp:259]     Train net output #0: error_blob = 0.116007 (* 1 = 0.116007 loss)
I1002 01:16:05.517410 23775 solver.cpp:590] Iteration 9000, lr = 0.01
I1002 01:16:06.896277 23775 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 01:16:07.981060 23775 solver.cpp:243] Iteration 9100, loss = 0.111474
I1002 01:16:07.981089 23775 solver.cpp:259]     Train net output #0: error_blob = 0.111474 (* 1 = 0.111474 loss)
I1002 01:16:07.981093 23775 solver.cpp:590] Iteration 9100, lr = 0.01
I1002 01:16:10.459962 23775 solver.cpp:243] Iteration 9200, loss = 0.113652
I1002 01:16:10.459992 23775 solver.cpp:259]     Train net output #0: error_blob = 0.113652 (* 1 = 0.113652 loss)
I1002 01:16:10.459997 23775 solver.cpp:590] Iteration 9200, lr = 0.01
I1002 01:16:12.949380 23775 solver.cpp:243] Iteration 9300, loss = 0.116756
I1002 01:16:12.949410 23775 solver.cpp:259]     Train net output #0: error_blob = 0.116756 (* 1 = 0.116756 loss)
I1002 01:16:12.949414 23775 solver.cpp:590] Iteration 9300, lr = 0.01
I1002 01:16:15.421706 23775 solver.cpp:243] Iteration 9400, loss = 0.11328
I1002 01:16:15.422708 23775 solver.cpp:259]     Train net output #0: error_blob = 0.11328 (* 1 = 0.11328 loss)
I1002 01:16:15.422716 23775 solver.cpp:590] Iteration 9400, lr = 0.01
I1002 01:16:17.897061 23775 solver.cpp:243] Iteration 9500, loss = 0.11337
I1002 01:16:17.897089 23775 solver.cpp:259]     Train net output #0: error_blob = 0.11337 (* 1 = 0.11337 loss)
I1002 01:16:17.897094 23775 solver.cpp:590] Iteration 9500, lr = 0.01
I1002 01:16:20.367420 23775 solver.cpp:243] Iteration 9600, loss = 0.11505
I1002 01:16:20.367449 23775 solver.cpp:259]     Train net output #0: error_blob = 0.11505 (* 1 = 0.11505 loss)
I1002 01:16:20.367455 23775 solver.cpp:590] Iteration 9600, lr = 0.01
I1002 01:16:22.844211 23775 solver.cpp:243] Iteration 9700, loss = 0.117635
I1002 01:16:22.844240 23775 solver.cpp:259]     Train net output #0: error_blob = 0.117635 (* 1 = 0.117635 loss)
I1002 01:16:22.844249 23775 solver.cpp:590] Iteration 9700, lr = 0.01
I1002 01:16:25.302060 23775 solver.cpp:243] Iteration 9800, loss = 0.116355
I1002 01:16:25.302093 23775 solver.cpp:259]     Train net output #0: error_blob = 0.116355 (* 1 = 0.116355 loss)
I1002 01:16:25.302099 23775 solver.cpp:590] Iteration 9800, lr = 0.01
I1002 01:16:27.796286 23775 solver.cpp:243] Iteration 9900, loss = 0.116475
I1002 01:16:27.796319 23775 solver.cpp:259]     Train net output #0: error_blob = 0.116475 (* 1 = 0.116475 loss)
I1002 01:16:27.796325 23775 solver.cpp:590] Iteration 9900, lr = 0.01
I1002 01:16:30.251289 23775 solver.cpp:468] Snapshotting to binary proto file _iter_10000.caffemodel
I1002 01:16:30.252138 23775 solver.cpp:753] Snapshotting solver state to binary proto file _iter_10000.solverstate
I1002 01:16:30.275292 23775 solver.cpp:327] Iteration 10000, loss = 0.116728
I1002 01:16:30.275320 23775 solver.cpp:347] Iteration 10000, Testing net (#0)
I1002 01:16:30.441117 23775 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 01:16:30.545713 23775 solver.cpp:415]     Test net output #0: error_blob = 0.118806 (* 1 = 0.118806 loss)
I1002 01:16:30.545730 23775 solver.cpp:332] Optimization Done.
I1002 01:16:30.545733 23775 caffe.cpp:215] Optimization Done.
I1002 01:16:30.615978 23786 caffe.cpp:184] Using GPUs 0
I1002 01:16:31.173825 23786 solver.cpp:54] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "fixed"
momentum: 0.9
solver_mode: GPU
device_id: 0
net: "model/NNScore/nnscore_model_9.prototxt"
I1002 01:16:31.173856 23786 solver.cpp:97] Creating training net from net file: model/NNScore/nnscore_model_9.prototxt
I1002 01:16:31.174026 23786 net.cpp:339] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_layer
I1002 01:16:31.174072 23786 net.cpp:50] Initializing net from parameters: 
name: "model/NNScore/nnscore_model_9.prototxt"
state {
  phase: TRAIN
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TRAIN
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.9.train"
    batch_size: 20000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1002 01:16:31.174109 23786 layer_factory.hpp:76] Creating layer data_layer
I1002 01:16:31.187302 23786 net.cpp:110] Creating Layer data_layer
I1002 01:16:31.187322 23786 net.cpp:433] data_layer -> data_blob
I1002 01:16:31.187353 23786 net.cpp:433] data_layer -> label_blob
I1002 01:16:31.187935 23790 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.9.train
I1002 01:16:31.873235 23786 data_layer.cpp:45] output data size: 20000,61,1,1
I1002 01:16:31.878233 23786 net.cpp:155] Setting up data_layer
I1002 01:16:31.878265 23786 net.cpp:163] Top shape: 20000 61 1 1 (1220000)
I1002 01:16:31.878268 23786 net.cpp:163] Top shape: 20000 (20000)
I1002 01:16:31.878284 23786 layer_factory.hpp:76] Creating layer hidden_sum_layer
I1002 01:16:31.878296 23786 net.cpp:110] Creating Layer hidden_sum_layer
I1002 01:16:31.878299 23786 net.cpp:477] hidden_sum_layer <- data_blob
I1002 01:16:31.878309 23786 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I1002 01:16:31.878661 23786 net.cpp:155] Setting up hidden_sum_layer
I1002 01:16:31.878667 23786 net.cpp:163] Top shape: 20000 10 (200000)
I1002 01:16:31.878690 23786 layer_factory.hpp:76] Creating layer hidden_act_layer
I1002 01:16:31.878696 23786 net.cpp:110] Creating Layer hidden_act_layer
I1002 01:16:31.878698 23786 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I1002 01:16:31.878701 23786 net.cpp:433] hidden_act_layer -> hidden_act_blob
I1002 01:16:35.091627 23786 net.cpp:155] Setting up hidden_act_layer
I1002 01:16:35.091663 23786 net.cpp:163] Top shape: 20000 10 (200000)
I1002 01:16:35.091670 23786 layer_factory.hpp:76] Creating layer output_sum_layer
I1002 01:16:35.091683 23786 net.cpp:110] Creating Layer output_sum_layer
I1002 01:16:35.091697 23786 net.cpp:477] output_sum_layer <- hidden_act_blob
I1002 01:16:35.091706 23786 net.cpp:433] output_sum_layer -> output_sum_blob
I1002 01:16:35.091825 23786 net.cpp:155] Setting up output_sum_layer
I1002 01:16:35.091830 23786 net.cpp:163] Top shape: 20000 1 (20000)
I1002 01:16:35.091847 23786 layer_factory.hpp:76] Creating layer output_act_layer
I1002 01:16:35.091862 23786 net.cpp:110] Creating Layer output_act_layer
I1002 01:16:35.091864 23786 net.cpp:477] output_act_layer <- output_sum_blob
I1002 01:16:35.091867 23786 net.cpp:433] output_act_layer -> output_act_blob
I1002 01:16:35.091959 23786 net.cpp:155] Setting up output_act_layer
I1002 01:16:35.091989 23786 net.cpp:163] Top shape: 20000 1 (20000)
I1002 01:16:35.091992 23786 layer_factory.hpp:76] Creating layer error_layer
I1002 01:16:35.092007 23786 net.cpp:110] Creating Layer error_layer
I1002 01:16:35.092010 23786 net.cpp:477] error_layer <- output_act_blob
I1002 01:16:35.092012 23786 net.cpp:477] error_layer <- label_blob
I1002 01:16:35.092015 23786 net.cpp:433] error_layer -> error_blob
I1002 01:16:35.092048 23786 net.cpp:155] Setting up error_layer
I1002 01:16:35.092052 23786 net.cpp:163] Top shape: (1)
I1002 01:16:35.092054 23786 net.cpp:168]     with loss weight 1
I1002 01:16:35.092072 23786 net.cpp:236] error_layer needs backward computation.
I1002 01:16:35.092073 23786 net.cpp:236] output_act_layer needs backward computation.
I1002 01:16:35.092075 23786 net.cpp:236] output_sum_layer needs backward computation.
I1002 01:16:35.092077 23786 net.cpp:236] hidden_act_layer needs backward computation.
I1002 01:16:35.092079 23786 net.cpp:236] hidden_sum_layer needs backward computation.
I1002 01:16:35.092082 23786 net.cpp:240] data_layer does not need backward computation.
I1002 01:16:35.092083 23786 net.cpp:283] This network produces output error_blob
I1002 01:16:35.092088 23786 net.cpp:297] Network initialization done.
I1002 01:16:35.092089 23786 net.cpp:298] Memory required for data: 6720004
I1002 01:16:35.092227 23786 solver.cpp:187] Creating test net (#0) specified by net file: model/NNScore/nnscore_model_9.prototxt
I1002 01:16:35.092238 23786 net.cpp:339] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_layer
I1002 01:16:35.092278 23786 net.cpp:50] Initializing net from parameters: 
name: "model/NNScore/nnscore_model_9.prototxt"
state {
  phase: TEST
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TEST
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.9.test"
    batch_size: 2000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1002 01:16:35.092308 23786 layer_factory.hpp:76] Creating layer data_layer
I1002 01:16:35.093495 23786 net.cpp:110] Creating Layer data_layer
I1002 01:16:35.093510 23786 net.cpp:433] data_layer -> data_blob
I1002 01:16:35.093516 23786 net.cpp:433] data_layer -> label_blob
I1002 01:16:35.094074 23792 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.9.test
I1002 01:16:35.094138 23786 data_layer.cpp:45] output data size: 2000,61,1,1
I1002 01:16:35.095523 23786 net.cpp:155] Setting up data_layer
I1002 01:16:35.095536 23786 net.cpp:163] Top shape: 2000 61 1 1 (122000)
I1002 01:16:35.095541 23786 net.cpp:163] Top shape: 2000 (2000)
I1002 01:16:35.095543 23786 layer_factory.hpp:76] Creating layer hidden_sum_layer
I1002 01:16:35.095561 23786 net.cpp:110] Creating Layer hidden_sum_layer
I1002 01:16:35.095564 23786 net.cpp:477] hidden_sum_layer <- data_blob
I1002 01:16:35.095567 23786 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I1002 01:16:35.095695 23786 net.cpp:155] Setting up hidden_sum_layer
I1002 01:16:35.095700 23786 net.cpp:163] Top shape: 2000 10 (20000)
I1002 01:16:35.095706 23786 layer_factory.hpp:76] Creating layer hidden_act_layer
I1002 01:16:35.095721 23786 net.cpp:110] Creating Layer hidden_act_layer
I1002 01:16:35.095723 23786 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I1002 01:16:35.095737 23786 net.cpp:433] hidden_act_layer -> hidden_act_blob
I1002 01:16:35.095964 23786 net.cpp:155] Setting up hidden_act_layer
I1002 01:16:35.095970 23786 net.cpp:163] Top shape: 2000 10 (20000)
I1002 01:16:35.095973 23786 layer_factory.hpp:76] Creating layer output_sum_layer
I1002 01:16:35.095978 23786 net.cpp:110] Creating Layer output_sum_layer
I1002 01:16:35.095989 23786 net.cpp:477] output_sum_layer <- hidden_act_blob
I1002 01:16:35.095993 23786 net.cpp:433] output_sum_layer -> output_sum_blob
I1002 01:16:35.096060 23786 net.cpp:155] Setting up output_sum_layer
I1002 01:16:35.096063 23786 net.cpp:163] Top shape: 2000 1 (2000)
I1002 01:16:35.096068 23786 layer_factory.hpp:76] Creating layer output_act_layer
I1002 01:16:35.096082 23786 net.cpp:110] Creating Layer output_act_layer
I1002 01:16:35.096084 23786 net.cpp:477] output_act_layer <- output_sum_blob
I1002 01:16:35.096087 23786 net.cpp:433] output_act_layer -> output_act_blob
I1002 01:16:35.096143 23786 net.cpp:155] Setting up output_act_layer
I1002 01:16:35.096148 23786 net.cpp:163] Top shape: 2000 1 (2000)
I1002 01:16:35.096150 23786 layer_factory.hpp:76] Creating layer error_layer
I1002 01:16:35.096153 23786 net.cpp:110] Creating Layer error_layer
I1002 01:16:35.096166 23786 net.cpp:477] error_layer <- output_act_blob
I1002 01:16:35.096168 23786 net.cpp:477] error_layer <- label_blob
I1002 01:16:35.096171 23786 net.cpp:433] error_layer -> error_blob
I1002 01:16:35.096189 23786 net.cpp:155] Setting up error_layer
I1002 01:16:35.096192 23786 net.cpp:163] Top shape: (1)
I1002 01:16:35.096194 23786 net.cpp:168]     with loss weight 1
I1002 01:16:35.096210 23786 net.cpp:236] error_layer needs backward computation.
I1002 01:16:35.096212 23786 net.cpp:236] output_act_layer needs backward computation.
I1002 01:16:35.096215 23786 net.cpp:236] output_sum_layer needs backward computation.
I1002 01:16:35.096216 23786 net.cpp:236] hidden_act_layer needs backward computation.
I1002 01:16:35.096228 23786 net.cpp:236] hidden_sum_layer needs backward computation.
I1002 01:16:35.096230 23786 net.cpp:240] data_layer does not need backward computation.
I1002 01:16:35.096232 23786 net.cpp:283] This network produces output error_blob
I1002 01:16:35.096236 23786 net.cpp:297] Network initialization done.
I1002 01:16:35.096238 23786 net.cpp:298] Memory required for data: 672004
I1002 01:16:35.096257 23786 solver.cpp:66] Solver scaffolding done.
I1002 01:16:35.096354 23786 caffe.cpp:212] Starting Optimization
I1002 01:16:35.096359 23786 solver.cpp:294] Solving model/NNScore/nnscore_model_9.prototxt
I1002 01:16:35.096360 23786 solver.cpp:295] Learning Rate Policy: fixed
I1002 01:16:35.096590 23786 solver.cpp:347] Iteration 0, Testing net (#0)
I1002 01:16:35.096704 23786 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 01:16:35.352684 23786 solver.cpp:415]     Test net output #0: error_blob = 0.127259 (* 1 = 0.127259 loss)
I1002 01:16:35.353976 23786 solver.cpp:243] Iteration 0, loss = 0.126121
I1002 01:16:35.353991 23786 solver.cpp:259]     Train net output #0: error_blob = 0.126121 (* 1 = 0.126121 loss)
I1002 01:16:35.353999 23786 solver.cpp:590] Iteration 0, lr = 0.01
I1002 01:16:37.868688 23786 solver.cpp:243] Iteration 100, loss = 0.118799
I1002 01:16:37.868731 23786 solver.cpp:259]     Train net output #0: error_blob = 0.118799 (* 1 = 0.118799 loss)
I1002 01:16:37.868736 23786 solver.cpp:590] Iteration 100, lr = 0.01
I1002 01:16:40.374614 23786 solver.cpp:243] Iteration 200, loss = 0.120459
I1002 01:16:40.374655 23786 solver.cpp:259]     Train net output #0: error_blob = 0.120459 (* 1 = 0.120459 loss)
I1002 01:16:40.374660 23786 solver.cpp:590] Iteration 200, lr = 0.01
I1002 01:16:42.926272 23786 solver.cpp:243] Iteration 300, loss = 0.120398
I1002 01:16:42.926316 23786 solver.cpp:259]     Train net output #0: error_blob = 0.120398 (* 1 = 0.120398 loss)
I1002 01:16:42.926321 23786 solver.cpp:590] Iteration 300, lr = 0.01
I1002 01:16:45.485646 23786 solver.cpp:243] Iteration 400, loss = 0.118161
I1002 01:16:45.485702 23786 solver.cpp:259]     Train net output #0: error_blob = 0.118161 (* 1 = 0.118161 loss)
I1002 01:16:45.485708 23786 solver.cpp:590] Iteration 400, lr = 0.01
I1002 01:16:48.043696 23786 solver.cpp:243] Iteration 500, loss = 0.119436
I1002 01:16:48.043745 23786 solver.cpp:259]     Train net output #0: error_blob = 0.119436 (* 1 = 0.119436 loss)
I1002 01:16:48.043753 23786 solver.cpp:590] Iteration 500, lr = 0.01
I1002 01:16:50.619127 23786 solver.cpp:243] Iteration 600, loss = 0.119714
I1002 01:16:50.619165 23786 solver.cpp:259]     Train net output #0: error_blob = 0.119714 (* 1 = 0.119714 loss)
I1002 01:16:50.619174 23786 solver.cpp:590] Iteration 600, lr = 0.01
I1002 01:16:53.195438 23786 solver.cpp:243] Iteration 700, loss = 0.116564
I1002 01:16:53.195472 23786 solver.cpp:259]     Train net output #0: error_blob = 0.116564 (* 1 = 0.116564 loss)
I1002 01:16:53.195477 23786 solver.cpp:590] Iteration 700, lr = 0.01
I1002 01:16:55.753268 23786 solver.cpp:243] Iteration 800, loss = 0.119004
I1002 01:16:55.753305 23786 solver.cpp:259]     Train net output #0: error_blob = 0.119004 (* 1 = 0.119004 loss)
I1002 01:16:55.753314 23786 solver.cpp:590] Iteration 800, lr = 0.01
I1002 01:16:58.314908 23786 solver.cpp:243] Iteration 900, loss = 0.117134
I1002 01:16:58.314950 23786 solver.cpp:259]     Train net output #0: error_blob = 0.117134 (* 1 = 0.117134 loss)
I1002 01:16:58.314956 23786 solver.cpp:590] Iteration 900, lr = 0.01
I1002 01:16:58.365818 23786 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 01:17:00.840327 23786 solver.cpp:347] Iteration 1000, Testing net (#0)
I1002 01:17:01.177844 23786 solver.cpp:415]     Test net output #0: error_blob = 0.119537 (* 1 = 0.119537 loss)
I1002 01:17:01.178526 23786 solver.cpp:243] Iteration 1000, loss = 0.118234
I1002 01:17:01.178555 23786 solver.cpp:259]     Train net output #0: error_blob = 0.118234 (* 1 = 0.118234 loss)
I1002 01:17:01.178562 23786 solver.cpp:590] Iteration 1000, lr = 0.01
I1002 01:17:03.684197 23786 solver.cpp:243] Iteration 1100, loss = 0.117962
I1002 01:17:03.684247 23786 solver.cpp:259]     Train net output #0: error_blob = 0.117962 (* 1 = 0.117962 loss)
I1002 01:17:03.684254 23786 solver.cpp:590] Iteration 1100, lr = 0.01
I1002 01:17:06.234642 23786 solver.cpp:243] Iteration 1200, loss = 0.118348
I1002 01:17:06.234678 23786 solver.cpp:259]     Train net output #0: error_blob = 0.118348 (* 1 = 0.118348 loss)
I1002 01:17:06.234688 23786 solver.cpp:590] Iteration 1200, lr = 0.01
I1002 01:17:08.806747 23786 solver.cpp:243] Iteration 1300, loss = 0.112897
I1002 01:17:08.806795 23786 solver.cpp:259]     Train net output #0: error_blob = 0.112897 (* 1 = 0.112897 loss)
I1002 01:17:08.806804 23786 solver.cpp:590] Iteration 1300, lr = 0.01
I1002 01:17:11.312887 23786 solver.cpp:243] Iteration 1400, loss = 0.120724
I1002 01:17:11.312930 23786 solver.cpp:259]     Train net output #0: error_blob = 0.120724 (* 1 = 0.120724 loss)
I1002 01:17:11.312937 23786 solver.cpp:590] Iteration 1400, lr = 0.01
I1002 01:17:13.863461 23786 solver.cpp:243] Iteration 1500, loss = 0.119588
I1002 01:17:13.863497 23786 solver.cpp:259]     Train net output #0: error_blob = 0.119588 (* 1 = 0.119588 loss)
I1002 01:17:13.863502 23786 solver.cpp:590] Iteration 1500, lr = 0.01
I1002 01:17:16.396836 23786 solver.cpp:243] Iteration 1600, loss = 0.116533
I1002 01:17:16.396877 23786 solver.cpp:259]     Train net output #0: error_blob = 0.116533 (* 1 = 0.116533 loss)
I1002 01:17:16.396883 23786 solver.cpp:590] Iteration 1600, lr = 0.01
I1002 01:17:18.957062 23786 solver.cpp:243] Iteration 1700, loss = 0.118996
I1002 01:17:18.957113 23786 solver.cpp:259]     Train net output #0: error_blob = 0.118996 (* 1 = 0.118996 loss)
I1002 01:17:18.957123 23786 solver.cpp:590] Iteration 1700, lr = 0.01
I1002 01:17:21.494307 23786 solver.cpp:243] Iteration 1800, loss = 0.121243
I1002 01:17:21.494345 23786 solver.cpp:259]     Train net output #0: error_blob = 0.121243 (* 1 = 0.121243 loss)
I1002 01:17:21.494354 23786 solver.cpp:590] Iteration 1800, lr = 0.01
I1002 01:17:21.700798 23786 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 01:17:24.060160 23786 solver.cpp:243] Iteration 1900, loss = 0.117438
I1002 01:17:24.060204 23786 solver.cpp:259]     Train net output #0: error_blob = 0.117438 (* 1 = 0.117438 loss)
I1002 01:17:24.060211 23786 solver.cpp:590] Iteration 1900, lr = 0.01
I1002 01:17:26.556800 23786 solver.cpp:347] Iteration 2000, Testing net (#0)
I1002 01:17:26.850437 23786 solver.cpp:415]     Test net output #0: error_blob = 0.122835 (* 1 = 0.122835 loss)
I1002 01:17:26.851132 23786 solver.cpp:243] Iteration 2000, loss = 0.118276
I1002 01:17:26.851151 23786 solver.cpp:259]     Train net output #0: error_blob = 0.118276 (* 1 = 0.118276 loss)
I1002 01:17:26.851158 23786 solver.cpp:590] Iteration 2000, lr = 0.01
I1002 01:17:29.326656 23786 solver.cpp:243] Iteration 2100, loss = 0.116196
I1002 01:17:29.326692 23786 solver.cpp:259]     Train net output #0: error_blob = 0.116196 (* 1 = 0.116196 loss)
I1002 01:17:29.326699 23786 solver.cpp:590] Iteration 2100, lr = 0.01
I1002 01:17:31.878746 23786 solver.cpp:243] Iteration 2200, loss = 0.117595
I1002 01:17:31.878875 23786 solver.cpp:259]     Train net output #0: error_blob = 0.117595 (* 1 = 0.117595 loss)
I1002 01:17:31.878882 23786 solver.cpp:590] Iteration 2200, lr = 0.01
I1002 01:17:34.408726 23786 solver.cpp:243] Iteration 2300, loss = 0.117817
I1002 01:17:34.408768 23786 solver.cpp:259]     Train net output #0: error_blob = 0.117817 (* 1 = 0.117817 loss)
I1002 01:17:34.408774 23786 solver.cpp:590] Iteration 2300, lr = 0.01
I1002 01:17:36.965286 23786 solver.cpp:243] Iteration 2400, loss = 0.115201
I1002 01:17:36.965327 23786 solver.cpp:259]     Train net output #0: error_blob = 0.115201 (* 1 = 0.115201 loss)
I1002 01:17:36.965347 23786 solver.cpp:590] Iteration 2400, lr = 0.01
I1002 01:17:39.518913 23786 solver.cpp:243] Iteration 2500, loss = 0.116077
I1002 01:17:39.518964 23786 solver.cpp:259]     Train net output #0: error_blob = 0.116077 (* 1 = 0.116077 loss)
I1002 01:17:39.518972 23786 solver.cpp:590] Iteration 2500, lr = 0.01
I1002 01:17:42.071666 23786 solver.cpp:243] Iteration 2600, loss = 0.119545
I1002 01:17:42.071708 23786 solver.cpp:259]     Train net output #0: error_blob = 0.119545 (* 1 = 0.119545 loss)
I1002 01:17:42.071713 23786 solver.cpp:590] Iteration 2600, lr = 0.01
I1002 01:17:44.626078 23786 solver.cpp:243] Iteration 2700, loss = 0.115845
I1002 01:17:44.626127 23786 solver.cpp:259]     Train net output #0: error_blob = 0.115845 (* 1 = 0.115845 loss)
I1002 01:17:44.626134 23786 solver.cpp:590] Iteration 2700, lr = 0.01
I1002 01:17:44.979014 23786 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 01:17:47.187237 23786 solver.cpp:243] Iteration 2800, loss = 0.119269
I1002 01:17:47.187278 23786 solver.cpp:259]     Train net output #0: error_blob = 0.119269 (* 1 = 0.119269 loss)
I1002 01:17:47.187286 23786 solver.cpp:590] Iteration 2800, lr = 0.01
I1002 01:17:49.768055 23786 solver.cpp:243] Iteration 2900, loss = 0.119208
I1002 01:17:49.768092 23786 solver.cpp:259]     Train net output #0: error_blob = 0.119208 (* 1 = 0.119208 loss)
I1002 01:17:49.768100 23786 solver.cpp:590] Iteration 2900, lr = 0.01
I1002 01:17:52.301610 23786 solver.cpp:347] Iteration 3000, Testing net (#0)
I1002 01:17:52.581224 23786 solver.cpp:415]     Test net output #0: error_blob = 0.122365 (* 1 = 0.122365 loss)
I1002 01:17:52.581889 23786 solver.cpp:243] Iteration 3000, loss = 0.11719
I1002 01:17:52.581933 23786 solver.cpp:259]     Train net output #0: error_blob = 0.11719 (* 1 = 0.11719 loss)
I1002 01:17:52.581943 23786 solver.cpp:590] Iteration 3000, lr = 0.01
I1002 01:17:55.068727 23786 solver.cpp:243] Iteration 3100, loss = 0.115785
I1002 01:17:55.068760 23786 solver.cpp:259]     Train net output #0: error_blob = 0.115785 (* 1 = 0.115785 loss)
I1002 01:17:55.068766 23786 solver.cpp:590] Iteration 3100, lr = 0.01
I1002 01:17:57.570673 23786 solver.cpp:243] Iteration 3200, loss = 0.117786
I1002 01:17:57.570716 23786 solver.cpp:259]     Train net output #0: error_blob = 0.117786 (* 1 = 0.117786 loss)
I1002 01:17:57.570722 23786 solver.cpp:590] Iteration 3200, lr = 0.01
I1002 01:18:00.122776 23786 solver.cpp:243] Iteration 3300, loss = 0.113194
I1002 01:18:00.122815 23786 solver.cpp:259]     Train net output #0: error_blob = 0.113194 (* 1 = 0.113194 loss)
I1002 01:18:00.122835 23786 solver.cpp:590] Iteration 3300, lr = 0.01
I1002 01:18:02.644100 23786 solver.cpp:243] Iteration 3400, loss = 0.117351
I1002 01:18:02.644217 23786 solver.cpp:259]     Train net output #0: error_blob = 0.117351 (* 1 = 0.117351 loss)
I1002 01:18:02.644223 23786 solver.cpp:590] Iteration 3400, lr = 0.01
I1002 01:18:05.161372 23786 solver.cpp:243] Iteration 3500, loss = 0.11711
I1002 01:18:05.161414 23786 solver.cpp:259]     Train net output #0: error_blob = 0.11711 (* 1 = 0.11711 loss)
I1002 01:18:05.161420 23786 solver.cpp:590] Iteration 3500, lr = 0.01
I1002 01:18:07.693146 23786 solver.cpp:243] Iteration 3600, loss = 0.116681
I1002 01:18:07.693191 23786 solver.cpp:259]     Train net output #0: error_blob = 0.116681 (* 1 = 0.116681 loss)
I1002 01:18:07.693197 23786 solver.cpp:590] Iteration 3600, lr = 0.01
I1002 01:18:08.201603 23786 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 01:18:10.254055 23786 solver.cpp:243] Iteration 3700, loss = 0.117425
I1002 01:18:10.254102 23786 solver.cpp:259]     Train net output #0: error_blob = 0.117425 (* 1 = 0.117425 loss)
I1002 01:18:10.254112 23786 solver.cpp:590] Iteration 3700, lr = 0.01
I1002 01:18:12.792292 23786 solver.cpp:243] Iteration 3800, loss = 0.116412
I1002 01:18:12.792325 23786 solver.cpp:259]     Train net output #0: error_blob = 0.116412 (* 1 = 0.116412 loss)
I1002 01:18:12.792331 23786 solver.cpp:590] Iteration 3800, lr = 0.01
I1002 01:18:15.324671 23786 solver.cpp:243] Iteration 3900, loss = 0.114013
I1002 01:18:15.324713 23786 solver.cpp:259]     Train net output #0: error_blob = 0.114013 (* 1 = 0.114013 loss)
I1002 01:18:15.324719 23786 solver.cpp:590] Iteration 3900, lr = 0.01
I1002 01:18:17.863747 23786 solver.cpp:347] Iteration 4000, Testing net (#0)
I1002 01:18:18.139886 23786 solver.cpp:415]     Test net output #0: error_blob = 0.120065 (* 1 = 0.120065 loss)
I1002 01:18:18.140570 23786 solver.cpp:243] Iteration 4000, loss = 0.117981
I1002 01:18:18.140588 23786 solver.cpp:259]     Train net output #0: error_blob = 0.117981 (* 1 = 0.117981 loss)
I1002 01:18:18.140595 23786 solver.cpp:590] Iteration 4000, lr = 0.01
I1002 01:18:20.650997 23786 solver.cpp:243] Iteration 4100, loss = 0.118308
I1002 01:18:20.651036 23786 solver.cpp:259]     Train net output #0: error_blob = 0.118308 (* 1 = 0.118308 loss)
I1002 01:18:20.651042 23786 solver.cpp:590] Iteration 4100, lr = 0.01
I1002 01:18:23.181277 23786 solver.cpp:243] Iteration 4200, loss = 0.115504
I1002 01:18:23.181318 23786 solver.cpp:259]     Train net output #0: error_blob = 0.115504 (* 1 = 0.115504 loss)
I1002 01:18:23.181325 23786 solver.cpp:590] Iteration 4200, lr = 0.01
I1002 01:18:25.749526 23786 solver.cpp:243] Iteration 4300, loss = 0.120156
I1002 01:18:25.749560 23786 solver.cpp:259]     Train net output #0: error_blob = 0.120156 (* 1 = 0.120156 loss)
I1002 01:18:25.749567 23786 solver.cpp:590] Iteration 4300, lr = 0.01
I1002 01:18:28.310225 23786 solver.cpp:243] Iteration 4400, loss = 0.117162
I1002 01:18:28.310276 23786 solver.cpp:259]     Train net output #0: error_blob = 0.117162 (* 1 = 0.117162 loss)
I1002 01:18:28.310286 23786 solver.cpp:590] Iteration 4400, lr = 0.01
I1002 01:18:30.822793 23786 solver.cpp:243] Iteration 4500, loss = 0.112862
I1002 01:18:30.822837 23786 solver.cpp:259]     Train net output #0: error_blob = 0.112862 (* 1 = 0.112862 loss)
I1002 01:18:30.822844 23786 solver.cpp:590] Iteration 4500, lr = 0.01
I1002 01:18:31.483034 23786 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 01:18:33.347358 23786 solver.cpp:243] Iteration 4600, loss = 0.118473
I1002 01:18:33.347476 23786 solver.cpp:259]     Train net output #0: error_blob = 0.118473 (* 1 = 0.118473 loss)
I1002 01:18:33.347486 23786 solver.cpp:590] Iteration 4600, lr = 0.01
I1002 01:18:35.927932 23786 solver.cpp:243] Iteration 4700, loss = 0.124107
I1002 01:18:35.927981 23786 solver.cpp:259]     Train net output #0: error_blob = 0.124107 (* 1 = 0.124107 loss)
I1002 01:18:35.927989 23786 solver.cpp:590] Iteration 4700, lr = 0.01
I1002 01:18:38.475122 23786 solver.cpp:243] Iteration 4800, loss = 0.11776
I1002 01:18:38.475165 23786 solver.cpp:259]     Train net output #0: error_blob = 0.11776 (* 1 = 0.11776 loss)
I1002 01:18:38.475172 23786 solver.cpp:590] Iteration 4800, lr = 0.01
I1002 01:18:40.982225 23786 solver.cpp:243] Iteration 4900, loss = 0.11793
I1002 01:18:40.982275 23786 solver.cpp:259]     Train net output #0: error_blob = 0.11793 (* 1 = 0.11793 loss)
I1002 01:18:40.982285 23786 solver.cpp:590] Iteration 4900, lr = 0.01
I1002 01:18:43.478231 23786 solver.cpp:347] Iteration 5000, Testing net (#0)
I1002 01:18:43.770997 23786 solver.cpp:415]     Test net output #0: error_blob = 0.122966 (* 1 = 0.122966 loss)
I1002 01:18:43.771708 23786 solver.cpp:243] Iteration 5000, loss = 0.11566
I1002 01:18:43.771735 23786 solver.cpp:259]     Train net output #0: error_blob = 0.11566 (* 1 = 0.11566 loss)
I1002 01:18:43.771742 23786 solver.cpp:590] Iteration 5000, lr = 0.01
I1002 01:18:46.286911 23786 solver.cpp:243] Iteration 5100, loss = 0.114573
I1002 01:18:46.286943 23786 solver.cpp:259]     Train net output #0: error_blob = 0.114573 (* 1 = 0.114573 loss)
I1002 01:18:46.286949 23786 solver.cpp:590] Iteration 5100, lr = 0.01
I1002 01:18:48.830627 23786 solver.cpp:243] Iteration 5200, loss = 0.116561
I1002 01:18:48.830658 23786 solver.cpp:259]     Train net output #0: error_blob = 0.116561 (* 1 = 0.116561 loss)
I1002 01:18:48.830664 23786 solver.cpp:590] Iteration 5200, lr = 0.01
I1002 01:18:51.349177 23786 solver.cpp:243] Iteration 5300, loss = 0.114794
I1002 01:18:51.349211 23786 solver.cpp:259]     Train net output #0: error_blob = 0.114794 (* 1 = 0.114794 loss)
I1002 01:18:51.349217 23786 solver.cpp:590] Iteration 5300, lr = 0.01
I1002 01:18:53.880182 23786 solver.cpp:243] Iteration 5400, loss = 0.113985
I1002 01:18:53.880220 23786 solver.cpp:259]     Train net output #0: error_blob = 0.113985 (* 1 = 0.113985 loss)
I1002 01:18:53.880239 23786 solver.cpp:590] Iteration 5400, lr = 0.01
I1002 01:18:54.698906 23786 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 01:18:56.437099 23786 solver.cpp:243] Iteration 5500, loss = 0.117956
I1002 01:18:56.437139 23786 solver.cpp:259]     Train net output #0: error_blob = 0.117956 (* 1 = 0.117956 loss)
I1002 01:18:56.437156 23786 solver.cpp:590] Iteration 5500, lr = 0.01
I1002 01:18:58.989485 23786 solver.cpp:243] Iteration 5600, loss = 0.121324
I1002 01:18:58.989529 23786 solver.cpp:259]     Train net output #0: error_blob = 0.121324 (* 1 = 0.121324 loss)
I1002 01:18:58.989536 23786 solver.cpp:590] Iteration 5600, lr = 0.01
I1002 01:19:01.514983 23786 solver.cpp:243] Iteration 5700, loss = 0.116814
I1002 01:19:01.515017 23786 solver.cpp:259]     Train net output #0: error_blob = 0.116814 (* 1 = 0.116814 loss)
I1002 01:19:01.515023 23786 solver.cpp:590] Iteration 5700, lr = 0.01
I1002 01:19:04.082623 23786 solver.cpp:243] Iteration 5800, loss = 0.115392
I1002 01:19:04.082761 23786 solver.cpp:259]     Train net output #0: error_blob = 0.115392 (* 1 = 0.115392 loss)
I1002 01:19:04.082769 23786 solver.cpp:590] Iteration 5800, lr = 0.01
I1002 01:19:06.615468 23786 solver.cpp:243] Iteration 5900, loss = 0.115813
I1002 01:19:06.615502 23786 solver.cpp:259]     Train net output #0: error_blob = 0.115813 (* 1 = 0.115813 loss)
I1002 01:19:06.615509 23786 solver.cpp:590] Iteration 5900, lr = 0.01
I1002 01:19:09.134340 23786 solver.cpp:347] Iteration 6000, Testing net (#0)
I1002 01:19:09.406349 23786 solver.cpp:415]     Test net output #0: error_blob = 0.122282 (* 1 = 0.122282 loss)
I1002 01:19:09.407014 23786 solver.cpp:243] Iteration 6000, loss = 0.113424
I1002 01:19:09.407058 23786 solver.cpp:259]     Train net output #0: error_blob = 0.113424 (* 1 = 0.113424 loss)
I1002 01:19:09.407073 23786 solver.cpp:590] Iteration 6000, lr = 0.01
I1002 01:19:11.903988 23786 solver.cpp:243] Iteration 6100, loss = 0.12016
I1002 01:19:11.904021 23786 solver.cpp:259]     Train net output #0: error_blob = 0.12016 (* 1 = 0.12016 loss)
I1002 01:19:11.904026 23786 solver.cpp:590] Iteration 6100, lr = 0.01
I1002 01:19:14.434614 23786 solver.cpp:243] Iteration 6200, loss = 0.113403
I1002 01:19:14.434656 23786 solver.cpp:259]     Train net output #0: error_blob = 0.113403 (* 1 = 0.113403 loss)
I1002 01:19:14.434664 23786 solver.cpp:590] Iteration 6200, lr = 0.01
I1002 01:19:16.954993 23786 solver.cpp:243] Iteration 6300, loss = 0.114663
I1002 01:19:16.955034 23786 solver.cpp:259]     Train net output #0: error_blob = 0.114663 (* 1 = 0.114663 loss)
I1002 01:19:16.955042 23786 solver.cpp:590] Iteration 6300, lr = 0.01
I1002 01:19:17.913352 23786 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 01:19:19.487515 23786 solver.cpp:243] Iteration 6400, loss = 0.116589
I1002 01:19:19.487563 23786 solver.cpp:259]     Train net output #0: error_blob = 0.116589 (* 1 = 0.116589 loss)
I1002 01:19:19.487572 23786 solver.cpp:590] Iteration 6400, lr = 0.01
I1002 01:19:22.110518 23786 solver.cpp:243] Iteration 6500, loss = 0.111654
I1002 01:19:22.110570 23786 solver.cpp:259]     Train net output #0: error_blob = 0.111654 (* 1 = 0.111654 loss)
I1002 01:19:22.110579 23786 solver.cpp:590] Iteration 6500, lr = 0.01
I1002 01:19:24.665879 23786 solver.cpp:243] Iteration 6600, loss = 0.11613
I1002 01:19:24.665927 23786 solver.cpp:259]     Train net output #0: error_blob = 0.11613 (* 1 = 0.11613 loss)
I1002 01:19:24.665936 23786 solver.cpp:590] Iteration 6600, lr = 0.01
I1002 01:19:27.213969 23786 solver.cpp:243] Iteration 6700, loss = 0.116298
I1002 01:19:27.214020 23786 solver.cpp:259]     Train net output #0: error_blob = 0.116298 (* 1 = 0.116298 loss)
I1002 01:19:27.214027 23786 solver.cpp:590] Iteration 6700, lr = 0.01
I1002 01:19:29.763754 23786 solver.cpp:243] Iteration 6800, loss = 0.110859
I1002 01:19:29.763797 23786 solver.cpp:259]     Train net output #0: error_blob = 0.110859 (* 1 = 0.110859 loss)
I1002 01:19:29.763804 23786 solver.cpp:590] Iteration 6800, lr = 0.01
I1002 01:19:32.332227 23786 solver.cpp:243] Iteration 6900, loss = 0.113276
I1002 01:19:32.332264 23786 solver.cpp:259]     Train net output #0: error_blob = 0.113276 (* 1 = 0.113276 loss)
I1002 01:19:32.332273 23786 solver.cpp:590] Iteration 6900, lr = 0.01
I1002 01:19:34.861289 23786 solver.cpp:347] Iteration 7000, Testing net (#0)
I1002 01:19:35.144731 23786 solver.cpp:415]     Test net output #0: error_blob = 0.120081 (* 1 = 0.120081 loss)
I1002 01:19:35.145426 23786 solver.cpp:243] Iteration 7000, loss = 0.115872
I1002 01:19:35.145450 23786 solver.cpp:259]     Train net output #0: error_blob = 0.115872 (* 1 = 0.115872 loss)
I1002 01:19:35.145462 23786 solver.cpp:590] Iteration 7000, lr = 0.01
I1002 01:19:37.630777 23786 solver.cpp:243] Iteration 7100, loss = 0.115607
I1002 01:19:37.630817 23786 solver.cpp:259]     Train net output #0: error_blob = 0.115607 (* 1 = 0.115607 loss)
I1002 01:19:37.630827 23786 solver.cpp:590] Iteration 7100, lr = 0.01
I1002 01:19:40.168578 23786 solver.cpp:243] Iteration 7200, loss = 0.118518
I1002 01:19:40.168629 23786 solver.cpp:259]     Train net output #0: error_blob = 0.118518 (* 1 = 0.118518 loss)
I1002 01:19:40.168638 23786 solver.cpp:590] Iteration 7200, lr = 0.01
I1002 01:19:41.293454 23786 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 01:19:42.708581 23786 solver.cpp:243] Iteration 7300, loss = 0.115385
I1002 01:19:42.708631 23786 solver.cpp:259]     Train net output #0: error_blob = 0.115385 (* 1 = 0.115385 loss)
I1002 01:19:42.708641 23786 solver.cpp:590] Iteration 7300, lr = 0.01
I1002 01:19:45.258190 23786 solver.cpp:243] Iteration 7400, loss = 0.120817
I1002 01:19:45.258234 23786 solver.cpp:259]     Train net output #0: error_blob = 0.120817 (* 1 = 0.120817 loss)
I1002 01:19:45.258241 23786 solver.cpp:590] Iteration 7400, lr = 0.01
I1002 01:19:47.807222 23786 solver.cpp:243] Iteration 7500, loss = 0.114757
I1002 01:19:47.807274 23786 solver.cpp:259]     Train net output #0: error_blob = 0.114757 (* 1 = 0.114757 loss)
I1002 01:19:47.807282 23786 solver.cpp:590] Iteration 7500, lr = 0.01
I1002 01:19:50.379539 23786 solver.cpp:243] Iteration 7600, loss = 0.115519
I1002 01:19:50.379570 23786 solver.cpp:259]     Train net output #0: error_blob = 0.115519 (* 1 = 0.115519 loss)
I1002 01:19:50.379577 23786 solver.cpp:590] Iteration 7600, lr = 0.01
I1002 01:19:52.945847 23786 solver.cpp:243] Iteration 7700, loss = 0.111911
I1002 01:19:52.945890 23786 solver.cpp:259]     Train net output #0: error_blob = 0.111911 (* 1 = 0.111911 loss)
I1002 01:19:52.945895 23786 solver.cpp:590] Iteration 7700, lr = 0.01
I1002 01:19:55.487422 23786 solver.cpp:243] Iteration 7800, loss = 0.115631
I1002 01:19:55.487455 23786 solver.cpp:259]     Train net output #0: error_blob = 0.115631 (* 1 = 0.115631 loss)
I1002 01:19:55.487463 23786 solver.cpp:590] Iteration 7800, lr = 0.01
I1002 01:19:58.051661 23786 solver.cpp:243] Iteration 7900, loss = 0.115716
I1002 01:19:58.051707 23786 solver.cpp:259]     Train net output #0: error_blob = 0.115716 (* 1 = 0.115716 loss)
I1002 01:19:58.051713 23786 solver.cpp:590] Iteration 7900, lr = 0.01
I1002 01:20:00.564410 23786 solver.cpp:347] Iteration 8000, Testing net (#0)
I1002 01:20:00.837210 23786 solver.cpp:415]     Test net output #0: error_blob = 0.120584 (* 1 = 0.120584 loss)
I1002 01:20:00.837818 23786 solver.cpp:243] Iteration 8000, loss = 0.111509
I1002 01:20:00.837831 23786 solver.cpp:259]     Train net output #0: error_blob = 0.111509 (* 1 = 0.111509 loss)
I1002 01:20:00.837836 23786 solver.cpp:590] Iteration 8000, lr = 0.01
I1002 01:20:03.385910 23786 solver.cpp:243] Iteration 8100, loss = 0.115975
I1002 01:20:03.385959 23786 solver.cpp:259]     Train net output #0: error_blob = 0.115975 (* 1 = 0.115975 loss)
I1002 01:20:03.385968 23786 solver.cpp:590] Iteration 8100, lr = 0.01
I1002 01:20:04.627226 23786 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 01:20:05.867421 23786 solver.cpp:243] Iteration 8200, loss = 0.115108
I1002 01:20:05.867565 23786 solver.cpp:259]     Train net output #0: error_blob = 0.115108 (* 1 = 0.115108 loss)
I1002 01:20:05.867573 23786 solver.cpp:590] Iteration 8200, lr = 0.01
I1002 01:20:08.386409 23786 solver.cpp:243] Iteration 8300, loss = 0.112041
I1002 01:20:08.386453 23786 solver.cpp:259]     Train net output #0: error_blob = 0.112041 (* 1 = 0.112041 loss)
I1002 01:20:08.386459 23786 solver.cpp:590] Iteration 8300, lr = 0.01
I1002 01:20:10.912164 23786 solver.cpp:243] Iteration 8400, loss = 0.115493
I1002 01:20:10.912207 23786 solver.cpp:259]     Train net output #0: error_blob = 0.115493 (* 1 = 0.115493 loss)
I1002 01:20:10.912216 23786 solver.cpp:590] Iteration 8400, lr = 0.01
I1002 01:20:13.471998 23786 solver.cpp:243] Iteration 8500, loss = 0.116714
I1002 01:20:13.472033 23786 solver.cpp:259]     Train net output #0: error_blob = 0.116714 (* 1 = 0.116714 loss)
I1002 01:20:13.472040 23786 solver.cpp:590] Iteration 8500, lr = 0.01
I1002 01:20:16.022894 23786 solver.cpp:243] Iteration 8600, loss = 0.117233
I1002 01:20:16.022928 23786 solver.cpp:259]     Train net output #0: error_blob = 0.117233 (* 1 = 0.117233 loss)
I1002 01:20:16.022933 23786 solver.cpp:590] Iteration 8600, lr = 0.01
I1002 01:20:18.576992 23786 solver.cpp:243] Iteration 8700, loss = 0.116476
I1002 01:20:18.577033 23786 solver.cpp:259]     Train net output #0: error_blob = 0.116476 (* 1 = 0.116476 loss)
I1002 01:20:18.577038 23786 solver.cpp:590] Iteration 8700, lr = 0.01
I1002 01:20:21.104413 23786 solver.cpp:243] Iteration 8800, loss = 0.114035
I1002 01:20:21.104454 23786 solver.cpp:259]     Train net output #0: error_blob = 0.114035 (* 1 = 0.114035 loss)
I1002 01:20:21.104465 23786 solver.cpp:590] Iteration 8800, lr = 0.01
I1002 01:20:23.684353 23786 solver.cpp:243] Iteration 8900, loss = 0.118266
I1002 01:20:23.684394 23786 solver.cpp:259]     Train net output #0: error_blob = 0.118266 (* 1 = 0.118266 loss)
I1002 01:20:23.684402 23786 solver.cpp:590] Iteration 8900, lr = 0.01
I1002 01:20:26.239778 23786 solver.cpp:347] Iteration 9000, Testing net (#0)
I1002 01:20:26.510905 23786 solver.cpp:415]     Test net output #0: error_blob = 0.120847 (* 1 = 0.120847 loss)
I1002 01:20:26.511560 23786 solver.cpp:243] Iteration 9000, loss = 0.11456
I1002 01:20:26.511607 23786 solver.cpp:259]     Train net output #0: error_blob = 0.11456 (* 1 = 0.11456 loss)
I1002 01:20:26.511629 23786 solver.cpp:590] Iteration 9000, lr = 0.01
I1002 01:20:27.885514 23786 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 01:20:28.991091 23786 solver.cpp:243] Iteration 9100, loss = 0.112494
I1002 01:20:28.991122 23786 solver.cpp:259]     Train net output #0: error_blob = 0.112494 (* 1 = 0.112494 loss)
I1002 01:20:28.991128 23786 solver.cpp:590] Iteration 9100, lr = 0.01
I1002 01:20:31.569383 23786 solver.cpp:243] Iteration 9200, loss = 0.114031
I1002 01:20:31.569434 23786 solver.cpp:259]     Train net output #0: error_blob = 0.114031 (* 1 = 0.114031 loss)
I1002 01:20:31.569442 23786 solver.cpp:590] Iteration 9200, lr = 0.01
I1002 01:20:34.144875 23786 solver.cpp:243] Iteration 9300, loss = 0.116024
I1002 01:20:34.144924 23786 solver.cpp:259]     Train net output #0: error_blob = 0.116024 (* 1 = 0.116024 loss)
I1002 01:20:34.144933 23786 solver.cpp:590] Iteration 9300, lr = 0.01
I1002 01:20:36.709585 23786 solver.cpp:243] Iteration 9400, loss = 0.112276
I1002 01:20:36.709677 23786 solver.cpp:259]     Train net output #0: error_blob = 0.112276 (* 1 = 0.112276 loss)
I1002 01:20:36.709684 23786 solver.cpp:590] Iteration 9400, lr = 0.01
I1002 01:20:39.265244 23786 solver.cpp:243] Iteration 9500, loss = 0.112389
I1002 01:20:39.265277 23786 solver.cpp:259]     Train net output #0: error_blob = 0.112389 (* 1 = 0.112389 loss)
I1002 01:20:39.265283 23786 solver.cpp:590] Iteration 9500, lr = 0.01
I1002 01:20:41.828321 23786 solver.cpp:243] Iteration 9600, loss = 0.115872
I1002 01:20:41.828353 23786 solver.cpp:259]     Train net output #0: error_blob = 0.115872 (* 1 = 0.115872 loss)
I1002 01:20:41.828358 23786 solver.cpp:590] Iteration 9600, lr = 0.01
I1002 01:20:44.382055 23786 solver.cpp:243] Iteration 9700, loss = 0.1102
I1002 01:20:44.382104 23786 solver.cpp:259]     Train net output #0: error_blob = 0.1102 (* 1 = 0.1102 loss)
I1002 01:20:44.382112 23786 solver.cpp:590] Iteration 9700, lr = 0.01
I1002 01:20:46.951459 23786 solver.cpp:243] Iteration 9800, loss = 0.113163
I1002 01:20:46.951504 23786 solver.cpp:259]     Train net output #0: error_blob = 0.113163 (* 1 = 0.113163 loss)
I1002 01:20:46.951510 23786 solver.cpp:590] Iteration 9800, lr = 0.01
I1002 01:20:49.491343 23786 solver.cpp:243] Iteration 9900, loss = 0.115885
I1002 01:20:49.491374 23786 solver.cpp:259]     Train net output #0: error_blob = 0.115885 (* 1 = 0.115885 loss)
I1002 01:20:49.491379 23786 solver.cpp:590] Iteration 9900, lr = 0.01
I1002 01:20:51.991350 23786 solver.cpp:468] Snapshotting to binary proto file _iter_10000.caffemodel
I1002 01:20:51.992580 23786 solver.cpp:753] Snapshotting solver state to binary proto file _iter_10000.solverstate
I1002 01:20:52.016314 23786 solver.cpp:327] Iteration 10000, loss = 0.109854
I1002 01:20:52.016341 23786 solver.cpp:347] Iteration 10000, Testing net (#0)
I1002 01:20:52.186521 23786 blocking_queue.cpp:50] Data layer prefetch queue empty
I1002 01:20:52.294584 23786 solver.cpp:415]     Test net output #0: error_blob = 0.120601 (* 1 = 0.120601 loss)
I1002 01:20:52.294605 23786 solver.cpp:332] Optimization Done.
I1002 01:20:52.294610 23786 caffe.cpp:215] Optimization Done.
I1002 01:20:52.361964 23798 caffe.cpp:184] Using GPUs 0
I1002 01:20:52.921849 23798 solver.cpp:54] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "fixed"
momentum: 0.9
solver_mode: GPU
device_id: 0
net: "model/NNScore/nnscore_model_full.prototxt"
I1002 01:20:52.921880 23798 solver.cpp:97] Creating training net from net file: model/NNScore/nnscore_model_full.prototxt
I1002 01:20:52.922050 23798 net.cpp:339] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_layer
I1002 01:20:52.922094 23798 net.cpp:50] Initializing net from parameters: 
name: "model/NNScore/nnscore_model_full.prototxt"
state {
  phase: TRAIN
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TRAIN
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.full"
    batch_size: 20000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1002 01:20:52.922132 23798 layer_factory.hpp:76] Creating layer data_layer
I1002 01:20:52.935407 23798 net.cpp:110] Creating Layer data_layer
I1002 01:20:52.935439 23798 net.cpp:433] data_layer -> data_blob
I1002 01:20:52.935472 23798 net.cpp:433] data_layer -> label_blob
I1002 01:20:52.936086 23802 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.full
I1002 01:20:53.621458 23798 data_layer.cpp:45] output data size: 20000,61,1,1
I1002 01:20:53.626420 23798 net.cpp:155] Setting up data_layer
I1002 01:20:53.626461 23798 net.cpp:163] Top shape: 20000 61 1 1 (1220000)
I1002 01:20:53.626466 23798 net.cpp:163] Top shape: 20000 (20000)
I1002 01:20:53.626482 23798 layer_factory.hpp:76] Creating layer hidden_sum_layer
I1002 01:20:53.626494 23798 net.cpp:110] Creating Layer hidden_sum_layer
I1002 01:20:53.626497 23798 net.cpp:477] hidden_sum_layer <- data_blob
I1002 01:20:53.626507 23798 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I1002 01:20:53.626864 23798 net.cpp:155] Setting up hidden_sum_layer
I1002 01:20:53.626873 23798 net.cpp:163] Top shape: 20000 10 (200000)
I1002 01:20:53.626893 23798 layer_factory.hpp:76] Creating layer hidden_act_layer
I1002 01:20:53.626911 23798 net.cpp:110] Creating Layer hidden_act_layer
I1002 01:20:53.626914 23798 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I1002 01:20:53.626916 23798 net.cpp:433] hidden_act_layer -> hidden_act_blob
I1002 01:20:56.867233 23798 net.cpp:155] Setting up hidden_act_layer
I1002 01:20:56.867256 23798 net.cpp:163] Top shape: 20000 10 (200000)
I1002 01:20:56.867260 23798 layer_factory.hpp:76] Creating layer output_sum_layer
I1002 01:20:56.867271 23798 net.cpp:110] Creating Layer output_sum_layer
I1002 01:20:56.867274 23798 net.cpp:477] output_sum_layer <- hidden_act_blob
I1002 01:20:56.867280 23798 net.cpp:433] output_sum_layer -> output_sum_blob
I1002 01:20:56.867378 23798 net.cpp:155] Setting up output_sum_layer
I1002 01:20:56.867383 23798 net.cpp:163] Top shape: 20000 1 (20000)
I1002 01:20:56.867408 23798 layer_factory.hpp:76] Creating layer output_act_layer
I1002 01:20:56.867413 23798 net.cpp:110] Creating Layer output_act_layer
I1002 01:20:56.867414 23798 net.cpp:477] output_act_layer <- output_sum_blob
I1002 01:20:56.867426 23798 net.cpp:433] output_act_layer -> output_act_blob
I1002 01:20:56.867498 23798 net.cpp:155] Setting up output_act_layer
I1002 01:20:56.867516 23798 net.cpp:163] Top shape: 20000 1 (20000)
I1002 01:20:56.867527 23798 layer_factory.hpp:76] Creating layer error_layer
I1002 01:20:56.867532 23798 net.cpp:110] Creating Layer error_layer
I1002 01:20:56.867534 23798 net.cpp:477] error_layer <- output_act_blob
I1002 01:20:56.867545 23798 net.cpp:477] error_layer <- label_blob
I1002 01:20:56.867549 23798 net.cpp:433] error_layer -> error_blob
I1002 01:20:56.867581 23798 net.cpp:155] Setting up error_layer
I1002 01:20:56.867585 23798 net.cpp:163] Top shape: (1)
I1002 01:20:56.867586 23798 net.cpp:168]     with loss weight 1
I1002 01:20:56.867621 23798 net.cpp:236] error_layer needs backward computation.
I1002 01:20:56.867624 23798 net.cpp:236] output_act_layer needs backward computation.
I1002 01:20:56.867635 23798 net.cpp:236] output_sum_layer needs backward computation.
I1002 01:20:56.867636 23798 net.cpp:236] hidden_act_layer needs backward computation.
I1002 01:20:56.867638 23798 net.cpp:236] hidden_sum_layer needs backward computation.
I1002 01:20:56.867640 23798 net.cpp:240] data_layer does not need backward computation.
I1002 01:20:56.867642 23798 net.cpp:283] This network produces output error_blob
I1002 01:20:56.867657 23798 net.cpp:297] Network initialization done.
I1002 01:20:56.867658 23798 net.cpp:298] Memory required for data: 6720004
I1002 01:20:56.867785 23798 solver.cpp:187] Creating test net (#0) specified by net file: model/NNScore/nnscore_model_full.prototxt
I1002 01:20:56.867807 23798 net.cpp:339] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_layer
I1002 01:20:56.867846 23798 net.cpp:50] Initializing net from parameters: 
name: "model/NNScore/nnscore_model_full.prototxt"
state {
  phase: TEST
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TEST
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.full"
    batch_size: 2000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1002 01:20:56.867876 23798 layer_factory.hpp:76] Creating layer data_layer
I1002 01:20:56.869139 23798 net.cpp:110] Creating Layer data_layer
I1002 01:20:56.869143 23798 net.cpp:433] data_layer -> data_blob
I1002 01:20:56.869158 23798 net.cpp:433] data_layer -> label_blob
