I1005 20:37:09.289739 16110 caffe.cpp:184] Using GPUs 0
I1005 20:37:09.865824 16110 solver.cpp:54] Initializing solver from parameters: 
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "fixed"
momentum: 0.9
solver_mode: GPU
device_id: 0
net: "large_batch/model0_full.prototxt"
I1005 20:37:09.865855 16110 solver.cpp:97] Creating training net from net file: large_batch/model0_full.prototxt
I1005 20:37:09.866078 16110 net.cpp:50] Initializing net from parameters: 
name: "large_batch/model0_full.prototxt"
state {
  phase: TRAIN
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.full"
    batch_size: 20000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1005 20:37:09.866128 16110 layer_factory.hpp:76] Creating layer data_layer
I1005 20:37:09.879513 16110 net.cpp:110] Creating Layer data_layer
I1005 20:37:09.879545 16110 net.cpp:433] data_layer -> data_blob
I1005 20:37:09.879566 16110 net.cpp:433] data_layer -> label_blob
I1005 20:37:09.880179 16115 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.full
I1005 20:37:10.566716 16110 data_layer.cpp:45] output data size: 20000,61,1,1
I1005 20:37:10.571645 16110 net.cpp:155] Setting up data_layer
I1005 20:37:10.571686 16110 net.cpp:163] Top shape: 20000 61 1 1 (1220000)
I1005 20:37:10.571689 16110 net.cpp:163] Top shape: 20000 (20000)
I1005 20:37:10.571694 16110 layer_factory.hpp:76] Creating layer hidden_sum_layer
I1005 20:37:10.571705 16110 net.cpp:110] Creating Layer hidden_sum_layer
I1005 20:37:10.571722 16110 net.cpp:477] hidden_sum_layer <- data_blob
I1005 20:37:10.571743 16110 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I1005 20:37:10.572113 16110 net.cpp:155] Setting up hidden_sum_layer
I1005 20:37:10.572119 16110 net.cpp:163] Top shape: 20000 10 (200000)
I1005 20:37:10.572141 16110 layer_factory.hpp:76] Creating layer hidden_act_layer
I1005 20:37:10.572162 16110 net.cpp:110] Creating Layer hidden_act_layer
I1005 20:37:10.572177 16110 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I1005 20:37:10.572181 16110 net.cpp:433] hidden_act_layer -> hidden_act_blob
I1005 20:37:13.791424 16110 net.cpp:155] Setting up hidden_act_layer
I1005 20:37:13.791446 16110 net.cpp:163] Top shape: 20000 10 (200000)
I1005 20:37:13.791450 16110 layer_factory.hpp:76] Creating layer output_sum_layer
I1005 20:37:13.791460 16110 net.cpp:110] Creating Layer output_sum_layer
I1005 20:37:13.791463 16110 net.cpp:477] output_sum_layer <- hidden_act_blob
I1005 20:37:13.791468 16110 net.cpp:433] output_sum_layer -> output_sum_blob
I1005 20:37:13.791565 16110 net.cpp:155] Setting up output_sum_layer
I1005 20:37:13.791569 16110 net.cpp:163] Top shape: 20000 1 (20000)
I1005 20:37:13.791576 16110 layer_factory.hpp:76] Creating layer output_act_layer
I1005 20:37:13.791599 16110 net.cpp:110] Creating Layer output_act_layer
I1005 20:37:13.791601 16110 net.cpp:477] output_act_layer <- output_sum_blob
I1005 20:37:13.791604 16110 net.cpp:433] output_act_layer -> output_act_blob
I1005 20:37:13.791666 16110 net.cpp:155] Setting up output_act_layer
I1005 20:37:13.791669 16110 net.cpp:163] Top shape: 20000 1 (20000)
I1005 20:37:13.791671 16110 layer_factory.hpp:76] Creating layer error_layer
I1005 20:37:13.791676 16110 net.cpp:110] Creating Layer error_layer
I1005 20:37:13.791702 16110 net.cpp:477] error_layer <- output_act_blob
I1005 20:37:13.791705 16110 net.cpp:477] error_layer <- label_blob
I1005 20:37:13.791709 16110 net.cpp:433] error_layer -> error_blob
I1005 20:37:13.791733 16110 net.cpp:155] Setting up error_layer
I1005 20:37:13.791749 16110 net.cpp:163] Top shape: (1)
I1005 20:37:13.791750 16110 net.cpp:168]     with loss weight 1
I1005 20:37:13.791775 16110 net.cpp:236] error_layer needs backward computation.
I1005 20:37:13.791777 16110 net.cpp:236] output_act_layer needs backward computation.
I1005 20:37:13.791779 16110 net.cpp:236] output_sum_layer needs backward computation.
I1005 20:37:13.791780 16110 net.cpp:236] hidden_act_layer needs backward computation.
I1005 20:37:13.791782 16110 net.cpp:236] hidden_sum_layer needs backward computation.
I1005 20:37:13.791785 16110 net.cpp:240] data_layer does not need backward computation.
I1005 20:37:13.791786 16110 net.cpp:283] This network produces output error_blob
I1005 20:37:13.791791 16110 net.cpp:297] Network initialization done.
I1005 20:37:13.791792 16110 net.cpp:298] Memory required for data: 6720004
I1005 20:37:13.791812 16110 solver.cpp:66] Solver scaffolding done.
I1005 20:37:13.791923 16110 caffe.cpp:212] Starting Optimization
I1005 20:37:13.791928 16110 solver.cpp:294] Solving large_batch/model0_full.prototxt
I1005 20:37:13.791929 16110 solver.cpp:295] Learning Rate Policy: fixed
I1005 20:37:13.793280 16110 solver.cpp:243] Iteration 0, loss = 0.12406
I1005 20:37:13.793304 16110 solver.cpp:259]     Train net output #0: error_blob = 0.12406 (* 1 = 0.12406 loss)
I1005 20:37:13.793310 16110 solver.cpp:590] Iteration 0, lr = 0.01
I1005 20:37:13.795513 16110 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:37:16.246665 16110 solver.cpp:243] Iteration 100, loss = 0.117638
I1005 20:37:16.246706 16110 solver.cpp:259]     Train net output #0: error_blob = 0.117638 (* 1 = 0.117638 loss)
I1005 20:37:16.246711 16110 solver.cpp:590] Iteration 100, lr = 0.01
I1005 20:37:18.727488 16110 solver.cpp:243] Iteration 200, loss = 0.115311
I1005 20:37:18.727527 16110 solver.cpp:259]     Train net output #0: error_blob = 0.115311 (* 1 = 0.115311 loss)
I1005 20:37:18.727531 16110 solver.cpp:590] Iteration 200, lr = 0.01
I1005 20:37:21.187608 16110 solver.cpp:243] Iteration 300, loss = 0.11346
I1005 20:37:21.187650 16110 solver.cpp:259]     Train net output #0: error_blob = 0.11346 (* 1 = 0.11346 loss)
I1005 20:37:21.187655 16110 solver.cpp:590] Iteration 300, lr = 0.01
I1005 20:37:23.633838 16110 solver.cpp:243] Iteration 400, loss = 0.110884
I1005 20:37:23.633877 16110 solver.cpp:259]     Train net output #0: error_blob = 0.110884 (* 1 = 0.110884 loss)
I1005 20:37:23.633883 16110 solver.cpp:590] Iteration 400, lr = 0.01
I1005 20:37:26.092922 16110 solver.cpp:243] Iteration 500, loss = 0.109134
I1005 20:37:26.092963 16110 solver.cpp:259]     Train net output #0: error_blob = 0.109134 (* 1 = 0.109134 loss)
I1005 20:37:26.092968 16110 solver.cpp:590] Iteration 500, lr = 0.01
I1005 20:37:28.574034 16110 solver.cpp:243] Iteration 600, loss = 0.107659
I1005 20:37:28.574074 16110 solver.cpp:259]     Train net output #0: error_blob = 0.107659 (* 1 = 0.107659 loss)
I1005 20:37:28.574079 16110 solver.cpp:590] Iteration 600, lr = 0.01
I1005 20:37:31.030669 16110 solver.cpp:243] Iteration 700, loss = 0.1059
I1005 20:37:31.030715 16110 solver.cpp:259]     Train net output #0: error_blob = 0.1059 (* 1 = 0.1059 loss)
I1005 20:37:31.030721 16110 solver.cpp:590] Iteration 700, lr = 0.01
I1005 20:37:33.531195 16110 solver.cpp:243] Iteration 800, loss = 0.105452
I1005 20:37:33.531234 16110 solver.cpp:259]     Train net output #0: error_blob = 0.105452 (* 1 = 0.105452 loss)
I1005 20:37:33.531237 16110 solver.cpp:590] Iteration 800, lr = 0.01
I1005 20:37:35.987390 16110 solver.cpp:243] Iteration 900, loss = 0.104645
I1005 20:37:35.987437 16110 solver.cpp:259]     Train net output #0: error_blob = 0.104645 (* 1 = 0.104645 loss)
I1005 20:37:35.987442 16110 solver.cpp:590] Iteration 900, lr = 0.01
I1005 20:37:38.483932 16110 solver.cpp:243] Iteration 1000, loss = 0.104904
I1005 20:37:38.484006 16110 solver.cpp:259]     Train net output #0: error_blob = 0.104904 (* 1 = 0.104904 loss)
I1005 20:37:38.484014 16110 solver.cpp:590] Iteration 1000, lr = 0.01
I1005 20:37:38.533872 16110 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:37:40.968909 16110 solver.cpp:243] Iteration 1100, loss = 0.106359
I1005 20:37:40.968976 16110 solver.cpp:259]     Train net output #0: error_blob = 0.106359 (* 1 = 0.106359 loss)
I1005 20:37:40.968981 16110 solver.cpp:590] Iteration 1100, lr = 0.01
I1005 20:37:43.442927 16110 solver.cpp:243] Iteration 1200, loss = 0.107142
I1005 20:37:43.442971 16110 solver.cpp:259]     Train net output #0: error_blob = 0.107142 (* 1 = 0.107142 loss)
I1005 20:37:43.442978 16110 solver.cpp:590] Iteration 1200, lr = 0.01
I1005 20:37:45.937784 16110 solver.cpp:243] Iteration 1300, loss = 0.106905
I1005 20:37:45.937831 16110 solver.cpp:259]     Train net output #0: error_blob = 0.106905 (* 1 = 0.106905 loss)
I1005 20:37:45.937839 16110 solver.cpp:590] Iteration 1300, lr = 0.01
I1005 20:37:48.418104 16110 solver.cpp:243] Iteration 1400, loss = 0.106535
I1005 20:37:48.418143 16110 solver.cpp:259]     Train net output #0: error_blob = 0.106535 (* 1 = 0.106535 loss)
I1005 20:37:48.418149 16110 solver.cpp:590] Iteration 1400, lr = 0.01
I1005 20:37:50.903292 16110 solver.cpp:243] Iteration 1500, loss = 0.106823
I1005 20:37:50.903340 16110 solver.cpp:259]     Train net output #0: error_blob = 0.106823 (* 1 = 0.106823 loss)
I1005 20:37:50.903347 16110 solver.cpp:590] Iteration 1500, lr = 0.01
I1005 20:37:53.402988 16110 solver.cpp:243] Iteration 1600, loss = 0.104418
I1005 20:37:53.403018 16110 solver.cpp:259]     Train net output #0: error_blob = 0.104418 (* 1 = 0.104418 loss)
I1005 20:37:53.403023 16110 solver.cpp:590] Iteration 1600, lr = 0.01
I1005 20:37:55.888913 16110 solver.cpp:243] Iteration 1700, loss = 0.102748
I1005 20:37:55.888953 16110 solver.cpp:259]     Train net output #0: error_blob = 0.102748 (* 1 = 0.102748 loss)
I1005 20:37:55.888960 16110 solver.cpp:590] Iteration 1700, lr = 0.01
I1005 20:37:58.366364 16110 solver.cpp:243] Iteration 1800, loss = 0.101273
I1005 20:37:58.366391 16110 solver.cpp:259]     Train net output #0: error_blob = 0.101273 (* 1 = 0.101273 loss)
I1005 20:37:58.366396 16110 solver.cpp:590] Iteration 1800, lr = 0.01
I1005 20:38:00.808647 16110 solver.cpp:243] Iteration 1900, loss = 0.0996822
I1005 20:38:00.808686 16110 solver.cpp:259]     Train net output #0: error_blob = 0.0996822 (* 1 = 0.0996822 loss)
I1005 20:38:00.808692 16110 solver.cpp:590] Iteration 1900, lr = 0.01
I1005 20:38:03.291224 16110 solver.cpp:243] Iteration 2000, loss = 0.102084
I1005 20:38:03.291271 16110 solver.cpp:259]     Train net output #0: error_blob = 0.102084 (* 1 = 0.102084 loss)
I1005 20:38:03.291278 16110 solver.cpp:590] Iteration 2000, lr = 0.01
I1005 20:38:03.341017 16110 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:38:05.768198 16110 solver.cpp:243] Iteration 2100, loss = 0.10025
I1005 20:38:05.768229 16110 solver.cpp:259]     Train net output #0: error_blob = 0.10025 (* 1 = 0.10025 loss)
I1005 20:38:05.768234 16110 solver.cpp:590] Iteration 2100, lr = 0.01
I1005 20:38:08.256222 16110 solver.cpp:243] Iteration 2200, loss = 0.100743
I1005 20:38:08.256258 16110 solver.cpp:259]     Train net output #0: error_blob = 0.100743 (* 1 = 0.100743 loss)
I1005 20:38:08.256265 16110 solver.cpp:590] Iteration 2200, lr = 0.01
I1005 20:38:10.760735 16110 solver.cpp:243] Iteration 2300, loss = 0.102558
I1005 20:38:10.760772 16110 solver.cpp:259]     Train net output #0: error_blob = 0.102558 (* 1 = 0.102558 loss)
I1005 20:38:10.760777 16110 solver.cpp:590] Iteration 2300, lr = 0.01
I1005 20:38:13.220176 16110 solver.cpp:243] Iteration 2400, loss = 0.104658
I1005 20:38:13.220266 16110 solver.cpp:259]     Train net output #0: error_blob = 0.104658 (* 1 = 0.104658 loss)
I1005 20:38:13.220271 16110 solver.cpp:590] Iteration 2400, lr = 0.01
I1005 20:38:15.690435 16110 solver.cpp:243] Iteration 2500, loss = 0.104325
I1005 20:38:15.690474 16110 solver.cpp:259]     Train net output #0: error_blob = 0.104325 (* 1 = 0.104325 loss)
I1005 20:38:15.690479 16110 solver.cpp:590] Iteration 2500, lr = 0.01
I1005 20:38:18.136286 16110 solver.cpp:243] Iteration 2600, loss = 0.104162
I1005 20:38:18.136325 16110 solver.cpp:259]     Train net output #0: error_blob = 0.104162 (* 1 = 0.104162 loss)
I1005 20:38:18.136332 16110 solver.cpp:590] Iteration 2600, lr = 0.01
I1005 20:38:20.597113 16110 solver.cpp:243] Iteration 2700, loss = 0.104559
I1005 20:38:20.597152 16110 solver.cpp:259]     Train net output #0: error_blob = 0.104559 (* 1 = 0.104559 loss)
I1005 20:38:20.597157 16110 solver.cpp:590] Iteration 2700, lr = 0.01
I1005 20:38:23.080579 16110 solver.cpp:243] Iteration 2800, loss = 0.102676
I1005 20:38:23.080617 16110 solver.cpp:259]     Train net output #0: error_blob = 0.102676 (* 1 = 0.102676 loss)
I1005 20:38:23.080622 16110 solver.cpp:590] Iteration 2800, lr = 0.01
I1005 20:38:25.543758 16110 solver.cpp:243] Iteration 2900, loss = 0.100116
I1005 20:38:25.543789 16110 solver.cpp:259]     Train net output #0: error_blob = 0.100116 (* 1 = 0.100116 loss)
I1005 20:38:25.543793 16110 solver.cpp:590] Iteration 2900, lr = 0.01
I1005 20:38:28.040695 16110 solver.cpp:243] Iteration 3000, loss = 0.0995888
I1005 20:38:28.040725 16110 solver.cpp:259]     Train net output #0: error_blob = 0.0995888 (* 1 = 0.0995888 loss)
I1005 20:38:28.040730 16110 solver.cpp:590] Iteration 3000, lr = 0.01
I1005 20:38:28.090466 16110 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:38:30.499516 16110 solver.cpp:243] Iteration 3100, loss = 0.0984851
I1005 20:38:30.499553 16110 solver.cpp:259]     Train net output #0: error_blob = 0.0984851 (* 1 = 0.0984851 loss)
I1005 20:38:30.499558 16110 solver.cpp:590] Iteration 3100, lr = 0.01
I1005 20:38:32.956517 16110 solver.cpp:243] Iteration 3200, loss = 0.0976561
I1005 20:38:32.956555 16110 solver.cpp:259]     Train net output #0: error_blob = 0.0976561 (* 1 = 0.0976561 loss)
I1005 20:38:32.956562 16110 solver.cpp:590] Iteration 3200, lr = 0.01
I1005 20:38:35.409006 16110 solver.cpp:243] Iteration 3300, loss = 0.100179
I1005 20:38:35.409045 16110 solver.cpp:259]     Train net output #0: error_blob = 0.100179 (* 1 = 0.100179 loss)
I1005 20:38:35.409050 16110 solver.cpp:590] Iteration 3300, lr = 0.01
I1005 20:38:37.896369 16110 solver.cpp:243] Iteration 3400, loss = 0.0971975
I1005 20:38:37.896399 16110 solver.cpp:259]     Train net output #0: error_blob = 0.0971975 (* 1 = 0.0971975 loss)
I1005 20:38:37.896404 16110 solver.cpp:590] Iteration 3400, lr = 0.01
I1005 20:38:40.358839 16110 solver.cpp:243] Iteration 3500, loss = 0.100878
I1005 20:38:40.358870 16110 solver.cpp:259]     Train net output #0: error_blob = 0.100878 (* 1 = 0.100878 loss)
I1005 20:38:40.358873 16110 solver.cpp:590] Iteration 3500, lr = 0.01
I1005 20:38:42.832085 16110 solver.cpp:243] Iteration 3600, loss = 0.101777
I1005 20:38:42.832115 16110 solver.cpp:259]     Train net output #0: error_blob = 0.101777 (* 1 = 0.101777 loss)
I1005 20:38:42.832120 16110 solver.cpp:590] Iteration 3600, lr = 0.01
I1005 20:38:45.268584 16110 solver.cpp:243] Iteration 3700, loss = 0.10284
I1005 20:38:45.269629 16110 solver.cpp:259]     Train net output #0: error_blob = 0.10284 (* 1 = 0.10284 loss)
I1005 20:38:45.269637 16110 solver.cpp:590] Iteration 3700, lr = 0.01
I1005 20:38:47.723598 16110 solver.cpp:243] Iteration 3800, loss = 0.10302
I1005 20:38:47.723628 16110 solver.cpp:259]     Train net output #0: error_blob = 0.10302 (* 1 = 0.10302 loss)
I1005 20:38:47.723634 16110 solver.cpp:590] Iteration 3800, lr = 0.01
I1005 20:38:50.166112 16110 solver.cpp:243] Iteration 3900, loss = 0.10122
I1005 20:38:50.166143 16110 solver.cpp:259]     Train net output #0: error_blob = 0.10122 (* 1 = 0.10122 loss)
I1005 20:38:50.166147 16110 solver.cpp:590] Iteration 3900, lr = 0.01
I1005 20:38:52.594013 16110 solver.cpp:243] Iteration 4000, loss = 0.102581
I1005 20:38:52.594044 16110 solver.cpp:259]     Train net output #0: error_blob = 0.102581 (* 1 = 0.102581 loss)
I1005 20:38:52.594048 16110 solver.cpp:590] Iteration 4000, lr = 0.01
I1005 20:38:52.642686 16110 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:38:55.028350 16110 solver.cpp:243] Iteration 4100, loss = 0.100392
I1005 20:38:55.028391 16110 solver.cpp:259]     Train net output #0: error_blob = 0.100392 (* 1 = 0.100392 loss)
I1005 20:38:55.028398 16110 solver.cpp:590] Iteration 4100, lr = 0.01
I1005 20:38:57.481971 16110 solver.cpp:243] Iteration 4200, loss = 0.0984595
I1005 20:38:57.482012 16110 solver.cpp:259]     Train net output #0: error_blob = 0.0984595 (* 1 = 0.0984595 loss)
I1005 20:38:57.482017 16110 solver.cpp:590] Iteration 4200, lr = 0.01
I1005 20:38:59.916952 16110 solver.cpp:243] Iteration 4300, loss = 0.097258
I1005 20:38:59.916991 16110 solver.cpp:259]     Train net output #0: error_blob = 0.097258 (* 1 = 0.097258 loss)
I1005 20:38:59.916996 16110 solver.cpp:590] Iteration 4300, lr = 0.01
I1005 20:39:02.379925 16110 solver.cpp:243] Iteration 4400, loss = 0.0968349
I1005 20:39:02.379956 16110 solver.cpp:259]     Train net output #0: error_blob = 0.0968349 (* 1 = 0.0968349 loss)
I1005 20:39:02.379961 16110 solver.cpp:590] Iteration 4400, lr = 0.01
I1005 20:39:04.825506 16110 solver.cpp:243] Iteration 4500, loss = 0.0975218
I1005 20:39:04.825546 16110 solver.cpp:259]     Train net output #0: error_blob = 0.0975218 (* 1 = 0.0975218 loss)
I1005 20:39:04.825551 16110 solver.cpp:590] Iteration 4500, lr = 0.01
I1005 20:39:07.241578 16110 solver.cpp:243] Iteration 4600, loss = 0.097095
I1005 20:39:07.241608 16110 solver.cpp:259]     Train net output #0: error_blob = 0.097095 (* 1 = 0.097095 loss)
I1005 20:39:07.241612 16110 solver.cpp:590] Iteration 4600, lr = 0.01
I1005 20:39:09.693343 16110 solver.cpp:243] Iteration 4700, loss = 0.0985065
I1005 20:39:09.693382 16110 solver.cpp:259]     Train net output #0: error_blob = 0.0985065 (* 1 = 0.0985065 loss)
I1005 20:39:09.693387 16110 solver.cpp:590] Iteration 4700, lr = 0.01
I1005 20:39:12.152730 16110 solver.cpp:243] Iteration 4800, loss = 0.10018
I1005 20:39:12.152770 16110 solver.cpp:259]     Train net output #0: error_blob = 0.10018 (* 1 = 0.10018 loss)
I1005 20:39:12.152776 16110 solver.cpp:590] Iteration 4800, lr = 0.01
I1005 20:39:14.588049 16110 solver.cpp:243] Iteration 4900, loss = 0.101494
I1005 20:39:14.588079 16110 solver.cpp:259]     Train net output #0: error_blob = 0.101494 (* 1 = 0.101494 loss)
I1005 20:39:14.588083 16110 solver.cpp:590] Iteration 4900, lr = 0.01
I1005 20:39:17.013536 16110 solver.cpp:243] Iteration 5000, loss = 0.101669
I1005 20:39:17.013669 16110 solver.cpp:259]     Train net output #0: error_blob = 0.101669 (* 1 = 0.101669 loss)
I1005 20:39:17.013675 16110 solver.cpp:590] Iteration 5000, lr = 0.01
I1005 20:39:17.061208 16110 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:39:19.443945 16110 solver.cpp:243] Iteration 5100, loss = 0.103043
I1005 20:39:19.443984 16110 solver.cpp:259]     Train net output #0: error_blob = 0.103043 (* 1 = 0.103043 loss)
I1005 20:39:19.443990 16110 solver.cpp:590] Iteration 5100, lr = 0.01
I1005 20:39:21.895463 16110 solver.cpp:243] Iteration 5200, loss = 0.100091
I1005 20:39:21.895503 16110 solver.cpp:259]     Train net output #0: error_blob = 0.100091 (* 1 = 0.100091 loss)
I1005 20:39:21.895509 16110 solver.cpp:590] Iteration 5200, lr = 0.01
I1005 20:39:24.370374 16110 solver.cpp:243] Iteration 5300, loss = 0.103369
I1005 20:39:24.370404 16110 solver.cpp:259]     Train net output #0: error_blob = 0.103369 (* 1 = 0.103369 loss)
I1005 20:39:24.370409 16110 solver.cpp:590] Iteration 5300, lr = 0.01
I1005 20:39:26.811421 16110 solver.cpp:243] Iteration 5400, loss = 0.0987918
I1005 20:39:26.811461 16110 solver.cpp:259]     Train net output #0: error_blob = 0.0987918 (* 1 = 0.0987918 loss)
I1005 20:39:26.811466 16110 solver.cpp:590] Iteration 5400, lr = 0.01
I1005 20:39:29.244070 16110 solver.cpp:243] Iteration 5500, loss = 0.0959
I1005 20:39:29.244107 16110 solver.cpp:259]     Train net output #0: error_blob = 0.0959 (* 1 = 0.0959 loss)
I1005 20:39:29.244113 16110 solver.cpp:590] Iteration 5500, lr = 0.01
I1005 20:39:31.678638 16110 solver.cpp:243] Iteration 5600, loss = 0.0957845
I1005 20:39:31.678670 16110 solver.cpp:259]     Train net output #0: error_blob = 0.0957845 (* 1 = 0.0957845 loss)
I1005 20:39:31.678675 16110 solver.cpp:590] Iteration 5600, lr = 0.01
I1005 20:39:34.145010 16110 solver.cpp:243] Iteration 5700, loss = 0.0949298
I1005 20:39:34.145051 16110 solver.cpp:259]     Train net output #0: error_blob = 0.0949298 (* 1 = 0.0949298 loss)
I1005 20:39:34.145056 16110 solver.cpp:590] Iteration 5700, lr = 0.01
I1005 20:39:36.580386 16110 solver.cpp:243] Iteration 5800, loss = 0.0974765
I1005 20:39:36.580416 16110 solver.cpp:259]     Train net output #0: error_blob = 0.0974765 (* 1 = 0.0974765 loss)
I1005 20:39:36.580421 16110 solver.cpp:590] Iteration 5800, lr = 0.01
I1005 20:39:39.032016 16110 solver.cpp:243] Iteration 5900, loss = 0.0959677
I1005 20:39:39.032047 16110 solver.cpp:259]     Train net output #0: error_blob = 0.0959677 (* 1 = 0.0959677 loss)
I1005 20:39:39.032052 16110 solver.cpp:590] Iteration 5900, lr = 0.01
I1005 20:39:41.495085 16110 solver.cpp:243] Iteration 6000, loss = 0.0978966
I1005 20:39:41.495122 16110 solver.cpp:259]     Train net output #0: error_blob = 0.0978966 (* 1 = 0.0978966 loss)
I1005 20:39:41.495128 16110 solver.cpp:590] Iteration 6000, lr = 0.01
I1005 20:39:41.544652 16110 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:39:43.972467 16110 solver.cpp:243] Iteration 6100, loss = 0.100397
I1005 20:39:43.972511 16110 solver.cpp:259]     Train net output #0: error_blob = 0.100397 (* 1 = 0.100397 loss)
I1005 20:39:43.972517 16110 solver.cpp:590] Iteration 6100, lr = 0.01
I1005 20:39:46.444649 16110 solver.cpp:243] Iteration 6200, loss = 0.101789
I1005 20:39:46.444679 16110 solver.cpp:259]     Train net output #0: error_blob = 0.101789 (* 1 = 0.101789 loss)
I1005 20:39:46.444684 16110 solver.cpp:590] Iteration 6200, lr = 0.01
I1005 20:39:48.912135 16110 solver.cpp:243] Iteration 6300, loss = 0.100364
I1005 20:39:48.912271 16110 solver.cpp:259]     Train net output #0: error_blob = 0.100364 (* 1 = 0.100364 loss)
I1005 20:39:48.912287 16110 solver.cpp:590] Iteration 6300, lr = 0.01
I1005 20:39:51.364379 16110 solver.cpp:243] Iteration 6400, loss = 0.101006
I1005 20:39:51.364411 16110 solver.cpp:259]     Train net output #0: error_blob = 0.101006 (* 1 = 0.101006 loss)
I1005 20:39:51.364416 16110 solver.cpp:590] Iteration 6400, lr = 0.01
I1005 20:39:53.825016 16110 solver.cpp:243] Iteration 6500, loss = 0.101359
I1005 20:39:53.825045 16110 solver.cpp:259]     Train net output #0: error_blob = 0.101359 (* 1 = 0.101359 loss)
I1005 20:39:53.825050 16110 solver.cpp:590] Iteration 6500, lr = 0.01
I1005 20:39:56.262778 16110 solver.cpp:243] Iteration 6600, loss = 0.0993381
I1005 20:39:56.262807 16110 solver.cpp:259]     Train net output #0: error_blob = 0.0993381 (* 1 = 0.0993381 loss)
I1005 20:39:56.262812 16110 solver.cpp:590] Iteration 6600, lr = 0.01
I1005 20:39:58.713315 16110 solver.cpp:243] Iteration 6700, loss = 0.0958558
I1005 20:39:58.713346 16110 solver.cpp:259]     Train net output #0: error_blob = 0.0958558 (* 1 = 0.0958558 loss)
I1005 20:39:58.713349 16110 solver.cpp:590] Iteration 6700, lr = 0.01
I1005 20:40:01.187139 16110 solver.cpp:243] Iteration 6800, loss = 0.0954053
I1005 20:40:01.187168 16110 solver.cpp:259]     Train net output #0: error_blob = 0.0954053 (* 1 = 0.0954053 loss)
I1005 20:40:01.187175 16110 solver.cpp:590] Iteration 6800, lr = 0.01
I1005 20:40:03.631479 16110 solver.cpp:243] Iteration 6900, loss = 0.0943398
I1005 20:40:03.631508 16110 solver.cpp:259]     Train net output #0: error_blob = 0.0943398 (* 1 = 0.0943398 loss)
I1005 20:40:03.631512 16110 solver.cpp:590] Iteration 6900, lr = 0.01
I1005 20:40:06.078325 16110 solver.cpp:243] Iteration 7000, loss = 0.0941009
I1005 20:40:06.078356 16110 solver.cpp:259]     Train net output #0: error_blob = 0.0941009 (* 1 = 0.0941009 loss)
I1005 20:40:06.078361 16110 solver.cpp:590] Iteration 7000, lr = 0.01
I1005 20:40:06.126744 16110 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:40:08.535424 16110 solver.cpp:243] Iteration 7100, loss = 0.0970375
I1005 20:40:08.535464 16110 solver.cpp:259]     Train net output #0: error_blob = 0.0970375 (* 1 = 0.0970375 loss)
I1005 20:40:08.535470 16110 solver.cpp:590] Iteration 7100, lr = 0.01
I1005 20:40:11.009275 16110 solver.cpp:243] Iteration 7200, loss = 0.0950628
I1005 20:40:11.009306 16110 solver.cpp:259]     Train net output #0: error_blob = 0.0950628 (* 1 = 0.0950628 loss)
I1005 20:40:11.009311 16110 solver.cpp:590] Iteration 7200, lr = 0.01
I1005 20:40:13.477591 16110 solver.cpp:243] Iteration 7300, loss = 0.0980043
I1005 20:40:13.477620 16110 solver.cpp:259]     Train net output #0: error_blob = 0.0980043 (* 1 = 0.0980043 loss)
I1005 20:40:13.477624 16110 solver.cpp:590] Iteration 7300, lr = 0.01
I1005 20:40:15.940441 16110 solver.cpp:243] Iteration 7400, loss = 0.100849
I1005 20:40:15.940480 16110 solver.cpp:259]     Train net output #0: error_blob = 0.100849 (* 1 = 0.100849 loss)
I1005 20:40:15.940485 16110 solver.cpp:590] Iteration 7400, lr = 0.01
I1005 20:40:18.375334 16110 solver.cpp:243] Iteration 7500, loss = 0.101013
I1005 20:40:18.375375 16110 solver.cpp:259]     Train net output #0: error_blob = 0.101013 (* 1 = 0.101013 loss)
I1005 20:40:18.375380 16110 solver.cpp:590] Iteration 7500, lr = 0.01
I1005 20:40:20.824136 16110 solver.cpp:243] Iteration 7600, loss = 0.100915
I1005 20:40:20.824237 16110 solver.cpp:259]     Train net output #0: error_blob = 0.100915 (* 1 = 0.100915 loss)
I1005 20:40:20.824244 16110 solver.cpp:590] Iteration 7600, lr = 0.01
I1005 20:40:23.270148 16110 solver.cpp:243] Iteration 7700, loss = 0.100071
I1005 20:40:23.270186 16110 solver.cpp:259]     Train net output #0: error_blob = 0.100071 (* 1 = 0.100071 loss)
I1005 20:40:23.270191 16110 solver.cpp:590] Iteration 7700, lr = 0.01
I1005 20:40:25.702980 16110 solver.cpp:243] Iteration 7800, loss = 0.099487
I1005 20:40:25.703008 16110 solver.cpp:259]     Train net output #0: error_blob = 0.099487 (* 1 = 0.099487 loss)
I1005 20:40:25.703012 16110 solver.cpp:590] Iteration 7800, lr = 0.01
I1005 20:40:28.150724 16110 solver.cpp:243] Iteration 7900, loss = 0.0978347
I1005 20:40:28.150753 16110 solver.cpp:259]     Train net output #0: error_blob = 0.0978347 (* 1 = 0.0978347 loss)
I1005 20:40:28.150758 16110 solver.cpp:590] Iteration 7900, lr = 0.01
I1005 20:40:30.674737 16110 solver.cpp:243] Iteration 8000, loss = 0.094993
I1005 20:40:30.674777 16110 solver.cpp:259]     Train net output #0: error_blob = 0.094993 (* 1 = 0.094993 loss)
I1005 20:40:30.674782 16110 solver.cpp:590] Iteration 8000, lr = 0.01
I1005 20:40:30.723104 16110 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:40:33.116390 16110 solver.cpp:243] Iteration 8100, loss = 0.09407
I1005 20:40:33.116420 16110 solver.cpp:259]     Train net output #0: error_blob = 0.09407 (* 1 = 0.09407 loss)
I1005 20:40:33.116423 16110 solver.cpp:590] Iteration 8100, lr = 0.01
I1005 20:40:35.553434 16110 solver.cpp:243] Iteration 8200, loss = 0.0937531
I1005 20:40:35.553473 16110 solver.cpp:259]     Train net output #0: error_blob = 0.0937531 (* 1 = 0.0937531 loss)
I1005 20:40:35.553479 16110 solver.cpp:590] Iteration 8200, lr = 0.01
I1005 20:40:37.997159 16110 solver.cpp:243] Iteration 8300, loss = 0.0947625
I1005 20:40:37.997198 16110 solver.cpp:259]     Train net output #0: error_blob = 0.0947625 (* 1 = 0.0947625 loss)
I1005 20:40:37.997203 16110 solver.cpp:590] Iteration 8300, lr = 0.01
I1005 20:40:40.454500 16110 solver.cpp:243] Iteration 8400, loss = 0.0949726
I1005 20:40:40.454540 16110 solver.cpp:259]     Train net output #0: error_blob = 0.0949726 (* 1 = 0.0949726 loss)
I1005 20:40:40.454545 16110 solver.cpp:590] Iteration 8400, lr = 0.01
I1005 20:40:42.884234 16110 solver.cpp:243] Iteration 8500, loss = 0.0954523
I1005 20:40:42.884275 16110 solver.cpp:259]     Train net output #0: error_blob = 0.0954523 (* 1 = 0.0954523 loss)
I1005 20:40:42.884281 16110 solver.cpp:590] Iteration 8500, lr = 0.01
I1005 20:40:45.369452 16110 solver.cpp:243] Iteration 8600, loss = 0.0990236
I1005 20:40:45.369493 16110 solver.cpp:259]     Train net output #0: error_blob = 0.0990236 (* 1 = 0.0990236 loss)
I1005 20:40:45.369498 16110 solver.cpp:590] Iteration 8600, lr = 0.01
I1005 20:40:47.813238 16110 solver.cpp:243] Iteration 8700, loss = 0.0995377
I1005 20:40:47.813269 16110 solver.cpp:259]     Train net output #0: error_blob = 0.0995377 (* 1 = 0.0995377 loss)
I1005 20:40:47.813273 16110 solver.cpp:590] Iteration 8700, lr = 0.01
I1005 20:40:50.234319 16110 solver.cpp:243] Iteration 8800, loss = 0.0991857
I1005 20:40:50.234357 16110 solver.cpp:259]     Train net output #0: error_blob = 0.0991857 (* 1 = 0.0991857 loss)
I1005 20:40:50.234362 16110 solver.cpp:590] Iteration 8800, lr = 0.01
I1005 20:40:52.677777 16110 solver.cpp:243] Iteration 8900, loss = 0.101378
I1005 20:40:52.677891 16110 solver.cpp:259]     Train net output #0: error_blob = 0.101378 (* 1 = 0.101378 loss)
I1005 20:40:52.677897 16110 solver.cpp:590] Iteration 8900, lr = 0.01
I1005 20:40:55.129101 16110 solver.cpp:243] Iteration 9000, loss = 0.097095
I1005 20:40:55.129135 16110 solver.cpp:259]     Train net output #0: error_blob = 0.097095 (* 1 = 0.097095 loss)
I1005 20:40:55.129142 16110 solver.cpp:590] Iteration 9000, lr = 0.01
I1005 20:40:55.177726 16110 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:40:57.601392 16110 solver.cpp:243] Iteration 9100, loss = 0.100369
I1005 20:40:57.601423 16110 solver.cpp:259]     Train net output #0: error_blob = 0.100369 (* 1 = 0.100369 loss)
I1005 20:40:57.601428 16110 solver.cpp:590] Iteration 9100, lr = 0.01
I1005 20:41:00.060281 16110 solver.cpp:243] Iteration 9200, loss = 0.0964147
I1005 20:41:00.060312 16110 solver.cpp:259]     Train net output #0: error_blob = 0.0964147 (* 1 = 0.0964147 loss)
I1005 20:41:00.060315 16110 solver.cpp:590] Iteration 9200, lr = 0.01
I1005 20:41:02.506922 16110 solver.cpp:243] Iteration 9300, loss = 0.0935812
I1005 20:41:02.506960 16110 solver.cpp:259]     Train net output #0: error_blob = 0.0935812 (* 1 = 0.0935812 loss)
I1005 20:41:02.506964 16110 solver.cpp:590] Iteration 9300, lr = 0.01
I1005 20:41:04.966080 16110 solver.cpp:243] Iteration 9400, loss = 0.0933559
I1005 20:41:04.966121 16110 solver.cpp:259]     Train net output #0: error_blob = 0.0933559 (* 1 = 0.0933559 loss)
I1005 20:41:04.966126 16110 solver.cpp:590] Iteration 9400, lr = 0.01
I1005 20:41:07.438253 16110 solver.cpp:243] Iteration 9500, loss = 0.0937963
I1005 20:41:07.438292 16110 solver.cpp:259]     Train net output #0: error_blob = 0.0937963 (* 1 = 0.0937963 loss)
I1005 20:41:07.438298 16110 solver.cpp:590] Iteration 9500, lr = 0.01
I1005 20:41:09.888257 16110 solver.cpp:243] Iteration 9600, loss = 0.0948558
I1005 20:41:09.888295 16110 solver.cpp:259]     Train net output #0: error_blob = 0.0948558 (* 1 = 0.0948558 loss)
I1005 20:41:09.888301 16110 solver.cpp:590] Iteration 9600, lr = 0.01
I1005 20:41:12.341300 16110 solver.cpp:243] Iteration 9700, loss = 0.0940768
I1005 20:41:12.341331 16110 solver.cpp:259]     Train net output #0: error_blob = 0.0940768 (* 1 = 0.0940768 loss)
I1005 20:41:12.341334 16110 solver.cpp:590] Iteration 9700, lr = 0.01
I1005 20:41:14.822515 16110 solver.cpp:243] Iteration 9800, loss = 0.0961905
I1005 20:41:14.822554 16110 solver.cpp:259]     Train net output #0: error_blob = 0.0961905 (* 1 = 0.0961905 loss)
I1005 20:41:14.822559 16110 solver.cpp:590] Iteration 9800, lr = 0.01
I1005 20:41:17.283118 16110 solver.cpp:243] Iteration 9900, loss = 0.099218
I1005 20:41:17.283149 16110 solver.cpp:259]     Train net output #0: error_blob = 0.099218 (* 1 = 0.099218 loss)
I1005 20:41:17.283154 16110 solver.cpp:590] Iteration 9900, lr = 0.01
I1005 20:41:19.714350 16110 solver.cpp:468] Snapshotting to binary proto file _iter_10000.caffemodel
I1005 20:41:19.716223 16110 solver.cpp:753] Snapshotting solver state to binary proto file _iter_10000.solverstate
I1005 20:41:19.738858 16110 solver.cpp:327] Iteration 10000, loss = 0.0996566
I1005 20:41:19.738883 16110 solver.cpp:332] Optimization Done.
I1005 20:41:19.738895 16110 caffe.cpp:215] Optimization Done.
I1005 20:41:19.826477 16130 caffe.cpp:184] Using GPUs 0
I1005 20:41:20.386570 16130 solver.cpp:54] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "fixed"
momentum: 0.9
solver_mode: GPU
device_id: 0
net: "large_batch/model0_part9.prototxt"
I1005 20:41:20.386602 16130 solver.cpp:97] Creating training net from net file: large_batch/model0_part9.prototxt
I1005 20:41:20.386771 16130 net.cpp:339] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_layer
I1005 20:41:20.386816 16130 net.cpp:50] Initializing net from parameters: 
name: "large_batch/model0_part9.prototxt"
state {
  phase: TRAIN
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TRAIN
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.part9.train"
    batch_size: 20000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1005 20:41:20.386895 16130 layer_factory.hpp:76] Creating layer data_layer
I1005 20:41:20.399405 16130 net.cpp:110] Creating Layer data_layer
I1005 20:41:20.399435 16130 net.cpp:433] data_layer -> data_blob
I1005 20:41:20.399466 16130 net.cpp:433] data_layer -> label_blob
I1005 20:41:20.400065 16134 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.part9.train
I1005 20:41:21.085469 16130 data_layer.cpp:45] output data size: 20000,61,1,1
I1005 20:41:21.090415 16130 net.cpp:155] Setting up data_layer
I1005 20:41:21.090457 16130 net.cpp:163] Top shape: 20000 61 1 1 (1220000)
I1005 20:41:21.090461 16130 net.cpp:163] Top shape: 20000 (20000)
I1005 20:41:21.090477 16130 layer_factory.hpp:76] Creating layer hidden_sum_layer
I1005 20:41:21.090489 16130 net.cpp:110] Creating Layer hidden_sum_layer
I1005 20:41:21.090492 16130 net.cpp:477] hidden_sum_layer <- data_blob
I1005 20:41:21.090502 16130 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I1005 20:41:21.090876 16130 net.cpp:155] Setting up hidden_sum_layer
I1005 20:41:21.090883 16130 net.cpp:163] Top shape: 20000 10 (200000)
I1005 20:41:21.090905 16130 layer_factory.hpp:76] Creating layer hidden_act_layer
I1005 20:41:21.090924 16130 net.cpp:110] Creating Layer hidden_act_layer
I1005 20:41:21.090925 16130 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I1005 20:41:21.090929 16130 net.cpp:433] hidden_act_layer -> hidden_act_blob
I1005 20:41:24.301841 16130 net.cpp:155] Setting up hidden_act_layer
I1005 20:41:24.301865 16130 net.cpp:163] Top shape: 20000 10 (200000)
I1005 20:41:24.301869 16130 layer_factory.hpp:76] Creating layer output_sum_layer
I1005 20:41:24.301879 16130 net.cpp:110] Creating Layer output_sum_layer
I1005 20:41:24.301882 16130 net.cpp:477] output_sum_layer <- hidden_act_blob
I1005 20:41:24.301887 16130 net.cpp:433] output_sum_layer -> output_sum_blob
I1005 20:41:24.301966 16130 net.cpp:155] Setting up output_sum_layer
I1005 20:41:24.301975 16130 net.cpp:163] Top shape: 20000 1 (20000)
I1005 20:41:24.301980 16130 layer_factory.hpp:76] Creating layer output_act_layer
I1005 20:41:24.301986 16130 net.cpp:110] Creating Layer output_act_layer
I1005 20:41:24.301988 16130 net.cpp:477] output_act_layer <- output_sum_blob
I1005 20:41:24.301990 16130 net.cpp:433] output_act_layer -> output_act_blob
I1005 20:41:24.302050 16130 net.cpp:155] Setting up output_act_layer
I1005 20:41:24.302068 16130 net.cpp:163] Top shape: 20000 1 (20000)
I1005 20:41:24.302072 16130 layer_factory.hpp:76] Creating layer error_layer
I1005 20:41:24.302078 16130 net.cpp:110] Creating Layer error_layer
I1005 20:41:24.302079 16130 net.cpp:477] error_layer <- output_act_blob
I1005 20:41:24.302081 16130 net.cpp:477] error_layer <- label_blob
I1005 20:41:24.302085 16130 net.cpp:433] error_layer -> error_blob
I1005 20:41:24.302109 16130 net.cpp:155] Setting up error_layer
I1005 20:41:24.302112 16130 net.cpp:163] Top shape: (1)
I1005 20:41:24.302114 16130 net.cpp:168]     with loss weight 1
I1005 20:41:24.302129 16130 net.cpp:236] error_layer needs backward computation.
I1005 20:41:24.302132 16130 net.cpp:236] output_act_layer needs backward computation.
I1005 20:41:24.302134 16130 net.cpp:236] output_sum_layer needs backward computation.
I1005 20:41:24.302136 16130 net.cpp:236] hidden_act_layer needs backward computation.
I1005 20:41:24.302139 16130 net.cpp:236] hidden_sum_layer needs backward computation.
I1005 20:41:24.302140 16130 net.cpp:240] data_layer does not need backward computation.
I1005 20:41:24.302142 16130 net.cpp:283] This network produces output error_blob
I1005 20:41:24.302146 16130 net.cpp:297] Network initialization done.
I1005 20:41:24.302148 16130 net.cpp:298] Memory required for data: 6720004
I1005 20:41:24.302270 16130 solver.cpp:187] Creating test net (#0) specified by net file: large_batch/model0_part9.prototxt
I1005 20:41:24.302283 16130 net.cpp:339] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_layer
I1005 20:41:24.302314 16130 net.cpp:50] Initializing net from parameters: 
name: "large_batch/model0_part9.prototxt"
state {
  phase: TEST
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TEST
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.part9.test"
    batch_size: 2000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1005 20:41:24.302333 16130 layer_factory.hpp:76] Creating layer data_layer
I1005 20:41:24.303514 16130 net.cpp:110] Creating Layer data_layer
I1005 20:41:24.303529 16130 net.cpp:433] data_layer -> data_blob
I1005 20:41:24.303534 16130 net.cpp:433] data_layer -> label_blob
I1005 20:41:24.304080 16136 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.part9.test
I1005 20:41:24.304142 16130 data_layer.cpp:45] output data size: 2000,61,1,1
I1005 20:41:24.305519 16130 net.cpp:155] Setting up data_layer
I1005 20:41:24.305531 16130 net.cpp:163] Top shape: 2000 61 1 1 (122000)
I1005 20:41:24.305534 16130 net.cpp:163] Top shape: 2000 (2000)
I1005 20:41:24.305537 16130 layer_factory.hpp:76] Creating layer hidden_sum_layer
I1005 20:41:24.305546 16130 net.cpp:110] Creating Layer hidden_sum_layer
I1005 20:41:24.305547 16130 net.cpp:477] hidden_sum_layer <- data_blob
I1005 20:41:24.305552 16130 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I1005 20:41:24.305699 16130 net.cpp:155] Setting up hidden_sum_layer
I1005 20:41:24.305706 16130 net.cpp:163] Top shape: 2000 10 (20000)
I1005 20:41:24.305713 16130 layer_factory.hpp:76] Creating layer hidden_act_layer
I1005 20:41:24.305717 16130 net.cpp:110] Creating Layer hidden_act_layer
I1005 20:41:24.305721 16130 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I1005 20:41:24.305734 16130 net.cpp:433] hidden_act_layer -> hidden_act_blob
I1005 20:41:24.305903 16130 net.cpp:155] Setting up hidden_act_layer
I1005 20:41:24.305912 16130 net.cpp:163] Top shape: 2000 10 (20000)
I1005 20:41:24.305914 16130 layer_factory.hpp:76] Creating layer output_sum_layer
I1005 20:41:24.305919 16130 net.cpp:110] Creating Layer output_sum_layer
I1005 20:41:24.305922 16130 net.cpp:477] output_sum_layer <- hidden_act_blob
I1005 20:41:24.305925 16130 net.cpp:433] output_sum_layer -> output_sum_blob
I1005 20:41:24.305984 16130 net.cpp:155] Setting up output_sum_layer
I1005 20:41:24.305989 16130 net.cpp:163] Top shape: 2000 1 (2000)
I1005 20:41:24.305994 16130 layer_factory.hpp:76] Creating layer output_act_layer
I1005 20:41:24.305997 16130 net.cpp:110] Creating Layer output_act_layer
I1005 20:41:24.305999 16130 net.cpp:477] output_act_layer <- output_sum_blob
I1005 20:41:24.306002 16130 net.cpp:433] output_act_layer -> output_act_blob
I1005 20:41:24.306051 16130 net.cpp:155] Setting up output_act_layer
I1005 20:41:24.306054 16130 net.cpp:163] Top shape: 2000 1 (2000)
I1005 20:41:24.306057 16130 layer_factory.hpp:76] Creating layer error_layer
I1005 20:41:24.306061 16130 net.cpp:110] Creating Layer error_layer
I1005 20:41:24.306063 16130 net.cpp:477] error_layer <- output_act_blob
I1005 20:41:24.306066 16130 net.cpp:477] error_layer <- label_blob
I1005 20:41:24.306068 16130 net.cpp:433] error_layer -> error_blob
I1005 20:41:24.306087 16130 net.cpp:155] Setting up error_layer
I1005 20:41:24.306092 16130 net.cpp:163] Top shape: (1)
I1005 20:41:24.306093 16130 net.cpp:168]     with loss weight 1
I1005 20:41:24.306100 16130 net.cpp:236] error_layer needs backward computation.
I1005 20:41:24.306102 16130 net.cpp:236] output_act_layer needs backward computation.
I1005 20:41:24.306104 16130 net.cpp:236] output_sum_layer needs backward computation.
I1005 20:41:24.306107 16130 net.cpp:236] hidden_act_layer needs backward computation.
I1005 20:41:24.306108 16130 net.cpp:236] hidden_sum_layer needs backward computation.
I1005 20:41:24.306110 16130 net.cpp:240] data_layer does not need backward computation.
I1005 20:41:24.306113 16130 net.cpp:283] This network produces output error_blob
I1005 20:41:24.306118 16130 net.cpp:297] Network initialization done.
I1005 20:41:24.306118 16130 net.cpp:298] Memory required for data: 672004
I1005 20:41:24.306136 16130 solver.cpp:66] Solver scaffolding done.
I1005 20:41:24.306226 16130 caffe.cpp:212] Starting Optimization
I1005 20:41:24.306232 16130 solver.cpp:294] Solving large_batch/model0_part9.prototxt
I1005 20:41:24.306234 16130 solver.cpp:295] Learning Rate Policy: fixed
I1005 20:41:24.306376 16130 solver.cpp:347] Iteration 0, Testing net (#0)
I1005 20:41:24.306430 16130 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:41:24.591219 16130 solver.cpp:415]     Test net output #0: error_blob = 0.124659 (* 1 = 0.124659 loss)
I1005 20:41:24.592733 16130 solver.cpp:243] Iteration 0, loss = 0.125901
I1005 20:41:24.592752 16130 solver.cpp:259]     Train net output #0: error_blob = 0.125901 (* 1 = 0.125901 loss)
I1005 20:41:24.592766 16130 solver.cpp:590] Iteration 0, lr = 0.01
I1005 20:41:27.049629 16130 solver.cpp:243] Iteration 100, loss = 0.119654
I1005 20:41:27.049661 16130 solver.cpp:259]     Train net output #0: error_blob = 0.119654 (* 1 = 0.119654 loss)
I1005 20:41:27.049666 16130 solver.cpp:590] Iteration 100, lr = 0.01
I1005 20:41:29.572077 16130 solver.cpp:243] Iteration 200, loss = 0.11694
I1005 20:41:29.572109 16130 solver.cpp:259]     Train net output #0: error_blob = 0.11694 (* 1 = 0.11694 loss)
I1005 20:41:29.572114 16130 solver.cpp:590] Iteration 200, lr = 0.01
I1005 20:41:32.095681 16130 solver.cpp:243] Iteration 300, loss = 0.115068
I1005 20:41:32.095721 16130 solver.cpp:259]     Train net output #0: error_blob = 0.115068 (* 1 = 0.115068 loss)
I1005 20:41:32.095731 16130 solver.cpp:590] Iteration 300, lr = 0.01
I1005 20:41:34.606739 16130 solver.cpp:243] Iteration 400, loss = 0.112287
I1005 20:41:34.606780 16130 solver.cpp:259]     Train net output #0: error_blob = 0.112287 (* 1 = 0.112287 loss)
I1005 20:41:34.606816 16130 solver.cpp:590] Iteration 400, lr = 0.01
I1005 20:41:37.133765 16130 solver.cpp:243] Iteration 500, loss = 0.11188
I1005 20:41:37.133806 16130 solver.cpp:259]     Train net output #0: error_blob = 0.11188 (* 1 = 0.11188 loss)
I1005 20:41:37.133813 16130 solver.cpp:590] Iteration 500, lr = 0.01
I1005 20:41:39.657129 16130 solver.cpp:243] Iteration 600, loss = 0.111336
I1005 20:41:39.657168 16130 solver.cpp:259]     Train net output #0: error_blob = 0.111336 (* 1 = 0.111336 loss)
I1005 20:41:39.657173 16130 solver.cpp:590] Iteration 600, lr = 0.01
I1005 20:41:42.177089 16130 solver.cpp:243] Iteration 700, loss = 0.107575
I1005 20:41:42.177129 16130 solver.cpp:259]     Train net output #0: error_blob = 0.107575 (* 1 = 0.107575 loss)
I1005 20:41:42.177134 16130 solver.cpp:590] Iteration 700, lr = 0.01
I1005 20:41:44.707814 16130 solver.cpp:243] Iteration 800, loss = 0.109385
I1005 20:41:44.707855 16130 solver.cpp:259]     Train net output #0: error_blob = 0.109385 (* 1 = 0.109385 loss)
I1005 20:41:44.707860 16130 solver.cpp:590] Iteration 800, lr = 0.01
I1005 20:41:47.233899 16130 solver.cpp:243] Iteration 900, loss = 0.10773
I1005 20:41:47.233940 16130 solver.cpp:259]     Train net output #0: error_blob = 0.10773 (* 1 = 0.10773 loss)
I1005 20:41:47.233947 16130 solver.cpp:590] Iteration 900, lr = 0.01
I1005 20:41:47.283680 16130 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:41:49.743242 16130 solver.cpp:347] Iteration 1000, Testing net (#0)
I1005 20:41:50.023799 16130 solver.cpp:415]     Test net output #0: error_blob = 0.109692 (* 1 = 0.109692 loss)
I1005 20:41:50.024580 16130 solver.cpp:243] Iteration 1000, loss = 0.104789
I1005 20:41:50.024619 16130 solver.cpp:259]     Train net output #0: error_blob = 0.104789 (* 1 = 0.104789 loss)
I1005 20:41:50.024629 16130 solver.cpp:590] Iteration 1000, lr = 0.01
I1005 20:41:52.466240 16130 solver.cpp:243] Iteration 1100, loss = 0.107658
I1005 20:41:52.466284 16130 solver.cpp:259]     Train net output #0: error_blob = 0.107658 (* 1 = 0.107658 loss)
I1005 20:41:52.466289 16130 solver.cpp:590] Iteration 1100, lr = 0.01
I1005 20:41:55.009696 16130 solver.cpp:243] Iteration 1200, loss = 0.106589
I1005 20:41:55.009729 16130 solver.cpp:259]     Train net output #0: error_blob = 0.106589 (* 1 = 0.106589 loss)
I1005 20:41:55.009735 16130 solver.cpp:590] Iteration 1200, lr = 0.01
I1005 20:41:57.560904 16130 solver.cpp:243] Iteration 1300, loss = 0.10308
I1005 20:41:57.560935 16130 solver.cpp:259]     Train net output #0: error_blob = 0.10308 (* 1 = 0.10308 loss)
I1005 20:41:57.560942 16130 solver.cpp:590] Iteration 1300, lr = 0.01
I1005 20:42:00.144670 16130 solver.cpp:243] Iteration 1400, loss = 0.106322
I1005 20:42:00.144701 16130 solver.cpp:259]     Train net output #0: error_blob = 0.106322 (* 1 = 0.106322 loss)
I1005 20:42:00.144707 16130 solver.cpp:590] Iteration 1400, lr = 0.01
I1005 20:42:02.658296 16130 solver.cpp:243] Iteration 1500, loss = 0.104501
I1005 20:42:02.658335 16130 solver.cpp:259]     Train net output #0: error_blob = 0.104501 (* 1 = 0.104501 loss)
I1005 20:42:02.658340 16130 solver.cpp:590] Iteration 1500, lr = 0.01
I1005 20:42:05.166244 16130 solver.cpp:243] Iteration 1600, loss = 0.101717
I1005 20:42:05.166275 16130 solver.cpp:259]     Train net output #0: error_blob = 0.101717 (* 1 = 0.101717 loss)
I1005 20:42:05.166280 16130 solver.cpp:590] Iteration 1600, lr = 0.01
I1005 20:42:07.663051 16130 solver.cpp:243] Iteration 1700, loss = 0.103341
I1005 20:42:07.663082 16130 solver.cpp:259]     Train net output #0: error_blob = 0.103341 (* 1 = 0.103341 loss)
I1005 20:42:07.663087 16130 solver.cpp:590] Iteration 1700, lr = 0.01
I1005 20:42:10.191051 16130 solver.cpp:243] Iteration 1800, loss = 0.104377
I1005 20:42:10.191079 16130 solver.cpp:259]     Train net output #0: error_blob = 0.104377 (* 1 = 0.104377 loss)
I1005 20:42:10.191086 16130 solver.cpp:590] Iteration 1800, lr = 0.01
I1005 20:42:10.391062 16130 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:42:12.728920 16130 solver.cpp:243] Iteration 1900, loss = 0.101838
I1005 20:42:12.728950 16130 solver.cpp:259]     Train net output #0: error_blob = 0.101838 (* 1 = 0.101838 loss)
I1005 20:42:12.728955 16130 solver.cpp:590] Iteration 1900, lr = 0.01
I1005 20:42:15.189472 16130 solver.cpp:347] Iteration 2000, Testing net (#0)
I1005 20:42:15.476872 16130 solver.cpp:415]     Test net output #0: error_blob = 0.109321 (* 1 = 0.109321 loss)
I1005 20:42:15.477499 16130 solver.cpp:243] Iteration 2000, loss = 0.102136
I1005 20:42:15.477514 16130 solver.cpp:259]     Train net output #0: error_blob = 0.102136 (* 1 = 0.102136 loss)
I1005 20:42:15.477519 16130 solver.cpp:590] Iteration 2000, lr = 0.01
I1005 20:42:18.011878 16130 solver.cpp:243] Iteration 2100, loss = 0.101611
I1005 20:42:18.011909 16130 solver.cpp:259]     Train net output #0: error_blob = 0.101611 (* 1 = 0.101611 loss)
I1005 20:42:18.011914 16130 solver.cpp:590] Iteration 2100, lr = 0.01
I1005 20:42:20.591128 16130 solver.cpp:243] Iteration 2200, loss = 0.101264
I1005 20:42:20.591255 16130 solver.cpp:259]     Train net output #0: error_blob = 0.101264 (* 1 = 0.101264 loss)
I1005 20:42:20.591274 16130 solver.cpp:590] Iteration 2200, lr = 0.01
I1005 20:42:23.102429 16130 solver.cpp:243] Iteration 2300, loss = 0.102685
I1005 20:42:23.102459 16130 solver.cpp:259]     Train net output #0: error_blob = 0.102685 (* 1 = 0.102685 loss)
I1005 20:42:23.102463 16130 solver.cpp:590] Iteration 2300, lr = 0.01
I1005 20:42:25.606573 16130 solver.cpp:243] Iteration 2400, loss = 0.100827
I1005 20:42:25.606603 16130 solver.cpp:259]     Train net output #0: error_blob = 0.100827 (* 1 = 0.100827 loss)
I1005 20:42:25.606608 16130 solver.cpp:590] Iteration 2400, lr = 0.01
I1005 20:42:28.147843 16130 solver.cpp:243] Iteration 2500, loss = 0.0998392
I1005 20:42:28.147876 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0998392 (* 1 = 0.0998392 loss)
I1005 20:42:28.147881 16130 solver.cpp:590] Iteration 2500, lr = 0.01
I1005 20:42:30.645884 16130 solver.cpp:243] Iteration 2600, loss = 0.102916
I1005 20:42:30.645925 16130 solver.cpp:259]     Train net output #0: error_blob = 0.102916 (* 1 = 0.102916 loss)
I1005 20:42:30.645931 16130 solver.cpp:590] Iteration 2600, lr = 0.01
I1005 20:42:33.131469 16130 solver.cpp:243] Iteration 2700, loss = 0.0992995
I1005 20:42:33.131500 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0992995 (* 1 = 0.0992995 loss)
I1005 20:42:33.131505 16130 solver.cpp:590] Iteration 2700, lr = 0.01
I1005 20:42:33.487799 16130 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:42:35.640933 16130 solver.cpp:243] Iteration 2800, loss = 0.0995908
I1005 20:42:35.640962 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0995908 (* 1 = 0.0995908 loss)
I1005 20:42:35.640967 16130 solver.cpp:590] Iteration 2800, lr = 0.01
I1005 20:42:38.149708 16130 solver.cpp:243] Iteration 2900, loss = 0.102967
I1005 20:42:38.149739 16130 solver.cpp:259]     Train net output #0: error_blob = 0.102967 (* 1 = 0.102967 loss)
I1005 20:42:38.149744 16130 solver.cpp:590] Iteration 2900, lr = 0.01
I1005 20:42:40.642678 16130 solver.cpp:347] Iteration 3000, Testing net (#0)
I1005 20:42:40.941437 16130 solver.cpp:415]     Test net output #0: error_blob = 0.111786 (* 1 = 0.111786 loss)
I1005 20:42:40.942041 16130 solver.cpp:243] Iteration 3000, loss = 0.0983902
I1005 20:42:40.942059 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0983902 (* 1 = 0.0983902 loss)
I1005 20:42:40.942065 16130 solver.cpp:590] Iteration 3000, lr = 0.01
I1005 20:42:43.433182 16130 solver.cpp:243] Iteration 3100, loss = 0.0996628
I1005 20:42:43.433217 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0996628 (* 1 = 0.0996628 loss)
I1005 20:42:43.433224 16130 solver.cpp:590] Iteration 3100, lr = 0.01
I1005 20:42:45.986585 16130 solver.cpp:243] Iteration 3200, loss = 0.102723
I1005 20:42:45.986618 16130 solver.cpp:259]     Train net output #0: error_blob = 0.102723 (* 1 = 0.102723 loss)
I1005 20:42:45.986626 16130 solver.cpp:590] Iteration 3200, lr = 0.01
I1005 20:42:48.484057 16130 solver.cpp:243] Iteration 3300, loss = 0.0978799
I1005 20:42:48.484091 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0978799 (* 1 = 0.0978799 loss)
I1005 20:42:48.484096 16130 solver.cpp:590] Iteration 3300, lr = 0.01
I1005 20:42:51.048959 16130 solver.cpp:243] Iteration 3400, loss = 0.0994818
I1005 20:42:51.050683 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0994818 (* 1 = 0.0994818 loss)
I1005 20:42:51.050693 16130 solver.cpp:590] Iteration 3400, lr = 0.01
I1005 20:42:53.561161 16130 solver.cpp:243] Iteration 3500, loss = 0.102539
I1005 20:42:53.561210 16130 solver.cpp:259]     Train net output #0: error_blob = 0.102539 (* 1 = 0.102539 loss)
I1005 20:42:53.561220 16130 solver.cpp:590] Iteration 3500, lr = 0.01
I1005 20:42:56.093822 16130 solver.cpp:243] Iteration 3600, loss = 0.0979635
I1005 20:42:56.093873 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0979635 (* 1 = 0.0979635 loss)
I1005 20:42:56.093881 16130 solver.cpp:590] Iteration 3600, lr = 0.01
I1005 20:42:56.606470 16130 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:42:58.626508 16130 solver.cpp:243] Iteration 3700, loss = 0.0997386
I1005 20:42:58.626550 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0997386 (* 1 = 0.0997386 loss)
I1005 20:42:58.626556 16130 solver.cpp:590] Iteration 3700, lr = 0.01
I1005 20:43:01.191756 16130 solver.cpp:243] Iteration 3800, loss = 0.102169
I1005 20:43:01.191787 16130 solver.cpp:259]     Train net output #0: error_blob = 0.102169 (* 1 = 0.102169 loss)
I1005 20:43:01.191793 16130 solver.cpp:590] Iteration 3800, lr = 0.01
I1005 20:43:03.730000 16130 solver.cpp:243] Iteration 3900, loss = 0.0989013
I1005 20:43:03.730042 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0989013 (* 1 = 0.0989013 loss)
I1005 20:43:03.730051 16130 solver.cpp:590] Iteration 3900, lr = 0.01
I1005 20:43:06.232527 16130 solver.cpp:347] Iteration 4000, Testing net (#0)
I1005 20:43:06.547436 16130 solver.cpp:415]     Test net output #0: error_blob = 0.114318 (* 1 = 0.114318 loss)
I1005 20:43:06.548089 16130 solver.cpp:243] Iteration 4000, loss = 0.0999558
I1005 20:43:06.548126 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0999558 (* 1 = 0.0999558 loss)
I1005 20:43:06.548135 16130 solver.cpp:590] Iteration 4000, lr = 0.01
I1005 20:43:09.058639 16130 solver.cpp:243] Iteration 4100, loss = 0.100074
I1005 20:43:09.058676 16130 solver.cpp:259]     Train net output #0: error_blob = 0.100074 (* 1 = 0.100074 loss)
I1005 20:43:09.058683 16130 solver.cpp:590] Iteration 4100, lr = 0.01
I1005 20:43:11.613742 16130 solver.cpp:243] Iteration 4200, loss = 0.0974085
I1005 20:43:11.613776 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0974085 (* 1 = 0.0974085 loss)
I1005 20:43:11.613785 16130 solver.cpp:590] Iteration 4200, lr = 0.01
I1005 20:43:14.177983 16130 solver.cpp:243] Iteration 4300, loss = 0.100551
I1005 20:43:14.178025 16130 solver.cpp:259]     Train net output #0: error_blob = 0.100551 (* 1 = 0.100551 loss)
I1005 20:43:14.178030 16130 solver.cpp:590] Iteration 4300, lr = 0.01
I1005 20:43:16.678241 16130 solver.cpp:243] Iteration 4400, loss = 0.100199
I1005 20:43:16.678283 16130 solver.cpp:259]     Train net output #0: error_blob = 0.100199 (* 1 = 0.100199 loss)
I1005 20:43:16.678290 16130 solver.cpp:590] Iteration 4400, lr = 0.01
I1005 20:43:19.200866 16130 solver.cpp:243] Iteration 4500, loss = 0.0960895
I1005 20:43:19.200907 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0960895 (* 1 = 0.0960895 loss)
I1005 20:43:19.200912 16130 solver.cpp:590] Iteration 4500, lr = 0.01
I1005 20:43:19.855625 16130 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:43:21.712864 16130 solver.cpp:243] Iteration 4600, loss = 0.100098
I1005 20:43:21.713002 16130 solver.cpp:259]     Train net output #0: error_blob = 0.100098 (* 1 = 0.100098 loss)
I1005 20:43:21.713011 16130 solver.cpp:590] Iteration 4600, lr = 0.01
I1005 20:43:24.249002 16130 solver.cpp:243] Iteration 4700, loss = 0.100626
I1005 20:43:24.249049 16130 solver.cpp:259]     Train net output #0: error_blob = 0.100626 (* 1 = 0.100626 loss)
I1005 20:43:24.249058 16130 solver.cpp:590] Iteration 4700, lr = 0.01
I1005 20:43:26.791117 16130 solver.cpp:243] Iteration 4800, loss = 0.0955022
I1005 20:43:26.791158 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0955022 (* 1 = 0.0955022 loss)
I1005 20:43:26.791164 16130 solver.cpp:590] Iteration 4800, lr = 0.01
I1005 20:43:29.319591 16130 solver.cpp:243] Iteration 4900, loss = 0.0988314
I1005 20:43:29.319641 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0988314 (* 1 = 0.0988314 loss)
I1005 20:43:29.319649 16130 solver.cpp:590] Iteration 4900, lr = 0.01
I1005 20:43:31.815253 16130 solver.cpp:347] Iteration 5000, Testing net (#0)
I1005 20:43:32.099874 16130 solver.cpp:415]     Test net output #0: error_blob = 0.116157 (* 1 = 0.116157 loss)
I1005 20:43:32.100497 16130 solver.cpp:243] Iteration 5000, loss = 0.100524
I1005 20:43:32.100513 16130 solver.cpp:259]     Train net output #0: error_blob = 0.100524 (* 1 = 0.100524 loss)
I1005 20:43:32.100524 16130 solver.cpp:590] Iteration 5000, lr = 0.01
I1005 20:43:34.615942 16130 solver.cpp:243] Iteration 5100, loss = 0.0960268
I1005 20:43:34.615973 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0960268 (* 1 = 0.0960268 loss)
I1005 20:43:34.615980 16130 solver.cpp:590] Iteration 5100, lr = 0.01
I1005 20:43:37.127754 16130 solver.cpp:243] Iteration 5200, loss = 0.0979696
I1005 20:43:37.127794 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0979696 (* 1 = 0.0979696 loss)
I1005 20:43:37.127802 16130 solver.cpp:590] Iteration 5200, lr = 0.01
I1005 20:43:39.659963 16130 solver.cpp:243] Iteration 5300, loss = 0.0995651
I1005 20:43:39.660003 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0995651 (* 1 = 0.0995651 loss)
I1005 20:43:39.660009 16130 solver.cpp:590] Iteration 5300, lr = 0.01
I1005 20:43:42.207237 16130 solver.cpp:243] Iteration 5400, loss = 0.0958224
I1005 20:43:42.207284 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0958224 (* 1 = 0.0958224 loss)
I1005 20:43:42.207293 16130 solver.cpp:590] Iteration 5400, lr = 0.01
I1005 20:43:43.016702 16130 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:43:44.728320 16130 solver.cpp:243] Iteration 5500, loss = 0.0984917
I1005 20:43:44.728358 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0984917 (* 1 = 0.0984917 loss)
I1005 20:43:44.728368 16130 solver.cpp:590] Iteration 5500, lr = 0.01
I1005 20:43:47.263562 16130 solver.cpp:243] Iteration 5600, loss = 0.0976082
I1005 20:43:47.263612 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0976082 (* 1 = 0.0976082 loss)
I1005 20:43:47.263619 16130 solver.cpp:590] Iteration 5600, lr = 0.01
I1005 20:43:49.813138 16130 solver.cpp:243] Iteration 5700, loss = 0.0950736
I1005 20:43:49.813179 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0950736 (* 1 = 0.0950736 loss)
I1005 20:43:49.813186 16130 solver.cpp:590] Iteration 5700, lr = 0.01
I1005 20:43:52.338348 16130 solver.cpp:243] Iteration 5800, loss = 0.0987465
I1005 20:43:52.340010 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0987465 (* 1 = 0.0987465 loss)
I1005 20:43:52.340018 16130 solver.cpp:590] Iteration 5800, lr = 0.01
I1005 20:43:54.876559 16130 solver.cpp:243] Iteration 5900, loss = 0.0963172
I1005 20:43:54.876592 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0963172 (* 1 = 0.0963172 loss)
I1005 20:43:54.876597 16130 solver.cpp:590] Iteration 5900, lr = 0.01
I1005 20:43:57.398044 16130 solver.cpp:347] Iteration 6000, Testing net (#0)
I1005 20:43:57.704454 16130 solver.cpp:415]     Test net output #0: error_blob = 0.117374 (* 1 = 0.117374 loss)
I1005 20:43:57.705134 16130 solver.cpp:243] Iteration 6000, loss = 0.0949201
I1005 20:43:57.705152 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0949201 (* 1 = 0.0949201 loss)
I1005 20:43:57.705157 16130 solver.cpp:590] Iteration 6000, lr = 0.01
I1005 20:44:00.235060 16130 solver.cpp:243] Iteration 6100, loss = 0.0998521
I1005 20:44:00.235108 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0998521 (* 1 = 0.0998521 loss)
I1005 20:44:00.235116 16130 solver.cpp:590] Iteration 6100, lr = 0.01
I1005 20:44:02.747786 16130 solver.cpp:243] Iteration 6200, loss = 0.0947582
I1005 20:44:02.747828 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0947582 (* 1 = 0.0947582 loss)
I1005 20:44:02.747833 16130 solver.cpp:590] Iteration 6200, lr = 0.01
I1005 20:44:05.268034 16130 solver.cpp:243] Iteration 6300, loss = 0.0949505
I1005 20:44:05.268065 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0949505 (* 1 = 0.0949505 loss)
I1005 20:44:05.268071 16130 solver.cpp:590] Iteration 6300, lr = 0.01
I1005 20:44:06.226759 16130 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:44:07.794301 16130 solver.cpp:243] Iteration 6400, loss = 0.0992842
I1005 20:44:07.794342 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0992842 (* 1 = 0.0992842 loss)
I1005 20:44:07.794347 16130 solver.cpp:590] Iteration 6400, lr = 0.01
I1005 20:44:10.312834 16130 solver.cpp:243] Iteration 6500, loss = 0.0955901
I1005 20:44:10.312875 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0955901 (* 1 = 0.0955901 loss)
I1005 20:44:10.312880 16130 solver.cpp:590] Iteration 6500, lr = 0.01
I1005 20:44:12.820989 16130 solver.cpp:243] Iteration 6600, loss = 0.0956953
I1005 20:44:12.821029 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0956953 (* 1 = 0.0956953 loss)
I1005 20:44:12.821034 16130 solver.cpp:590] Iteration 6600, lr = 0.01
I1005 20:44:15.349616 16130 solver.cpp:243] Iteration 6700, loss = 0.100115
I1005 20:44:15.349647 16130 solver.cpp:259]     Train net output #0: error_blob = 0.100115 (* 1 = 0.100115 loss)
I1005 20:44:15.349652 16130 solver.cpp:590] Iteration 6700, lr = 0.01
I1005 20:44:17.882969 16130 solver.cpp:243] Iteration 6800, loss = 0.0946375
I1005 20:44:17.883003 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0946375 (* 1 = 0.0946375 loss)
I1005 20:44:17.883010 16130 solver.cpp:590] Iteration 6800, lr = 0.01
I1005 20:44:20.405705 16130 solver.cpp:243] Iteration 6900, loss = 0.0953777
I1005 20:44:20.405746 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0953777 (* 1 = 0.0953777 loss)
I1005 20:44:20.405751 16130 solver.cpp:590] Iteration 6900, lr = 0.01
I1005 20:44:22.901983 16130 solver.cpp:347] Iteration 7000, Testing net (#0)
I1005 20:44:23.186647 16130 solver.cpp:415]     Test net output #0: error_blob = 0.118081 (* 1 = 0.118081 loss)
I1005 20:44:23.187332 16130 solver.cpp:243] Iteration 7000, loss = 0.100417
I1005 20:44:23.187352 16130 solver.cpp:259]     Train net output #0: error_blob = 0.100417 (* 1 = 0.100417 loss)
I1005 20:44:23.187361 16130 solver.cpp:590] Iteration 7000, lr = 0.01
I1005 20:44:25.676038 16130 solver.cpp:243] Iteration 7100, loss = 0.0973107
I1005 20:44:25.676086 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0973107 (* 1 = 0.0973107 loss)
I1005 20:44:25.676095 16130 solver.cpp:590] Iteration 7100, lr = 0.01
I1005 20:44:28.235473 16130 solver.cpp:243] Iteration 7200, loss = 0.0960993
I1005 20:44:28.235515 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0960993 (* 1 = 0.0960993 loss)
I1005 20:44:28.235522 16130 solver.cpp:590] Iteration 7200, lr = 0.01
I1005 20:44:29.354008 16130 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:44:30.780819 16130 solver.cpp:243] Iteration 7300, loss = 0.0992106
I1005 20:44:30.780849 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0992106 (* 1 = 0.0992106 loss)
I1005 20:44:30.780855 16130 solver.cpp:590] Iteration 7300, lr = 0.01
I1005 20:44:33.324903 16130 solver.cpp:243] Iteration 7400, loss = 0.0946198
I1005 20:44:33.324951 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0946198 (* 1 = 0.0946198 loss)
I1005 20:44:33.324959 16130 solver.cpp:590] Iteration 7400, lr = 0.01
I1005 20:44:35.811113 16130 solver.cpp:243] Iteration 7500, loss = 0.0975952
I1005 20:44:35.811156 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0975952 (* 1 = 0.0975952 loss)
I1005 20:44:35.811161 16130 solver.cpp:590] Iteration 7500, lr = 0.01
I1005 20:44:38.343515 16130 solver.cpp:243] Iteration 7600, loss = 0.0979107
I1005 20:44:38.343552 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0979107 (* 1 = 0.0979107 loss)
I1005 20:44:38.343561 16130 solver.cpp:590] Iteration 7600, lr = 0.01
I1005 20:44:40.913573 16130 solver.cpp:243] Iteration 7700, loss = 0.0943576
I1005 20:44:40.913622 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0943576 (* 1 = 0.0943576 loss)
I1005 20:44:40.913630 16130 solver.cpp:590] Iteration 7700, lr = 0.01
I1005 20:44:43.462435 16130 solver.cpp:243] Iteration 7800, loss = 0.0968692
I1005 20:44:43.462478 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0968692 (* 1 = 0.0968692 loss)
I1005 20:44:43.462484 16130 solver.cpp:590] Iteration 7800, lr = 0.01
I1005 20:44:45.995146 16130 solver.cpp:243] Iteration 7900, loss = 0.0991799
I1005 20:44:45.995178 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0991799 (* 1 = 0.0991799 loss)
I1005 20:44:45.995184 16130 solver.cpp:590] Iteration 7900, lr = 0.01
I1005 20:44:48.479836 16130 solver.cpp:347] Iteration 8000, Testing net (#0)
I1005 20:44:48.763109 16130 solver.cpp:415]     Test net output #0: error_blob = 0.118407 (* 1 = 0.118407 loss)
I1005 20:44:48.763818 16130 solver.cpp:243] Iteration 8000, loss = 0.0936098
I1005 20:44:48.763846 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0936098 (* 1 = 0.0936098 loss)
I1005 20:44:48.763854 16130 solver.cpp:590] Iteration 8000, lr = 0.01
I1005 20:44:51.270635 16130 solver.cpp:243] Iteration 8100, loss = 0.0965045
I1005 20:44:51.270675 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0965045 (* 1 = 0.0965045 loss)
I1005 20:44:51.270681 16130 solver.cpp:590] Iteration 8100, lr = 0.01
I1005 20:44:52.507323 16130 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:44:53.763227 16130 solver.cpp:243] Iteration 8200, loss = 0.0992878
I1005 20:44:53.764245 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0992878 (* 1 = 0.0992878 loss)
I1005 20:44:53.764253 16130 solver.cpp:590] Iteration 8200, lr = 0.01
I1005 20:44:56.259083 16130 solver.cpp:243] Iteration 8300, loss = 0.0933875
I1005 20:44:56.259124 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0933875 (* 1 = 0.0933875 loss)
I1005 20:44:56.259142 16130 solver.cpp:590] Iteration 8300, lr = 0.01
I1005 20:44:58.824769 16130 solver.cpp:243] Iteration 8400, loss = 0.0953821
I1005 20:44:58.824801 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0953821 (* 1 = 0.0953821 loss)
I1005 20:44:58.824806 16130 solver.cpp:590] Iteration 8400, lr = 0.01
I1005 20:45:01.355464 16130 solver.cpp:243] Iteration 8500, loss = 0.0991436
I1005 20:45:01.355494 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0991436 (* 1 = 0.0991436 loss)
I1005 20:45:01.355500 16130 solver.cpp:590] Iteration 8500, lr = 0.01
I1005 20:45:03.876569 16130 solver.cpp:243] Iteration 8600, loss = 0.0943308
I1005 20:45:03.876608 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0943308 (* 1 = 0.0943308 loss)
I1005 20:45:03.876617 16130 solver.cpp:590] Iteration 8600, lr = 0.01
I1005 20:45:06.411608 16130 solver.cpp:243] Iteration 8700, loss = 0.0954481
I1005 20:45:06.411641 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0954481 (* 1 = 0.0954481 loss)
I1005 20:45:06.411646 16130 solver.cpp:590] Iteration 8700, lr = 0.01
I1005 20:45:08.955401 16130 solver.cpp:243] Iteration 8800, loss = 0.0964421
I1005 20:45:08.955443 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0964421 (* 1 = 0.0964421 loss)
I1005 20:45:08.955449 16130 solver.cpp:590] Iteration 8800, lr = 0.01
I1005 20:45:11.488167 16130 solver.cpp:243] Iteration 8900, loss = 0.0933321
I1005 20:45:11.488204 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0933321 (* 1 = 0.0933321 loss)
I1005 20:45:11.488212 16130 solver.cpp:590] Iteration 8900, lr = 0.01
I1005 20:45:14.025835 16130 solver.cpp:347] Iteration 9000, Testing net (#0)
I1005 20:45:14.303155 16130 solver.cpp:415]     Test net output #0: error_blob = 0.118513 (* 1 = 0.118513 loss)
I1005 20:45:14.303855 16130 solver.cpp:243] Iteration 9000, loss = 0.0955789
I1005 20:45:14.303884 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0955789 (* 1 = 0.0955789 loss)
I1005 20:45:14.303891 16130 solver.cpp:590] Iteration 9000, lr = 0.01
I1005 20:45:15.665913 16130 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:45:16.763584 16130 solver.cpp:243] Iteration 9100, loss = 0.0957883
I1005 20:45:16.763630 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0957883 (* 1 = 0.0957883 loss)
I1005 20:45:16.763638 16130 solver.cpp:590] Iteration 9100, lr = 0.01
I1005 20:45:19.316929 16130 solver.cpp:243] Iteration 9200, loss = 0.0920104
I1005 20:45:19.316977 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0920104 (* 1 = 0.0920104 loss)
I1005 20:45:19.316987 16130 solver.cpp:590] Iteration 9200, lr = 0.01
I1005 20:45:21.844833 16130 solver.cpp:243] Iteration 9300, loss = 0.0967655
I1005 20:45:21.844880 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0967655 (* 1 = 0.0967655 loss)
I1005 20:45:21.844887 16130 solver.cpp:590] Iteration 9300, lr = 0.01
I1005 20:45:24.379777 16130 solver.cpp:243] Iteration 9400, loss = 0.0929626
I1005 20:45:24.380828 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0929626 (* 1 = 0.0929626 loss)
I1005 20:45:24.380837 16130 solver.cpp:590] Iteration 9400, lr = 0.01
I1005 20:45:26.920202 16130 solver.cpp:243] Iteration 9500, loss = 0.0930117
I1005 20:45:26.920241 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0930117 (* 1 = 0.0930117 loss)
I1005 20:45:26.920249 16130 solver.cpp:590] Iteration 9500, lr = 0.01
I1005 20:45:29.446260 16130 solver.cpp:243] Iteration 9600, loss = 0.0969888
I1005 20:45:29.446302 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0969888 (* 1 = 0.0969888 loss)
I1005 20:45:29.446310 16130 solver.cpp:590] Iteration 9600, lr = 0.01
I1005 20:45:31.956074 16130 solver.cpp:243] Iteration 9700, loss = 0.0928068
I1005 20:45:31.956104 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0928068 (* 1 = 0.0928068 loss)
I1005 20:45:31.956110 16130 solver.cpp:590] Iteration 9700, lr = 0.01
I1005 20:45:34.457547 16130 solver.cpp:243] Iteration 9800, loss = 0.09332
I1005 20:45:34.457578 16130 solver.cpp:259]     Train net output #0: error_blob = 0.09332 (* 1 = 0.09332 loss)
I1005 20:45:34.457583 16130 solver.cpp:590] Iteration 9800, lr = 0.01
I1005 20:45:37.000613 16130 solver.cpp:243] Iteration 9900, loss = 0.0987998
I1005 20:45:37.000663 16130 solver.cpp:259]     Train net output #0: error_blob = 0.0987998 (* 1 = 0.0987998 loss)
I1005 20:45:37.000671 16130 solver.cpp:590] Iteration 9900, lr = 0.01
I1005 20:45:39.520700 16130 solver.cpp:468] Snapshotting to binary proto file _iter_10000.caffemodel
I1005 20:45:39.521986 16130 solver.cpp:753] Snapshotting solver state to binary proto file _iter_10000.solverstate
I1005 20:45:39.545111 16130 solver.cpp:327] Iteration 10000, loss = 0.0924441
I1005 20:45:39.545153 16130 solver.cpp:347] Iteration 10000, Testing net (#0)
I1005 20:45:39.716868 16130 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:45:39.825161 16130 solver.cpp:415]     Test net output #0: error_blob = 0.118455 (* 1 = 0.118455 loss)
I1005 20:45:39.825181 16130 solver.cpp:332] Optimization Done.
I1005 20:45:39.825183 16130 caffe.cpp:215] Optimization Done.
I1005 20:45:39.894778 16140 caffe.cpp:184] Using GPUs 0
I1005 20:45:40.456877 16140 solver.cpp:54] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "fixed"
momentum: 0.9
solver_mode: GPU
device_id: 0
net: "large_batch/model0_part4.prototxt"
I1005 20:45:40.456907 16140 solver.cpp:97] Creating training net from net file: large_batch/model0_part4.prototxt
I1005 20:45:40.457078 16140 net.cpp:339] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_layer
I1005 20:45:40.457125 16140 net.cpp:50] Initializing net from parameters: 
name: "large_batch/model0_part4.prototxt"
state {
  phase: TRAIN
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TRAIN
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.part4.train"
    batch_size: 20000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1005 20:45:40.457207 16140 layer_factory.hpp:76] Creating layer data_layer
I1005 20:45:40.470981 16140 net.cpp:110] Creating Layer data_layer
I1005 20:45:40.471009 16140 net.cpp:433] data_layer -> data_blob
I1005 20:45:40.471043 16140 net.cpp:433] data_layer -> label_blob
I1005 20:45:40.471639 16144 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.part4.train
I1005 20:45:41.157944 16140 data_layer.cpp:45] output data size: 20000,61,1,1
I1005 20:45:41.162901 16140 net.cpp:155] Setting up data_layer
I1005 20:45:41.162943 16140 net.cpp:163] Top shape: 20000 61 1 1 (1220000)
I1005 20:45:41.162946 16140 net.cpp:163] Top shape: 20000 (20000)
I1005 20:45:41.162962 16140 layer_factory.hpp:76] Creating layer hidden_sum_layer
I1005 20:45:41.162974 16140 net.cpp:110] Creating Layer hidden_sum_layer
I1005 20:45:41.162978 16140 net.cpp:477] hidden_sum_layer <- data_blob
I1005 20:45:41.162988 16140 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I1005 20:45:41.163350 16140 net.cpp:155] Setting up hidden_sum_layer
I1005 20:45:41.163358 16140 net.cpp:163] Top shape: 20000 10 (200000)
I1005 20:45:41.163379 16140 layer_factory.hpp:76] Creating layer hidden_act_layer
I1005 20:45:41.163396 16140 net.cpp:110] Creating Layer hidden_act_layer
I1005 20:45:41.163398 16140 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I1005 20:45:41.163403 16140 net.cpp:433] hidden_act_layer -> hidden_act_blob
I1005 20:45:44.389274 16140 net.cpp:155] Setting up hidden_act_layer
I1005 20:45:44.389300 16140 net.cpp:163] Top shape: 20000 10 (200000)
I1005 20:45:44.389307 16140 layer_factory.hpp:76] Creating layer output_sum_layer
I1005 20:45:44.389318 16140 net.cpp:110] Creating Layer output_sum_layer
I1005 20:45:44.389333 16140 net.cpp:477] output_sum_layer <- hidden_act_blob
I1005 20:45:44.389339 16140 net.cpp:433] output_sum_layer -> output_sum_blob
I1005 20:45:44.389453 16140 net.cpp:155] Setting up output_sum_layer
I1005 20:45:44.389458 16140 net.cpp:163] Top shape: 20000 1 (20000)
I1005 20:45:44.389466 16140 layer_factory.hpp:76] Creating layer output_act_layer
I1005 20:45:44.389472 16140 net.cpp:110] Creating Layer output_act_layer
I1005 20:45:44.389473 16140 net.cpp:477] output_act_layer <- output_sum_blob
I1005 20:45:44.389477 16140 net.cpp:433] output_act_layer -> output_act_blob
I1005 20:45:44.389539 16140 net.cpp:155] Setting up output_act_layer
I1005 20:45:44.389570 16140 net.cpp:163] Top shape: 20000 1 (20000)
I1005 20:45:44.389574 16140 layer_factory.hpp:76] Creating layer error_layer
I1005 20:45:44.389578 16140 net.cpp:110] Creating Layer error_layer
I1005 20:45:44.389580 16140 net.cpp:477] error_layer <- output_act_blob
I1005 20:45:44.389583 16140 net.cpp:477] error_layer <- label_blob
I1005 20:45:44.389586 16140 net.cpp:433] error_layer -> error_blob
I1005 20:45:44.389611 16140 net.cpp:155] Setting up error_layer
I1005 20:45:44.389613 16140 net.cpp:163] Top shape: (1)
I1005 20:45:44.389624 16140 net.cpp:168]     with loss weight 1
I1005 20:45:44.389652 16140 net.cpp:236] error_layer needs backward computation.
I1005 20:45:44.389653 16140 net.cpp:236] output_act_layer needs backward computation.
I1005 20:45:44.389655 16140 net.cpp:236] output_sum_layer needs backward computation.
I1005 20:45:44.389657 16140 net.cpp:236] hidden_act_layer needs backward computation.
I1005 20:45:44.389659 16140 net.cpp:236] hidden_sum_layer needs backward computation.
I1005 20:45:44.389662 16140 net.cpp:240] data_layer does not need backward computation.
I1005 20:45:44.389663 16140 net.cpp:283] This network produces output error_blob
I1005 20:45:44.389667 16140 net.cpp:297] Network initialization done.
I1005 20:45:44.389669 16140 net.cpp:298] Memory required for data: 6720004
I1005 20:45:44.389794 16140 solver.cpp:187] Creating test net (#0) specified by net file: large_batch/model0_part4.prototxt
I1005 20:45:44.389806 16140 net.cpp:339] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_layer
I1005 20:45:44.389847 16140 net.cpp:50] Initializing net from parameters: 
name: "large_batch/model0_part4.prototxt"
state {
  phase: TEST
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TEST
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.part4.test"
    batch_size: 2000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1005 20:45:44.389894 16140 layer_factory.hpp:76] Creating layer data_layer
I1005 20:45:44.391062 16140 net.cpp:110] Creating Layer data_layer
I1005 20:45:44.391067 16140 net.cpp:433] data_layer -> data_blob
I1005 20:45:44.391089 16140 net.cpp:433] data_layer -> label_blob
I1005 20:45:44.391669 16146 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.part4.test
I1005 20:45:44.391777 16140 data_layer.cpp:45] output data size: 2000,61,1,1
I1005 20:45:44.393199 16140 net.cpp:155] Setting up data_layer
I1005 20:45:44.393230 16140 net.cpp:163] Top shape: 2000 61 1 1 (122000)
I1005 20:45:44.393234 16140 net.cpp:163] Top shape: 2000 (2000)
I1005 20:45:44.393235 16140 layer_factory.hpp:76] Creating layer hidden_sum_layer
I1005 20:45:44.393241 16140 net.cpp:110] Creating Layer hidden_sum_layer
I1005 20:45:44.393244 16140 net.cpp:477] hidden_sum_layer <- data_blob
I1005 20:45:44.393247 16140 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I1005 20:45:44.393355 16140 net.cpp:155] Setting up hidden_sum_layer
I1005 20:45:44.393370 16140 net.cpp:163] Top shape: 2000 10 (20000)
I1005 20:45:44.393386 16140 layer_factory.hpp:76] Creating layer hidden_act_layer
I1005 20:45:44.393390 16140 net.cpp:110] Creating Layer hidden_act_layer
I1005 20:45:44.393393 16140 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I1005 20:45:44.393415 16140 net.cpp:433] hidden_act_layer -> hidden_act_blob
I1005 20:45:44.393622 16140 net.cpp:155] Setting up hidden_act_layer
I1005 20:45:44.393628 16140 net.cpp:163] Top shape: 2000 10 (20000)
I1005 20:45:44.393641 16140 layer_factory.hpp:76] Creating layer output_sum_layer
I1005 20:45:44.393646 16140 net.cpp:110] Creating Layer output_sum_layer
I1005 20:45:44.393647 16140 net.cpp:477] output_sum_layer <- hidden_act_blob
I1005 20:45:44.393651 16140 net.cpp:433] output_sum_layer -> output_sum_blob
I1005 20:45:44.393717 16140 net.cpp:155] Setting up output_sum_layer
I1005 20:45:44.393721 16140 net.cpp:163] Top shape: 2000 1 (2000)
I1005 20:45:44.393736 16140 layer_factory.hpp:76] Creating layer output_act_layer
I1005 20:45:44.393740 16140 net.cpp:110] Creating Layer output_act_layer
I1005 20:45:44.393743 16140 net.cpp:477] output_act_layer <- output_sum_blob
I1005 20:45:44.393745 16140 net.cpp:433] output_act_layer -> output_act_blob
I1005 20:45:44.393800 16140 net.cpp:155] Setting up output_act_layer
I1005 20:45:44.393805 16140 net.cpp:163] Top shape: 2000 1 (2000)
I1005 20:45:44.393806 16140 layer_factory.hpp:76] Creating layer error_layer
I1005 20:45:44.393821 16140 net.cpp:110] Creating Layer error_layer
I1005 20:45:44.393822 16140 net.cpp:477] error_layer <- output_act_blob
I1005 20:45:44.393824 16140 net.cpp:477] error_layer <- label_blob
I1005 20:45:44.393827 16140 net.cpp:433] error_layer -> error_blob
I1005 20:45:44.393844 16140 net.cpp:155] Setting up error_layer
I1005 20:45:44.393847 16140 net.cpp:163] Top shape: (1)
I1005 20:45:44.393849 16140 net.cpp:168]     with loss weight 1
I1005 20:45:44.393854 16140 net.cpp:236] error_layer needs backward computation.
I1005 20:45:44.393857 16140 net.cpp:236] output_act_layer needs backward computation.
I1005 20:45:44.393859 16140 net.cpp:236] output_sum_layer needs backward computation.
I1005 20:45:44.393860 16140 net.cpp:236] hidden_act_layer needs backward computation.
I1005 20:45:44.393862 16140 net.cpp:236] hidden_sum_layer needs backward computation.
I1005 20:45:44.393864 16140 net.cpp:240] data_layer does not need backward computation.
I1005 20:45:44.393867 16140 net.cpp:283] This network produces output error_blob
I1005 20:45:44.393872 16140 net.cpp:297] Network initialization done.
I1005 20:45:44.393873 16140 net.cpp:298] Memory required for data: 672004
I1005 20:45:44.393889 16140 solver.cpp:66] Solver scaffolding done.
I1005 20:45:44.393983 16140 caffe.cpp:212] Starting Optimization
I1005 20:45:44.393990 16140 solver.cpp:294] Solving large_batch/model0_part4.prototxt
I1005 20:45:44.394001 16140 solver.cpp:295] Learning Rate Policy: fixed
I1005 20:45:44.394172 16140 solver.cpp:347] Iteration 0, Testing net (#0)
I1005 20:45:44.394281 16140 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:45:44.660959 16140 solver.cpp:415]     Test net output #0: error_blob = 0.117097 (* 1 = 0.117097 loss)
I1005 20:45:44.662272 16140 solver.cpp:243] Iteration 0, loss = 0.121271
I1005 20:45:44.662298 16140 solver.cpp:259]     Train net output #0: error_blob = 0.121271 (* 1 = 0.121271 loss)
I1005 20:45:44.662308 16140 solver.cpp:590] Iteration 0, lr = 0.01
I1005 20:45:47.143390 16140 solver.cpp:243] Iteration 100, loss = 0.114346
I1005 20:45:47.143434 16140 solver.cpp:259]     Train net output #0: error_blob = 0.114346 (* 1 = 0.114346 loss)
I1005 20:45:47.143440 16140 solver.cpp:590] Iteration 100, lr = 0.01
I1005 20:45:49.650600 16140 solver.cpp:243] Iteration 200, loss = 0.108987
I1005 20:45:49.650641 16140 solver.cpp:259]     Train net output #0: error_blob = 0.108987 (* 1 = 0.108987 loss)
I1005 20:45:49.650647 16140 solver.cpp:590] Iteration 200, lr = 0.01
I1005 20:45:52.169427 16140 solver.cpp:243] Iteration 300, loss = 0.109875
I1005 20:45:52.169468 16140 solver.cpp:259]     Train net output #0: error_blob = 0.109875 (* 1 = 0.109875 loss)
I1005 20:45:52.169476 16140 solver.cpp:590] Iteration 300, lr = 0.01
I1005 20:45:54.695307 16140 solver.cpp:243] Iteration 400, loss = 0.108715
I1005 20:45:54.695371 16140 solver.cpp:259]     Train net output #0: error_blob = 0.108715 (* 1 = 0.108715 loss)
I1005 20:45:54.695377 16140 solver.cpp:590] Iteration 400, lr = 0.01
I1005 20:45:57.184813 16140 solver.cpp:243] Iteration 500, loss = 0.107856
I1005 20:45:57.184845 16140 solver.cpp:259]     Train net output #0: error_blob = 0.107856 (* 1 = 0.107856 loss)
I1005 20:45:57.184851 16140 solver.cpp:590] Iteration 500, lr = 0.01
I1005 20:45:59.650709 16140 solver.cpp:243] Iteration 600, loss = 0.10489
I1005 20:45:59.650740 16140 solver.cpp:259]     Train net output #0: error_blob = 0.10489 (* 1 = 0.10489 loss)
I1005 20:45:59.650746 16140 solver.cpp:590] Iteration 600, lr = 0.01
I1005 20:46:02.123234 16140 solver.cpp:243] Iteration 700, loss = 0.105175
I1005 20:46:02.123265 16140 solver.cpp:259]     Train net output #0: error_blob = 0.105175 (* 1 = 0.105175 loss)
I1005 20:46:02.123270 16140 solver.cpp:590] Iteration 700, lr = 0.01
I1005 20:46:04.652757 16140 solver.cpp:243] Iteration 800, loss = 0.106821
I1005 20:46:04.652796 16140 solver.cpp:259]     Train net output #0: error_blob = 0.106821 (* 1 = 0.106821 loss)
I1005 20:46:04.652802 16140 solver.cpp:590] Iteration 800, lr = 0.01
I1005 20:46:07.171948 16140 solver.cpp:243] Iteration 900, loss = 0.106626
I1005 20:46:07.171991 16140 solver.cpp:259]     Train net output #0: error_blob = 0.106626 (* 1 = 0.106626 loss)
I1005 20:46:07.171998 16140 solver.cpp:590] Iteration 900, lr = 0.01
I1005 20:46:07.222537 16140 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:46:09.663523 16140 solver.cpp:347] Iteration 1000, Testing net (#0)
I1005 20:46:09.934386 16140 solver.cpp:415]     Test net output #0: error_blob = 0.102823 (* 1 = 0.102823 loss)
I1005 20:46:09.935086 16140 solver.cpp:243] Iteration 1000, loss = 0.105508
I1005 20:46:09.935103 16140 solver.cpp:259]     Train net output #0: error_blob = 0.105508 (* 1 = 0.105508 loss)
I1005 20:46:09.935111 16140 solver.cpp:590] Iteration 1000, lr = 0.01
I1005 20:46:12.406337 16140 solver.cpp:243] Iteration 1100, loss = 0.101958
I1005 20:46:12.406369 16140 solver.cpp:259]     Train net output #0: error_blob = 0.101958 (* 1 = 0.101958 loss)
I1005 20:46:12.406375 16140 solver.cpp:590] Iteration 1100, lr = 0.01
I1005 20:46:14.928081 16140 solver.cpp:243] Iteration 1200, loss = 0.103971
I1005 20:46:14.928112 16140 solver.cpp:259]     Train net output #0: error_blob = 0.103971 (* 1 = 0.103971 loss)
I1005 20:46:14.928118 16140 solver.cpp:590] Iteration 1200, lr = 0.01
I1005 20:46:17.428335 16140 solver.cpp:243] Iteration 1300, loss = 0.103886
I1005 20:46:17.428366 16140 solver.cpp:259]     Train net output #0: error_blob = 0.103886 (* 1 = 0.103886 loss)
I1005 20:46:17.428372 16140 solver.cpp:590] Iteration 1300, lr = 0.01
I1005 20:46:19.915154 16140 solver.cpp:243] Iteration 1400, loss = 0.104462
I1005 20:46:19.915185 16140 solver.cpp:259]     Train net output #0: error_blob = 0.104462 (* 1 = 0.104462 loss)
I1005 20:46:19.915191 16140 solver.cpp:590] Iteration 1400, lr = 0.01
I1005 20:46:22.396404 16140 solver.cpp:243] Iteration 1500, loss = 0.101222
I1005 20:46:22.396432 16140 solver.cpp:259]     Train net output #0: error_blob = 0.101222 (* 1 = 0.101222 loss)
I1005 20:46:22.396437 16140 solver.cpp:590] Iteration 1500, lr = 0.01
I1005 20:46:24.853216 16140 solver.cpp:243] Iteration 1600, loss = 0.101776
I1005 20:46:24.853247 16140 solver.cpp:259]     Train net output #0: error_blob = 0.101776 (* 1 = 0.101776 loss)
I1005 20:46:24.853253 16140 solver.cpp:590] Iteration 1600, lr = 0.01
I1005 20:46:27.349073 16140 solver.cpp:243] Iteration 1700, loss = 0.104734
I1005 20:46:27.349104 16140 solver.cpp:259]     Train net output #0: error_blob = 0.104734 (* 1 = 0.104734 loss)
I1005 20:46:27.349109 16140 solver.cpp:590] Iteration 1700, lr = 0.01
I1005 20:46:29.864140 16140 solver.cpp:243] Iteration 1800, loss = 0.104239
I1005 20:46:29.864167 16140 solver.cpp:259]     Train net output #0: error_blob = 0.104239 (* 1 = 0.104239 loss)
I1005 20:46:29.864173 16140 solver.cpp:590] Iteration 1800, lr = 0.01
I1005 20:46:30.070222 16140 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:46:32.341652 16140 solver.cpp:243] Iteration 1900, loss = 0.103242
I1005 20:46:32.341693 16140 solver.cpp:259]     Train net output #0: error_blob = 0.103242 (* 1 = 0.103242 loss)
I1005 20:46:32.341701 16140 solver.cpp:590] Iteration 1900, lr = 0.01
I1005 20:46:34.857435 16140 solver.cpp:347] Iteration 2000, Testing net (#0)
I1005 20:46:35.165228 16140 solver.cpp:415]     Test net output #0: error_blob = 0.100799 (* 1 = 0.100799 loss)
I1005 20:46:35.165843 16140 solver.cpp:243] Iteration 2000, loss = 0.0994082
I1005 20:46:35.165860 16140 solver.cpp:259]     Train net output #0: error_blob = 0.0994082 (* 1 = 0.0994082 loss)
I1005 20:46:35.165868 16140 solver.cpp:590] Iteration 2000, lr = 0.01
I1005 20:46:37.652179 16140 solver.cpp:243] Iteration 2100, loss = 0.102019
I1005 20:46:37.652214 16140 solver.cpp:259]     Train net output #0: error_blob = 0.102019 (* 1 = 0.102019 loss)
I1005 20:46:37.652221 16140 solver.cpp:590] Iteration 2100, lr = 0.01
I1005 20:46:40.167502 16140 solver.cpp:243] Iteration 2200, loss = 0.101982
I1005 20:46:40.169174 16140 solver.cpp:259]     Train net output #0: error_blob = 0.101982 (* 1 = 0.101982 loss)
I1005 20:46:40.169185 16140 solver.cpp:590] Iteration 2200, lr = 0.01
I1005 20:46:42.669112 16140 solver.cpp:243] Iteration 2300, loss = 0.103731
I1005 20:46:42.669155 16140 solver.cpp:259]     Train net output #0: error_blob = 0.103731 (* 1 = 0.103731 loss)
I1005 20:46:42.669160 16140 solver.cpp:590] Iteration 2300, lr = 0.01
I1005 20:46:45.188362 16140 solver.cpp:243] Iteration 2400, loss = 0.0998722
I1005 20:46:45.188393 16140 solver.cpp:259]     Train net output #0: error_blob = 0.0998722 (* 1 = 0.0998722 loss)
I1005 20:46:45.188398 16140 solver.cpp:590] Iteration 2400, lr = 0.01
I1005 20:46:47.722425 16140 solver.cpp:243] Iteration 2500, loss = 0.0997428
I1005 20:46:47.722455 16140 solver.cpp:259]     Train net output #0: error_blob = 0.0997428 (* 1 = 0.0997428 loss)
I1005 20:46:47.722461 16140 solver.cpp:590] Iteration 2500, lr = 0.01
I1005 20:46:50.260366 16140 solver.cpp:243] Iteration 2600, loss = 0.103369
I1005 20:46:50.260408 16140 solver.cpp:259]     Train net output #0: error_blob = 0.103369 (* 1 = 0.103369 loss)
I1005 20:46:50.260414 16140 solver.cpp:590] Iteration 2600, lr = 0.01
I1005 20:46:52.796401 16140 solver.cpp:243] Iteration 2700, loss = 0.102894
I1005 20:46:52.796432 16140 solver.cpp:259]     Train net output #0: error_blob = 0.102894 (* 1 = 0.102894 loss)
I1005 20:46:52.796437 16140 solver.cpp:590] Iteration 2700, lr = 0.01
I1005 20:46:53.149379 16140 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:46:55.345113 16140 solver.cpp:243] Iteration 2800, loss = 0.102584
I1005 20:46:55.345144 16140 solver.cpp:259]     Train net output #0: error_blob = 0.102584 (* 1 = 0.102584 loss)
I1005 20:46:55.345150 16140 solver.cpp:590] Iteration 2800, lr = 0.01
I1005 20:46:57.865255 16140 solver.cpp:243] Iteration 2900, loss = 0.0981993
I1005 20:46:57.865304 16140 solver.cpp:259]     Train net output #0: error_blob = 0.0981993 (* 1 = 0.0981993 loss)
I1005 20:46:57.865314 16140 solver.cpp:590] Iteration 2900, lr = 0.01
I1005 20:47:00.376453 16140 solver.cpp:347] Iteration 3000, Testing net (#0)
I1005 20:47:00.684620 16140 solver.cpp:415]     Test net output #0: error_blob = 0.0997411 (* 1 = 0.0997411 loss)
I1005 20:47:00.685245 16140 solver.cpp:243] Iteration 3000, loss = 0.100304
I1005 20:47:00.685264 16140 solver.cpp:259]     Train net output #0: error_blob = 0.100304 (* 1 = 0.100304 loss)
I1005 20:47:00.685279 16140 solver.cpp:590] Iteration 3000, lr = 0.01
I1005 20:47:03.140642 16140 solver.cpp:243] Iteration 3100, loss = 0.100918
I1005 20:47:03.140683 16140 solver.cpp:259]     Train net output #0: error_blob = 0.100918 (* 1 = 0.100918 loss)
I1005 20:47:03.140689 16140 solver.cpp:590] Iteration 3100, lr = 0.01
I1005 20:47:05.633008 16140 solver.cpp:243] Iteration 3200, loss = 0.102604
I1005 20:47:05.633056 16140 solver.cpp:259]     Train net output #0: error_blob = 0.102604 (* 1 = 0.102604 loss)
I1005 20:47:05.633064 16140 solver.cpp:590] Iteration 3200, lr = 0.01
I1005 20:47:08.149950 16140 solver.cpp:243] Iteration 3300, loss = 0.0992449
I1005 20:47:08.149993 16140 solver.cpp:259]     Train net output #0: error_blob = 0.0992449 (* 1 = 0.0992449 loss)
I1005 20:47:08.149999 16140 solver.cpp:590] Iteration 3300, lr = 0.01
I1005 20:47:10.668294 16140 solver.cpp:243] Iteration 3400, loss = 0.0987856
I1005 20:47:10.668455 16140 solver.cpp:259]     Train net output #0: error_blob = 0.0987856 (* 1 = 0.0987856 loss)
I1005 20:47:10.668465 16140 solver.cpp:590] Iteration 3400, lr = 0.01
I1005 20:47:13.182809 16140 solver.cpp:243] Iteration 3500, loss = 0.102029
I1005 20:47:13.182840 16140 solver.cpp:259]     Train net output #0: error_blob = 0.102029 (* 1 = 0.102029 loss)
I1005 20:47:13.182847 16140 solver.cpp:590] Iteration 3500, lr = 0.01
I1005 20:47:15.715890 16140 solver.cpp:243] Iteration 3600, loss = 0.101809
I1005 20:47:15.715930 16140 solver.cpp:259]     Train net output #0: error_blob = 0.101809 (* 1 = 0.101809 loss)
I1005 20:47:15.715939 16140 solver.cpp:590] Iteration 3600, lr = 0.01
I1005 20:47:16.225044 16140 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:47:18.241966 16140 solver.cpp:243] Iteration 3700, loss = 0.101761
I1005 20:47:18.242007 16140 solver.cpp:259]     Train net output #0: error_blob = 0.101761 (* 1 = 0.101761 loss)
I1005 20:47:18.242012 16140 solver.cpp:590] Iteration 3700, lr = 0.01
I1005 20:47:20.766597 16140 solver.cpp:243] Iteration 3800, loss = 0.0975773
I1005 20:47:20.766638 16140 solver.cpp:259]     Train net output #0: error_blob = 0.0975773 (* 1 = 0.0975773 loss)
I1005 20:47:20.766644 16140 solver.cpp:590] Iteration 3800, lr = 0.01
I1005 20:47:23.301223 16140 solver.cpp:243] Iteration 3900, loss = 0.0990078
I1005 20:47:23.301254 16140 solver.cpp:259]     Train net output #0: error_blob = 0.0990078 (* 1 = 0.0990078 loss)
I1005 20:47:23.301260 16140 solver.cpp:590] Iteration 3900, lr = 0.01
I1005 20:47:25.811274 16140 solver.cpp:347] Iteration 4000, Testing net (#0)
I1005 20:47:26.092514 16140 solver.cpp:415]     Test net output #0: error_blob = 0.0987411 (* 1 = 0.0987411 loss)
I1005 20:47:26.093163 16140 solver.cpp:243] Iteration 4000, loss = 0.100116
I1005 20:47:26.093188 16140 solver.cpp:259]     Train net output #0: error_blob = 0.100116 (* 1 = 0.100116 loss)
I1005 20:47:26.093194 16140 solver.cpp:590] Iteration 4000, lr = 0.01
I1005 20:47:28.581887 16140 solver.cpp:243] Iteration 4100, loss = 0.10158
I1005 20:47:28.581928 16140 solver.cpp:259]     Train net output #0: error_blob = 0.10158 (* 1 = 0.10158 loss)
I1005 20:47:28.581934 16140 solver.cpp:590] Iteration 4100, lr = 0.01
I1005 20:47:31.082332 16140 solver.cpp:243] Iteration 4200, loss = 0.0985307
I1005 20:47:31.082382 16140 solver.cpp:259]     Train net output #0: error_blob = 0.0985307 (* 1 = 0.0985307 loss)
I1005 20:47:31.082391 16140 solver.cpp:590] Iteration 4200, lr = 0.01
I1005 20:47:33.590832 16140 solver.cpp:243] Iteration 4300, loss = 0.0975765
I1005 20:47:33.590873 16140 solver.cpp:259]     Train net output #0: error_blob = 0.0975765 (* 1 = 0.0975765 loss)
I1005 20:47:33.590879 16140 solver.cpp:590] Iteration 4300, lr = 0.01
I1005 20:47:36.124002 16140 solver.cpp:243] Iteration 4400, loss = 0.100806
I1005 20:47:36.124035 16140 solver.cpp:259]     Train net output #0: error_blob = 0.100806 (* 1 = 0.100806 loss)
I1005 20:47:36.124042 16140 solver.cpp:590] Iteration 4400, lr = 0.01
I1005 20:47:38.669080 16140 solver.cpp:243] Iteration 4500, loss = 0.101243
I1005 20:47:38.669111 16140 solver.cpp:259]     Train net output #0: error_blob = 0.101243 (* 1 = 0.101243 loss)
I1005 20:47:38.669116 16140 solver.cpp:590] Iteration 4500, lr = 0.01
I1005 20:47:39.316754 16140 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:47:41.190206 16140 solver.cpp:243] Iteration 4600, loss = 0.100988
I1005 20:47:41.190292 16140 solver.cpp:259]     Train net output #0: error_blob = 0.100988 (* 1 = 0.100988 loss)
I1005 20:47:41.190299 16140 solver.cpp:590] Iteration 4600, lr = 0.01
I1005 20:47:43.718922 16140 solver.cpp:243] Iteration 4700, loss = 0.0970391
I1005 20:47:43.718961 16140 solver.cpp:259]     Train net output #0: error_blob = 0.0970391 (* 1 = 0.0970391 loss)
I1005 20:47:43.718969 16140 solver.cpp:590] Iteration 4700, lr = 0.01
I1005 20:47:46.234637 16140 solver.cpp:243] Iteration 4800, loss = 0.0981056
I1005 20:47:46.234668 16140 solver.cpp:259]     Train net output #0: error_blob = 0.0981056 (* 1 = 0.0981056 loss)
I1005 20:47:46.234673 16140 solver.cpp:590] Iteration 4800, lr = 0.01
I1005 20:47:48.764999 16140 solver.cpp:243] Iteration 4900, loss = 0.0993331
I1005 20:47:48.765035 16140 solver.cpp:259]     Train net output #0: error_blob = 0.0993331 (* 1 = 0.0993331 loss)
I1005 20:47:48.765043 16140 solver.cpp:590] Iteration 4900, lr = 0.01
I1005 20:47:51.275012 16140 solver.cpp:347] Iteration 5000, Testing net (#0)
I1005 20:47:51.576619 16140 solver.cpp:415]     Test net output #0: error_blob = 0.0978073 (* 1 = 0.0978073 loss)
I1005 20:47:51.577219 16140 solver.cpp:243] Iteration 5000, loss = 0.101198
I1005 20:47:51.577234 16140 solver.cpp:259]     Train net output #0: error_blob = 0.101198 (* 1 = 0.101198 loss)
I1005 20:47:51.577241 16140 solver.cpp:590] Iteration 5000, lr = 0.01
I1005 20:47:54.038074 16140 solver.cpp:243] Iteration 5100, loss = 0.0978028
I1005 20:47:54.038106 16140 solver.cpp:259]     Train net output #0: error_blob = 0.0978028 (* 1 = 0.0978028 loss)
I1005 20:47:54.038113 16140 solver.cpp:590] Iteration 5100, lr = 0.01
I1005 20:47:56.554514 16140 solver.cpp:243] Iteration 5200, loss = 0.0957438
I1005 20:47:56.554563 16140 solver.cpp:259]     Train net output #0: error_blob = 0.0957438 (* 1 = 0.0957438 loss)
I1005 20:47:56.554572 16140 solver.cpp:590] Iteration 5200, lr = 0.01
I1005 20:47:59.109305 16140 solver.cpp:243] Iteration 5300, loss = 0.0996055
I1005 20:47:59.109344 16140 solver.cpp:259]     Train net output #0: error_blob = 0.0996055 (* 1 = 0.0996055 loss)
I1005 20:47:59.109351 16140 solver.cpp:590] Iteration 5300, lr = 0.01
I1005 20:48:01.633522 16140 solver.cpp:243] Iteration 5400, loss = 0.100648
I1005 20:48:01.633561 16140 solver.cpp:259]     Train net output #0: error_blob = 0.100648 (* 1 = 0.100648 loss)
I1005 20:48:01.633569 16140 solver.cpp:590] Iteration 5400, lr = 0.01
I1005 20:48:02.440174 16140 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:48:04.166832 16140 solver.cpp:243] Iteration 5500, loss = 0.100304
I1005 20:48:04.166872 16140 solver.cpp:259]     Train net output #0: error_blob = 0.100304 (* 1 = 0.100304 loss)
I1005 20:48:04.166877 16140 solver.cpp:590] Iteration 5500, lr = 0.01
I1005 20:48:06.677821 16140 solver.cpp:243] Iteration 5600, loss = 0.0965084
I1005 20:48:06.677856 16140 solver.cpp:259]     Train net output #0: error_blob = 0.0965084 (* 1 = 0.0965084 loss)
I1005 20:48:06.677863 16140 solver.cpp:590] Iteration 5600, lr = 0.01
I1005 20:48:09.221364 16140 solver.cpp:243] Iteration 5700, loss = 0.0973415
I1005 20:48:09.221405 16140 solver.cpp:259]     Train net output #0: error_blob = 0.0973415 (* 1 = 0.0973415 loss)
I1005 20:48:09.221413 16140 solver.cpp:590] Iteration 5700, lr = 0.01
I1005 20:48:11.757518 16140 solver.cpp:243] Iteration 5800, loss = 0.0988329
I1005 20:48:11.757643 16140 solver.cpp:259]     Train net output #0: error_blob = 0.0988329 (* 1 = 0.0988329 loss)
I1005 20:48:11.757652 16140 solver.cpp:590] Iteration 5800, lr = 0.01
I1005 20:48:14.269517 16140 solver.cpp:243] Iteration 5900, loss = 0.10075
I1005 20:48:14.269549 16140 solver.cpp:259]     Train net output #0: error_blob = 0.10075 (* 1 = 0.10075 loss)
I1005 20:48:14.269554 16140 solver.cpp:590] Iteration 5900, lr = 0.01
I1005 20:48:16.771666 16140 solver.cpp:347] Iteration 6000, Testing net (#0)
I1005 20:48:17.056082 16140 solver.cpp:415]     Test net output #0: error_blob = 0.0969801 (* 1 = 0.0969801 loss)
I1005 20:48:17.056751 16140 solver.cpp:243] Iteration 6000, loss = 0.0970573
I1005 20:48:17.056768 16140 solver.cpp:259]     Train net output #0: error_blob = 0.0970573 (* 1 = 0.0970573 loss)
I1005 20:48:17.056776 16140 solver.cpp:590] Iteration 6000, lr = 0.01
I1005 20:48:19.550367 16140 solver.cpp:243] Iteration 6100, loss = 0.0949088
I1005 20:48:19.550398 16140 solver.cpp:259]     Train net output #0: error_blob = 0.0949088 (* 1 = 0.0949088 loss)
I1005 20:48:19.550406 16140 solver.cpp:590] Iteration 6100, lr = 0.01
I1005 20:48:22.062155 16140 solver.cpp:243] Iteration 6200, loss = 0.0985326
I1005 20:48:22.062204 16140 solver.cpp:259]     Train net output #0: error_blob = 0.0985326 (* 1 = 0.0985326 loss)
I1005 20:48:22.062212 16140 solver.cpp:590] Iteration 6200, lr = 0.01
I1005 20:48:24.591702 16140 solver.cpp:243] Iteration 6300, loss = 0.100017
I1005 20:48:24.591742 16140 solver.cpp:259]     Train net output #0: error_blob = 0.100017 (* 1 = 0.100017 loss)
I1005 20:48:24.591749 16140 solver.cpp:590] Iteration 6300, lr = 0.01
I1005 20:48:25.546741 16140 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:48:27.137907 16140 solver.cpp:243] Iteration 6400, loss = 0.0995114
I1005 20:48:27.137948 16140 solver.cpp:259]     Train net output #0: error_blob = 0.0995114 (* 1 = 0.0995114 loss)
I1005 20:48:27.137954 16140 solver.cpp:590] Iteration 6400, lr = 0.01
I1005 20:48:29.637048 16140 solver.cpp:243] Iteration 6500, loss = 0.0961838
I1005 20:48:29.637086 16140 solver.cpp:259]     Train net output #0: error_blob = 0.0961838 (* 1 = 0.0961838 loss)
I1005 20:48:29.637095 16140 solver.cpp:590] Iteration 6500, lr = 0.01
I1005 20:48:32.158483 16140 solver.cpp:243] Iteration 6600, loss = 0.0966783
I1005 20:48:32.158531 16140 solver.cpp:259]     Train net output #0: error_blob = 0.0966783 (* 1 = 0.0966783 loss)
I1005 20:48:32.158540 16140 solver.cpp:590] Iteration 6600, lr = 0.01
I1005 20:48:34.697540 16140 solver.cpp:243] Iteration 6700, loss = 0.0983073
I1005 20:48:34.697582 16140 solver.cpp:259]     Train net output #0: error_blob = 0.0983073 (* 1 = 0.0983073 loss)
I1005 20:48:34.697587 16140 solver.cpp:590] Iteration 6700, lr = 0.01
I1005 20:48:37.206604 16140 solver.cpp:243] Iteration 6800, loss = 0.100264
I1005 20:48:37.206634 16140 solver.cpp:259]     Train net output #0: error_blob = 0.100264 (* 1 = 0.100264 loss)
I1005 20:48:37.206639 16140 solver.cpp:590] Iteration 6800, lr = 0.01
I1005 20:48:39.748412 16140 solver.cpp:243] Iteration 6900, loss = 0.0963662
I1005 20:48:39.748455 16140 solver.cpp:259]     Train net output #0: error_blob = 0.0963662 (* 1 = 0.0963662 loss)
I1005 20:48:39.748461 16140 solver.cpp:590] Iteration 6900, lr = 0.01
I1005 20:48:42.243553 16140 solver.cpp:347] Iteration 7000, Testing net (#0)
I1005 20:48:42.526270 16140 solver.cpp:415]     Test net output #0: error_blob = 0.0962833 (* 1 = 0.0962833 loss)
I1005 20:48:42.526903 16140 solver.cpp:243] Iteration 7000, loss = 0.0947331
I1005 20:48:42.526918 16140 solver.cpp:259]     Train net output #0: error_blob = 0.0947331 (* 1 = 0.0947331 loss)
I1005 20:48:42.526924 16140 solver.cpp:590] Iteration 7000, lr = 0.01
I1005 20:48:44.957744 16140 solver.cpp:243] Iteration 7100, loss = 0.0978001
I1005 20:48:44.957779 16140 solver.cpp:259]     Train net output #0: error_blob = 0.0978001 (* 1 = 0.0978001 loss)
I1005 20:48:44.957787 16140 solver.cpp:590] Iteration 7100, lr = 0.01
I1005 20:48:47.462734 16140 solver.cpp:243] Iteration 7200, loss = 0.0995642
I1005 20:48:47.462764 16140 solver.cpp:259]     Train net output #0: error_blob = 0.0995642 (* 1 = 0.0995642 loss)
I1005 20:48:47.462769 16140 solver.cpp:590] Iteration 7200, lr = 0.01
I1005 20:48:48.545063 16140 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:48:49.985178 16140 solver.cpp:243] Iteration 7300, loss = 0.0988875
I1005 20:48:49.985213 16140 solver.cpp:259]     Train net output #0: error_blob = 0.0988875 (* 1 = 0.0988875 loss)
I1005 20:48:49.985221 16140 solver.cpp:590] Iteration 7300, lr = 0.01
I1005 20:48:52.455153 16140 solver.cpp:243] Iteration 7400, loss = 0.095438
I1005 20:48:52.455184 16140 solver.cpp:259]     Train net output #0: error_blob = 0.095438 (* 1 = 0.095438 loss)
I1005 20:48:52.455189 16140 solver.cpp:590] Iteration 7400, lr = 0.01
I1005 20:48:54.955467 16140 solver.cpp:243] Iteration 7500, loss = 0.0962064
I1005 20:48:54.955498 16140 solver.cpp:259]     Train net output #0: error_blob = 0.0962064 (* 1 = 0.0962064 loss)
I1005 20:48:54.955503 16140 solver.cpp:590] Iteration 7500, lr = 0.01
I1005 20:48:57.459556 16140 solver.cpp:243] Iteration 7600, loss = 0.0975033
I1005 20:48:57.459586 16140 solver.cpp:259]     Train net output #0: error_blob = 0.0975033 (* 1 = 0.0975033 loss)
I1005 20:48:57.459594 16140 solver.cpp:590] Iteration 7600, lr = 0.01
I1005 20:48:59.976183 16140 solver.cpp:243] Iteration 7700, loss = 0.0996216
I1005 20:48:59.976215 16140 solver.cpp:259]     Train net output #0: error_blob = 0.0996216 (* 1 = 0.0996216 loss)
I1005 20:48:59.976222 16140 solver.cpp:590] Iteration 7700, lr = 0.01
I1005 20:49:02.496238 16140 solver.cpp:243] Iteration 7800, loss = 0.0958196
I1005 20:49:02.496271 16140 solver.cpp:259]     Train net output #0: error_blob = 0.0958196 (* 1 = 0.0958196 loss)
I1005 20:49:02.496279 16140 solver.cpp:590] Iteration 7800, lr = 0.01
I1005 20:49:04.983294 16140 solver.cpp:243] Iteration 7900, loss = 0.0944354
I1005 20:49:04.983328 16140 solver.cpp:259]     Train net output #0: error_blob = 0.0944354 (* 1 = 0.0944354 loss)
I1005 20:49:04.983337 16140 solver.cpp:590] Iteration 7900, lr = 0.01
I1005 20:49:07.483341 16140 solver.cpp:347] Iteration 8000, Testing net (#0)
I1005 20:49:07.772101 16140 solver.cpp:415]     Test net output #0: error_blob = 0.0957285 (* 1 = 0.0957285 loss)
I1005 20:49:07.772723 16140 solver.cpp:243] Iteration 8000, loss = 0.0975852
I1005 20:49:07.772738 16140 solver.cpp:259]     Train net output #0: error_blob = 0.0975852 (* 1 = 0.0975852 loss)
I1005 20:49:07.772742 16140 solver.cpp:590] Iteration 8000, lr = 0.01
I1005 20:49:10.358603 16140 solver.cpp:243] Iteration 8100, loss = 0.0995424
I1005 20:49:10.358636 16140 solver.cpp:259]     Train net output #0: error_blob = 0.0995424 (* 1 = 0.0995424 loss)
I1005 20:49:10.358641 16140 solver.cpp:590] Iteration 8100, lr = 0.01
I1005 20:49:11.604607 16140 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:49:12.865344 16140 solver.cpp:243] Iteration 8200, loss = 0.0982884
I1005 20:49:12.865452 16140 solver.cpp:259]     Train net output #0: error_blob = 0.0982884 (* 1 = 0.0982884 loss)
I1005 20:49:12.865458 16140 solver.cpp:590] Iteration 8200, lr = 0.01
I1005 20:49:15.358674 16140 solver.cpp:243] Iteration 8300, loss = 0.0945887
I1005 20:49:15.358708 16140 solver.cpp:259]     Train net output #0: error_blob = 0.0945887 (* 1 = 0.0945887 loss)
I1005 20:49:15.358713 16140 solver.cpp:590] Iteration 8300, lr = 0.01
I1005 20:49:17.899967 16140 solver.cpp:243] Iteration 8400, loss = 0.0958113
I1005 20:49:17.900002 16140 solver.cpp:259]     Train net output #0: error_blob = 0.0958113 (* 1 = 0.0958113 loss)
I1005 20:49:17.900010 16140 solver.cpp:590] Iteration 8400, lr = 0.01
I1005 20:49:20.390844 16140 solver.cpp:243] Iteration 8500, loss = 0.0971276
I1005 20:49:20.390877 16140 solver.cpp:259]     Train net output #0: error_blob = 0.0971276 (* 1 = 0.0971276 loss)
I1005 20:49:20.390885 16140 solver.cpp:590] Iteration 8500, lr = 0.01
I1005 20:49:22.866852 16140 solver.cpp:243] Iteration 8600, loss = 0.0993878
I1005 20:49:22.866885 16140 solver.cpp:259]     Train net output #0: error_blob = 0.0993878 (* 1 = 0.0993878 loss)
I1005 20:49:22.866895 16140 solver.cpp:590] Iteration 8600, lr = 0.01
I1005 20:49:25.346570 16140 solver.cpp:243] Iteration 8700, loss = 0.095297
I1005 20:49:25.346598 16140 solver.cpp:259]     Train net output #0: error_blob = 0.095297 (* 1 = 0.095297 loss)
I1005 20:49:25.346604 16140 solver.cpp:590] Iteration 8700, lr = 0.01
I1005 20:49:27.821713 16140 solver.cpp:243] Iteration 8800, loss = 0.0935225
I1005 20:49:27.821744 16140 solver.cpp:259]     Train net output #0: error_blob = 0.0935225 (* 1 = 0.0935225 loss)
I1005 20:49:27.821750 16140 solver.cpp:590] Iteration 8800, lr = 0.01
I1005 20:49:30.279865 16140 solver.cpp:243] Iteration 8900, loss = 0.0975135
I1005 20:49:30.279896 16140 solver.cpp:259]     Train net output #0: error_blob = 0.0975135 (* 1 = 0.0975135 loss)
I1005 20:49:30.279901 16140 solver.cpp:590] Iteration 8900, lr = 0.01
I1005 20:49:32.739946 16140 solver.cpp:347] Iteration 9000, Testing net (#0)
I1005 20:49:33.032579 16140 solver.cpp:415]     Test net output #0: error_blob = 0.0953099 (* 1 = 0.0953099 loss)
I1005 20:49:33.033222 16140 solver.cpp:243] Iteration 9000, loss = 0.0995915
I1005 20:49:33.033236 16140 solver.cpp:259]     Train net output #0: error_blob = 0.0995915 (* 1 = 0.0995915 loss)
I1005 20:49:33.033241 16140 solver.cpp:590] Iteration 9000, lr = 0.01
I1005 20:49:34.381508 16140 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:49:35.468041 16140 solver.cpp:243] Iteration 9100, loss = 0.0980782
I1005 20:49:35.468075 16140 solver.cpp:259]     Train net output #0: error_blob = 0.0980782 (* 1 = 0.0980782 loss)
I1005 20:49:35.468080 16140 solver.cpp:590] Iteration 9100, lr = 0.01
I1005 20:49:37.952277 16140 solver.cpp:243] Iteration 9200, loss = 0.094021
I1005 20:49:37.952308 16140 solver.cpp:259]     Train net output #0: error_blob = 0.094021 (* 1 = 0.094021 loss)
I1005 20:49:37.952314 16140 solver.cpp:590] Iteration 9200, lr = 0.01
I1005 20:49:40.481297 16140 solver.cpp:243] Iteration 9300, loss = 0.0953485
I1005 20:49:40.481328 16140 solver.cpp:259]     Train net output #0: error_blob = 0.0953485 (* 1 = 0.0953485 loss)
I1005 20:49:40.481336 16140 solver.cpp:590] Iteration 9300, lr = 0.01
I1005 20:49:42.989565 16140 solver.cpp:243] Iteration 9400, loss = 0.0967913
I1005 20:49:42.989972 16140 solver.cpp:259]     Train net output #0: error_blob = 0.0967913 (* 1 = 0.0967913 loss)
I1005 20:49:42.989984 16140 solver.cpp:590] Iteration 9400, lr = 0.01
I1005 20:49:45.489742 16140 solver.cpp:243] Iteration 9500, loss = 0.0990501
I1005 20:49:45.489771 16140 solver.cpp:259]     Train net output #0: error_blob = 0.0990501 (* 1 = 0.0990501 loss)
I1005 20:49:45.489778 16140 solver.cpp:590] Iteration 9500, lr = 0.01
I1005 20:49:47.956815 16140 solver.cpp:243] Iteration 9600, loss = 0.0945217
I1005 20:49:47.956845 16140 solver.cpp:259]     Train net output #0: error_blob = 0.0945217 (* 1 = 0.0945217 loss)
I1005 20:49:47.956851 16140 solver.cpp:590] Iteration 9600, lr = 0.01
I1005 20:49:50.455359 16140 solver.cpp:243] Iteration 9700, loss = 0.0930639
I1005 20:49:50.455401 16140 solver.cpp:259]     Train net output #0: error_blob = 0.0930639 (* 1 = 0.0930639 loss)
I1005 20:49:50.455409 16140 solver.cpp:590] Iteration 9700, lr = 0.01
I1005 20:49:52.959553 16140 solver.cpp:243] Iteration 9800, loss = 0.0970559
I1005 20:49:52.959583 16140 solver.cpp:259]     Train net output #0: error_blob = 0.0970559 (* 1 = 0.0970559 loss)
I1005 20:49:52.959589 16140 solver.cpp:590] Iteration 9800, lr = 0.01
I1005 20:49:55.466045 16140 solver.cpp:243] Iteration 9900, loss = 0.0988999
I1005 20:49:55.466086 16140 solver.cpp:259]     Train net output #0: error_blob = 0.0988999 (* 1 = 0.0988999 loss)
I1005 20:49:55.466092 16140 solver.cpp:590] Iteration 9900, lr = 0.01
I1005 20:49:57.945236 16140 solver.cpp:468] Snapshotting to binary proto file _iter_10000.caffemodel
I1005 20:49:57.946087 16140 solver.cpp:753] Snapshotting solver state to binary proto file _iter_10000.solverstate
I1005 20:49:57.970473 16140 solver.cpp:327] Iteration 10000, loss = 0.0975526
I1005 20:49:57.970510 16140 solver.cpp:347] Iteration 10000, Testing net (#0)
I1005 20:49:58.136669 16140 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:49:58.239629 16140 solver.cpp:415]     Test net output #0: error_blob = 0.0950738 (* 1 = 0.0950738 loss)
I1005 20:49:58.239650 16140 solver.cpp:332] Optimization Done.
I1005 20:49:58.239655 16140 caffe.cpp:215] Optimization Done.
I1005 20:49:58.306623 16150 caffe.cpp:184] Using GPUs 0
I1005 20:49:58.869009 16150 solver.cpp:54] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "fixed"
momentum: 0.9
solver_mode: GPU
device_id: 0
net: "large_batch/model0_part1.prototxt"
I1005 20:49:58.869038 16150 solver.cpp:97] Creating training net from net file: large_batch/model0_part1.prototxt
I1005 20:49:58.869209 16150 net.cpp:339] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_layer
I1005 20:49:58.869254 16150 net.cpp:50] Initializing net from parameters: 
name: "large_batch/model0_part1.prototxt"
state {
  phase: TRAIN
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TRAIN
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.part1.train"
    batch_size: 20000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1005 20:49:58.869319 16150 layer_factory.hpp:76] Creating layer data_layer
I1005 20:49:58.882637 16150 net.cpp:110] Creating Layer data_layer
I1005 20:49:58.882666 16150 net.cpp:433] data_layer -> data_blob
I1005 20:49:58.882697 16150 net.cpp:433] data_layer -> label_blob
I1005 20:49:58.883301 16155 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.part1.train
I1005 20:49:59.568195 16150 data_layer.cpp:45] output data size: 20000,61,1,1
I1005 20:49:59.573159 16150 net.cpp:155] Setting up data_layer
I1005 20:49:59.573201 16150 net.cpp:163] Top shape: 20000 61 1 1 (1220000)
I1005 20:49:59.573206 16150 net.cpp:163] Top shape: 20000 (20000)
I1005 20:49:59.573222 16150 layer_factory.hpp:76] Creating layer hidden_sum_layer
I1005 20:49:59.573235 16150 net.cpp:110] Creating Layer hidden_sum_layer
I1005 20:49:59.573238 16150 net.cpp:477] hidden_sum_layer <- data_blob
I1005 20:49:59.573247 16150 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I1005 20:49:59.573628 16150 net.cpp:155] Setting up hidden_sum_layer
I1005 20:49:59.573635 16150 net.cpp:163] Top shape: 20000 10 (200000)
I1005 20:49:59.573657 16150 layer_factory.hpp:76] Creating layer hidden_act_layer
I1005 20:49:59.573674 16150 net.cpp:110] Creating Layer hidden_act_layer
I1005 20:49:59.573676 16150 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I1005 20:49:59.573679 16150 net.cpp:433] hidden_act_layer -> hidden_act_blob
I1005 20:50:02.793025 16150 net.cpp:155] Setting up hidden_act_layer
I1005 20:50:02.793058 16150 net.cpp:163] Top shape: 20000 10 (200000)
I1005 20:50:02.793063 16150 layer_factory.hpp:76] Creating layer output_sum_layer
I1005 20:50:02.793073 16150 net.cpp:110] Creating Layer output_sum_layer
I1005 20:50:02.793076 16150 net.cpp:477] output_sum_layer <- hidden_act_blob
I1005 20:50:02.793081 16150 net.cpp:433] output_sum_layer -> output_sum_blob
I1005 20:50:02.793174 16150 net.cpp:155] Setting up output_sum_layer
I1005 20:50:02.793179 16150 net.cpp:163] Top shape: 20000 1 (20000)
I1005 20:50:02.793196 16150 layer_factory.hpp:76] Creating layer output_act_layer
I1005 20:50:02.793202 16150 net.cpp:110] Creating Layer output_act_layer
I1005 20:50:02.793205 16150 net.cpp:477] output_act_layer <- output_sum_blob
I1005 20:50:02.793207 16150 net.cpp:433] output_act_layer -> output_act_blob
I1005 20:50:02.793272 16150 net.cpp:155] Setting up output_act_layer
I1005 20:50:02.793292 16150 net.cpp:163] Top shape: 20000 1 (20000)
I1005 20:50:02.793306 16150 layer_factory.hpp:76] Creating layer error_layer
I1005 20:50:02.793311 16150 net.cpp:110] Creating Layer error_layer
I1005 20:50:02.793313 16150 net.cpp:477] error_layer <- output_act_blob
I1005 20:50:02.793316 16150 net.cpp:477] error_layer <- label_blob
I1005 20:50:02.793320 16150 net.cpp:433] error_layer -> error_blob
I1005 20:50:02.793344 16150 net.cpp:155] Setting up error_layer
I1005 20:50:02.793347 16150 net.cpp:163] Top shape: (1)
I1005 20:50:02.793349 16150 net.cpp:168]     with loss weight 1
I1005 20:50:02.793365 16150 net.cpp:236] error_layer needs backward computation.
I1005 20:50:02.793367 16150 net.cpp:236] output_act_layer needs backward computation.
I1005 20:50:02.793370 16150 net.cpp:236] output_sum_layer needs backward computation.
I1005 20:50:02.793371 16150 net.cpp:236] hidden_act_layer needs backward computation.
I1005 20:50:02.793373 16150 net.cpp:236] hidden_sum_layer needs backward computation.
I1005 20:50:02.793375 16150 net.cpp:240] data_layer does not need backward computation.
I1005 20:50:02.793377 16150 net.cpp:283] This network produces output error_blob
I1005 20:50:02.793381 16150 net.cpp:297] Network initialization done.
I1005 20:50:02.793383 16150 net.cpp:298] Memory required for data: 6720004
I1005 20:50:02.793517 16150 solver.cpp:187] Creating test net (#0) specified by net file: large_batch/model0_part1.prototxt
I1005 20:50:02.793540 16150 net.cpp:339] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_layer
I1005 20:50:02.793570 16150 net.cpp:50] Initializing net from parameters: 
name: "large_batch/model0_part1.prototxt"
state {
  phase: TEST
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TEST
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.part1.test"
    batch_size: 2000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1005 20:50:02.793608 16150 layer_factory.hpp:76] Creating layer data_layer
I1005 20:50:02.794816 16150 net.cpp:110] Creating Layer data_layer
I1005 20:50:02.794831 16150 net.cpp:433] data_layer -> data_blob
I1005 20:50:02.794836 16150 net.cpp:433] data_layer -> label_blob
I1005 20:50:02.795400 16157 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.part1.test
I1005 20:50:02.796576 16150 data_layer.cpp:45] output data size: 2000,61,1,1
I1005 20:50:02.798230 16150 net.cpp:155] Setting up data_layer
I1005 20:50:02.798254 16150 net.cpp:163] Top shape: 2000 61 1 1 (122000)
I1005 20:50:02.798259 16150 net.cpp:163] Top shape: 2000 (2000)
I1005 20:50:02.798264 16150 layer_factory.hpp:76] Creating layer hidden_sum_layer
I1005 20:50:02.798272 16150 net.cpp:110] Creating Layer hidden_sum_layer
I1005 20:50:02.798276 16150 net.cpp:477] hidden_sum_layer <- data_blob
I1005 20:50:02.798281 16150 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I1005 20:50:02.798450 16150 net.cpp:155] Setting up hidden_sum_layer
I1005 20:50:02.798460 16150 net.cpp:163] Top shape: 2000 10 (20000)
I1005 20:50:02.798470 16150 layer_factory.hpp:76] Creating layer hidden_act_layer
I1005 20:50:02.798476 16150 net.cpp:110] Creating Layer hidden_act_layer
I1005 20:50:02.798480 16150 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I1005 20:50:02.798494 16150 net.cpp:433] hidden_act_layer -> hidden_act_blob
I1005 20:50:02.798758 16150 net.cpp:155] Setting up hidden_act_layer
I1005 20:50:02.798768 16150 net.cpp:163] Top shape: 2000 10 (20000)
I1005 20:50:02.798773 16150 layer_factory.hpp:76] Creating layer output_sum_layer
I1005 20:50:02.798779 16150 net.cpp:110] Creating Layer output_sum_layer
I1005 20:50:02.798782 16150 net.cpp:477] output_sum_layer <- hidden_act_blob
I1005 20:50:02.798787 16150 net.cpp:433] output_sum_layer -> output_sum_blob
I1005 20:50:02.798874 16150 net.cpp:155] Setting up output_sum_layer
I1005 20:50:02.798882 16150 net.cpp:163] Top shape: 2000 1 (2000)
I1005 20:50:02.798889 16150 layer_factory.hpp:76] Creating layer output_act_layer
I1005 20:50:02.798895 16150 net.cpp:110] Creating Layer output_act_layer
I1005 20:50:02.798900 16150 net.cpp:477] output_act_layer <- output_sum_blob
I1005 20:50:02.798904 16150 net.cpp:433] output_act_layer -> output_act_blob
I1005 20:50:02.798975 16150 net.cpp:155] Setting up output_act_layer
I1005 20:50:02.798981 16150 net.cpp:163] Top shape: 2000 1 (2000)
I1005 20:50:02.798985 16150 layer_factory.hpp:76] Creating layer error_layer
I1005 20:50:02.798990 16150 net.cpp:110] Creating Layer error_layer
I1005 20:50:02.798995 16150 net.cpp:477] error_layer <- output_act_blob
I1005 20:50:02.799000 16150 net.cpp:477] error_layer <- label_blob
I1005 20:50:02.799005 16150 net.cpp:433] error_layer -> error_blob
I1005 20:50:02.799032 16150 net.cpp:155] Setting up error_layer
I1005 20:50:02.799038 16150 net.cpp:163] Top shape: (1)
I1005 20:50:02.799043 16150 net.cpp:168]     with loss weight 1
I1005 20:50:02.799054 16150 net.cpp:236] error_layer needs backward computation.
I1005 20:50:02.799057 16150 net.cpp:236] output_act_layer needs backward computation.
I1005 20:50:02.799062 16150 net.cpp:236] output_sum_layer needs backward computation.
I1005 20:50:02.799064 16150 net.cpp:236] hidden_act_layer needs backward computation.
I1005 20:50:02.799067 16150 net.cpp:236] hidden_sum_layer needs backward computation.
I1005 20:50:02.799072 16150 net.cpp:240] data_layer does not need backward computation.
I1005 20:50:02.799074 16150 net.cpp:283] This network produces output error_blob
I1005 20:50:02.799082 16150 net.cpp:297] Network initialization done.
I1005 20:50:02.799084 16150 net.cpp:298] Memory required for data: 672004
I1005 20:50:02.799109 16150 solver.cpp:66] Solver scaffolding done.
I1005 20:50:02.799240 16150 caffe.cpp:212] Starting Optimization
I1005 20:50:02.799250 16150 solver.cpp:294] Solving large_batch/model0_part1.prototxt
I1005 20:50:02.799254 16150 solver.cpp:295] Learning Rate Policy: fixed
I1005 20:50:02.799531 16150 solver.cpp:347] Iteration 0, Testing net (#0)
I1005 20:50:02.799602 16150 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:50:03.057649 16150 solver.cpp:415]     Test net output #0: error_blob = 0.122344 (* 1 = 0.122344 loss)
I1005 20:50:03.058962 16150 solver.cpp:243] Iteration 0, loss = 0.122548
I1005 20:50:03.058981 16150 solver.cpp:259]     Train net output #0: error_blob = 0.122548 (* 1 = 0.122548 loss)
I1005 20:50:03.058993 16150 solver.cpp:590] Iteration 0, lr = 0.01
I1005 20:50:05.555294 16150 solver.cpp:243] Iteration 100, loss = 0.110791
I1005 20:50:05.555325 16150 solver.cpp:259]     Train net output #0: error_blob = 0.110791 (* 1 = 0.110791 loss)
I1005 20:50:05.555331 16150 solver.cpp:590] Iteration 100, lr = 0.01
I1005 20:50:08.035725 16150 solver.cpp:243] Iteration 200, loss = 0.110144
I1005 20:50:08.035766 16150 solver.cpp:259]     Train net output #0: error_blob = 0.110144 (* 1 = 0.110144 loss)
I1005 20:50:08.035773 16150 solver.cpp:590] Iteration 200, lr = 0.01
I1005 20:50:10.519307 16150 solver.cpp:243] Iteration 300, loss = 0.106366
I1005 20:50:10.519338 16150 solver.cpp:259]     Train net output #0: error_blob = 0.106366 (* 1 = 0.106366 loss)
I1005 20:50:10.519343 16150 solver.cpp:590] Iteration 300, lr = 0.01
I1005 20:50:13.006232 16150 solver.cpp:243] Iteration 400, loss = 0.108931
I1005 20:50:13.006291 16150 solver.cpp:259]     Train net output #0: error_blob = 0.108931 (* 1 = 0.108931 loss)
I1005 20:50:13.006297 16150 solver.cpp:590] Iteration 400, lr = 0.01
I1005 20:50:15.509080 16150 solver.cpp:243] Iteration 500, loss = 0.105501
I1005 20:50:15.509127 16150 solver.cpp:259]     Train net output #0: error_blob = 0.105501 (* 1 = 0.105501 loss)
I1005 20:50:15.509136 16150 solver.cpp:590] Iteration 500, lr = 0.01
I1005 20:50:17.978762 16150 solver.cpp:243] Iteration 600, loss = 0.106953
I1005 20:50:17.978812 16150 solver.cpp:259]     Train net output #0: error_blob = 0.106953 (* 1 = 0.106953 loss)
I1005 20:50:17.978821 16150 solver.cpp:590] Iteration 600, lr = 0.01
I1005 20:50:20.458528 16150 solver.cpp:243] Iteration 700, loss = 0.105475
I1005 20:50:20.458561 16150 solver.cpp:259]     Train net output #0: error_blob = 0.105475 (* 1 = 0.105475 loss)
I1005 20:50:20.458569 16150 solver.cpp:590] Iteration 700, lr = 0.01
I1005 20:50:22.938946 16150 solver.cpp:243] Iteration 800, loss = 0.104514
I1005 20:50:22.938989 16150 solver.cpp:259]     Train net output #0: error_blob = 0.104514 (* 1 = 0.104514 loss)
I1005 20:50:22.938995 16150 solver.cpp:590] Iteration 800, lr = 0.01
I1005 20:50:25.503506 16150 solver.cpp:243] Iteration 900, loss = 0.10586
I1005 20:50:25.503538 16150 solver.cpp:259]     Train net output #0: error_blob = 0.10586 (* 1 = 0.10586 loss)
I1005 20:50:25.503545 16150 solver.cpp:590] Iteration 900, lr = 0.01
I1005 20:50:25.554381 16150 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:50:28.004072 16150 solver.cpp:347] Iteration 1000, Testing net (#0)
I1005 20:50:28.282987 16150 solver.cpp:415]     Test net output #0: error_blob = 0.106051 (* 1 = 0.106051 loss)
I1005 20:50:28.283610 16150 solver.cpp:243] Iteration 1000, loss = 0.103373
I1005 20:50:28.283627 16150 solver.cpp:259]     Train net output #0: error_blob = 0.103373 (* 1 = 0.103373 loss)
I1005 20:50:28.283640 16150 solver.cpp:590] Iteration 1000, lr = 0.01
I1005 20:50:30.712235 16150 solver.cpp:243] Iteration 1100, loss = 0.105818
I1005 20:50:30.712363 16150 solver.cpp:259]     Train net output #0: error_blob = 0.105818 (* 1 = 0.105818 loss)
I1005 20:50:30.712371 16150 solver.cpp:590] Iteration 1100, lr = 0.01
I1005 20:50:33.183537 16150 solver.cpp:243] Iteration 1200, loss = 0.100513
I1005 20:50:33.183570 16150 solver.cpp:259]     Train net output #0: error_blob = 0.100513 (* 1 = 0.100513 loss)
I1005 20:50:33.183576 16150 solver.cpp:590] Iteration 1200, lr = 0.01
I1005 20:50:35.638880 16150 solver.cpp:243] Iteration 1300, loss = 0.103884
I1005 20:50:35.638926 16150 solver.cpp:259]     Train net output #0: error_blob = 0.103884 (* 1 = 0.103884 loss)
I1005 20:50:35.638931 16150 solver.cpp:590] Iteration 1300, lr = 0.01
I1005 20:50:38.077636 16150 solver.cpp:243] Iteration 1400, loss = 0.100131
I1005 20:50:38.077677 16150 solver.cpp:259]     Train net output #0: error_blob = 0.100131 (* 1 = 0.100131 loss)
I1005 20:50:38.077683 16150 solver.cpp:590] Iteration 1400, lr = 0.01
I1005 20:50:40.566161 16150 solver.cpp:243] Iteration 1500, loss = 0.104903
I1005 20:50:40.566195 16150 solver.cpp:259]     Train net output #0: error_blob = 0.104903 (* 1 = 0.104903 loss)
I1005 20:50:40.566200 16150 solver.cpp:590] Iteration 1500, lr = 0.01
I1005 20:50:43.059592 16150 solver.cpp:243] Iteration 1600, loss = 0.101177
I1005 20:50:43.059633 16150 solver.cpp:259]     Train net output #0: error_blob = 0.101177 (* 1 = 0.101177 loss)
I1005 20:50:43.059639 16150 solver.cpp:590] Iteration 1600, lr = 0.01
I1005 20:50:45.515415 16150 solver.cpp:243] Iteration 1700, loss = 0.10316
I1005 20:50:45.515450 16150 solver.cpp:259]     Train net output #0: error_blob = 0.10316 (* 1 = 0.10316 loss)
I1005 20:50:45.515455 16150 solver.cpp:590] Iteration 1700, lr = 0.01
I1005 20:50:47.980290 16150 solver.cpp:243] Iteration 1800, loss = 0.102858
I1005 20:50:47.980322 16150 solver.cpp:259]     Train net output #0: error_blob = 0.102858 (* 1 = 0.102858 loss)
I1005 20:50:47.980329 16150 solver.cpp:590] Iteration 1800, lr = 0.01
I1005 20:50:48.174386 16150 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:50:50.440251 16150 solver.cpp:243] Iteration 1900, loss = 0.101052
I1005 20:50:50.440284 16150 solver.cpp:259]     Train net output #0: error_blob = 0.101052 (* 1 = 0.101052 loss)
I1005 20:50:50.440289 16150 solver.cpp:590] Iteration 1900, lr = 0.01
I1005 20:50:52.855427 16150 solver.cpp:347] Iteration 2000, Testing net (#0)
I1005 20:50:53.145673 16150 solver.cpp:415]     Test net output #0: error_blob = 0.104898 (* 1 = 0.104898 loss)
I1005 20:50:53.146309 16150 solver.cpp:243] Iteration 2000, loss = 0.102962
I1005 20:50:53.146327 16150 solver.cpp:259]     Train net output #0: error_blob = 0.102962 (* 1 = 0.102962 loss)
I1005 20:50:53.146334 16150 solver.cpp:590] Iteration 2000, lr = 0.01
I1005 20:50:55.605351 16150 solver.cpp:243] Iteration 2100, loss = 0.10119
I1005 20:50:55.605384 16150 solver.cpp:259]     Train net output #0: error_blob = 0.10119 (* 1 = 0.10119 loss)
I1005 20:50:55.605394 16150 solver.cpp:590] Iteration 2100, lr = 0.01
I1005 20:50:58.048996 16150 solver.cpp:243] Iteration 2200, loss = 0.103588
I1005 20:50:58.049046 16150 solver.cpp:259]     Train net output #0: error_blob = 0.103588 (* 1 = 0.103588 loss)
I1005 20:50:58.049054 16150 solver.cpp:590] Iteration 2200, lr = 0.01
I1005 20:51:00.529184 16150 solver.cpp:243] Iteration 2300, loss = 0.0983004
I1005 20:51:00.529224 16150 solver.cpp:259]     Train net output #0: error_blob = 0.0983004 (* 1 = 0.0983004 loss)
I1005 20:51:00.529229 16150 solver.cpp:590] Iteration 2300, lr = 0.01
I1005 20:51:02.981717 16150 solver.cpp:243] Iteration 2400, loss = 0.101845
I1005 20:51:02.981848 16150 solver.cpp:259]     Train net output #0: error_blob = 0.101845 (* 1 = 0.101845 loss)
I1005 20:51:02.981853 16150 solver.cpp:590] Iteration 2400, lr = 0.01
I1005 20:51:05.475072 16150 solver.cpp:243] Iteration 2500, loss = 0.0979742
I1005 20:51:05.475113 16150 solver.cpp:259]     Train net output #0: error_blob = 0.0979742 (* 1 = 0.0979742 loss)
I1005 20:51:05.475118 16150 solver.cpp:590] Iteration 2500, lr = 0.01
I1005 20:51:07.950641 16150 solver.cpp:243] Iteration 2600, loss = 0.102828
I1005 20:51:07.950672 16150 solver.cpp:259]     Train net output #0: error_blob = 0.102828 (* 1 = 0.102828 loss)
I1005 20:51:07.950677 16150 solver.cpp:590] Iteration 2600, lr = 0.01
I1005 20:51:10.411515 16150 solver.cpp:243] Iteration 2700, loss = 0.0997634
I1005 20:51:10.411546 16150 solver.cpp:259]     Train net output #0: error_blob = 0.0997634 (* 1 = 0.0997634 loss)
I1005 20:51:10.411551 16150 solver.cpp:590] Iteration 2700, lr = 0.01
I1005 20:51:10.749840 16150 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:51:12.842172 16150 solver.cpp:243] Iteration 2800, loss = 0.100986
I1005 20:51:12.842201 16150 solver.cpp:259]     Train net output #0: error_blob = 0.100986 (* 1 = 0.100986 loss)
I1005 20:51:12.842206 16150 solver.cpp:590] Iteration 2800, lr = 0.01
I1005 20:51:15.303275 16150 solver.cpp:243] Iteration 2900, loss = 0.101519
I1005 20:51:15.303305 16150 solver.cpp:259]     Train net output #0: error_blob = 0.101519 (* 1 = 0.101519 loss)
I1005 20:51:15.303310 16150 solver.cpp:590] Iteration 2900, lr = 0.01
I1005 20:51:17.704774 16150 solver.cpp:347] Iteration 3000, Testing net (#0)
I1005 20:51:17.982467 16150 solver.cpp:415]     Test net output #0: error_blob = 0.104085 (* 1 = 0.104085 loss)
I1005 20:51:17.983150 16150 solver.cpp:243] Iteration 3000, loss = 0.0992941
I1005 20:51:17.983165 16150 solver.cpp:259]     Train net output #0: error_blob = 0.0992941 (* 1 = 0.0992941 loss)
I1005 20:51:17.983171 16150 solver.cpp:590] Iteration 3000, lr = 0.01
I1005 20:51:20.407335 16150 solver.cpp:243] Iteration 3100, loss = 0.101519
I1005 20:51:20.407366 16150 solver.cpp:259]     Train net output #0: error_blob = 0.101519 (* 1 = 0.101519 loss)
I1005 20:51:20.407372 16150 solver.cpp:590] Iteration 3100, lr = 0.01
I1005 20:51:22.868618 16150 solver.cpp:243] Iteration 3200, loss = 0.0999409
I1005 20:51:22.868659 16150 solver.cpp:259]     Train net output #0: error_blob = 0.0999409 (* 1 = 0.0999409 loss)
I1005 20:51:22.868664 16150 solver.cpp:590] Iteration 3200, lr = 0.01
I1005 20:51:25.347308 16150 solver.cpp:243] Iteration 3300, loss = 0.102139
I1005 20:51:25.347352 16150 solver.cpp:259]     Train net output #0: error_blob = 0.102139 (* 1 = 0.102139 loss)
I1005 20:51:25.347357 16150 solver.cpp:590] Iteration 3300, lr = 0.01
I1005 20:51:27.869266 16150 solver.cpp:243] Iteration 3400, loss = 0.0970881
I1005 20:51:27.869297 16150 solver.cpp:259]     Train net output #0: error_blob = 0.0970881 (* 1 = 0.0970881 loss)
I1005 20:51:27.869303 16150 solver.cpp:590] Iteration 3400, lr = 0.01
I1005 20:51:30.324265 16150 solver.cpp:243] Iteration 3500, loss = 0.10039
I1005 20:51:30.324297 16150 solver.cpp:259]     Train net output #0: error_blob = 0.10039 (* 1 = 0.10039 loss)
I1005 20:51:30.324303 16150 solver.cpp:590] Iteration 3500, lr = 0.01
I1005 20:51:32.774173 16150 solver.cpp:243] Iteration 3600, loss = 0.0969281
I1005 20:51:32.774204 16150 solver.cpp:259]     Train net output #0: error_blob = 0.0969281 (* 1 = 0.0969281 loss)
I1005 20:51:32.774209 16150 solver.cpp:590] Iteration 3600, lr = 0.01
I1005 20:51:33.257169 16150 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:51:35.214581 16150 solver.cpp:243] Iteration 3700, loss = 0.101165
I1005 20:51:35.214611 16150 solver.cpp:259]     Train net output #0: error_blob = 0.101165 (* 1 = 0.101165 loss)
I1005 20:51:35.214615 16150 solver.cpp:590] Iteration 3700, lr = 0.01
I1005 20:51:37.677002 16150 solver.cpp:243] Iteration 3800, loss = 0.0989341
I1005 20:51:37.677052 16150 solver.cpp:259]     Train net output #0: error_blob = 0.0989341 (* 1 = 0.0989341 loss)
I1005 20:51:37.677059 16150 solver.cpp:590] Iteration 3800, lr = 0.01
I1005 20:51:40.187482 16150 solver.cpp:243] Iteration 3900, loss = 0.0993825
I1005 20:51:40.187522 16150 solver.cpp:259]     Train net output #0: error_blob = 0.0993825 (* 1 = 0.0993825 loss)
I1005 20:51:40.187528 16150 solver.cpp:590] Iteration 3900, lr = 0.01
I1005 20:51:42.617125 16150 solver.cpp:347] Iteration 4000, Testing net (#0)
I1005 20:51:42.887267 16150 solver.cpp:415]     Test net output #0: error_blob = 0.103411 (* 1 = 0.103411 loss)
I1005 20:51:42.887918 16150 solver.cpp:243] Iteration 4000, loss = 0.100597
I1005 20:51:42.887962 16150 solver.cpp:259]     Train net output #0: error_blob = 0.100597 (* 1 = 0.100597 loss)
I1005 20:51:42.887972 16150 solver.cpp:590] Iteration 4000, lr = 0.01
I1005 20:51:45.340265 16150 solver.cpp:243] Iteration 4100, loss = 0.0977433
I1005 20:51:45.340306 16150 solver.cpp:259]     Train net output #0: error_blob = 0.0977433 (* 1 = 0.0977433 loss)
I1005 20:51:45.340312 16150 solver.cpp:590] Iteration 4100, lr = 0.01
I1005 20:51:47.861038 16150 solver.cpp:243] Iteration 4200, loss = 0.100295
I1005 20:51:47.861069 16150 solver.cpp:259]     Train net output #0: error_blob = 0.100295 (* 1 = 0.100295 loss)
I1005 20:51:47.861075 16150 solver.cpp:590] Iteration 4200, lr = 0.01
I1005 20:51:50.377358 16150 solver.cpp:243] Iteration 4300, loss = 0.0988878
I1005 20:51:50.377392 16150 solver.cpp:259]     Train net output #0: error_blob = 0.0988878 (* 1 = 0.0988878 loss)
I1005 20:51:50.377398 16150 solver.cpp:590] Iteration 4300, lr = 0.01
I1005 20:51:52.859473 16150 solver.cpp:243] Iteration 4400, loss = 0.100705
I1005 20:51:52.859521 16150 solver.cpp:259]     Train net output #0: error_blob = 0.100705 (* 1 = 0.100705 loss)
I1005 20:51:52.859530 16150 solver.cpp:590] Iteration 4400, lr = 0.01
I1005 20:51:55.357442 16150 solver.cpp:243] Iteration 4500, loss = 0.0962651
I1005 20:51:55.357484 16150 solver.cpp:259]     Train net output #0: error_blob = 0.0962651 (* 1 = 0.0962651 loss)
I1005 20:51:55.357491 16150 solver.cpp:590] Iteration 4500, lr = 0.01
I1005 20:51:56.003005 16150 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:51:57.876555 16150 solver.cpp:243] Iteration 4600, loss = 0.0990963
I1005 20:51:57.876605 16150 solver.cpp:259]     Train net output #0: error_blob = 0.0990963 (* 1 = 0.0990963 loss)
I1005 20:51:57.876612 16150 solver.cpp:590] Iteration 4600, lr = 0.01
I1005 20:52:00.388780 16150 solver.cpp:243] Iteration 4700, loss = 0.0961351
I1005 20:52:00.388828 16150 solver.cpp:259]     Train net output #0: error_blob = 0.0961351 (* 1 = 0.0961351 loss)
I1005 20:52:00.388836 16150 solver.cpp:590] Iteration 4700, lr = 0.01
I1005 20:52:02.871012 16150 solver.cpp:243] Iteration 4800, loss = 0.0998992
I1005 20:52:02.871053 16150 solver.cpp:259]     Train net output #0: error_blob = 0.0998992 (* 1 = 0.0998992 loss)
I1005 20:52:02.871059 16150 solver.cpp:590] Iteration 4800, lr = 0.01
I1005 20:52:05.387048 16150 solver.cpp:243] Iteration 4900, loss = 0.0979268
I1005 20:52:05.387168 16150 solver.cpp:259]     Train net output #0: error_blob = 0.0979268 (* 1 = 0.0979268 loss)
I1005 20:52:05.387177 16150 solver.cpp:590] Iteration 4900, lr = 0.01
I1005 20:52:07.869308 16150 solver.cpp:347] Iteration 5000, Testing net (#0)
I1005 20:52:08.157107 16150 solver.cpp:415]     Test net output #0: error_blob = 0.103007 (* 1 = 0.103007 loss)
I1005 20:52:08.157793 16150 solver.cpp:243] Iteration 5000, loss = 0.0981384
I1005 20:52:08.157812 16150 solver.cpp:259]     Train net output #0: error_blob = 0.0981384 (* 1 = 0.0981384 loss)
I1005 20:52:08.157819 16150 solver.cpp:590] Iteration 5000, lr = 0.01
I1005 20:52:10.573824 16150 solver.cpp:243] Iteration 5100, loss = 0.0998827
I1005 20:52:10.573874 16150 solver.cpp:259]     Train net output #0: error_blob = 0.0998827 (* 1 = 0.0998827 loss)
I1005 20:52:10.573884 16150 solver.cpp:590] Iteration 5100, lr = 0.01
I1005 20:52:13.041465 16150 solver.cpp:243] Iteration 5200, loss = 0.096459
I1005 20:52:13.041510 16150 solver.cpp:259]     Train net output #0: error_blob = 0.096459 (* 1 = 0.096459 loss)
I1005 20:52:13.041517 16150 solver.cpp:590] Iteration 5200, lr = 0.01
I1005 20:52:15.493067 16150 solver.cpp:243] Iteration 5300, loss = 0.0992988
I1005 20:52:15.493098 16150 solver.cpp:259]     Train net output #0: error_blob = 0.0992988 (* 1 = 0.0992988 loss)
I1005 20:52:15.493101 16150 solver.cpp:590] Iteration 5300, lr = 0.01
I1005 20:52:17.957619 16150 solver.cpp:243] Iteration 5400, loss = 0.0978342
I1005 20:52:17.957667 16150 solver.cpp:259]     Train net output #0: error_blob = 0.0978342 (* 1 = 0.0978342 loss)
I1005 20:52:17.957675 16150 solver.cpp:590] Iteration 5400, lr = 0.01
I1005 20:52:18.757576 16150 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:52:20.428289 16150 solver.cpp:243] Iteration 5500, loss = 0.0997785
I1005 20:52:20.428331 16150 solver.cpp:259]     Train net output #0: error_blob = 0.0997785 (* 1 = 0.0997785 loss)
I1005 20:52:20.428336 16150 solver.cpp:590] Iteration 5500, lr = 0.01
I1005 20:52:22.899978 16150 solver.cpp:243] Iteration 5600, loss = 0.0953888
I1005 20:52:22.900009 16150 solver.cpp:259]     Train net output #0: error_blob = 0.0953888 (* 1 = 0.0953888 loss)
I1005 20:52:22.900015 16150 solver.cpp:590] Iteration 5600, lr = 0.01
I1005 20:52:25.372812 16150 solver.cpp:243] Iteration 5700, loss = 0.0978871
I1005 20:52:25.372844 16150 solver.cpp:259]     Train net output #0: error_blob = 0.0978871 (* 1 = 0.0978871 loss)
I1005 20:52:25.372850 16150 solver.cpp:590] Iteration 5700, lr = 0.01
I1005 20:52:27.863140 16150 solver.cpp:243] Iteration 5800, loss = 0.0953009
I1005 20:52:27.863183 16150 solver.cpp:259]     Train net output #0: error_blob = 0.0953009 (* 1 = 0.0953009 loss)
I1005 20:52:27.863190 16150 solver.cpp:590] Iteration 5800, lr = 0.01
I1005 20:52:30.341657 16150 solver.cpp:243] Iteration 5900, loss = 0.0988642
I1005 20:52:30.341689 16150 solver.cpp:259]     Train net output #0: error_blob = 0.0988642 (* 1 = 0.0988642 loss)
I1005 20:52:30.341696 16150 solver.cpp:590] Iteration 5900, lr = 0.01
I1005 20:52:32.774595 16150 solver.cpp:347] Iteration 6000, Testing net (#0)
I1005 20:52:33.047063 16150 solver.cpp:415]     Test net output #0: error_blob = 0.102623 (* 1 = 0.102623 loss)
I1005 20:52:33.047713 16150 solver.cpp:243] Iteration 6000, loss = 0.0971432
I1005 20:52:33.047730 16150 solver.cpp:259]     Train net output #0: error_blob = 0.0971432 (* 1 = 0.0971432 loss)
I1005 20:52:33.047737 16150 solver.cpp:590] Iteration 6000, lr = 0.01
I1005 20:52:35.603526 16150 solver.cpp:243] Iteration 6100, loss = 0.0970665
I1005 20:52:35.603652 16150 solver.cpp:259]     Train net output #0: error_blob = 0.0970665 (* 1 = 0.0970665 loss)
I1005 20:52:35.603658 16150 solver.cpp:590] Iteration 6100, lr = 0.01
I1005 20:52:38.090562 16150 solver.cpp:243] Iteration 6200, loss = 0.0990626
I1005 20:52:38.090595 16150 solver.cpp:259]     Train net output #0: error_blob = 0.0990626 (* 1 = 0.0990626 loss)
I1005 20:52:38.090600 16150 solver.cpp:590] Iteration 6200, lr = 0.01
I1005 20:52:40.548630 16150 solver.cpp:243] Iteration 6300, loss = 0.0956967
I1005 20:52:40.548672 16150 solver.cpp:259]     Train net output #0: error_blob = 0.0956967 (* 1 = 0.0956967 loss)
I1005 20:52:40.548677 16150 solver.cpp:590] Iteration 6300, lr = 0.01
I1005 20:52:41.492871 16150 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:52:43.025214 16150 solver.cpp:243] Iteration 6400, loss = 0.0985072
I1005 20:52:43.025254 16150 solver.cpp:259]     Train net output #0: error_blob = 0.0985072 (* 1 = 0.0985072 loss)
I1005 20:52:43.025260 16150 solver.cpp:590] Iteration 6400, lr = 0.01
I1005 20:52:45.506456 16150 solver.cpp:243] Iteration 6500, loss = 0.0970306
I1005 20:52:45.506490 16150 solver.cpp:259]     Train net output #0: error_blob = 0.0970306 (* 1 = 0.0970306 loss)
I1005 20:52:45.506499 16150 solver.cpp:590] Iteration 6500, lr = 0.01
I1005 20:52:47.994360 16150 solver.cpp:243] Iteration 6600, loss = 0.0988828
I1005 20:52:47.994395 16150 solver.cpp:259]     Train net output #0: error_blob = 0.0988828 (* 1 = 0.0988828 loss)
I1005 20:52:47.994402 16150 solver.cpp:590] Iteration 6600, lr = 0.01
I1005 20:52:50.447741 16150 solver.cpp:243] Iteration 6700, loss = 0.0949007
I1005 20:52:50.447777 16150 solver.cpp:259]     Train net output #0: error_blob = 0.0949007 (* 1 = 0.0949007 loss)
I1005 20:52:50.447784 16150 solver.cpp:590] Iteration 6700, lr = 0.01
I1005 20:52:52.924651 16150 solver.cpp:243] Iteration 6800, loss = 0.0969709
I1005 20:52:52.924685 16150 solver.cpp:259]     Train net output #0: error_blob = 0.0969709 (* 1 = 0.0969709 loss)
I1005 20:52:52.924693 16150 solver.cpp:590] Iteration 6800, lr = 0.01
I1005 20:52:55.413574 16150 solver.cpp:243] Iteration 6900, loss = 0.0947067
I1005 20:52:55.413604 16150 solver.cpp:259]     Train net output #0: error_blob = 0.0947067 (* 1 = 0.0947067 loss)
I1005 20:52:55.413609 16150 solver.cpp:590] Iteration 6900, lr = 0.01
I1005 20:52:57.846906 16150 solver.cpp:347] Iteration 7000, Testing net (#0)
I1005 20:52:58.118137 16150 solver.cpp:415]     Test net output #0: error_blob = 0.102388 (* 1 = 0.102388 loss)
I1005 20:52:58.118744 16150 solver.cpp:243] Iteration 7000, loss = 0.0977621
I1005 20:52:58.118757 16150 solver.cpp:259]     Train net output #0: error_blob = 0.0977621 (* 1 = 0.0977621 loss)
I1005 20:52:58.118760 16150 solver.cpp:590] Iteration 7000, lr = 0.01
I1005 20:53:00.556109 16150 solver.cpp:243] Iteration 7100, loss = 0.0966752
I1005 20:53:00.556138 16150 solver.cpp:259]     Train net output #0: error_blob = 0.0966752 (* 1 = 0.0966752 loss)
I1005 20:53:00.556144 16150 solver.cpp:590] Iteration 7100, lr = 0.01
I1005 20:53:03.047283 16150 solver.cpp:243] Iteration 7200, loss = 0.096044
I1005 20:53:03.047314 16150 solver.cpp:259]     Train net output #0: error_blob = 0.096044 (* 1 = 0.096044 loss)
I1005 20:53:03.047322 16150 solver.cpp:590] Iteration 7200, lr = 0.01
I1005 20:53:04.136353 16150 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:53:05.529163 16150 solver.cpp:243] Iteration 7300, loss = 0.0980261
I1005 20:53:05.529194 16150 solver.cpp:259]     Train net output #0: error_blob = 0.0980261 (* 1 = 0.0980261 loss)
I1005 20:53:05.529198 16150 solver.cpp:590] Iteration 7300, lr = 0.01
I1005 20:53:08.007701 16150 solver.cpp:243] Iteration 7400, loss = 0.0949937
I1005 20:53:08.007779 16150 solver.cpp:259]     Train net output #0: error_blob = 0.0949937 (* 1 = 0.0949937 loss)
I1005 20:53:08.007786 16150 solver.cpp:590] Iteration 7400, lr = 0.01
I1005 20:53:10.483139 16150 solver.cpp:243] Iteration 7500, loss = 0.0976006
I1005 20:53:10.483171 16150 solver.cpp:259]     Train net output #0: error_blob = 0.0976006 (* 1 = 0.0976006 loss)
I1005 20:53:10.483175 16150 solver.cpp:590] Iteration 7500, lr = 0.01
I1005 20:53:12.929718 16150 solver.cpp:243] Iteration 7600, loss = 0.0962671
I1005 20:53:12.929759 16150 solver.cpp:259]     Train net output #0: error_blob = 0.0962671 (* 1 = 0.0962671 loss)
I1005 20:53:12.929764 16150 solver.cpp:590] Iteration 7600, lr = 0.01
I1005 20:53:15.350914 16150 solver.cpp:243] Iteration 7700, loss = 0.09796
I1005 20:53:15.350944 16150 solver.cpp:259]     Train net output #0: error_blob = 0.09796 (* 1 = 0.09796 loss)
I1005 20:53:15.350950 16150 solver.cpp:590] Iteration 7700, lr = 0.01
I1005 20:53:17.792583 16150 solver.cpp:243] Iteration 7800, loss = 0.094393
I1005 20:53:17.792614 16150 solver.cpp:259]     Train net output #0: error_blob = 0.094393 (* 1 = 0.094393 loss)
I1005 20:53:17.792621 16150 solver.cpp:590] Iteration 7800, lr = 0.01
I1005 20:53:20.250257 16150 solver.cpp:243] Iteration 7900, loss = 0.0959685
I1005 20:53:20.250290 16150 solver.cpp:259]     Train net output #0: error_blob = 0.0959685 (* 1 = 0.0959685 loss)
I1005 20:53:20.250298 16150 solver.cpp:590] Iteration 7900, lr = 0.01
I1005 20:53:22.682420 16150 solver.cpp:347] Iteration 8000, Testing net (#0)
I1005 20:53:23.024610 16150 solver.cpp:415]     Test net output #0: error_blob = 0.102217 (* 1 = 0.102217 loss)
I1005 20:53:23.025241 16150 solver.cpp:243] Iteration 8000, loss = 0.094279
I1005 20:53:23.025252 16150 solver.cpp:259]     Train net output #0: error_blob = 0.094279 (* 1 = 0.094279 loss)
I1005 20:53:23.025257 16150 solver.cpp:590] Iteration 8000, lr = 0.01
I1005 20:53:25.502414 16150 solver.cpp:243] Iteration 8100, loss = 0.0967168
I1005 20:53:25.502444 16150 solver.cpp:259]     Train net output #0: error_blob = 0.0967168 (* 1 = 0.0967168 loss)
I1005 20:53:25.502449 16150 solver.cpp:590] Iteration 8100, lr = 0.01
I1005 20:53:26.730417 16150 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:53:27.954985 16150 solver.cpp:243] Iteration 8200, loss = 0.0962918
I1005 20:53:27.955014 16150 solver.cpp:259]     Train net output #0: error_blob = 0.0962918 (* 1 = 0.0962918 loss)
I1005 20:53:27.955019 16150 solver.cpp:590] Iteration 8200, lr = 0.01
I1005 20:53:30.423094 16150 solver.cpp:243] Iteration 8300, loss = 0.095229
I1005 20:53:30.423131 16150 solver.cpp:259]     Train net output #0: error_blob = 0.095229 (* 1 = 0.095229 loss)
I1005 20:53:30.423140 16150 solver.cpp:590] Iteration 8300, lr = 0.01
I1005 20:53:32.916481 16150 solver.cpp:243] Iteration 8400, loss = 0.0972527
I1005 20:53:32.916530 16150 solver.cpp:259]     Train net output #0: error_blob = 0.0972527 (* 1 = 0.0972527 loss)
I1005 20:53:32.916538 16150 solver.cpp:590] Iteration 8400, lr = 0.01
I1005 20:53:35.445220 16150 solver.cpp:243] Iteration 8500, loss = 0.0943795
I1005 20:53:35.445258 16150 solver.cpp:259]     Train net output #0: error_blob = 0.0943795 (* 1 = 0.0943795 loss)
I1005 20:53:35.445266 16150 solver.cpp:590] Iteration 8500, lr = 0.01
I1005 20:53:37.921550 16150 solver.cpp:243] Iteration 8600, loss = 0.096884
I1005 20:53:37.921579 16150 solver.cpp:259]     Train net output #0: error_blob = 0.096884 (* 1 = 0.096884 loss)
I1005 20:53:37.921584 16150 solver.cpp:590] Iteration 8600, lr = 0.01
I1005 20:53:40.399015 16150 solver.cpp:243] Iteration 8700, loss = 0.0955989
I1005 20:53:40.399134 16150 solver.cpp:259]     Train net output #0: error_blob = 0.0955989 (* 1 = 0.0955989 loss)
I1005 20:53:40.399152 16150 solver.cpp:590] Iteration 8700, lr = 0.01
I1005 20:53:42.835482 16150 solver.cpp:243] Iteration 8800, loss = 0.0971787
I1005 20:53:42.835518 16150 solver.cpp:259]     Train net output #0: error_blob = 0.0971787 (* 1 = 0.0971787 loss)
I1005 20:53:42.835525 16150 solver.cpp:590] Iteration 8800, lr = 0.01
I1005 20:53:45.293683 16150 solver.cpp:243] Iteration 8900, loss = 0.0938649
I1005 20:53:45.293712 16150 solver.cpp:259]     Train net output #0: error_blob = 0.0938649 (* 1 = 0.0938649 loss)
I1005 20:53:45.293717 16150 solver.cpp:590] Iteration 8900, lr = 0.01
I1005 20:53:47.717988 16150 solver.cpp:347] Iteration 9000, Testing net (#0)
I1005 20:53:47.997648 16150 solver.cpp:415]     Test net output #0: error_blob = 0.102014 (* 1 = 0.102014 loss)
I1005 20:53:47.998312 16150 solver.cpp:243] Iteration 9000, loss = 0.0950836
I1005 20:53:47.998332 16150 solver.cpp:259]     Train net output #0: error_blob = 0.0950836 (* 1 = 0.0950836 loss)
I1005 20:53:47.998338 16150 solver.cpp:590] Iteration 9000, lr = 0.01
I1005 20:53:49.372774 16150 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:53:50.461009 16150 solver.cpp:243] Iteration 9100, loss = 0.0938619
I1005 20:53:50.461046 16150 solver.cpp:259]     Train net output #0: error_blob = 0.0938619 (* 1 = 0.0938619 loss)
I1005 20:53:50.461051 16150 solver.cpp:590] Iteration 9100, lr = 0.01
I1005 20:53:52.931895 16150 solver.cpp:243] Iteration 9200, loss = 0.0960476
I1005 20:53:52.931924 16150 solver.cpp:259]     Train net output #0: error_blob = 0.0960476 (* 1 = 0.0960476 loss)
I1005 20:53:52.931929 16150 solver.cpp:590] Iteration 9200, lr = 0.01
I1005 20:53:55.399799 16150 solver.cpp:243] Iteration 9300, loss = 0.0954671
I1005 20:53:55.399830 16150 solver.cpp:259]     Train net output #0: error_blob = 0.0954671 (* 1 = 0.0954671 loss)
I1005 20:53:55.399834 16150 solver.cpp:590] Iteration 9300, lr = 0.01
I1005 20:53:57.913004 16150 solver.cpp:243] Iteration 9400, loss = 0.0943968
I1005 20:53:57.913035 16150 solver.cpp:259]     Train net output #0: error_blob = 0.0943968 (* 1 = 0.0943968 loss)
I1005 20:53:57.913041 16150 solver.cpp:590] Iteration 9400, lr = 0.01
I1005 20:54:00.372658 16150 solver.cpp:243] Iteration 9500, loss = 0.0965643
I1005 20:54:00.372689 16150 solver.cpp:259]     Train net output #0: error_blob = 0.0965643 (* 1 = 0.0965643 loss)
I1005 20:54:00.372695 16150 solver.cpp:590] Iteration 9500, lr = 0.01
I1005 20:54:02.857281 16150 solver.cpp:243] Iteration 9600, loss = 0.0935442
I1005 20:54:02.857311 16150 solver.cpp:259]     Train net output #0: error_blob = 0.0935442 (* 1 = 0.0935442 loss)
I1005 20:54:02.857316 16150 solver.cpp:590] Iteration 9600, lr = 0.01
I1005 20:54:05.333876 16150 solver.cpp:243] Iteration 9700, loss = 0.096441
I1005 20:54:05.333905 16150 solver.cpp:259]     Train net output #0: error_blob = 0.096441 (* 1 = 0.096441 loss)
I1005 20:54:05.333910 16150 solver.cpp:590] Iteration 9700, lr = 0.01
I1005 20:54:07.776378 16150 solver.cpp:243] Iteration 9800, loss = 0.0946399
I1005 20:54:07.776407 16150 solver.cpp:259]     Train net output #0: error_blob = 0.0946399 (* 1 = 0.0946399 loss)
I1005 20:54:07.776412 16150 solver.cpp:590] Iteration 9800, lr = 0.01
I1005 20:54:10.230577 16150 solver.cpp:243] Iteration 9900, loss = 0.096545
I1005 20:54:10.230605 16150 solver.cpp:259]     Train net output #0: error_blob = 0.096545 (* 1 = 0.096545 loss)
I1005 20:54:10.230610 16150 solver.cpp:590] Iteration 9900, lr = 0.01
I1005 20:54:12.640635 16150 solver.cpp:468] Snapshotting to binary proto file _iter_10000.caffemodel
I1005 20:54:12.641969 16150 solver.cpp:753] Snapshotting solver state to binary proto file _iter_10000.solverstate
I1005 20:54:12.665457 16150 solver.cpp:327] Iteration 10000, loss = 0.093461
I1005 20:54:12.665483 16150 solver.cpp:347] Iteration 10000, Testing net (#0)
I1005 20:54:12.840169 16150 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:54:12.944908 16150 solver.cpp:415]     Test net output #0: error_blob = 0.101982 (* 1 = 0.101982 loss)
I1005 20:54:12.944938 16150 solver.cpp:332] Optimization Done.
I1005 20:54:12.944941 16150 caffe.cpp:215] Optimization Done.
I1005 20:54:13.018128 16163 caffe.cpp:184] Using GPUs 0
I1005 20:54:13.577838 16163 solver.cpp:54] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "fixed"
momentum: 0.9
solver_mode: GPU
device_id: 0
net: "large_batch/model0_part8.prototxt"
I1005 20:54:13.577869 16163 solver.cpp:97] Creating training net from net file: large_batch/model0_part8.prototxt
I1005 20:54:13.578037 16163 net.cpp:339] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_layer
I1005 20:54:13.578083 16163 net.cpp:50] Initializing net from parameters: 
name: "large_batch/model0_part8.prototxt"
state {
  phase: TRAIN
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TRAIN
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.part8.train"
    batch_size: 20000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1005 20:54:13.578157 16163 layer_factory.hpp:76] Creating layer data_layer
I1005 20:54:13.592006 16163 net.cpp:110] Creating Layer data_layer
I1005 20:54:13.592026 16163 net.cpp:433] data_layer -> data_blob
I1005 20:54:13.592058 16163 net.cpp:433] data_layer -> label_blob
I1005 20:54:13.592666 16167 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.part8.train
I1005 20:54:14.278229 16163 data_layer.cpp:45] output data size: 20000,61,1,1
I1005 20:54:14.283390 16163 net.cpp:155] Setting up data_layer
I1005 20:54:14.283422 16163 net.cpp:163] Top shape: 20000 61 1 1 (1220000)
I1005 20:54:14.283427 16163 net.cpp:163] Top shape: 20000 (20000)
I1005 20:54:14.283442 16163 layer_factory.hpp:76] Creating layer hidden_sum_layer
I1005 20:54:14.283454 16163 net.cpp:110] Creating Layer hidden_sum_layer
I1005 20:54:14.283457 16163 net.cpp:477] hidden_sum_layer <- data_blob
I1005 20:54:14.283466 16163 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I1005 20:54:14.283835 16163 net.cpp:155] Setting up hidden_sum_layer
I1005 20:54:14.283843 16163 net.cpp:163] Top shape: 20000 10 (200000)
I1005 20:54:14.283864 16163 layer_factory.hpp:76] Creating layer hidden_act_layer
I1005 20:54:14.283872 16163 net.cpp:110] Creating Layer hidden_act_layer
I1005 20:54:14.283874 16163 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I1005 20:54:14.283877 16163 net.cpp:433] hidden_act_layer -> hidden_act_blob
I1005 20:54:17.522749 16163 net.cpp:155] Setting up hidden_act_layer
I1005 20:54:17.522773 16163 net.cpp:163] Top shape: 20000 10 (200000)
I1005 20:54:17.522778 16163 layer_factory.hpp:76] Creating layer output_sum_layer
I1005 20:54:17.522786 16163 net.cpp:110] Creating Layer output_sum_layer
I1005 20:54:17.522790 16163 net.cpp:477] output_sum_layer <- hidden_act_blob
I1005 20:54:17.522795 16163 net.cpp:433] output_sum_layer -> output_sum_blob
I1005 20:54:17.522881 16163 net.cpp:155] Setting up output_sum_layer
I1005 20:54:17.522888 16163 net.cpp:163] Top shape: 20000 1 (20000)
I1005 20:54:17.522896 16163 layer_factory.hpp:76] Creating layer output_act_layer
I1005 20:54:17.522900 16163 net.cpp:110] Creating Layer output_act_layer
I1005 20:54:17.522902 16163 net.cpp:477] output_act_layer <- output_sum_blob
I1005 20:54:17.522905 16163 net.cpp:433] output_act_layer -> output_act_blob
I1005 20:54:17.522979 16163 net.cpp:155] Setting up output_act_layer
I1005 20:54:17.522997 16163 net.cpp:163] Top shape: 20000 1 (20000)
I1005 20:54:17.523011 16163 layer_factory.hpp:76] Creating layer error_layer
I1005 20:54:17.523016 16163 net.cpp:110] Creating Layer error_layer
I1005 20:54:17.523018 16163 net.cpp:477] error_layer <- output_act_blob
I1005 20:54:17.523021 16163 net.cpp:477] error_layer <- label_blob
I1005 20:54:17.523025 16163 net.cpp:433] error_layer -> error_blob
I1005 20:54:17.523047 16163 net.cpp:155] Setting up error_layer
I1005 20:54:17.523051 16163 net.cpp:163] Top shape: (1)
I1005 20:54:17.523053 16163 net.cpp:168]     with loss weight 1
I1005 20:54:17.523069 16163 net.cpp:236] error_layer needs backward computation.
I1005 20:54:17.523072 16163 net.cpp:236] output_act_layer needs backward computation.
I1005 20:54:17.523074 16163 net.cpp:236] output_sum_layer needs backward computation.
I1005 20:54:17.523077 16163 net.cpp:236] hidden_act_layer needs backward computation.
I1005 20:54:17.523078 16163 net.cpp:236] hidden_sum_layer needs backward computation.
I1005 20:54:17.523080 16163 net.cpp:240] data_layer does not need backward computation.
I1005 20:54:17.523082 16163 net.cpp:283] This network produces output error_blob
I1005 20:54:17.523087 16163 net.cpp:297] Network initialization done.
I1005 20:54:17.523089 16163 net.cpp:298] Memory required for data: 6720004
I1005 20:54:17.523221 16163 solver.cpp:187] Creating test net (#0) specified by net file: large_batch/model0_part8.prototxt
I1005 20:54:17.523247 16163 net.cpp:339] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_layer
I1005 20:54:17.523288 16163 net.cpp:50] Initializing net from parameters: 
name: "large_batch/model0_part8.prototxt"
state {
  phase: TEST
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TEST
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.part8.test"
    batch_size: 2000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1005 20:54:17.523319 16163 layer_factory.hpp:76] Creating layer data_layer
I1005 20:54:17.524536 16163 net.cpp:110] Creating Layer data_layer
I1005 20:54:17.524552 16163 net.cpp:433] data_layer -> data_blob
I1005 20:54:17.524559 16163 net.cpp:433] data_layer -> label_blob
I1005 20:54:17.525109 16169 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.part8.test
I1005 20:54:17.525174 16163 data_layer.cpp:45] output data size: 2000,61,1,1
I1005 20:54:17.526552 16163 net.cpp:155] Setting up data_layer
I1005 20:54:17.526564 16163 net.cpp:163] Top shape: 2000 61 1 1 (122000)
I1005 20:54:17.526567 16163 net.cpp:163] Top shape: 2000 (2000)
I1005 20:54:17.526571 16163 layer_factory.hpp:76] Creating layer hidden_sum_layer
I1005 20:54:17.526577 16163 net.cpp:110] Creating Layer hidden_sum_layer
I1005 20:54:17.526581 16163 net.cpp:477] hidden_sum_layer <- data_blob
I1005 20:54:17.526584 16163 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I1005 20:54:17.526705 16163 net.cpp:155] Setting up hidden_sum_layer
I1005 20:54:17.526710 16163 net.cpp:163] Top shape: 2000 10 (20000)
I1005 20:54:17.526716 16163 layer_factory.hpp:76] Creating layer hidden_act_layer
I1005 20:54:17.526721 16163 net.cpp:110] Creating Layer hidden_act_layer
I1005 20:54:17.526723 16163 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I1005 20:54:17.526738 16163 net.cpp:433] hidden_act_layer -> hidden_act_blob
I1005 20:54:17.526908 16163 net.cpp:155] Setting up hidden_act_layer
I1005 20:54:17.526916 16163 net.cpp:163] Top shape: 2000 10 (20000)
I1005 20:54:17.526919 16163 layer_factory.hpp:76] Creating layer output_sum_layer
I1005 20:54:17.526924 16163 net.cpp:110] Creating Layer output_sum_layer
I1005 20:54:17.526926 16163 net.cpp:477] output_sum_layer <- hidden_act_blob
I1005 20:54:17.526929 16163 net.cpp:433] output_sum_layer -> output_sum_blob
I1005 20:54:17.526988 16163 net.cpp:155] Setting up output_sum_layer
I1005 20:54:17.526993 16163 net.cpp:163] Top shape: 2000 1 (2000)
I1005 20:54:17.526999 16163 layer_factory.hpp:76] Creating layer output_act_layer
I1005 20:54:17.527004 16163 net.cpp:110] Creating Layer output_act_layer
I1005 20:54:17.527006 16163 net.cpp:477] output_act_layer <- output_sum_blob
I1005 20:54:17.527009 16163 net.cpp:433] output_act_layer -> output_act_blob
I1005 20:54:17.527056 16163 net.cpp:155] Setting up output_act_layer
I1005 20:54:17.527061 16163 net.cpp:163] Top shape: 2000 1 (2000)
I1005 20:54:17.527063 16163 layer_factory.hpp:76] Creating layer error_layer
I1005 20:54:17.527067 16163 net.cpp:110] Creating Layer error_layer
I1005 20:54:17.527070 16163 net.cpp:477] error_layer <- output_act_blob
I1005 20:54:17.527071 16163 net.cpp:477] error_layer <- label_blob
I1005 20:54:17.527075 16163 net.cpp:433] error_layer -> error_blob
I1005 20:54:17.527093 16163 net.cpp:155] Setting up error_layer
I1005 20:54:17.527096 16163 net.cpp:163] Top shape: (1)
I1005 20:54:17.527098 16163 net.cpp:168]     with loss weight 1
I1005 20:54:17.527107 16163 net.cpp:236] error_layer needs backward computation.
I1005 20:54:17.527108 16163 net.cpp:236] output_act_layer needs backward computation.
I1005 20:54:17.527111 16163 net.cpp:236] output_sum_layer needs backward computation.
I1005 20:54:17.527112 16163 net.cpp:236] hidden_act_layer needs backward computation.
I1005 20:54:17.527114 16163 net.cpp:236] hidden_sum_layer needs backward computation.
I1005 20:54:17.527117 16163 net.cpp:240] data_layer does not need backward computation.
I1005 20:54:17.527119 16163 net.cpp:283] This network produces output error_blob
I1005 20:54:17.527123 16163 net.cpp:297] Network initialization done.
I1005 20:54:17.527125 16163 net.cpp:298] Memory required for data: 672004
I1005 20:54:17.527144 16163 solver.cpp:66] Solver scaffolding done.
I1005 20:54:17.527237 16163 caffe.cpp:212] Starting Optimization
I1005 20:54:17.527243 16163 solver.cpp:294] Solving large_batch/model0_part8.prototxt
I1005 20:54:17.527245 16163 solver.cpp:295] Learning Rate Policy: fixed
I1005 20:54:17.527385 16163 solver.cpp:347] Iteration 0, Testing net (#0)
I1005 20:54:17.527451 16163 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:54:17.804862 16163 solver.cpp:415]     Test net output #0: error_blob = 0.147506 (* 1 = 0.147506 loss)
I1005 20:54:17.806334 16163 solver.cpp:243] Iteration 0, loss = 0.148891
I1005 20:54:17.806361 16163 solver.cpp:259]     Train net output #0: error_blob = 0.148891 (* 1 = 0.148891 loss)
I1005 20:54:17.806375 16163 solver.cpp:590] Iteration 0, lr = 0.01
I1005 20:54:20.277750 16163 solver.cpp:243] Iteration 100, loss = 0.11781
I1005 20:54:20.277782 16163 solver.cpp:259]     Train net output #0: error_blob = 0.11781 (* 1 = 0.11781 loss)
I1005 20:54:20.277787 16163 solver.cpp:590] Iteration 100, lr = 0.01
I1005 20:54:22.784931 16163 solver.cpp:243] Iteration 200, loss = 0.112521
I1005 20:54:22.784978 16163 solver.cpp:259]     Train net output #0: error_blob = 0.112521 (* 1 = 0.112521 loss)
I1005 20:54:22.784987 16163 solver.cpp:590] Iteration 200, lr = 0.01
I1005 20:54:25.299204 16163 solver.cpp:243] Iteration 300, loss = 0.110612
I1005 20:54:25.299255 16163 solver.cpp:259]     Train net output #0: error_blob = 0.110612 (* 1 = 0.110612 loss)
I1005 20:54:25.299265 16163 solver.cpp:590] Iteration 300, lr = 0.01
I1005 20:54:27.821372 16163 solver.cpp:243] Iteration 400, loss = 0.108431
I1005 20:54:27.821421 16163 solver.cpp:259]     Train net output #0: error_blob = 0.108431 (* 1 = 0.108431 loss)
I1005 20:54:27.821460 16163 solver.cpp:590] Iteration 400, lr = 0.01
I1005 20:54:30.337399 16163 solver.cpp:243] Iteration 500, loss = 0.107097
I1005 20:54:30.337450 16163 solver.cpp:259]     Train net output #0: error_blob = 0.107097 (* 1 = 0.107097 loss)
I1005 20:54:30.337457 16163 solver.cpp:590] Iteration 500, lr = 0.01
I1005 20:54:32.809932 16163 solver.cpp:243] Iteration 600, loss = 0.108913
I1005 20:54:32.809981 16163 solver.cpp:259]     Train net output #0: error_blob = 0.108913 (* 1 = 0.108913 loss)
I1005 20:54:32.809988 16163 solver.cpp:590] Iteration 600, lr = 0.01
I1005 20:54:35.269595 16163 solver.cpp:243] Iteration 700, loss = 0.108237
I1005 20:54:35.269632 16163 solver.cpp:259]     Train net output #0: error_blob = 0.108237 (* 1 = 0.108237 loss)
I1005 20:54:35.269640 16163 solver.cpp:590] Iteration 700, lr = 0.01
I1005 20:54:37.753293 16163 solver.cpp:243] Iteration 800, loss = 0.105007
I1005 20:54:37.753330 16163 solver.cpp:259]     Train net output #0: error_blob = 0.105007 (* 1 = 0.105007 loss)
I1005 20:54:37.753339 16163 solver.cpp:590] Iteration 800, lr = 0.01
I1005 20:54:40.263334 16163 solver.cpp:243] Iteration 900, loss = 0.105603
I1005 20:54:40.263372 16163 solver.cpp:259]     Train net output #0: error_blob = 0.105603 (* 1 = 0.105603 loss)
I1005 20:54:40.263381 16163 solver.cpp:590] Iteration 900, lr = 0.01
I1005 20:54:40.313110 16163 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:54:42.735406 16163 solver.cpp:347] Iteration 1000, Testing net (#0)
I1005 20:54:43.046643 16163 solver.cpp:415]     Test net output #0: error_blob = 0.111509 (* 1 = 0.111509 loss)
I1005 20:54:43.049052 16163 solver.cpp:243] Iteration 1000, loss = 0.106426
I1005 20:54:43.049078 16163 solver.cpp:259]     Train net output #0: error_blob = 0.106426 (* 1 = 0.106426 loss)
I1005 20:54:43.049087 16163 solver.cpp:590] Iteration 1000, lr = 0.01
I1005 20:54:45.506656 16163 solver.cpp:243] Iteration 1100, loss = 0.102612
I1005 20:54:45.506705 16163 solver.cpp:259]     Train net output #0: error_blob = 0.102612 (* 1 = 0.102612 loss)
I1005 20:54:45.506713 16163 solver.cpp:590] Iteration 1100, lr = 0.01
I1005 20:54:48.015064 16163 solver.cpp:243] Iteration 1200, loss = 0.103176
I1005 20:54:48.015108 16163 solver.cpp:259]     Train net output #0: error_blob = 0.103176 (* 1 = 0.103176 loss)
I1005 20:54:48.015115 16163 solver.cpp:590] Iteration 1200, lr = 0.01
I1005 20:54:50.443444 16163 solver.cpp:243] Iteration 1300, loss = 0.103766
I1005 20:54:50.443493 16163 solver.cpp:259]     Train net output #0: error_blob = 0.103766 (* 1 = 0.103766 loss)
I1005 20:54:50.443501 16163 solver.cpp:590] Iteration 1300, lr = 0.01
I1005 20:54:52.883754 16163 solver.cpp:243] Iteration 1400, loss = 0.102973
I1005 20:54:52.883788 16163 solver.cpp:259]     Train net output #0: error_blob = 0.102973 (* 1 = 0.102973 loss)
I1005 20:54:52.883795 16163 solver.cpp:590] Iteration 1400, lr = 0.01
I1005 20:54:55.338340 16163 solver.cpp:243] Iteration 1500, loss = 0.102443
I1005 20:54:55.338390 16163 solver.cpp:259]     Train net output #0: error_blob = 0.102443 (* 1 = 0.102443 loss)
I1005 20:54:55.338400 16163 solver.cpp:590] Iteration 1500, lr = 0.01
I1005 20:54:57.850567 16163 solver.cpp:243] Iteration 1600, loss = 0.105043
I1005 20:54:57.850618 16163 solver.cpp:259]     Train net output #0: error_blob = 0.105043 (* 1 = 0.105043 loss)
I1005 20:54:57.850626 16163 solver.cpp:590] Iteration 1600, lr = 0.01
I1005 20:55:00.358856 16163 solver.cpp:243] Iteration 1700, loss = 0.104959
I1005 20:55:00.358898 16163 solver.cpp:259]     Train net output #0: error_blob = 0.104959 (* 1 = 0.104959 loss)
I1005 20:55:00.358904 16163 solver.cpp:590] Iteration 1700, lr = 0.01
I1005 20:55:02.787472 16163 solver.cpp:243] Iteration 1800, loss = 0.101138
I1005 20:55:02.787515 16163 solver.cpp:259]     Train net output #0: error_blob = 0.101138 (* 1 = 0.101138 loss)
I1005 20:55:02.787520 16163 solver.cpp:590] Iteration 1800, lr = 0.01
I1005 20:55:02.979667 16163 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:55:05.277215 16163 solver.cpp:243] Iteration 1900, loss = 0.101949
I1005 20:55:05.277246 16163 solver.cpp:259]     Train net output #0: error_blob = 0.101949 (* 1 = 0.101949 loss)
I1005 20:55:05.277252 16163 solver.cpp:590] Iteration 1900, lr = 0.01
I1005 20:55:07.779415 16163 solver.cpp:347] Iteration 2000, Testing net (#0)
I1005 20:55:08.121614 16163 solver.cpp:415]     Test net output #0: error_blob = 0.10899 (* 1 = 0.10899 loss)
I1005 20:55:08.122238 16163 solver.cpp:243] Iteration 2000, loss = 0.103769
I1005 20:55:08.122251 16163 solver.cpp:259]     Train net output #0: error_blob = 0.103769 (* 1 = 0.103769 loss)
I1005 20:55:08.122254 16163 solver.cpp:590] Iteration 2000, lr = 0.01
I1005 20:55:10.580312 16163 solver.cpp:243] Iteration 2100, loss = 0.100583
I1005 20:55:10.580345 16163 solver.cpp:259]     Train net output #0: error_blob = 0.100583 (* 1 = 0.100583 loss)
I1005 20:55:10.580363 16163 solver.cpp:590] Iteration 2100, lr = 0.01
I1005 20:55:13.104358 16163 solver.cpp:243] Iteration 2200, loss = 0.100745
I1005 20:55:13.105586 16163 solver.cpp:259]     Train net output #0: error_blob = 0.100745 (* 1 = 0.100745 loss)
I1005 20:55:13.105594 16163 solver.cpp:590] Iteration 2200, lr = 0.01
I1005 20:55:15.557430 16163 solver.cpp:243] Iteration 2300, loss = 0.101991
I1005 20:55:15.557461 16163 solver.cpp:259]     Train net output #0: error_blob = 0.101991 (* 1 = 0.101991 loss)
I1005 20:55:15.557466 16163 solver.cpp:590] Iteration 2300, lr = 0.01
I1005 20:55:18.048449 16163 solver.cpp:243] Iteration 2400, loss = 0.101375
I1005 20:55:18.048485 16163 solver.cpp:259]     Train net output #0: error_blob = 0.101375 (* 1 = 0.101375 loss)
I1005 20:55:18.048508 16163 solver.cpp:590] Iteration 2400, lr = 0.01
I1005 20:55:20.532793 16163 solver.cpp:243] Iteration 2500, loss = 0.099788
I1005 20:55:20.532825 16163 solver.cpp:259]     Train net output #0: error_blob = 0.099788 (* 1 = 0.099788 loss)
I1005 20:55:20.532830 16163 solver.cpp:590] Iteration 2500, lr = 0.01
I1005 20:55:22.978854 16163 solver.cpp:243] Iteration 2600, loss = 0.102793
I1005 20:55:22.978899 16163 solver.cpp:259]     Train net output #0: error_blob = 0.102793 (* 1 = 0.102793 loss)
I1005 20:55:22.978904 16163 solver.cpp:590] Iteration 2600, lr = 0.01
I1005 20:55:25.454960 16163 solver.cpp:243] Iteration 2700, loss = 0.103331
I1005 20:55:25.454994 16163 solver.cpp:259]     Train net output #0: error_blob = 0.103331 (* 1 = 0.103331 loss)
I1005 20:55:25.455000 16163 solver.cpp:590] Iteration 2700, lr = 0.01
I1005 20:55:25.802750 16163 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:55:27.914182 16163 solver.cpp:243] Iteration 2800, loss = 0.0995411
I1005 20:55:27.914214 16163 solver.cpp:259]     Train net output #0: error_blob = 0.0995411 (* 1 = 0.0995411 loss)
I1005 20:55:27.914221 16163 solver.cpp:590] Iteration 2800, lr = 0.01
I1005 20:55:30.378422 16163 solver.cpp:243] Iteration 2900, loss = 0.100413
I1005 20:55:30.378454 16163 solver.cpp:259]     Train net output #0: error_blob = 0.100413 (* 1 = 0.100413 loss)
I1005 20:55:30.378460 16163 solver.cpp:590] Iteration 2900, lr = 0.01
I1005 20:55:32.773167 16163 solver.cpp:347] Iteration 3000, Testing net (#0)
I1005 20:55:33.054708 16163 solver.cpp:415]     Test net output #0: error_blob = 0.107248 (* 1 = 0.107248 loss)
I1005 20:55:33.055393 16163 solver.cpp:243] Iteration 3000, loss = 0.102629
I1005 20:55:33.055413 16163 solver.cpp:259]     Train net output #0: error_blob = 0.102629 (* 1 = 0.102629 loss)
I1005 20:55:33.055420 16163 solver.cpp:590] Iteration 3000, lr = 0.01
I1005 20:55:35.474031 16163 solver.cpp:243] Iteration 3100, loss = 0.0987319
I1005 20:55:35.474068 16163 solver.cpp:259]     Train net output #0: error_blob = 0.0987319 (* 1 = 0.0987319 loss)
I1005 20:55:35.474076 16163 solver.cpp:590] Iteration 3100, lr = 0.01
I1005 20:55:37.891242 16163 solver.cpp:243] Iteration 3200, loss = 0.0988198
I1005 20:55:37.891278 16163 solver.cpp:259]     Train net output #0: error_blob = 0.0988198 (* 1 = 0.0988198 loss)
I1005 20:55:37.891288 16163 solver.cpp:590] Iteration 3200, lr = 0.01
I1005 20:55:40.315868 16163 solver.cpp:243] Iteration 3300, loss = 0.101125
I1005 20:55:40.315903 16163 solver.cpp:259]     Train net output #0: error_blob = 0.101125 (* 1 = 0.101125 loss)
I1005 20:55:40.315910 16163 solver.cpp:590] Iteration 3300, lr = 0.01
I1005 20:55:42.780597 16163 solver.cpp:243] Iteration 3400, loss = 0.100572
I1005 20:55:42.780629 16163 solver.cpp:259]     Train net output #0: error_blob = 0.100572 (* 1 = 0.100572 loss)
I1005 20:55:42.780634 16163 solver.cpp:590] Iteration 3400, lr = 0.01
I1005 20:55:45.235674 16163 solver.cpp:243] Iteration 3500, loss = 0.098266
I1005 20:55:45.235784 16163 solver.cpp:259]     Train net output #0: error_blob = 0.098266 (* 1 = 0.098266 loss)
I1005 20:55:45.235790 16163 solver.cpp:590] Iteration 3500, lr = 0.01
I1005 20:55:47.715523 16163 solver.cpp:243] Iteration 3600, loss = 0.101591
I1005 20:55:47.715554 16163 solver.cpp:259]     Train net output #0: error_blob = 0.101591 (* 1 = 0.101591 loss)
I1005 20:55:47.715559 16163 solver.cpp:590] Iteration 3600, lr = 0.01
I1005 20:55:48.214335 16163 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:55:50.185278 16163 solver.cpp:243] Iteration 3700, loss = 0.10241
I1005 20:55:50.185309 16163 solver.cpp:259]     Train net output #0: error_blob = 0.10241 (* 1 = 0.10241 loss)
I1005 20:55:50.185315 16163 solver.cpp:590] Iteration 3700, lr = 0.01
I1005 20:55:52.605347 16163 solver.cpp:243] Iteration 3800, loss = 0.097825
I1005 20:55:52.605379 16163 solver.cpp:259]     Train net output #0: error_blob = 0.097825 (* 1 = 0.097825 loss)
I1005 20:55:52.605386 16163 solver.cpp:590] Iteration 3800, lr = 0.01
I1005 20:55:55.094887 16163 solver.cpp:243] Iteration 3900, loss = 0.099605
I1005 20:55:55.094920 16163 solver.cpp:259]     Train net output #0: error_blob = 0.099605 (* 1 = 0.099605 loss)
I1005 20:55:55.094926 16163 solver.cpp:590] Iteration 3900, lr = 0.01
I1005 20:55:57.548168 16163 solver.cpp:347] Iteration 4000, Testing net (#0)
I1005 20:55:57.832741 16163 solver.cpp:415]     Test net output #0: error_blob = 0.106216 (* 1 = 0.106216 loss)
I1005 20:55:57.833410 16163 solver.cpp:243] Iteration 4000, loss = 0.101865
I1005 20:55:57.833430 16163 solver.cpp:259]     Train net output #0: error_blob = 0.101865 (* 1 = 0.101865 loss)
I1005 20:55:57.833437 16163 solver.cpp:590] Iteration 4000, lr = 0.01
I1005 20:56:00.263466 16163 solver.cpp:243] Iteration 4100, loss = 0.0971594
I1005 20:56:00.263499 16163 solver.cpp:259]     Train net output #0: error_blob = 0.0971594 (* 1 = 0.0971594 loss)
I1005 20:56:00.263504 16163 solver.cpp:590] Iteration 4100, lr = 0.01
I1005 20:56:02.726560 16163 solver.cpp:243] Iteration 4200, loss = 0.097356
I1005 20:56:02.726596 16163 solver.cpp:259]     Train net output #0: error_blob = 0.097356 (* 1 = 0.097356 loss)
I1005 20:56:02.726605 16163 solver.cpp:590] Iteration 4200, lr = 0.01
I1005 20:56:05.170083 16163 solver.cpp:243] Iteration 4300, loss = 0.100514
I1005 20:56:05.170114 16163 solver.cpp:259]     Train net output #0: error_blob = 0.100514 (* 1 = 0.100514 loss)
I1005 20:56:05.170120 16163 solver.cpp:590] Iteration 4300, lr = 0.01
I1005 20:56:07.636590 16163 solver.cpp:243] Iteration 4400, loss = 0.0999799
I1005 20:56:07.636622 16163 solver.cpp:259]     Train net output #0: error_blob = 0.0999799 (* 1 = 0.0999799 loss)
I1005 20:56:07.636628 16163 solver.cpp:590] Iteration 4400, lr = 0.01
I1005 20:56:10.086786 16163 solver.cpp:243] Iteration 4500, loss = 0.0962448
I1005 20:56:10.086828 16163 solver.cpp:259]     Train net output #0: error_blob = 0.0962448 (* 1 = 0.0962448 loss)
I1005 20:56:10.086833 16163 solver.cpp:590] Iteration 4500, lr = 0.01
I1005 20:56:10.724050 16163 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:56:12.559316 16163 solver.cpp:243] Iteration 4600, loss = 0.09997
I1005 20:56:12.559350 16163 solver.cpp:259]     Train net output #0: error_blob = 0.09997 (* 1 = 0.09997 loss)
I1005 20:56:12.559360 16163 solver.cpp:590] Iteration 4600, lr = 0.01
I1005 20:56:15.052618 16163 solver.cpp:243] Iteration 4700, loss = 0.101785
I1005 20:56:15.052650 16163 solver.cpp:259]     Train net output #0: error_blob = 0.101785 (* 1 = 0.101785 loss)
I1005 20:56:15.052655 16163 solver.cpp:590] Iteration 4700, lr = 0.01
I1005 20:56:17.489006 16163 solver.cpp:243] Iteration 4800, loss = 0.0962465
I1005 20:56:17.489154 16163 solver.cpp:259]     Train net output #0: error_blob = 0.0962465 (* 1 = 0.0962465 loss)
I1005 20:56:17.489172 16163 solver.cpp:590] Iteration 4800, lr = 0.01
I1005 20:56:19.917618 16163 solver.cpp:243] Iteration 4900, loss = 0.0993111
I1005 20:56:19.917654 16163 solver.cpp:259]     Train net output #0: error_blob = 0.0993111 (* 1 = 0.0993111 loss)
I1005 20:56:19.917660 16163 solver.cpp:590] Iteration 4900, lr = 0.01
I1005 20:56:22.359208 16163 solver.cpp:347] Iteration 5000, Testing net (#0)
I1005 20:56:22.625732 16163 solver.cpp:415]     Test net output #0: error_blob = 0.105303 (* 1 = 0.105303 loss)
I1005 20:56:22.626343 16163 solver.cpp:243] Iteration 5000, loss = 0.101882
I1005 20:56:22.626358 16163 solver.cpp:259]     Train net output #0: error_blob = 0.101882 (* 1 = 0.101882 loss)
I1005 20:56:22.626361 16163 solver.cpp:590] Iteration 5000, lr = 0.01
I1005 20:56:25.072989 16163 solver.cpp:243] Iteration 5100, loss = 0.0963859
I1005 20:56:25.073030 16163 solver.cpp:259]     Train net output #0: error_blob = 0.0963859 (* 1 = 0.0963859 loss)
I1005 20:56:25.073036 16163 solver.cpp:590] Iteration 5100, lr = 0.01
I1005 20:56:27.561867 16163 solver.cpp:243] Iteration 5200, loss = 0.0962573
I1005 20:56:27.561898 16163 solver.cpp:259]     Train net output #0: error_blob = 0.0962573 (* 1 = 0.0962573 loss)
I1005 20:56:27.561903 16163 solver.cpp:590] Iteration 5200, lr = 0.01
I1005 20:56:30.004086 16163 solver.cpp:243] Iteration 5300, loss = 0.100472
I1005 20:56:30.004127 16163 solver.cpp:259]     Train net output #0: error_blob = 0.100472 (* 1 = 0.100472 loss)
I1005 20:56:30.004133 16163 solver.cpp:590] Iteration 5300, lr = 0.01
I1005 20:56:32.454361 16163 solver.cpp:243] Iteration 5400, loss = 0.0991541
I1005 20:56:32.454396 16163 solver.cpp:259]     Train net output #0: error_blob = 0.0991541 (* 1 = 0.0991541 loss)
I1005 20:56:32.454401 16163 solver.cpp:590] Iteration 5400, lr = 0.01
I1005 20:56:33.233438 16163 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:56:34.916697 16163 solver.cpp:243] Iteration 5500, loss = 0.0952312
I1005 20:56:34.916733 16163 solver.cpp:259]     Train net output #0: error_blob = 0.0952312 (* 1 = 0.0952312 loss)
I1005 20:56:34.916740 16163 solver.cpp:590] Iteration 5500, lr = 0.01
I1005 20:56:37.398877 16163 solver.cpp:243] Iteration 5600, loss = 0.0985675
I1005 20:56:37.398913 16163 solver.cpp:259]     Train net output #0: error_blob = 0.0985675 (* 1 = 0.0985675 loss)
I1005 20:56:37.398921 16163 solver.cpp:590] Iteration 5600, lr = 0.01
I1005 20:56:39.921499 16163 solver.cpp:243] Iteration 5700, loss = 0.101174
I1005 20:56:39.921535 16163 solver.cpp:259]     Train net output #0: error_blob = 0.101174 (* 1 = 0.101174 loss)
I1005 20:56:39.921542 16163 solver.cpp:590] Iteration 5700, lr = 0.01
I1005 20:56:42.435725 16163 solver.cpp:243] Iteration 5800, loss = 0.0954378
I1005 20:56:42.435757 16163 solver.cpp:259]     Train net output #0: error_blob = 0.0954378 (* 1 = 0.0954378 loss)
I1005 20:56:42.435763 16163 solver.cpp:590] Iteration 5800, lr = 0.01
I1005 20:56:44.882742 16163 solver.cpp:243] Iteration 5900, loss = 0.098535
I1005 20:56:44.882776 16163 solver.cpp:259]     Train net output #0: error_blob = 0.098535 (* 1 = 0.098535 loss)
I1005 20:56:44.882781 16163 solver.cpp:590] Iteration 5900, lr = 0.01
I1005 20:56:47.301218 16163 solver.cpp:347] Iteration 6000, Testing net (#0)
I1005 20:56:47.572170 16163 solver.cpp:415]     Test net output #0: error_blob = 0.104737 (* 1 = 0.104737 loss)
I1005 20:56:47.572813 16163 solver.cpp:243] Iteration 6000, loss = 0.101367
I1005 20:56:47.572829 16163 solver.cpp:259]     Train net output #0: error_blob = 0.101367 (* 1 = 0.101367 loss)
I1005 20:56:47.572836 16163 solver.cpp:590] Iteration 6000, lr = 0.01
I1005 20:56:50.029731 16163 solver.cpp:243] Iteration 6100, loss = 0.0951673
I1005 20:56:50.029763 16163 solver.cpp:259]     Train net output #0: error_blob = 0.0951673 (* 1 = 0.0951673 loss)
I1005 20:56:50.029769 16163 solver.cpp:590] Iteration 6100, lr = 0.01
I1005 20:56:52.491829 16163 solver.cpp:243] Iteration 6200, loss = 0.0952153
I1005 20:56:52.491871 16163 solver.cpp:259]     Train net output #0: error_blob = 0.0952153 (* 1 = 0.0952153 loss)
I1005 20:56:52.491876 16163 solver.cpp:590] Iteration 6200, lr = 0.01
I1005 20:56:55.008652 16163 solver.cpp:243] Iteration 6300, loss = 0.0996057
I1005 20:56:55.008684 16163 solver.cpp:259]     Train net output #0: error_blob = 0.0996057 (* 1 = 0.0996057 loss)
I1005 20:56:55.008690 16163 solver.cpp:590] Iteration 6300, lr = 0.01
I1005 20:56:55.948220 16163 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:56:57.510583 16163 solver.cpp:243] Iteration 6400, loss = 0.0987479
I1005 20:56:57.510615 16163 solver.cpp:259]     Train net output #0: error_blob = 0.0987479 (* 1 = 0.0987479 loss)
I1005 20:56:57.510622 16163 solver.cpp:590] Iteration 6400, lr = 0.01
I1005 20:56:59.988638 16163 solver.cpp:243] Iteration 6500, loss = 0.0941648
I1005 20:56:59.988682 16163 solver.cpp:259]     Train net output #0: error_blob = 0.0941648 (* 1 = 0.0941648 loss)
I1005 20:56:59.988687 16163 solver.cpp:590] Iteration 6500, lr = 0.01
I1005 20:57:02.485394 16163 solver.cpp:243] Iteration 6600, loss = 0.0973777
I1005 20:57:02.485430 16163 solver.cpp:259]     Train net output #0: error_blob = 0.0973777 (* 1 = 0.0973777 loss)
I1005 20:57:02.485435 16163 solver.cpp:590] Iteration 6600, lr = 0.01
I1005 20:57:04.944655 16163 solver.cpp:243] Iteration 6700, loss = 0.101298
I1005 20:57:04.944690 16163 solver.cpp:259]     Train net output #0: error_blob = 0.101298 (* 1 = 0.101298 loss)
I1005 20:57:04.944697 16163 solver.cpp:590] Iteration 6700, lr = 0.01
I1005 20:57:07.436553 16163 solver.cpp:243] Iteration 6800, loss = 0.0948044
I1005 20:57:07.436586 16163 solver.cpp:259]     Train net output #0: error_blob = 0.0948044 (* 1 = 0.0948044 loss)
I1005 20:57:07.436594 16163 solver.cpp:590] Iteration 6800, lr = 0.01
I1005 20:57:09.897877 16163 solver.cpp:243] Iteration 6900, loss = 0.09794
I1005 20:57:09.897913 16163 solver.cpp:259]     Train net output #0: error_blob = 0.09794 (* 1 = 0.09794 loss)
I1005 20:57:09.897920 16163 solver.cpp:590] Iteration 6900, lr = 0.01
I1005 20:57:12.315217 16163 solver.cpp:347] Iteration 7000, Testing net (#0)
I1005 20:57:12.601850 16163 solver.cpp:415]     Test net output #0: error_blob = 0.103824 (* 1 = 0.103824 loss)
I1005 20:57:12.602490 16163 solver.cpp:243] Iteration 7000, loss = 0.100842
I1005 20:57:12.602506 16163 solver.cpp:259]     Train net output #0: error_blob = 0.100842 (* 1 = 0.100842 loss)
I1005 20:57:12.602516 16163 solver.cpp:590] Iteration 7000, lr = 0.01
I1005 20:57:15.019003 16163 solver.cpp:243] Iteration 7100, loss = 0.0937175
I1005 20:57:15.019039 16163 solver.cpp:259]     Train net output #0: error_blob = 0.0937175 (* 1 = 0.0937175 loss)
I1005 20:57:15.019048 16163 solver.cpp:590] Iteration 7100, lr = 0.01
I1005 20:57:17.493019 16163 solver.cpp:243] Iteration 7200, loss = 0.094731
I1005 20:57:17.493049 16163 solver.cpp:259]     Train net output #0: error_blob = 0.094731 (* 1 = 0.094731 loss)
I1005 20:57:17.493054 16163 solver.cpp:590] Iteration 7200, lr = 0.01
I1005 20:57:18.580478 16163 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:57:19.953919 16163 solver.cpp:243] Iteration 7300, loss = 0.0989765
I1005 20:57:19.953953 16163 solver.cpp:259]     Train net output #0: error_blob = 0.0989765 (* 1 = 0.0989765 loss)
I1005 20:57:19.953959 16163 solver.cpp:590] Iteration 7300, lr = 0.01
I1005 20:57:22.440593 16163 solver.cpp:243] Iteration 7400, loss = 0.0972547
I1005 20:57:22.440624 16163 solver.cpp:259]     Train net output #0: error_blob = 0.0972547 (* 1 = 0.0972547 loss)
I1005 20:57:22.440631 16163 solver.cpp:590] Iteration 7400, lr = 0.01
I1005 20:57:24.896914 16163 solver.cpp:243] Iteration 7500, loss = 0.0942399
I1005 20:57:24.896945 16163 solver.cpp:259]     Train net output #0: error_blob = 0.0942399 (* 1 = 0.0942399 loss)
I1005 20:57:24.896951 16163 solver.cpp:590] Iteration 7500, lr = 0.01
I1005 20:57:27.392264 16163 solver.cpp:243] Iteration 7600, loss = 0.0968565
I1005 20:57:27.392309 16163 solver.cpp:259]     Train net output #0: error_blob = 0.0968565 (* 1 = 0.0968565 loss)
I1005 20:57:27.392315 16163 solver.cpp:590] Iteration 7600, lr = 0.01
I1005 20:57:29.840533 16163 solver.cpp:243] Iteration 7700, loss = 0.100593
I1005 20:57:29.840567 16163 solver.cpp:259]     Train net output #0: error_blob = 0.100593 (* 1 = 0.100593 loss)
I1005 20:57:29.840576 16163 solver.cpp:590] Iteration 7700, lr = 0.01
I1005 20:57:32.324280 16163 solver.cpp:243] Iteration 7800, loss = 0.0940943
I1005 20:57:32.324309 16163 solver.cpp:259]     Train net output #0: error_blob = 0.0940943 (* 1 = 0.0940943 loss)
I1005 20:57:32.324316 16163 solver.cpp:590] Iteration 7800, lr = 0.01
I1005 20:57:34.804441 16163 solver.cpp:243] Iteration 7900, loss = 0.0980736
I1005 20:57:34.804476 16163 solver.cpp:259]     Train net output #0: error_blob = 0.0980736 (* 1 = 0.0980736 loss)
I1005 20:57:34.804482 16163 solver.cpp:590] Iteration 7900, lr = 0.01
I1005 20:57:37.231147 16163 solver.cpp:347] Iteration 8000, Testing net (#0)
I1005 20:57:37.503432 16163 solver.cpp:415]     Test net output #0: error_blob = 0.103189 (* 1 = 0.103189 loss)
I1005 20:57:37.504048 16163 solver.cpp:243] Iteration 8000, loss = 0.100243
I1005 20:57:37.504061 16163 solver.cpp:259]     Train net output #0: error_blob = 0.100243 (* 1 = 0.100243 loss)
I1005 20:57:37.504066 16163 solver.cpp:590] Iteration 8000, lr = 0.01
I1005 20:57:40.050840 16163 solver.cpp:243] Iteration 8100, loss = 0.0934306
I1005 20:57:40.050873 16163 solver.cpp:259]     Train net output #0: error_blob = 0.0934306 (* 1 = 0.0934306 loss)
I1005 20:57:40.050879 16163 solver.cpp:590] Iteration 8100, lr = 0.01
I1005 20:57:41.276192 16163 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:57:42.504789 16163 solver.cpp:243] Iteration 8200, loss = 0.0943888
I1005 20:57:42.504819 16163 solver.cpp:259]     Train net output #0: error_blob = 0.0943888 (* 1 = 0.0943888 loss)
I1005 20:57:42.504825 16163 solver.cpp:590] Iteration 8200, lr = 0.01
I1005 20:57:44.946988 16163 solver.cpp:243] Iteration 8300, loss = 0.0991025
I1005 20:57:44.947021 16163 solver.cpp:259]     Train net output #0: error_blob = 0.0991025 (* 1 = 0.0991025 loss)
I1005 20:57:44.947026 16163 solver.cpp:590] Iteration 8300, lr = 0.01
I1005 20:57:47.393093 16163 solver.cpp:243] Iteration 8400, loss = 0.0965154
I1005 20:57:47.393126 16163 solver.cpp:259]     Train net output #0: error_blob = 0.0965154 (* 1 = 0.0965154 loss)
I1005 20:57:47.393136 16163 solver.cpp:590] Iteration 8400, lr = 0.01
I1005 20:57:49.850961 16163 solver.cpp:243] Iteration 8500, loss = 0.0938182
I1005 20:57:49.851068 16163 solver.cpp:259]     Train net output #0: error_blob = 0.0938182 (* 1 = 0.0938182 loss)
I1005 20:57:49.851079 16163 solver.cpp:590] Iteration 8500, lr = 0.01
I1005 20:57:52.333257 16163 solver.cpp:243] Iteration 8600, loss = 0.0958122
I1005 20:57:52.333292 16163 solver.cpp:259]     Train net output #0: error_blob = 0.0958122 (* 1 = 0.0958122 loss)
I1005 20:57:52.333299 16163 solver.cpp:590] Iteration 8600, lr = 0.01
I1005 20:57:54.789675 16163 solver.cpp:243] Iteration 8700, loss = 0.100055
I1005 20:57:54.789708 16163 solver.cpp:259]     Train net output #0: error_blob = 0.100055 (* 1 = 0.100055 loss)
I1005 20:57:54.789717 16163 solver.cpp:590] Iteration 8700, lr = 0.01
I1005 20:57:57.283184 16163 solver.cpp:243] Iteration 8800, loss = 0.09333
I1005 20:57:57.283215 16163 solver.cpp:259]     Train net output #0: error_blob = 0.09333 (* 1 = 0.09333 loss)
I1005 20:57:57.283221 16163 solver.cpp:590] Iteration 8800, lr = 0.01
I1005 20:57:59.713615 16163 solver.cpp:243] Iteration 8900, loss = 0.0987939
I1005 20:57:59.713649 16163 solver.cpp:259]     Train net output #0: error_blob = 0.0987939 (* 1 = 0.0987939 loss)
I1005 20:57:59.713654 16163 solver.cpp:590] Iteration 8900, lr = 0.01
I1005 20:58:02.137398 16163 solver.cpp:347] Iteration 9000, Testing net (#0)
I1005 20:58:02.432216 16163 solver.cpp:415]     Test net output #0: error_blob = 0.102531 (* 1 = 0.102531 loss)
I1005 20:58:02.432843 16163 solver.cpp:243] Iteration 9000, loss = 0.0996043
I1005 20:58:02.432860 16163 solver.cpp:259]     Train net output #0: error_blob = 0.0996043 (* 1 = 0.0996043 loss)
I1005 20:58:02.432869 16163 solver.cpp:590] Iteration 9000, lr = 0.01
I1005 20:58:03.760258 16163 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:58:04.843091 16163 solver.cpp:243] Iteration 9100, loss = 0.0937762
I1005 20:58:04.843127 16163 solver.cpp:259]     Train net output #0: error_blob = 0.0937762 (* 1 = 0.0937762 loss)
I1005 20:58:04.843133 16163 solver.cpp:590] Iteration 9100, lr = 0.01
I1005 20:58:07.337602 16163 solver.cpp:243] Iteration 9200, loss = 0.0939278
I1005 20:58:07.337635 16163 solver.cpp:259]     Train net output #0: error_blob = 0.0939278 (* 1 = 0.0939278 loss)
I1005 20:58:07.337641 16163 solver.cpp:590] Iteration 9200, lr = 0.01
I1005 20:58:09.827009 16163 solver.cpp:243] Iteration 9300, loss = 0.0984976
I1005 20:58:09.827042 16163 solver.cpp:259]     Train net output #0: error_blob = 0.0984976 (* 1 = 0.0984976 loss)
I1005 20:58:09.827049 16163 solver.cpp:590] Iteration 9300, lr = 0.01
I1005 20:58:12.264070 16163 solver.cpp:243] Iteration 9400, loss = 0.0964737
I1005 20:58:12.264102 16163 solver.cpp:259]     Train net output #0: error_blob = 0.0964737 (* 1 = 0.0964737 loss)
I1005 20:58:12.264109 16163 solver.cpp:590] Iteration 9400, lr = 0.01
I1005 20:58:14.725728 16163 solver.cpp:243] Iteration 9500, loss = 0.0924822
I1005 20:58:14.725760 16163 solver.cpp:259]     Train net output #0: error_blob = 0.0924822 (* 1 = 0.0924822 loss)
I1005 20:58:14.725766 16163 solver.cpp:590] Iteration 9500, lr = 0.01
I1005 20:58:17.188187 16163 solver.cpp:243] Iteration 9600, loss = 0.0955789
I1005 20:58:17.188230 16163 solver.cpp:259]     Train net output #0: error_blob = 0.0955789 (* 1 = 0.0955789 loss)
I1005 20:58:17.188236 16163 solver.cpp:590] Iteration 9600, lr = 0.01
I1005 20:58:19.650470 16163 solver.cpp:243] Iteration 9700, loss = 0.0997381
I1005 20:58:19.650502 16163 solver.cpp:259]     Train net output #0: error_blob = 0.0997381 (* 1 = 0.0997381 loss)
I1005 20:58:19.650508 16163 solver.cpp:590] Iteration 9700, lr = 0.01
I1005 20:58:22.113941 16163 solver.cpp:243] Iteration 9800, loss = 0.0923211
I1005 20:58:22.114042 16163 solver.cpp:259]     Train net output #0: error_blob = 0.0923211 (* 1 = 0.0923211 loss)
I1005 20:58:22.114050 16163 solver.cpp:590] Iteration 9800, lr = 0.01
I1005 20:58:24.568482 16163 solver.cpp:243] Iteration 9900, loss = 0.0989644
I1005 20:58:24.568539 16163 solver.cpp:259]     Train net output #0: error_blob = 0.0989644 (* 1 = 0.0989644 loss)
I1005 20:58:24.568545 16163 solver.cpp:590] Iteration 9900, lr = 0.01
I1005 20:58:27.009021 16163 solver.cpp:468] Snapshotting to binary proto file _iter_10000.caffemodel
I1005 20:58:27.009887 16163 solver.cpp:753] Snapshotting solver state to binary proto file _iter_10000.solverstate
I1005 20:58:27.033385 16163 solver.cpp:327] Iteration 10000, loss = 0.099666
I1005 20:58:27.033419 16163 solver.cpp:347] Iteration 10000, Testing net (#0)
I1005 20:58:27.268203 16163 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:58:27.390074 16163 solver.cpp:415]     Test net output #0: error_blob = 0.101851 (* 1 = 0.101851 loss)
I1005 20:58:27.390105 16163 solver.cpp:332] Optimization Done.
I1005 20:58:27.390107 16163 caffe.cpp:215] Optimization Done.
I1005 20:58:27.454787 16172 caffe.cpp:184] Using GPUs 0
I1005 20:58:28.017632 16172 solver.cpp:54] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "fixed"
momentum: 0.9
solver_mode: GPU
device_id: 0
net: "large_batch/model0_part0.prototxt"
I1005 20:58:28.017666 16172 solver.cpp:97] Creating training net from net file: large_batch/model0_part0.prototxt
I1005 20:58:28.017849 16172 net.cpp:339] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_layer
I1005 20:58:28.017892 16172 net.cpp:50] Initializing net from parameters: 
name: "large_batch/model0_part0.prototxt"
state {
  phase: TRAIN
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TRAIN
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.part0.train"
    batch_size: 20000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1005 20:58:28.017963 16172 layer_factory.hpp:76] Creating layer data_layer
I1005 20:58:28.031306 16172 net.cpp:110] Creating Layer data_layer
I1005 20:58:28.031327 16172 net.cpp:433] data_layer -> data_blob
I1005 20:58:28.031352 16172 net.cpp:433] data_layer -> label_blob
I1005 20:58:28.031939 16176 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.part0.train
I1005 20:58:28.722934 16172 data_layer.cpp:45] output data size: 20000,61,1,1
I1005 20:58:28.727874 16172 net.cpp:155] Setting up data_layer
I1005 20:58:28.727908 16172 net.cpp:163] Top shape: 20000 61 1 1 (1220000)
I1005 20:58:28.727915 16172 net.cpp:163] Top shape: 20000 (20000)
I1005 20:58:28.727921 16172 layer_factory.hpp:76] Creating layer hidden_sum_layer
I1005 20:58:28.727936 16172 net.cpp:110] Creating Layer hidden_sum_layer
I1005 20:58:28.727944 16172 net.cpp:477] hidden_sum_layer <- data_blob
I1005 20:58:28.727957 16172 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I1005 20:58:28.728312 16172 net.cpp:155] Setting up hidden_sum_layer
I1005 20:58:28.728320 16172 net.cpp:163] Top shape: 20000 10 (200000)
I1005 20:58:28.728337 16172 layer_factory.hpp:76] Creating layer hidden_act_layer
I1005 20:58:28.728349 16172 net.cpp:110] Creating Layer hidden_act_layer
I1005 20:58:28.728354 16172 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I1005 20:58:28.728358 16172 net.cpp:433] hidden_act_layer -> hidden_act_blob
I1005 20:58:31.951134 16172 net.cpp:155] Setting up hidden_act_layer
I1005 20:58:31.951158 16172 net.cpp:163] Top shape: 20000 10 (200000)
I1005 20:58:31.951164 16172 layer_factory.hpp:76] Creating layer output_sum_layer
I1005 20:58:31.951186 16172 net.cpp:110] Creating Layer output_sum_layer
I1005 20:58:31.951191 16172 net.cpp:477] output_sum_layer <- hidden_act_blob
I1005 20:58:31.951200 16172 net.cpp:433] output_sum_layer -> output_sum_blob
I1005 20:58:31.951295 16172 net.cpp:155] Setting up output_sum_layer
I1005 20:58:31.951311 16172 net.cpp:163] Top shape: 20000 1 (20000)
I1005 20:58:31.951321 16172 layer_factory.hpp:76] Creating layer output_act_layer
I1005 20:58:31.951329 16172 net.cpp:110] Creating Layer output_act_layer
I1005 20:58:31.951333 16172 net.cpp:477] output_act_layer <- output_sum_blob
I1005 20:58:31.951339 16172 net.cpp:433] output_act_layer -> output_act_blob
I1005 20:58:31.951403 16172 net.cpp:155] Setting up output_act_layer
I1005 20:58:31.951424 16172 net.cpp:163] Top shape: 20000 1 (20000)
I1005 20:58:31.951428 16172 layer_factory.hpp:76] Creating layer error_layer
I1005 20:58:31.951436 16172 net.cpp:110] Creating Layer error_layer
I1005 20:58:31.951441 16172 net.cpp:477] error_layer <- output_act_blob
I1005 20:58:31.951445 16172 net.cpp:477] error_layer <- label_blob
I1005 20:58:31.951452 16172 net.cpp:433] error_layer -> error_blob
I1005 20:58:31.951483 16172 net.cpp:155] Setting up error_layer
I1005 20:58:31.951488 16172 net.cpp:163] Top shape: (1)
I1005 20:58:31.951493 16172 net.cpp:168]     with loss weight 1
I1005 20:58:31.951514 16172 net.cpp:236] error_layer needs backward computation.
I1005 20:58:31.951521 16172 net.cpp:236] output_act_layer needs backward computation.
I1005 20:58:31.951526 16172 net.cpp:236] output_sum_layer needs backward computation.
I1005 20:58:31.951530 16172 net.cpp:236] hidden_act_layer needs backward computation.
I1005 20:58:31.951534 16172 net.cpp:236] hidden_sum_layer needs backward computation.
I1005 20:58:31.951539 16172 net.cpp:240] data_layer does not need backward computation.
I1005 20:58:31.951544 16172 net.cpp:283] This network produces output error_blob
I1005 20:58:31.951551 16172 net.cpp:297] Network initialization done.
I1005 20:58:31.951555 16172 net.cpp:298] Memory required for data: 6720004
I1005 20:58:31.951690 16172 solver.cpp:187] Creating test net (#0) specified by net file: large_batch/model0_part0.prototxt
I1005 20:58:31.951709 16172 net.cpp:339] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_layer
I1005 20:58:31.951748 16172 net.cpp:50] Initializing net from parameters: 
name: "large_batch/model0_part0.prototxt"
state {
  phase: TEST
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TEST
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.part0.test"
    batch_size: 2000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1005 20:58:31.951779 16172 layer_factory.hpp:76] Creating layer data_layer
I1005 20:58:31.953109 16172 net.cpp:110] Creating Layer data_layer
I1005 20:58:31.953119 16172 net.cpp:433] data_layer -> data_blob
I1005 20:58:31.953125 16172 net.cpp:433] data_layer -> label_blob
I1005 20:58:31.953667 16178 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.part0.test
I1005 20:58:31.953734 16172 data_layer.cpp:45] output data size: 2000,61,1,1
I1005 20:58:31.955101 16172 net.cpp:155] Setting up data_layer
I1005 20:58:31.955112 16172 net.cpp:163] Top shape: 2000 61 1 1 (122000)
I1005 20:58:31.955118 16172 net.cpp:163] Top shape: 2000 (2000)
I1005 20:58:31.955123 16172 layer_factory.hpp:76] Creating layer hidden_sum_layer
I1005 20:58:31.955134 16172 net.cpp:110] Creating Layer hidden_sum_layer
I1005 20:58:31.955139 16172 net.cpp:477] hidden_sum_layer <- data_blob
I1005 20:58:31.955147 16172 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I1005 20:58:31.955257 16172 net.cpp:155] Setting up hidden_sum_layer
I1005 20:58:31.955265 16172 net.cpp:163] Top shape: 2000 10 (20000)
I1005 20:58:31.955276 16172 layer_factory.hpp:76] Creating layer hidden_act_layer
I1005 20:58:31.955284 16172 net.cpp:110] Creating Layer hidden_act_layer
I1005 20:58:31.955289 16172 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I1005 20:58:31.955308 16172 net.cpp:433] hidden_act_layer -> hidden_act_blob
I1005 20:58:31.955495 16172 net.cpp:155] Setting up hidden_act_layer
I1005 20:58:31.955503 16172 net.cpp:163] Top shape: 2000 10 (20000)
I1005 20:58:31.955507 16172 layer_factory.hpp:76] Creating layer output_sum_layer
I1005 20:58:31.955514 16172 net.cpp:110] Creating Layer output_sum_layer
I1005 20:58:31.955518 16172 net.cpp:477] output_sum_layer <- hidden_act_blob
I1005 20:58:31.955524 16172 net.cpp:433] output_sum_layer -> output_sum_blob
I1005 20:58:31.955590 16172 net.cpp:155] Setting up output_sum_layer
I1005 20:58:31.955597 16172 net.cpp:163] Top shape: 2000 1 (2000)
I1005 20:58:31.955606 16172 layer_factory.hpp:76] Creating layer output_act_layer
I1005 20:58:31.955613 16172 net.cpp:110] Creating Layer output_act_layer
I1005 20:58:31.955616 16172 net.cpp:477] output_act_layer <- output_sum_blob
I1005 20:58:31.955623 16172 net.cpp:433] output_act_layer -> output_act_blob
I1005 20:58:31.955682 16172 net.cpp:155] Setting up output_act_layer
I1005 20:58:31.955687 16172 net.cpp:163] Top shape: 2000 1 (2000)
I1005 20:58:31.955692 16172 layer_factory.hpp:76] Creating layer error_layer
I1005 20:58:31.955698 16172 net.cpp:110] Creating Layer error_layer
I1005 20:58:31.955700 16172 net.cpp:477] error_layer <- output_act_blob
I1005 20:58:31.955705 16172 net.cpp:477] error_layer <- label_blob
I1005 20:58:31.955711 16172 net.cpp:433] error_layer -> error_blob
I1005 20:58:31.955737 16172 net.cpp:155] Setting up error_layer
I1005 20:58:31.955744 16172 net.cpp:163] Top shape: (1)
I1005 20:58:31.955746 16172 net.cpp:168]     with loss weight 1
I1005 20:58:31.955757 16172 net.cpp:236] error_layer needs backward computation.
I1005 20:58:31.955762 16172 net.cpp:236] output_act_layer needs backward computation.
I1005 20:58:31.955766 16172 net.cpp:236] output_sum_layer needs backward computation.
I1005 20:58:31.955770 16172 net.cpp:236] hidden_act_layer needs backward computation.
I1005 20:58:31.955775 16172 net.cpp:236] hidden_sum_layer needs backward computation.
I1005 20:58:31.955778 16172 net.cpp:240] data_layer does not need backward computation.
I1005 20:58:31.955781 16172 net.cpp:283] This network produces output error_blob
I1005 20:58:31.955790 16172 net.cpp:297] Network initialization done.
I1005 20:58:31.955793 16172 net.cpp:298] Memory required for data: 672004
I1005 20:58:31.955817 16172 solver.cpp:66] Solver scaffolding done.
I1005 20:58:31.955911 16172 caffe.cpp:212] Starting Optimization
I1005 20:58:31.955919 16172 solver.cpp:294] Solving large_batch/model0_part0.prototxt
I1005 20:58:31.955924 16172 solver.cpp:295] Learning Rate Policy: fixed
I1005 20:58:31.956102 16172 solver.cpp:347] Iteration 0, Testing net (#0)
I1005 20:58:31.956199 16172 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:58:32.234438 16172 solver.cpp:415]     Test net output #0: error_blob = 0.120653 (* 1 = 0.120653 loss)
I1005 20:58:32.235959 16172 solver.cpp:243] Iteration 0, loss = 0.122298
I1005 20:58:32.236001 16172 solver.cpp:259]     Train net output #0: error_blob = 0.122298 (* 1 = 0.122298 loss)
I1005 20:58:32.236017 16172 solver.cpp:590] Iteration 0, lr = 0.01
I1005 20:58:34.731807 16172 solver.cpp:243] Iteration 100, loss = 0.115373
I1005 20:58:34.731858 16172 solver.cpp:259]     Train net output #0: error_blob = 0.115373 (* 1 = 0.115373 loss)
I1005 20:58:34.731865 16172 solver.cpp:590] Iteration 100, lr = 0.01
I1005 20:58:37.232359 16172 solver.cpp:243] Iteration 200, loss = 0.111905
I1005 20:58:37.232390 16172 solver.cpp:259]     Train net output #0: error_blob = 0.111905 (* 1 = 0.111905 loss)
I1005 20:58:37.232396 16172 solver.cpp:590] Iteration 200, lr = 0.01
I1005 20:58:39.789657 16172 solver.cpp:243] Iteration 300, loss = 0.10784
I1005 20:58:39.789698 16172 solver.cpp:259]     Train net output #0: error_blob = 0.10784 (* 1 = 0.10784 loss)
I1005 20:58:39.789705 16172 solver.cpp:590] Iteration 300, lr = 0.01
I1005 20:58:42.328660 16172 solver.cpp:243] Iteration 400, loss = 0.107206
I1005 20:58:42.328691 16172 solver.cpp:259]     Train net output #0: error_blob = 0.107206 (* 1 = 0.107206 loss)
I1005 20:58:42.328721 16172 solver.cpp:590] Iteration 400, lr = 0.01
I1005 20:58:44.838770 16172 solver.cpp:243] Iteration 500, loss = 0.107689
I1005 20:58:44.838799 16172 solver.cpp:259]     Train net output #0: error_blob = 0.107689 (* 1 = 0.107689 loss)
I1005 20:58:44.838805 16172 solver.cpp:590] Iteration 500, lr = 0.01
I1005 20:58:47.355402 16172 solver.cpp:243] Iteration 600, loss = 0.108051
I1005 20:58:47.355440 16172 solver.cpp:259]     Train net output #0: error_blob = 0.108051 (* 1 = 0.108051 loss)
I1005 20:58:47.355448 16172 solver.cpp:590] Iteration 600, lr = 0.01
I1005 20:58:49.846127 16172 solver.cpp:243] Iteration 700, loss = 0.107376
I1005 20:58:49.846158 16172 solver.cpp:259]     Train net output #0: error_blob = 0.107376 (* 1 = 0.107376 loss)
I1005 20:58:49.846163 16172 solver.cpp:590] Iteration 700, lr = 0.01
I1005 20:58:52.346983 16172 solver.cpp:243] Iteration 800, loss = 0.105849
I1005 20:58:52.347023 16172 solver.cpp:259]     Train net output #0: error_blob = 0.105849 (* 1 = 0.105849 loss)
I1005 20:58:52.347029 16172 solver.cpp:590] Iteration 800, lr = 0.01
I1005 20:58:54.858733 16172 solver.cpp:243] Iteration 900, loss = 0.102122
I1005 20:58:54.858762 16172 solver.cpp:259]     Train net output #0: error_blob = 0.102122 (* 1 = 0.102122 loss)
I1005 20:58:54.858767 16172 solver.cpp:590] Iteration 900, lr = 0.01
I1005 20:58:54.908450 16172 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:58:57.333580 16172 solver.cpp:347] Iteration 1000, Testing net (#0)
I1005 20:58:57.678853 16172 solver.cpp:415]     Test net output #0: error_blob = 0.109516 (* 1 = 0.109516 loss)
I1005 20:58:57.679599 16172 solver.cpp:243] Iteration 1000, loss = 0.104936
I1005 20:58:57.679613 16172 solver.cpp:259]     Train net output #0: error_blob = 0.104936 (* 1 = 0.104936 loss)
I1005 20:58:57.679617 16172 solver.cpp:590] Iteration 1000, lr = 0.01
I1005 20:59:00.205186 16172 solver.cpp:243] Iteration 1100, loss = 0.106003
I1005 20:59:00.205217 16172 solver.cpp:259]     Train net output #0: error_blob = 0.106003 (* 1 = 0.106003 loss)
I1005 20:59:00.205222 16172 solver.cpp:590] Iteration 1100, lr = 0.01
I1005 20:59:02.764468 16172 solver.cpp:243] Iteration 1200, loss = 0.106513
I1005 20:59:02.764513 16172 solver.cpp:259]     Train net output #0: error_blob = 0.106513 (* 1 = 0.106513 loss)
I1005 20:59:02.764519 16172 solver.cpp:590] Iteration 1200, lr = 0.01
I1005 20:59:05.356395 16172 solver.cpp:243] Iteration 1300, loss = 0.103868
I1005 20:59:05.356426 16172 solver.cpp:259]     Train net output #0: error_blob = 0.103868 (* 1 = 0.103868 loss)
I1005 20:59:05.356431 16172 solver.cpp:590] Iteration 1300, lr = 0.01
I1005 20:59:07.842391 16172 solver.cpp:243] Iteration 1400, loss = 0.101835
I1005 20:59:07.842422 16172 solver.cpp:259]     Train net output #0: error_blob = 0.101835 (* 1 = 0.101835 loss)
I1005 20:59:07.842427 16172 solver.cpp:590] Iteration 1400, lr = 0.01
I1005 20:59:10.301023 16172 solver.cpp:243] Iteration 1500, loss = 0.102447
I1005 20:59:10.301053 16172 solver.cpp:259]     Train net output #0: error_blob = 0.102447 (* 1 = 0.102447 loss)
I1005 20:59:10.301057 16172 solver.cpp:590] Iteration 1500, lr = 0.01
I1005 20:59:12.755854 16172 solver.cpp:243] Iteration 1600, loss = 0.103461
I1005 20:59:12.755882 16172 solver.cpp:259]     Train net output #0: error_blob = 0.103461 (* 1 = 0.103461 loss)
I1005 20:59:12.755888 16172 solver.cpp:590] Iteration 1600, lr = 0.01
I1005 20:59:15.280710 16172 solver.cpp:243] Iteration 1700, loss = 0.103491
I1005 20:59:15.280741 16172 solver.cpp:259]     Train net output #0: error_blob = 0.103491 (* 1 = 0.103491 loss)
I1005 20:59:15.280747 16172 solver.cpp:590] Iteration 1700, lr = 0.01
I1005 20:59:17.848184 16172 solver.cpp:243] Iteration 1800, loss = 0.102532
I1005 20:59:17.848217 16172 solver.cpp:259]     Train net output #0: error_blob = 0.102532 (* 1 = 0.102532 loss)
I1005 20:59:17.848223 16172 solver.cpp:590] Iteration 1800, lr = 0.01
I1005 20:59:18.050504 16172 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:59:20.365236 16172 solver.cpp:243] Iteration 1900, loss = 0.100751
I1005 20:59:20.365267 16172 solver.cpp:259]     Train net output #0: error_blob = 0.100751 (* 1 = 0.100751 loss)
I1005 20:59:20.365274 16172 solver.cpp:590] Iteration 1900, lr = 0.01
I1005 20:59:22.883805 16172 solver.cpp:347] Iteration 2000, Testing net (#0)
I1005 20:59:23.279670 16172 solver.cpp:415]     Test net output #0: error_blob = 0.107635 (* 1 = 0.107635 loss)
I1005 20:59:23.280278 16172 solver.cpp:243] Iteration 2000, loss = 0.0984762
I1005 20:59:23.280289 16172 solver.cpp:259]     Train net output #0: error_blob = 0.0984762 (* 1 = 0.0984762 loss)
I1005 20:59:23.280293 16172 solver.cpp:590] Iteration 2000, lr = 0.01
I1005 20:59:25.724128 16172 solver.cpp:243] Iteration 2100, loss = 0.102591
I1005 20:59:25.724159 16172 solver.cpp:259]     Train net output #0: error_blob = 0.102591 (* 1 = 0.102591 loss)
I1005 20:59:25.724164 16172 solver.cpp:590] Iteration 2100, lr = 0.01
I1005 20:59:28.176687 16172 solver.cpp:243] Iteration 2200, loss = 0.103785
I1005 20:59:28.178463 16172 solver.cpp:259]     Train net output #0: error_blob = 0.103785 (* 1 = 0.103785 loss)
I1005 20:59:28.178473 16172 solver.cpp:590] Iteration 2200, lr = 0.01
I1005 20:59:30.667183 16172 solver.cpp:243] Iteration 2300, loss = 0.103127
I1005 20:59:30.667232 16172 solver.cpp:259]     Train net output #0: error_blob = 0.103127 (* 1 = 0.103127 loss)
I1005 20:59:30.667240 16172 solver.cpp:590] Iteration 2300, lr = 0.01
I1005 20:59:33.170590 16172 solver.cpp:243] Iteration 2400, loss = 0.1003
I1005 20:59:33.170630 16172 solver.cpp:259]     Train net output #0: error_blob = 0.1003 (* 1 = 0.1003 loss)
I1005 20:59:33.170640 16172 solver.cpp:590] Iteration 2400, lr = 0.01
I1005 20:59:35.657469 16172 solver.cpp:243] Iteration 2500, loss = 0.0972162
I1005 20:59:35.657498 16172 solver.cpp:259]     Train net output #0: error_blob = 0.0972162 (* 1 = 0.0972162 loss)
I1005 20:59:35.657503 16172 solver.cpp:590] Iteration 2500, lr = 0.01
I1005 20:59:38.160888 16172 solver.cpp:243] Iteration 2600, loss = 0.10114
I1005 20:59:38.160920 16172 solver.cpp:259]     Train net output #0: error_blob = 0.10114 (* 1 = 0.10114 loss)
I1005 20:59:38.160926 16172 solver.cpp:590] Iteration 2600, lr = 0.01
I1005 20:59:40.718729 16172 solver.cpp:243] Iteration 2700, loss = 0.102868
I1005 20:59:40.718758 16172 solver.cpp:259]     Train net output #0: error_blob = 0.102868 (* 1 = 0.102868 loss)
I1005 20:59:40.718763 16172 solver.cpp:590] Iteration 2700, lr = 0.01
I1005 20:59:41.076830 16172 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 20:59:43.235313 16172 solver.cpp:243] Iteration 2800, loss = 0.103856
I1005 20:59:43.235354 16172 solver.cpp:259]     Train net output #0: error_blob = 0.103856 (* 1 = 0.103856 loss)
I1005 20:59:43.235362 16172 solver.cpp:590] Iteration 2800, lr = 0.01
I1005 20:59:45.773816 16172 solver.cpp:243] Iteration 2900, loss = 0.0997424
I1005 20:59:45.773844 16172 solver.cpp:259]     Train net output #0: error_blob = 0.0997424 (* 1 = 0.0997424 loss)
I1005 20:59:45.773849 16172 solver.cpp:590] Iteration 2900, lr = 0.01
I1005 20:59:48.289753 16172 solver.cpp:347] Iteration 3000, Testing net (#0)
I1005 20:59:48.589869 16172 solver.cpp:415]     Test net output #0: error_blob = 0.106593 (* 1 = 0.106593 loss)
I1005 20:59:48.590481 16172 solver.cpp:243] Iteration 3000, loss = 0.0988061
I1005 20:59:48.590492 16172 solver.cpp:259]     Train net output #0: error_blob = 0.0988061 (* 1 = 0.0988061 loss)
I1005 20:59:48.590497 16172 solver.cpp:590] Iteration 3000, lr = 0.01
I1005 20:59:51.015712 16172 solver.cpp:243] Iteration 3100, loss = 0.098519
I1005 20:59:51.015740 16172 solver.cpp:259]     Train net output #0: error_blob = 0.098519 (* 1 = 0.098519 loss)
I1005 20:59:51.015745 16172 solver.cpp:590] Iteration 3100, lr = 0.01
I1005 20:59:53.536213 16172 solver.cpp:243] Iteration 3200, loss = 0.101759
I1005 20:59:53.536254 16172 solver.cpp:259]     Train net output #0: error_blob = 0.101759 (* 1 = 0.101759 loss)
I1005 20:59:53.536260 16172 solver.cpp:590] Iteration 3200, lr = 0.01
I1005 20:59:56.112416 16172 solver.cpp:243] Iteration 3300, loss = 0.101695
I1005 20:59:56.112448 16172 solver.cpp:259]     Train net output #0: error_blob = 0.101695 (* 1 = 0.101695 loss)
I1005 20:59:56.112454 16172 solver.cpp:590] Iteration 3300, lr = 0.01
I1005 20:59:58.646152 16172 solver.cpp:243] Iteration 3400, loss = 0.101119
I1005 20:59:58.646265 16172 solver.cpp:259]     Train net output #0: error_blob = 0.101119 (* 1 = 0.101119 loss)
I1005 20:59:58.646273 16172 solver.cpp:590] Iteration 3400, lr = 0.01
I1005 21:00:01.192893 16172 solver.cpp:243] Iteration 3500, loss = 0.0988916
I1005 21:00:01.192921 16172 solver.cpp:259]     Train net output #0: error_blob = 0.0988916 (* 1 = 0.0988916 loss)
I1005 21:00:01.192926 16172 solver.cpp:590] Iteration 3500, lr = 0.01
I1005 21:00:03.718332 16172 solver.cpp:243] Iteration 3600, loss = 0.0972755
I1005 21:00:03.718361 16172 solver.cpp:259]     Train net output #0: error_blob = 0.0972755 (* 1 = 0.0972755 loss)
I1005 21:00:03.718366 16172 solver.cpp:590] Iteration 3600, lr = 0.01
I1005 21:00:04.223114 16172 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:00:06.215519 16172 solver.cpp:243] Iteration 3700, loss = 0.100398
I1005 21:00:06.215549 16172 solver.cpp:259]     Train net output #0: error_blob = 0.100398 (* 1 = 0.100398 loss)
I1005 21:00:06.215553 16172 solver.cpp:590] Iteration 3700, lr = 0.01
I1005 21:00:08.728004 16172 solver.cpp:243] Iteration 3800, loss = 0.102273
I1005 21:00:08.728035 16172 solver.cpp:259]     Train net output #0: error_blob = 0.102273 (* 1 = 0.102273 loss)
I1005 21:00:08.728040 16172 solver.cpp:590] Iteration 3800, lr = 0.01
I1005 21:00:11.288115 16172 solver.cpp:243] Iteration 3900, loss = 0.102127
I1005 21:00:11.288146 16172 solver.cpp:259]     Train net output #0: error_blob = 0.102127 (* 1 = 0.102127 loss)
I1005 21:00:11.288151 16172 solver.cpp:590] Iteration 3900, lr = 0.01
I1005 21:00:13.791990 16172 solver.cpp:347] Iteration 4000, Testing net (#0)
I1005 21:00:14.080718 16172 solver.cpp:415]     Test net output #0: error_blob = 0.106223 (* 1 = 0.106223 loss)
I1005 21:00:14.081327 16172 solver.cpp:243] Iteration 4000, loss = 0.0989176
I1005 21:00:14.081341 16172 solver.cpp:259]     Train net output #0: error_blob = 0.0989176 (* 1 = 0.0989176 loss)
I1005 21:00:14.081351 16172 solver.cpp:590] Iteration 4000, lr = 0.01
I1005 21:00:16.558090 16172 solver.cpp:243] Iteration 4100, loss = 0.0968112
I1005 21:00:16.558127 16172 solver.cpp:259]     Train net output #0: error_blob = 0.0968112 (* 1 = 0.0968112 loss)
I1005 21:00:16.558138 16172 solver.cpp:590] Iteration 4100, lr = 0.01
I1005 21:00:19.095777 16172 solver.cpp:243] Iteration 4200, loss = 0.0978018
I1005 21:00:19.095808 16172 solver.cpp:259]     Train net output #0: error_blob = 0.0978018 (* 1 = 0.0978018 loss)
I1005 21:00:19.095813 16172 solver.cpp:590] Iteration 4200, lr = 0.01
I1005 21:00:21.677294 16172 solver.cpp:243] Iteration 4300, loss = 0.100766
I1005 21:00:21.677341 16172 solver.cpp:259]     Train net output #0: error_blob = 0.100766 (* 1 = 0.100766 loss)
I1005 21:00:21.677350 16172 solver.cpp:590] Iteration 4300, lr = 0.01
I1005 21:00:24.180483 16172 solver.cpp:243] Iteration 4400, loss = 0.0998807
I1005 21:00:24.180539 16172 solver.cpp:259]     Train net output #0: error_blob = 0.0998807 (* 1 = 0.0998807 loss)
I1005 21:00:24.180546 16172 solver.cpp:590] Iteration 4400, lr = 0.01
I1005 21:00:26.727205 16172 solver.cpp:243] Iteration 4500, loss = 0.0986883
I1005 21:00:26.727244 16172 solver.cpp:259]     Train net output #0: error_blob = 0.0986883 (* 1 = 0.0986883 loss)
I1005 21:00:26.727251 16172 solver.cpp:590] Iteration 4500, lr = 0.01
I1005 21:00:27.399821 16172 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:00:29.290729 16172 solver.cpp:243] Iteration 4600, loss = 0.0965981
I1005 21:00:29.290819 16172 solver.cpp:259]     Train net output #0: error_blob = 0.0965981 (* 1 = 0.0965981 loss)
I1005 21:00:29.290827 16172 solver.cpp:590] Iteration 4600, lr = 0.01
I1005 21:00:31.873450 16172 solver.cpp:243] Iteration 4700, loss = 0.0953608
I1005 21:00:31.873479 16172 solver.cpp:259]     Train net output #0: error_blob = 0.0953608 (* 1 = 0.0953608 loss)
I1005 21:00:31.873484 16172 solver.cpp:590] Iteration 4700, lr = 0.01
I1005 21:00:34.349346 16172 solver.cpp:243] Iteration 4800, loss = 0.100862
I1005 21:00:34.349376 16172 solver.cpp:259]     Train net output #0: error_blob = 0.100862 (* 1 = 0.100862 loss)
I1005 21:00:34.349381 16172 solver.cpp:590] Iteration 4800, lr = 0.01
I1005 21:00:36.912413 16172 solver.cpp:243] Iteration 4900, loss = 0.1011
I1005 21:00:36.912451 16172 solver.cpp:259]     Train net output #0: error_blob = 0.1011 (* 1 = 0.1011 loss)
I1005 21:00:36.912461 16172 solver.cpp:590] Iteration 4900, lr = 0.01
I1005 21:00:39.431263 16172 solver.cpp:347] Iteration 5000, Testing net (#0)
I1005 21:00:39.734905 16172 solver.cpp:415]     Test net output #0: error_blob = 0.105716 (* 1 = 0.105716 loss)
I1005 21:00:39.735594 16172 solver.cpp:243] Iteration 5000, loss = 0.101645
I1005 21:00:39.735625 16172 solver.cpp:259]     Train net output #0: error_blob = 0.101645 (* 1 = 0.101645 loss)
I1005 21:00:39.735633 16172 solver.cpp:590] Iteration 5000, lr = 0.01
I1005 21:00:42.230854 16172 solver.cpp:243] Iteration 5100, loss = 0.0969239
I1005 21:00:42.230901 16172 solver.cpp:259]     Train net output #0: error_blob = 0.0969239 (* 1 = 0.0969239 loss)
I1005 21:00:42.230909 16172 solver.cpp:590] Iteration 5100, lr = 0.01
I1005 21:00:44.746134 16172 solver.cpp:243] Iteration 5200, loss = 0.0956667
I1005 21:00:44.746170 16172 solver.cpp:259]     Train net output #0: error_blob = 0.0956667 (* 1 = 0.0956667 loss)
I1005 21:00:44.746177 16172 solver.cpp:590] Iteration 5200, lr = 0.01
I1005 21:00:47.282886 16172 solver.cpp:243] Iteration 5300, loss = 0.0992579
I1005 21:00:47.282917 16172 solver.cpp:259]     Train net output #0: error_blob = 0.0992579 (* 1 = 0.0992579 loss)
I1005 21:00:47.282922 16172 solver.cpp:590] Iteration 5300, lr = 0.01
I1005 21:00:49.804055 16172 solver.cpp:243] Iteration 5400, loss = 0.10085
I1005 21:00:49.804091 16172 solver.cpp:259]     Train net output #0: error_blob = 0.10085 (* 1 = 0.10085 loss)
I1005 21:00:49.804098 16172 solver.cpp:590] Iteration 5400, lr = 0.01
I1005 21:00:50.603806 16172 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:00:52.324570 16172 solver.cpp:243] Iteration 5500, loss = 0.0997535
I1005 21:00:52.324604 16172 solver.cpp:259]     Train net output #0: error_blob = 0.0997535 (* 1 = 0.0997535 loss)
I1005 21:00:52.324611 16172 solver.cpp:590] Iteration 5500, lr = 0.01
I1005 21:00:54.826797 16172 solver.cpp:243] Iteration 5600, loss = 0.096792
I1005 21:00:54.826841 16172 solver.cpp:259]     Train net output #0: error_blob = 0.096792 (* 1 = 0.096792 loss)
I1005 21:00:54.826848 16172 solver.cpp:590] Iteration 5600, lr = 0.01
I1005 21:00:57.331892 16172 solver.cpp:243] Iteration 5700, loss = 0.0948823
I1005 21:00:57.331926 16172 solver.cpp:259]     Train net output #0: error_blob = 0.0948823 (* 1 = 0.0948823 loss)
I1005 21:00:57.331933 16172 solver.cpp:590] Iteration 5700, lr = 0.01
I1005 21:00:59.764906 16172 solver.cpp:243] Iteration 5800, loss = 0.0964634
I1005 21:00:59.765075 16172 solver.cpp:259]     Train net output #0: error_blob = 0.0964634 (* 1 = 0.0964634 loss)
I1005 21:00:59.765084 16172 solver.cpp:590] Iteration 5800, lr = 0.01
I1005 21:01:02.317333 16172 solver.cpp:243] Iteration 5900, loss = 0.0999881
I1005 21:01:02.317370 16172 solver.cpp:259]     Train net output #0: error_blob = 0.0999881 (* 1 = 0.0999881 loss)
I1005 21:01:02.317378 16172 solver.cpp:590] Iteration 5900, lr = 0.01
I1005 21:01:04.855808 16172 solver.cpp:347] Iteration 6000, Testing net (#0)
I1005 21:01:05.135150 16172 solver.cpp:415]     Test net output #0: error_blob = 0.105531 (* 1 = 0.105531 loss)
I1005 21:01:05.135805 16172 solver.cpp:243] Iteration 6000, loss = 0.100163
I1005 21:01:05.135844 16172 solver.cpp:259]     Train net output #0: error_blob = 0.100163 (* 1 = 0.100163 loss)
I1005 21:01:05.135855 16172 solver.cpp:590] Iteration 6000, lr = 0.01
I1005 21:01:07.636977 16172 solver.cpp:243] Iteration 6100, loss = 0.0987215
I1005 21:01:07.637017 16172 solver.cpp:259]     Train net output #0: error_blob = 0.0987215 (* 1 = 0.0987215 loss)
I1005 21:01:07.637025 16172 solver.cpp:590] Iteration 6100, lr = 0.01
I1005 21:01:10.172593 16172 solver.cpp:243] Iteration 6200, loss = 0.0953457
I1005 21:01:10.172623 16172 solver.cpp:259]     Train net output #0: error_blob = 0.0953457 (* 1 = 0.0953457 loss)
I1005 21:01:10.172628 16172 solver.cpp:590] Iteration 6200, lr = 0.01
I1005 21:01:12.661384 16172 solver.cpp:243] Iteration 6300, loss = 0.0938594
I1005 21:01:12.661416 16172 solver.cpp:259]     Train net output #0: error_blob = 0.0938594 (* 1 = 0.0938594 loss)
I1005 21:01:12.661420 16172 solver.cpp:590] Iteration 6300, lr = 0.01
I1005 21:01:13.617280 16172 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:01:15.160945 16172 solver.cpp:243] Iteration 6400, loss = 0.0991282
I1005 21:01:15.160991 16172 solver.cpp:259]     Train net output #0: error_blob = 0.0991282 (* 1 = 0.0991282 loss)
I1005 21:01:15.160998 16172 solver.cpp:590] Iteration 6400, lr = 0.01
I1005 21:01:17.645802 16172 solver.cpp:243] Iteration 6500, loss = 0.100099
I1005 21:01:17.645848 16172 solver.cpp:259]     Train net output #0: error_blob = 0.100099 (* 1 = 0.100099 loss)
I1005 21:01:17.645856 16172 solver.cpp:590] Iteration 6500, lr = 0.01
I1005 21:01:20.175422 16172 solver.cpp:243] Iteration 6600, loss = 0.100354
I1005 21:01:20.175462 16172 solver.cpp:259]     Train net output #0: error_blob = 0.100354 (* 1 = 0.100354 loss)
I1005 21:01:20.175468 16172 solver.cpp:590] Iteration 6600, lr = 0.01
I1005 21:01:22.707619 16172 solver.cpp:243] Iteration 6700, loss = 0.0947528
I1005 21:01:22.707659 16172 solver.cpp:259]     Train net output #0: error_blob = 0.0947528 (* 1 = 0.0947528 loss)
I1005 21:01:22.707667 16172 solver.cpp:590] Iteration 6700, lr = 0.01
I1005 21:01:25.232287 16172 solver.cpp:243] Iteration 6800, loss = 0.0939385
I1005 21:01:25.232318 16172 solver.cpp:259]     Train net output #0: error_blob = 0.0939385 (* 1 = 0.0939385 loss)
I1005 21:01:25.232323 16172 solver.cpp:590] Iteration 6800, lr = 0.01
I1005 21:01:27.756233 16172 solver.cpp:243] Iteration 6900, loss = 0.0963686
I1005 21:01:27.756274 16172 solver.cpp:259]     Train net output #0: error_blob = 0.0963686 (* 1 = 0.0963686 loss)
I1005 21:01:27.756279 16172 solver.cpp:590] Iteration 6900, lr = 0.01
I1005 21:01:30.260131 16172 solver.cpp:347] Iteration 7000, Testing net (#0)
I1005 21:01:30.538462 16172 solver.cpp:415]     Test net output #0: error_blob = 0.105239 (* 1 = 0.105239 loss)
I1005 21:01:30.539121 16172 solver.cpp:243] Iteration 7000, loss = 0.0994443
I1005 21:01:30.539139 16172 solver.cpp:259]     Train net output #0: error_blob = 0.0994443 (* 1 = 0.0994443 loss)
I1005 21:01:30.539147 16172 solver.cpp:590] Iteration 7000, lr = 0.01
I1005 21:01:33.042541 16172 solver.cpp:243] Iteration 7100, loss = 0.0980351
I1005 21:01:33.042580 16172 solver.cpp:259]     Train net output #0: error_blob = 0.0980351 (* 1 = 0.0980351 loss)
I1005 21:01:33.042587 16172 solver.cpp:590] Iteration 7100, lr = 0.01
I1005 21:01:35.586349 16172 solver.cpp:243] Iteration 7200, loss = 0.0972243
I1005 21:01:35.586379 16172 solver.cpp:259]     Train net output #0: error_blob = 0.0972243 (* 1 = 0.0972243 loss)
I1005 21:01:35.586383 16172 solver.cpp:590] Iteration 7200, lr = 0.01
I1005 21:01:36.680943 16172 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:01:38.095798 16172 solver.cpp:243] Iteration 7300, loss = 0.0963625
I1005 21:01:38.095834 16172 solver.cpp:259]     Train net output #0: error_blob = 0.0963625 (* 1 = 0.0963625 loss)
I1005 21:01:38.095841 16172 solver.cpp:590] Iteration 7300, lr = 0.01
I1005 21:01:40.647439 16172 solver.cpp:243] Iteration 7400, loss = 0.0942859
I1005 21:01:40.647469 16172 solver.cpp:259]     Train net output #0: error_blob = 0.0942859 (* 1 = 0.0942859 loss)
I1005 21:01:40.647475 16172 solver.cpp:590] Iteration 7400, lr = 0.01
I1005 21:01:43.199744 16172 solver.cpp:243] Iteration 7500, loss = 0.0978775
I1005 21:01:43.199774 16172 solver.cpp:259]     Train net output #0: error_blob = 0.0978775 (* 1 = 0.0978775 loss)
I1005 21:01:43.199779 16172 solver.cpp:590] Iteration 7500, lr = 0.01
I1005 21:01:45.733011 16172 solver.cpp:243] Iteration 7600, loss = 0.0999576
I1005 21:01:45.733039 16172 solver.cpp:259]     Train net output #0: error_blob = 0.0999576 (* 1 = 0.0999576 loss)
I1005 21:01:45.733044 16172 solver.cpp:590] Iteration 7600, lr = 0.01
I1005 21:01:48.275214 16172 solver.cpp:243] Iteration 7700, loss = 0.0986059
I1005 21:01:48.275245 16172 solver.cpp:259]     Train net output #0: error_blob = 0.0986059 (* 1 = 0.0986059 loss)
I1005 21:01:48.275251 16172 solver.cpp:590] Iteration 7700, lr = 0.01
I1005 21:01:50.815783 16172 solver.cpp:243] Iteration 7800, loss = 0.0949973
I1005 21:01:50.815824 16172 solver.cpp:259]     Train net output #0: error_blob = 0.0949973 (* 1 = 0.0949973 loss)
I1005 21:01:50.815830 16172 solver.cpp:590] Iteration 7800, lr = 0.01
I1005 21:01:53.341013 16172 solver.cpp:243] Iteration 7900, loss = 0.0937268
I1005 21:01:53.341054 16172 solver.cpp:259]     Train net output #0: error_blob = 0.0937268 (* 1 = 0.0937268 loss)
I1005 21:01:53.341059 16172 solver.cpp:590] Iteration 7900, lr = 0.01
I1005 21:01:55.876657 16172 solver.cpp:347] Iteration 8000, Testing net (#0)
I1005 21:01:56.167103 16172 solver.cpp:415]     Test net output #0: error_blob = 0.105144 (* 1 = 0.105144 loss)
I1005 21:01:56.167706 16172 solver.cpp:243] Iteration 8000, loss = 0.0963619
I1005 21:01:56.167717 16172 solver.cpp:259]     Train net output #0: error_blob = 0.0963619 (* 1 = 0.0963619 loss)
I1005 21:01:56.167722 16172 solver.cpp:590] Iteration 8000, lr = 0.01
I1005 21:01:58.682868 16172 solver.cpp:243] Iteration 8100, loss = 0.0991959
I1005 21:01:58.682898 16172 solver.cpp:259]     Train net output #0: error_blob = 0.0991959 (* 1 = 0.0991959 loss)
I1005 21:01:58.682904 16172 solver.cpp:590] Iteration 8100, lr = 0.01
I1005 21:01:59.930361 16172 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:02:01.180726 16172 solver.cpp:243] Iteration 8200, loss = 0.0966953
I1005 21:02:01.180830 16172 solver.cpp:259]     Train net output #0: error_blob = 0.0966953 (* 1 = 0.0966953 loss)
I1005 21:02:01.180837 16172 solver.cpp:590] Iteration 8200, lr = 0.01
I1005 21:02:03.616757 16172 solver.cpp:243] Iteration 8300, loss = 0.0946867
I1005 21:02:03.616787 16172 solver.cpp:259]     Train net output #0: error_blob = 0.0946867 (* 1 = 0.0946867 loss)
I1005 21:02:03.616792 16172 solver.cpp:590] Iteration 8300, lr = 0.01
I1005 21:02:06.075616 16172 solver.cpp:243] Iteration 8400, loss = 0.094059
I1005 21:02:06.075645 16172 solver.cpp:259]     Train net output #0: error_blob = 0.094059 (* 1 = 0.094059 loss)
I1005 21:02:06.075650 16172 solver.cpp:590] Iteration 8400, lr = 0.01
I1005 21:02:08.546628 16172 solver.cpp:243] Iteration 8500, loss = 0.0916967
I1005 21:02:08.546659 16172 solver.cpp:259]     Train net output #0: error_blob = 0.0916967 (* 1 = 0.0916967 loss)
I1005 21:02:08.546664 16172 solver.cpp:590] Iteration 8500, lr = 0.01
I1005 21:02:11.087357 16172 solver.cpp:243] Iteration 8600, loss = 0.099211
I1005 21:02:11.087386 16172 solver.cpp:259]     Train net output #0: error_blob = 0.099211 (* 1 = 0.099211 loss)
I1005 21:02:11.087391 16172 solver.cpp:590] Iteration 8600, lr = 0.01
I1005 21:02:13.523298 16172 solver.cpp:243] Iteration 8700, loss = 0.0987879
I1005 21:02:13.523339 16172 solver.cpp:259]     Train net output #0: error_blob = 0.0987879 (* 1 = 0.0987879 loss)
I1005 21:02:13.523345 16172 solver.cpp:590] Iteration 8700, lr = 0.01
I1005 21:02:15.957614 16172 solver.cpp:243] Iteration 8800, loss = 0.0984229
I1005 21:02:15.957643 16172 solver.cpp:259]     Train net output #0: error_blob = 0.0984229 (* 1 = 0.0984229 loss)
I1005 21:02:15.957648 16172 solver.cpp:590] Iteration 8800, lr = 0.01
I1005 21:02:18.456126 16172 solver.cpp:243] Iteration 8900, loss = 0.093743
I1005 21:02:18.456156 16172 solver.cpp:259]     Train net output #0: error_blob = 0.093743 (* 1 = 0.093743 loss)
I1005 21:02:18.456161 16172 solver.cpp:590] Iteration 8900, lr = 0.01
I1005 21:02:20.938184 16172 solver.cpp:347] Iteration 9000, Testing net (#0)
I1005 21:02:21.232683 16172 solver.cpp:415]     Test net output #0: error_blob = 0.105012 (* 1 = 0.105012 loss)
I1005 21:02:21.233332 16172 solver.cpp:243] Iteration 9000, loss = 0.0926461
I1005 21:02:21.233345 16172 solver.cpp:259]     Train net output #0: error_blob = 0.0926461 (* 1 = 0.0926461 loss)
I1005 21:02:21.233351 16172 solver.cpp:590] Iteration 9000, lr = 0.01
I1005 21:02:22.628430 16172 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:02:23.755921 16172 solver.cpp:243] Iteration 9100, loss = 0.0973009
I1005 21:02:23.755957 16172 solver.cpp:259]     Train net output #0: error_blob = 0.0973009 (* 1 = 0.0973009 loss)
I1005 21:02:23.755964 16172 solver.cpp:590] Iteration 9100, lr = 0.01
I1005 21:02:26.306304 16172 solver.cpp:243] Iteration 9200, loss = 0.0994393
I1005 21:02:26.306344 16172 solver.cpp:259]     Train net output #0: error_blob = 0.0994393 (* 1 = 0.0994393 loss)
I1005 21:02:26.306350 16172 solver.cpp:590] Iteration 9200, lr = 0.01
I1005 21:02:28.875083 16172 solver.cpp:243] Iteration 9300, loss = 0.0970156
I1005 21:02:28.875130 16172 solver.cpp:259]     Train net output #0: error_blob = 0.0970156 (* 1 = 0.0970156 loss)
I1005 21:02:28.875138 16172 solver.cpp:590] Iteration 9300, lr = 0.01
I1005 21:02:31.449334 16172 solver.cpp:243] Iteration 9400, loss = 0.0936077
I1005 21:02:31.450389 16172 solver.cpp:259]     Train net output #0: error_blob = 0.0936077 (* 1 = 0.0936077 loss)
I1005 21:02:31.450405 16172 solver.cpp:590] Iteration 9400, lr = 0.01
I1005 21:02:34.048063 16172 solver.cpp:243] Iteration 9500, loss = 0.0926693
I1005 21:02:34.048094 16172 solver.cpp:259]     Train net output #0: error_blob = 0.0926693 (* 1 = 0.0926693 loss)
I1005 21:02:34.048099 16172 solver.cpp:590] Iteration 9500, lr = 0.01
I1005 21:02:36.596694 16172 solver.cpp:243] Iteration 9600, loss = 0.0944881
I1005 21:02:36.596724 16172 solver.cpp:259]     Train net output #0: error_blob = 0.0944881 (* 1 = 0.0944881 loss)
I1005 21:02:36.596729 16172 solver.cpp:590] Iteration 9600, lr = 0.01
I1005 21:02:39.102602 16172 solver.cpp:243] Iteration 9700, loss = 0.0976106
I1005 21:02:39.102643 16172 solver.cpp:259]     Train net output #0: error_blob = 0.0976106 (* 1 = 0.0976106 loss)
I1005 21:02:39.102648 16172 solver.cpp:590] Iteration 9700, lr = 0.01
I1005 21:02:41.617146 16172 solver.cpp:243] Iteration 9800, loss = 0.0971331
I1005 21:02:41.617175 16172 solver.cpp:259]     Train net output #0: error_blob = 0.0971331 (* 1 = 0.0971331 loss)
I1005 21:02:41.617180 16172 solver.cpp:590] Iteration 9800, lr = 0.01
I1005 21:02:44.152355 16172 solver.cpp:243] Iteration 9900, loss = 0.0961158
I1005 21:02:44.152386 16172 solver.cpp:259]     Train net output #0: error_blob = 0.0961158 (* 1 = 0.0961158 loss)
I1005 21:02:44.152391 16172 solver.cpp:590] Iteration 9900, lr = 0.01
I1005 21:02:46.661344 16172 solver.cpp:468] Snapshotting to binary proto file _iter_10000.caffemodel
I1005 21:02:46.662528 16172 solver.cpp:753] Snapshotting solver state to binary proto file _iter_10000.solverstate
I1005 21:02:46.686540 16172 solver.cpp:327] Iteration 10000, loss = 0.0933838
I1005 21:02:46.686568 16172 solver.cpp:347] Iteration 10000, Testing net (#0)
I1005 21:02:46.860184 16172 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:02:46.964908 16172 solver.cpp:415]     Test net output #0: error_blob = 0.104946 (* 1 = 0.104946 loss)
I1005 21:02:46.964931 16172 solver.cpp:332] Optimization Done.
I1005 21:02:46.964934 16172 caffe.cpp:215] Optimization Done.
I1005 21:02:47.031522 16183 caffe.cpp:184] Using GPUs 0
I1005 21:02:47.592723 16183 solver.cpp:54] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "fixed"
momentum: 0.9
solver_mode: GPU
device_id: 0
net: "large_batch/model0_part7.prototxt"
I1005 21:02:47.592756 16183 solver.cpp:97] Creating training net from net file: large_batch/model0_part7.prototxt
I1005 21:02:47.592923 16183 net.cpp:339] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_layer
I1005 21:02:47.592968 16183 net.cpp:50] Initializing net from parameters: 
name: "large_batch/model0_part7.prototxt"
state {
  phase: TRAIN
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TRAIN
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.part7.train"
    batch_size: 20000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1005 21:02:47.593025 16183 layer_factory.hpp:76] Creating layer data_layer
I1005 21:02:47.606341 16183 net.cpp:110] Creating Layer data_layer
I1005 21:02:47.606359 16183 net.cpp:433] data_layer -> data_blob
I1005 21:02:47.606384 16183 net.cpp:433] data_layer -> label_blob
I1005 21:02:47.606986 16187 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.part7.train
I1005 21:02:48.290724 16183 data_layer.cpp:45] output data size: 20000,61,1,1
I1005 21:02:48.295649 16183 net.cpp:155] Setting up data_layer
I1005 21:02:48.295678 16183 net.cpp:163] Top shape: 20000 61 1 1 (1220000)
I1005 21:02:48.295682 16183 net.cpp:163] Top shape: 20000 (20000)
I1005 21:02:48.295691 16183 layer_factory.hpp:76] Creating layer hidden_sum_layer
I1005 21:02:48.295703 16183 net.cpp:110] Creating Layer hidden_sum_layer
I1005 21:02:48.295708 16183 net.cpp:477] hidden_sum_layer <- data_blob
I1005 21:02:48.295720 16183 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I1005 21:02:48.296090 16183 net.cpp:155] Setting up hidden_sum_layer
I1005 21:02:48.296098 16183 net.cpp:163] Top shape: 20000 10 (200000)
I1005 21:02:48.296110 16183 layer_factory.hpp:76] Creating layer hidden_act_layer
I1005 21:02:48.296121 16183 net.cpp:110] Creating Layer hidden_act_layer
I1005 21:02:48.296126 16183 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I1005 21:02:48.296131 16183 net.cpp:433] hidden_act_layer -> hidden_act_blob
I1005 21:02:51.518857 16183 net.cpp:155] Setting up hidden_act_layer
I1005 21:02:51.518892 16183 net.cpp:163] Top shape: 20000 10 (200000)
I1005 21:02:51.518898 16183 layer_factory.hpp:76] Creating layer output_sum_layer
I1005 21:02:51.518910 16183 net.cpp:110] Creating Layer output_sum_layer
I1005 21:02:51.518914 16183 net.cpp:477] output_sum_layer <- hidden_act_blob
I1005 21:02:51.518924 16183 net.cpp:433] output_sum_layer -> output_sum_blob
I1005 21:02:51.519044 16183 net.cpp:155] Setting up output_sum_layer
I1005 21:02:51.519052 16183 net.cpp:163] Top shape: 20000 1 (20000)
I1005 21:02:51.519068 16183 layer_factory.hpp:76] Creating layer output_act_layer
I1005 21:02:51.519074 16183 net.cpp:110] Creating Layer output_act_layer
I1005 21:02:51.519078 16183 net.cpp:477] output_act_layer <- output_sum_blob
I1005 21:02:51.519081 16183 net.cpp:433] output_act_layer -> output_act_blob
I1005 21:02:51.519155 16183 net.cpp:155] Setting up output_act_layer
I1005 21:02:51.519176 16183 net.cpp:163] Top shape: 20000 1 (20000)
I1005 21:02:51.519189 16183 layer_factory.hpp:76] Creating layer error_layer
I1005 21:02:51.519196 16183 net.cpp:110] Creating Layer error_layer
I1005 21:02:51.519197 16183 net.cpp:477] error_layer <- output_act_blob
I1005 21:02:51.519201 16183 net.cpp:477] error_layer <- label_blob
I1005 21:02:51.519207 16183 net.cpp:433] error_layer -> error_blob
I1005 21:02:51.519248 16183 net.cpp:155] Setting up error_layer
I1005 21:02:51.519253 16183 net.cpp:163] Top shape: (1)
I1005 21:02:51.519265 16183 net.cpp:168]     with loss weight 1
I1005 21:02:51.519295 16183 net.cpp:236] error_layer needs backward computation.
I1005 21:02:51.519299 16183 net.cpp:236] output_act_layer needs backward computation.
I1005 21:02:51.519305 16183 net.cpp:236] output_sum_layer needs backward computation.
I1005 21:02:51.519309 16183 net.cpp:236] hidden_act_layer needs backward computation.
I1005 21:02:51.519311 16183 net.cpp:236] hidden_sum_layer needs backward computation.
I1005 21:02:51.519315 16183 net.cpp:240] data_layer does not need backward computation.
I1005 21:02:51.519318 16183 net.cpp:283] This network produces output error_blob
I1005 21:02:51.519325 16183 net.cpp:297] Network initialization done.
I1005 21:02:51.519330 16183 net.cpp:298] Memory required for data: 6720004
I1005 21:02:51.519448 16183 solver.cpp:187] Creating test net (#0) specified by net file: large_batch/model0_part7.prototxt
I1005 21:02:51.519460 16183 net.cpp:339] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_layer
I1005 21:02:51.519495 16183 net.cpp:50] Initializing net from parameters: 
name: "large_batch/model0_part7.prototxt"
state {
  phase: TEST
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TEST
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.part7.test"
    batch_size: 2000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1005 21:02:51.519515 16183 layer_factory.hpp:76] Creating layer data_layer
I1005 21:02:51.520695 16183 net.cpp:110] Creating Layer data_layer
I1005 21:02:51.520701 16183 net.cpp:433] data_layer -> data_blob
I1005 21:02:51.520705 16183 net.cpp:433] data_layer -> label_blob
I1005 21:02:51.521263 16189 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.part7.test
I1005 21:02:51.521329 16183 data_layer.cpp:45] output data size: 2000,61,1,1
I1005 21:02:51.522675 16183 net.cpp:155] Setting up data_layer
I1005 21:02:51.522693 16183 net.cpp:163] Top shape: 2000 61 1 1 (122000)
I1005 21:02:51.522696 16183 net.cpp:163] Top shape: 2000 (2000)
I1005 21:02:51.522699 16183 layer_factory.hpp:76] Creating layer hidden_sum_layer
I1005 21:02:51.522707 16183 net.cpp:110] Creating Layer hidden_sum_layer
I1005 21:02:51.522711 16183 net.cpp:477] hidden_sum_layer <- data_blob
I1005 21:02:51.522716 16183 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I1005 21:02:51.522827 16183 net.cpp:155] Setting up hidden_sum_layer
I1005 21:02:51.522833 16183 net.cpp:163] Top shape: 2000 10 (20000)
I1005 21:02:51.522840 16183 layer_factory.hpp:76] Creating layer hidden_act_layer
I1005 21:02:51.522847 16183 net.cpp:110] Creating Layer hidden_act_layer
I1005 21:02:51.522851 16183 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I1005 21:02:51.522868 16183 net.cpp:433] hidden_act_layer -> hidden_act_blob
I1005 21:02:51.523043 16183 net.cpp:155] Setting up hidden_act_layer
I1005 21:02:51.523049 16183 net.cpp:163] Top shape: 2000 10 (20000)
I1005 21:02:51.523052 16183 layer_factory.hpp:76] Creating layer output_sum_layer
I1005 21:02:51.523057 16183 net.cpp:110] Creating Layer output_sum_layer
I1005 21:02:51.523061 16183 net.cpp:477] output_sum_layer <- hidden_act_blob
I1005 21:02:51.523066 16183 net.cpp:433] output_sum_layer -> output_sum_blob
I1005 21:02:51.523131 16183 net.cpp:155] Setting up output_sum_layer
I1005 21:02:51.523138 16183 net.cpp:163] Top shape: 2000 1 (2000)
I1005 21:02:51.523144 16183 layer_factory.hpp:76] Creating layer output_act_layer
I1005 21:02:51.523149 16183 net.cpp:110] Creating Layer output_act_layer
I1005 21:02:51.523154 16183 net.cpp:477] output_act_layer <- output_sum_blob
I1005 21:02:51.523157 16183 net.cpp:433] output_act_layer -> output_act_blob
I1005 21:02:51.523213 16183 net.cpp:155] Setting up output_act_layer
I1005 21:02:51.523217 16183 net.cpp:163] Top shape: 2000 1 (2000)
I1005 21:02:51.523221 16183 layer_factory.hpp:76] Creating layer error_layer
I1005 21:02:51.523224 16183 net.cpp:110] Creating Layer error_layer
I1005 21:02:51.523227 16183 net.cpp:477] error_layer <- output_act_blob
I1005 21:02:51.523231 16183 net.cpp:477] error_layer <- label_blob
I1005 21:02:51.523236 16183 net.cpp:433] error_layer -> error_blob
I1005 21:02:51.523263 16183 net.cpp:155] Setting up error_layer
I1005 21:02:51.523267 16183 net.cpp:163] Top shape: (1)
I1005 21:02:51.523269 16183 net.cpp:168]     with loss weight 1
I1005 21:02:51.523277 16183 net.cpp:236] error_layer needs backward computation.
I1005 21:02:51.523282 16183 net.cpp:236] output_act_layer needs backward computation.
I1005 21:02:51.523284 16183 net.cpp:236] output_sum_layer needs backward computation.
I1005 21:02:51.523288 16183 net.cpp:236] hidden_act_layer needs backward computation.
I1005 21:02:51.523291 16183 net.cpp:236] hidden_sum_layer needs backward computation.
I1005 21:02:51.523294 16183 net.cpp:240] data_layer does not need backward computation.
I1005 21:02:51.523298 16183 net.cpp:283] This network produces output error_blob
I1005 21:02:51.523304 16183 net.cpp:297] Network initialization done.
I1005 21:02:51.523308 16183 net.cpp:298] Memory required for data: 672004
I1005 21:02:51.523331 16183 solver.cpp:66] Solver scaffolding done.
I1005 21:02:51.523437 16183 caffe.cpp:212] Starting Optimization
I1005 21:02:51.523442 16183 solver.cpp:294] Solving large_batch/model0_part7.prototxt
I1005 21:02:51.523443 16183 solver.cpp:295] Learning Rate Policy: fixed
I1005 21:02:51.523653 16183 solver.cpp:347] Iteration 0, Testing net (#0)
I1005 21:02:51.523706 16183 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:02:51.785398 16183 solver.cpp:415]     Test net output #0: error_blob = 0.133001 (* 1 = 0.133001 loss)
I1005 21:02:51.786684 16183 solver.cpp:243] Iteration 0, loss = 0.130889
I1005 21:02:51.786700 16183 solver.cpp:259]     Train net output #0: error_blob = 0.130889 (* 1 = 0.130889 loss)
I1005 21:02:51.786712 16183 solver.cpp:590] Iteration 0, lr = 0.01
I1005 21:02:54.283965 16183 solver.cpp:243] Iteration 100, loss = 0.122286
I1005 21:02:54.284014 16183 solver.cpp:259]     Train net output #0: error_blob = 0.122286 (* 1 = 0.122286 loss)
I1005 21:02:54.284023 16183 solver.cpp:590] Iteration 100, lr = 0.01
I1005 21:02:56.824180 16183 solver.cpp:243] Iteration 200, loss = 0.116549
I1005 21:02:56.824208 16183 solver.cpp:259]     Train net output #0: error_blob = 0.116549 (* 1 = 0.116549 loss)
I1005 21:02:56.824215 16183 solver.cpp:590] Iteration 200, lr = 0.01
I1005 21:02:59.368901 16183 solver.cpp:243] Iteration 300, loss = 0.114294
I1005 21:02:59.368932 16183 solver.cpp:259]     Train net output #0: error_blob = 0.114294 (* 1 = 0.114294 loss)
I1005 21:02:59.368937 16183 solver.cpp:590] Iteration 300, lr = 0.01
I1005 21:03:01.857736 16183 solver.cpp:243] Iteration 400, loss = 0.112942
I1005 21:03:01.857803 16183 solver.cpp:259]     Train net output #0: error_blob = 0.112942 (* 1 = 0.112942 loss)
I1005 21:03:01.857811 16183 solver.cpp:590] Iteration 400, lr = 0.01
I1005 21:03:04.358496 16183 solver.cpp:243] Iteration 500, loss = 0.108871
I1005 21:03:04.358544 16183 solver.cpp:259]     Train net output #0: error_blob = 0.108871 (* 1 = 0.108871 loss)
I1005 21:03:04.358554 16183 solver.cpp:590] Iteration 500, lr = 0.01
I1005 21:03:06.864889 16183 solver.cpp:243] Iteration 600, loss = 0.106622
I1005 21:03:06.864935 16183 solver.cpp:259]     Train net output #0: error_blob = 0.106622 (* 1 = 0.106622 loss)
I1005 21:03:06.864943 16183 solver.cpp:590] Iteration 600, lr = 0.01
I1005 21:03:09.393461 16183 solver.cpp:243] Iteration 700, loss = 0.108315
I1005 21:03:09.393501 16183 solver.cpp:259]     Train net output #0: error_blob = 0.108315 (* 1 = 0.108315 loss)
I1005 21:03:09.393507 16183 solver.cpp:590] Iteration 700, lr = 0.01
I1005 21:03:11.912896 16183 solver.cpp:243] Iteration 800, loss = 0.108757
I1005 21:03:11.912937 16183 solver.cpp:259]     Train net output #0: error_blob = 0.108757 (* 1 = 0.108757 loss)
I1005 21:03:11.912943 16183 solver.cpp:590] Iteration 800, lr = 0.01
I1005 21:03:14.395983 16183 solver.cpp:243] Iteration 900, loss = 0.104761
I1005 21:03:14.396023 16183 solver.cpp:259]     Train net output #0: error_blob = 0.104761 (* 1 = 0.104761 loss)
I1005 21:03:14.396029 16183 solver.cpp:590] Iteration 900, lr = 0.01
I1005 21:03:14.445583 16183 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:03:16.865739 16183 solver.cpp:347] Iteration 1000, Testing net (#0)
I1005 21:03:17.139286 16183 solver.cpp:415]     Test net output #0: error_blob = 0.109955 (* 1 = 0.109955 loss)
I1005 21:03:17.140036 16183 solver.cpp:243] Iteration 1000, loss = 0.102738
I1005 21:03:17.140053 16183 solver.cpp:259]     Train net output #0: error_blob = 0.102738 (* 1 = 0.102738 loss)
I1005 21:03:17.140063 16183 solver.cpp:590] Iteration 1000, lr = 0.01
I1005 21:03:19.598362 16183 solver.cpp:243] Iteration 1100, loss = 0.105493
I1005 21:03:19.598395 16183 solver.cpp:259]     Train net output #0: error_blob = 0.105493 (* 1 = 0.105493 loss)
I1005 21:03:19.598400 16183 solver.cpp:590] Iteration 1100, lr = 0.01
I1005 21:03:22.102985 16183 solver.cpp:243] Iteration 1200, loss = 0.106391
I1005 21:03:22.103032 16183 solver.cpp:259]     Train net output #0: error_blob = 0.106391 (* 1 = 0.106391 loss)
I1005 21:03:22.103044 16183 solver.cpp:590] Iteration 1200, lr = 0.01
I1005 21:03:24.647142 16183 solver.cpp:243] Iteration 1300, loss = 0.102698
I1005 21:03:24.647172 16183 solver.cpp:259]     Train net output #0: error_blob = 0.102698 (* 1 = 0.102698 loss)
I1005 21:03:24.647179 16183 solver.cpp:590] Iteration 1300, lr = 0.01
I1005 21:03:27.172072 16183 solver.cpp:243] Iteration 1400, loss = 0.100497
I1005 21:03:27.172111 16183 solver.cpp:259]     Train net output #0: error_blob = 0.100497 (* 1 = 0.100497 loss)
I1005 21:03:27.172130 16183 solver.cpp:590] Iteration 1400, lr = 0.01
I1005 21:03:29.708581 16183 solver.cpp:243] Iteration 1500, loss = 0.103947
I1005 21:03:29.708617 16183 solver.cpp:259]     Train net output #0: error_blob = 0.103947 (* 1 = 0.103947 loss)
I1005 21:03:29.708624 16183 solver.cpp:590] Iteration 1500, lr = 0.01
I1005 21:03:32.245437 16183 solver.cpp:243] Iteration 1600, loss = 0.105312
I1005 21:03:32.245476 16183 solver.cpp:259]     Train net output #0: error_blob = 0.105312 (* 1 = 0.105312 loss)
I1005 21:03:32.245483 16183 solver.cpp:590] Iteration 1600, lr = 0.01
I1005 21:03:34.784593 16183 solver.cpp:243] Iteration 1700, loss = 0.101409
I1005 21:03:34.784633 16183 solver.cpp:259]     Train net output #0: error_blob = 0.101409 (* 1 = 0.101409 loss)
I1005 21:03:34.784641 16183 solver.cpp:590] Iteration 1700, lr = 0.01
I1005 21:03:37.330109 16183 solver.cpp:243] Iteration 1800, loss = 0.099245
I1005 21:03:37.330142 16183 solver.cpp:259]     Train net output #0: error_blob = 0.099245 (* 1 = 0.099245 loss)
I1005 21:03:37.330147 16183 solver.cpp:590] Iteration 1800, lr = 0.01
I1005 21:03:37.530858 16183 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:03:39.853631 16183 solver.cpp:243] Iteration 1900, loss = 0.102875
I1005 21:03:39.853678 16183 solver.cpp:259]     Train net output #0: error_blob = 0.102875 (* 1 = 0.102875 loss)
I1005 21:03:39.853685 16183 solver.cpp:590] Iteration 1900, lr = 0.01
I1005 21:03:42.345676 16183 solver.cpp:347] Iteration 2000, Testing net (#0)
I1005 21:03:42.621855 16183 solver.cpp:415]     Test net output #0: error_blob = 0.108435 (* 1 = 0.108435 loss)
I1005 21:03:42.622515 16183 solver.cpp:243] Iteration 2000, loss = 0.104755
I1005 21:03:42.622534 16183 solver.cpp:259]     Train net output #0: error_blob = 0.104755 (* 1 = 0.104755 loss)
I1005 21:03:42.622545 16183 solver.cpp:590] Iteration 2000, lr = 0.01
I1005 21:03:45.124115 16183 solver.cpp:243] Iteration 2100, loss = 0.100724
I1005 21:03:45.124150 16183 solver.cpp:259]     Train net output #0: error_blob = 0.100724 (* 1 = 0.100724 loss)
I1005 21:03:45.124155 16183 solver.cpp:590] Iteration 2100, lr = 0.01
I1005 21:03:47.623822 16183 solver.cpp:243] Iteration 2200, loss = 0.0986341
I1005 21:03:47.623932 16183 solver.cpp:259]     Train net output #0: error_blob = 0.0986341 (* 1 = 0.0986341 loss)
I1005 21:03:47.623940 16183 solver.cpp:590] Iteration 2200, lr = 0.01
I1005 21:03:50.126286 16183 solver.cpp:243] Iteration 2300, loss = 0.101778
I1005 21:03:50.126328 16183 solver.cpp:259]     Train net output #0: error_blob = 0.101778 (* 1 = 0.101778 loss)
I1005 21:03:50.126333 16183 solver.cpp:590] Iteration 2300, lr = 0.01
I1005 21:03:52.680969 16183 solver.cpp:243] Iteration 2400, loss = 0.104503
I1005 21:03:52.681008 16183 solver.cpp:259]     Train net output #0: error_blob = 0.104503 (* 1 = 0.104503 loss)
I1005 21:03:52.681018 16183 solver.cpp:590] Iteration 2400, lr = 0.01
I1005 21:03:55.207696 16183 solver.cpp:243] Iteration 2500, loss = 0.100269
I1005 21:03:55.207729 16183 solver.cpp:259]     Train net output #0: error_blob = 0.100269 (* 1 = 0.100269 loss)
I1005 21:03:55.207736 16183 solver.cpp:590] Iteration 2500, lr = 0.01
I1005 21:03:57.730960 16183 solver.cpp:243] Iteration 2600, loss = 0.0984283
I1005 21:03:57.730995 16183 solver.cpp:259]     Train net output #0: error_blob = 0.0984283 (* 1 = 0.0984283 loss)
I1005 21:03:57.731003 16183 solver.cpp:590] Iteration 2600, lr = 0.01
I1005 21:04:00.282042 16183 solver.cpp:243] Iteration 2700, loss = 0.10133
I1005 21:04:00.282083 16183 solver.cpp:259]     Train net output #0: error_blob = 0.10133 (* 1 = 0.10133 loss)
I1005 21:04:00.282088 16183 solver.cpp:590] Iteration 2700, lr = 0.01
I1005 21:04:00.647907 16183 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:04:02.791618 16183 solver.cpp:243] Iteration 2800, loss = 0.104267
I1005 21:04:02.791649 16183 solver.cpp:259]     Train net output #0: error_blob = 0.104267 (* 1 = 0.104267 loss)
I1005 21:04:02.791656 16183 solver.cpp:590] Iteration 2800, lr = 0.01
I1005 21:04:05.310641 16183 solver.cpp:243] Iteration 2900, loss = 0.0999058
I1005 21:04:05.310679 16183 solver.cpp:259]     Train net output #0: error_blob = 0.0999058 (* 1 = 0.0999058 loss)
I1005 21:04:05.310688 16183 solver.cpp:590] Iteration 2900, lr = 0.01
I1005 21:04:07.795712 16183 solver.cpp:347] Iteration 3000, Testing net (#0)
I1005 21:04:08.074143 16183 solver.cpp:415]     Test net output #0: error_blob = 0.106986 (* 1 = 0.106986 loss)
I1005 21:04:08.074764 16183 solver.cpp:243] Iteration 3000, loss = 0.098684
I1005 21:04:08.074779 16183 solver.cpp:259]     Train net output #0: error_blob = 0.098684 (* 1 = 0.098684 loss)
I1005 21:04:08.074784 16183 solver.cpp:590] Iteration 3000, lr = 0.01
I1005 21:04:10.574543 16183 solver.cpp:243] Iteration 3100, loss = 0.101015
I1005 21:04:10.574575 16183 solver.cpp:259]     Train net output #0: error_blob = 0.101015 (* 1 = 0.101015 loss)
I1005 21:04:10.574583 16183 solver.cpp:590] Iteration 3100, lr = 0.01
I1005 21:04:13.087039 16183 solver.cpp:243] Iteration 3200, loss = 0.103799
I1005 21:04:13.087072 16183 solver.cpp:259]     Train net output #0: error_blob = 0.103799 (* 1 = 0.103799 loss)
I1005 21:04:13.087080 16183 solver.cpp:590] Iteration 3200, lr = 0.01
I1005 21:04:15.590311 16183 solver.cpp:243] Iteration 3300, loss = 0.100429
I1005 21:04:15.590342 16183 solver.cpp:259]     Train net output #0: error_blob = 0.100429 (* 1 = 0.100429 loss)
I1005 21:04:15.590349 16183 solver.cpp:590] Iteration 3300, lr = 0.01
I1005 21:04:18.085948 16183 solver.cpp:243] Iteration 3400, loss = 0.0979064
I1005 21:04:18.086048 16183 solver.cpp:259]     Train net output #0: error_blob = 0.0979064 (* 1 = 0.0979064 loss)
I1005 21:04:18.086056 16183 solver.cpp:590] Iteration 3400, lr = 0.01
I1005 21:04:20.631157 16183 solver.cpp:243] Iteration 3500, loss = 0.100327
I1005 21:04:20.631187 16183 solver.cpp:259]     Train net output #0: error_blob = 0.100327 (* 1 = 0.100327 loss)
I1005 21:04:20.631192 16183 solver.cpp:590] Iteration 3500, lr = 0.01
I1005 21:04:23.141109 16183 solver.cpp:243] Iteration 3600, loss = 0.103227
I1005 21:04:23.141140 16183 solver.cpp:259]     Train net output #0: error_blob = 0.103227 (* 1 = 0.103227 loss)
I1005 21:04:23.141149 16183 solver.cpp:590] Iteration 3600, lr = 0.01
I1005 21:04:23.658828 16183 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:04:25.656970 16183 solver.cpp:243] Iteration 3700, loss = 0.100637
I1005 21:04:25.656998 16183 solver.cpp:259]     Train net output #0: error_blob = 0.100637 (* 1 = 0.100637 loss)
I1005 21:04:25.657003 16183 solver.cpp:590] Iteration 3700, lr = 0.01
I1005 21:04:28.137380 16183 solver.cpp:243] Iteration 3800, loss = 0.0968085
I1005 21:04:28.137411 16183 solver.cpp:259]     Train net output #0: error_blob = 0.0968085 (* 1 = 0.0968085 loss)
I1005 21:04:28.137418 16183 solver.cpp:590] Iteration 3800, lr = 0.01
I1005 21:04:30.598361 16183 solver.cpp:243] Iteration 3900, loss = 0.0997813
I1005 21:04:30.598392 16183 solver.cpp:259]     Train net output #0: error_blob = 0.0997813 (* 1 = 0.0997813 loss)
I1005 21:04:30.598397 16183 solver.cpp:590] Iteration 3900, lr = 0.01
I1005 21:04:33.104092 16183 solver.cpp:347] Iteration 4000, Testing net (#0)
I1005 21:04:33.404218 16183 solver.cpp:415]     Test net output #0: error_blob = 0.105796 (* 1 = 0.105796 loss)
I1005 21:04:33.404922 16183 solver.cpp:243] Iteration 4000, loss = 0.103256
I1005 21:04:33.404942 16183 solver.cpp:259]     Train net output #0: error_blob = 0.103256 (* 1 = 0.103256 loss)
I1005 21:04:33.404952 16183 solver.cpp:590] Iteration 4000, lr = 0.01
I1005 21:04:35.877645 16183 solver.cpp:243] Iteration 4100, loss = 0.10108
I1005 21:04:35.877673 16183 solver.cpp:259]     Train net output #0: error_blob = 0.10108 (* 1 = 0.10108 loss)
I1005 21:04:35.877679 16183 solver.cpp:590] Iteration 4100, lr = 0.01
I1005 21:04:38.405145 16183 solver.cpp:243] Iteration 4200, loss = 0.0959495
I1005 21:04:38.405176 16183 solver.cpp:259]     Train net output #0: error_blob = 0.0959495 (* 1 = 0.0959495 loss)
I1005 21:04:38.405182 16183 solver.cpp:590] Iteration 4200, lr = 0.01
I1005 21:04:40.904837 16183 solver.cpp:243] Iteration 4300, loss = 0.0992909
I1005 21:04:40.904885 16183 solver.cpp:259]     Train net output #0: error_blob = 0.0992909 (* 1 = 0.0992909 loss)
I1005 21:04:40.904893 16183 solver.cpp:590] Iteration 4300, lr = 0.01
I1005 21:04:43.446843 16183 solver.cpp:243] Iteration 4400, loss = 0.102794
I1005 21:04:43.446873 16183 solver.cpp:259]     Train net output #0: error_blob = 0.102794 (* 1 = 0.102794 loss)
I1005 21:04:43.446879 16183 solver.cpp:590] Iteration 4400, lr = 0.01
I1005 21:04:45.966781 16183 solver.cpp:243] Iteration 4500, loss = 0.101069
I1005 21:04:45.966814 16183 solver.cpp:259]     Train net output #0: error_blob = 0.101069 (* 1 = 0.101069 loss)
I1005 21:04:45.966820 16183 solver.cpp:590] Iteration 4500, lr = 0.01
I1005 21:04:46.636030 16183 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:04:48.527256 16183 solver.cpp:243] Iteration 4600, loss = 0.0953008
I1005 21:04:48.527351 16183 solver.cpp:259]     Train net output #0: error_blob = 0.0953008 (* 1 = 0.0953008 loss)
I1005 21:04:48.527359 16183 solver.cpp:590] Iteration 4600, lr = 0.01
I1005 21:04:51.079288 16183 solver.cpp:243] Iteration 4700, loss = 0.0987993
I1005 21:04:51.079320 16183 solver.cpp:259]     Train net output #0: error_blob = 0.0987993 (* 1 = 0.0987993 loss)
I1005 21:04:51.079326 16183 solver.cpp:590] Iteration 4700, lr = 0.01
I1005 21:04:53.586680 16183 solver.cpp:243] Iteration 4800, loss = 0.10235
I1005 21:04:53.586711 16183 solver.cpp:259]     Train net output #0: error_blob = 0.10235 (* 1 = 0.10235 loss)
I1005 21:04:53.586716 16183 solver.cpp:590] Iteration 4800, lr = 0.01
I1005 21:04:56.096931 16183 solver.cpp:243] Iteration 4900, loss = 0.1012
I1005 21:04:56.096969 16183 solver.cpp:259]     Train net output #0: error_blob = 0.1012 (* 1 = 0.1012 loss)
I1005 21:04:56.096977 16183 solver.cpp:590] Iteration 4900, lr = 0.01
I1005 21:04:58.580615 16183 solver.cpp:347] Iteration 5000, Testing net (#0)
I1005 21:04:58.862406 16183 solver.cpp:415]     Test net output #0: error_blob = 0.104723 (* 1 = 0.104723 loss)
I1005 21:04:58.863056 16183 solver.cpp:243] Iteration 5000, loss = 0.0946102
I1005 21:04:58.863073 16183 solver.cpp:259]     Train net output #0: error_blob = 0.0946102 (* 1 = 0.0946102 loss)
I1005 21:04:58.863085 16183 solver.cpp:590] Iteration 5000, lr = 0.01
I1005 21:05:01.361536 16183 solver.cpp:243] Iteration 5100, loss = 0.098297
I1005 21:05:01.361584 16183 solver.cpp:259]     Train net output #0: error_blob = 0.098297 (* 1 = 0.098297 loss)
I1005 21:05:01.361595 16183 solver.cpp:590] Iteration 5100, lr = 0.01
I1005 21:05:03.922183 16183 solver.cpp:243] Iteration 5200, loss = 0.101788
I1005 21:05:03.922214 16183 solver.cpp:259]     Train net output #0: error_blob = 0.101788 (* 1 = 0.101788 loss)
I1005 21:05:03.922220 16183 solver.cpp:590] Iteration 5200, lr = 0.01
I1005 21:05:06.453121 16183 solver.cpp:243] Iteration 5300, loss = 0.10062
I1005 21:05:06.453171 16183 solver.cpp:259]     Train net output #0: error_blob = 0.10062 (* 1 = 0.10062 loss)
I1005 21:05:06.453179 16183 solver.cpp:590] Iteration 5300, lr = 0.01
I1005 21:05:09.004165 16183 solver.cpp:243] Iteration 5400, loss = 0.0946258
I1005 21:05:09.004202 16183 solver.cpp:259]     Train net output #0: error_blob = 0.0946258 (* 1 = 0.0946258 loss)
I1005 21:05:09.004209 16183 solver.cpp:590] Iteration 5400, lr = 0.01
I1005 21:05:09.809756 16183 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:05:11.520133 16183 solver.cpp:243] Iteration 5500, loss = 0.0976842
I1005 21:05:11.520180 16183 solver.cpp:259]     Train net output #0: error_blob = 0.0976842 (* 1 = 0.0976842 loss)
I1005 21:05:11.520189 16183 solver.cpp:590] Iteration 5500, lr = 0.01
I1005 21:05:14.082867 16183 solver.cpp:243] Iteration 5600, loss = 0.10157
I1005 21:05:14.082913 16183 solver.cpp:259]     Train net output #0: error_blob = 0.10157 (* 1 = 0.10157 loss)
I1005 21:05:14.082921 16183 solver.cpp:590] Iteration 5600, lr = 0.01
I1005 21:05:16.626528 16183 solver.cpp:243] Iteration 5700, loss = 0.100337
I1005 21:05:16.626576 16183 solver.cpp:259]     Train net output #0: error_blob = 0.100337 (* 1 = 0.100337 loss)
I1005 21:05:16.626585 16183 solver.cpp:590] Iteration 5700, lr = 0.01
I1005 21:05:19.143662 16183 solver.cpp:243] Iteration 5800, loss = 0.0944093
I1005 21:05:19.145413 16183 solver.cpp:259]     Train net output #0: error_blob = 0.0944093 (* 1 = 0.0944093 loss)
I1005 21:05:19.145422 16183 solver.cpp:590] Iteration 5800, lr = 0.01
I1005 21:05:21.633491 16183 solver.cpp:243] Iteration 5900, loss = 0.0970839
I1005 21:05:21.633528 16183 solver.cpp:259]     Train net output #0: error_blob = 0.0970839 (* 1 = 0.0970839 loss)
I1005 21:05:21.633534 16183 solver.cpp:590] Iteration 5900, lr = 0.01
I1005 21:05:24.105837 16183 solver.cpp:347] Iteration 6000, Testing net (#0)
I1005 21:05:24.504837 16183 solver.cpp:415]     Test net output #0: error_blob = 0.103644 (* 1 = 0.103644 loss)
I1005 21:05:24.505492 16183 solver.cpp:243] Iteration 6000, loss = 0.101562
I1005 21:05:24.505506 16183 solver.cpp:259]     Train net output #0: error_blob = 0.101562 (* 1 = 0.101562 loss)
I1005 21:05:24.505511 16183 solver.cpp:590] Iteration 6000, lr = 0.01
I1005 21:05:26.982537 16183 solver.cpp:243] Iteration 6100, loss = 0.100128
I1005 21:05:26.982568 16183 solver.cpp:259]     Train net output #0: error_blob = 0.100128 (* 1 = 0.100128 loss)
I1005 21:05:26.982573 16183 solver.cpp:590] Iteration 6100, lr = 0.01
I1005 21:05:29.506033 16183 solver.cpp:243] Iteration 6200, loss = 0.0943097
I1005 21:05:29.506063 16183 solver.cpp:259]     Train net output #0: error_blob = 0.0943097 (* 1 = 0.0943097 loss)
I1005 21:05:29.506068 16183 solver.cpp:590] Iteration 6200, lr = 0.01
I1005 21:05:31.994985 16183 solver.cpp:243] Iteration 6300, loss = 0.0966894
I1005 21:05:31.995015 16183 solver.cpp:259]     Train net output #0: error_blob = 0.0966894 (* 1 = 0.0966894 loss)
I1005 21:05:31.995023 16183 solver.cpp:590] Iteration 6300, lr = 0.01
I1005 21:05:32.934360 16183 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:05:34.484915 16183 solver.cpp:243] Iteration 6400, loss = 0.101591
I1005 21:05:34.484947 16183 solver.cpp:259]     Train net output #0: error_blob = 0.101591 (* 1 = 0.101591 loss)
I1005 21:05:34.484954 16183 solver.cpp:590] Iteration 6400, lr = 0.01
I1005 21:05:36.968484 16183 solver.cpp:243] Iteration 6500, loss = 0.0999551
I1005 21:05:36.968526 16183 solver.cpp:259]     Train net output #0: error_blob = 0.0999551 (* 1 = 0.0999551 loss)
I1005 21:05:36.968531 16183 solver.cpp:590] Iteration 6500, lr = 0.01
I1005 21:05:39.484836 16183 solver.cpp:243] Iteration 6600, loss = 0.0941674
I1005 21:05:39.484865 16183 solver.cpp:259]     Train net output #0: error_blob = 0.0941674 (* 1 = 0.0941674 loss)
I1005 21:05:39.484870 16183 solver.cpp:590] Iteration 6600, lr = 0.01
I1005 21:05:42.042840 16183 solver.cpp:243] Iteration 6700, loss = 0.0962571
I1005 21:05:42.042871 16183 solver.cpp:259]     Train net output #0: error_blob = 0.0962571 (* 1 = 0.0962571 loss)
I1005 21:05:42.042876 16183 solver.cpp:590] Iteration 6700, lr = 0.01
I1005 21:05:44.536725 16183 solver.cpp:243] Iteration 6800, loss = 0.100812
I1005 21:05:44.536767 16183 solver.cpp:259]     Train net output #0: error_blob = 0.100812 (* 1 = 0.100812 loss)
I1005 21:05:44.536772 16183 solver.cpp:590] Iteration 6800, lr = 0.01
I1005 21:05:47.026705 16183 solver.cpp:243] Iteration 6900, loss = 0.099804
I1005 21:05:47.026737 16183 solver.cpp:259]     Train net output #0: error_blob = 0.099804 (* 1 = 0.099804 loss)
I1005 21:05:47.026743 16183 solver.cpp:590] Iteration 6900, lr = 0.01
I1005 21:05:49.504186 16183 solver.cpp:347] Iteration 7000, Testing net (#0)
I1005 21:05:49.783710 16183 solver.cpp:415]     Test net output #0: error_blob = 0.102714 (* 1 = 0.102714 loss)
I1005 21:05:49.784319 16183 solver.cpp:243] Iteration 7000, loss = 0.094071
I1005 21:05:49.784333 16183 solver.cpp:259]     Train net output #0: error_blob = 0.094071 (* 1 = 0.094071 loss)
I1005 21:05:49.784339 16183 solver.cpp:590] Iteration 7000, lr = 0.01
I1005 21:05:52.231801 16183 solver.cpp:243] Iteration 7100, loss = 0.096288
I1005 21:05:52.231827 16183 solver.cpp:259]     Train net output #0: error_blob = 0.096288 (* 1 = 0.096288 loss)
I1005 21:05:52.231832 16183 solver.cpp:590] Iteration 7100, lr = 0.01
I1005 21:05:54.717790 16183 solver.cpp:243] Iteration 7200, loss = 0.0998029
I1005 21:05:54.717821 16183 solver.cpp:259]     Train net output #0: error_blob = 0.0998029 (* 1 = 0.0998029 loss)
I1005 21:05:54.717826 16183 solver.cpp:590] Iteration 7200, lr = 0.01
I1005 21:05:55.805549 16183 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:05:57.227025 16183 solver.cpp:243] Iteration 7300, loss = 0.0998516
I1005 21:05:57.227053 16183 solver.cpp:259]     Train net output #0: error_blob = 0.0998516 (* 1 = 0.0998516 loss)
I1005 21:05:57.227061 16183 solver.cpp:590] Iteration 7300, lr = 0.01
I1005 21:05:59.716402 16183 solver.cpp:243] Iteration 7400, loss = 0.0939486
I1005 21:05:59.716434 16183 solver.cpp:259]     Train net output #0: error_blob = 0.0939486 (* 1 = 0.0939486 loss)
I1005 21:05:59.716441 16183 solver.cpp:590] Iteration 7400, lr = 0.01
I1005 21:06:02.206580 16183 solver.cpp:243] Iteration 7500, loss = 0.0963069
I1005 21:06:02.206611 16183 solver.cpp:259]     Train net output #0: error_blob = 0.0963069 (* 1 = 0.0963069 loss)
I1005 21:06:02.206616 16183 solver.cpp:590] Iteration 7500, lr = 0.01
I1005 21:06:04.693238 16183 solver.cpp:243] Iteration 7600, loss = 0.0986879
I1005 21:06:04.693265 16183 solver.cpp:259]     Train net output #0: error_blob = 0.0986879 (* 1 = 0.0986879 loss)
I1005 21:06:04.693271 16183 solver.cpp:590] Iteration 7600, lr = 0.01
I1005 21:06:07.199690 16183 solver.cpp:243] Iteration 7700, loss = 0.0998202
I1005 21:06:07.199719 16183 solver.cpp:259]     Train net output #0: error_blob = 0.0998202 (* 1 = 0.0998202 loss)
I1005 21:06:07.199725 16183 solver.cpp:590] Iteration 7700, lr = 0.01
I1005 21:06:09.658318 16183 solver.cpp:243] Iteration 7800, loss = 0.0938357
I1005 21:06:09.658349 16183 solver.cpp:259]     Train net output #0: error_blob = 0.0938357 (* 1 = 0.0938357 loss)
I1005 21:06:09.658354 16183 solver.cpp:590] Iteration 7800, lr = 0.01
I1005 21:06:12.125589 16183 solver.cpp:243] Iteration 7900, loss = 0.0959624
I1005 21:06:12.125619 16183 solver.cpp:259]     Train net output #0: error_blob = 0.0959624 (* 1 = 0.0959624 loss)
I1005 21:06:12.125624 16183 solver.cpp:590] Iteration 7900, lr = 0.01
I1005 21:06:14.573842 16183 solver.cpp:347] Iteration 8000, Testing net (#0)
I1005 21:06:14.972898 16183 solver.cpp:415]     Test net output #0: error_blob = 0.10192 (* 1 = 0.10192 loss)
I1005 21:06:14.973539 16183 solver.cpp:243] Iteration 8000, loss = 0.0988283
I1005 21:06:14.973553 16183 solver.cpp:259]     Train net output #0: error_blob = 0.0988283 (* 1 = 0.0988283 loss)
I1005 21:06:14.973558 16183 solver.cpp:590] Iteration 8000, lr = 0.01
I1005 21:06:17.438894 16183 solver.cpp:243] Iteration 8100, loss = 0.100013
I1005 21:06:17.438925 16183 solver.cpp:259]     Train net output #0: error_blob = 0.100013 (* 1 = 0.100013 loss)
I1005 21:06:17.438931 16183 solver.cpp:590] Iteration 8100, lr = 0.01
I1005 21:06:18.701123 16183 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:06:19.946250 16183 solver.cpp:243] Iteration 8200, loss = 0.0942974
I1005 21:06:19.947273 16183 solver.cpp:259]     Train net output #0: error_blob = 0.0942974 (* 1 = 0.0942974 loss)
I1005 21:06:19.947283 16183 solver.cpp:590] Iteration 8200, lr = 0.01
I1005 21:06:22.458194 16183 solver.cpp:243] Iteration 8300, loss = 0.0956486
I1005 21:06:22.458223 16183 solver.cpp:259]     Train net output #0: error_blob = 0.0956486 (* 1 = 0.0956486 loss)
I1005 21:06:22.458228 16183 solver.cpp:590] Iteration 8300, lr = 0.01
I1005 21:06:24.958211 16183 solver.cpp:243] Iteration 8400, loss = 0.0983844
I1005 21:06:24.958240 16183 solver.cpp:259]     Train net output #0: error_blob = 0.0983844 (* 1 = 0.0983844 loss)
I1005 21:06:24.958248 16183 solver.cpp:590] Iteration 8400, lr = 0.01
I1005 21:06:27.448591 16183 solver.cpp:243] Iteration 8500, loss = 0.0995459
I1005 21:06:27.448621 16183 solver.cpp:259]     Train net output #0: error_blob = 0.0995459 (* 1 = 0.0995459 loss)
I1005 21:06:27.448626 16183 solver.cpp:590] Iteration 8500, lr = 0.01
I1005 21:06:29.930032 16183 solver.cpp:243] Iteration 8600, loss = 0.0937692
I1005 21:06:29.930061 16183 solver.cpp:259]     Train net output #0: error_blob = 0.0937692 (* 1 = 0.0937692 loss)
I1005 21:06:29.930068 16183 solver.cpp:590] Iteration 8600, lr = 0.01
I1005 21:06:32.432668 16183 solver.cpp:243] Iteration 8700, loss = 0.0953332
I1005 21:06:32.432696 16183 solver.cpp:259]     Train net output #0: error_blob = 0.0953332 (* 1 = 0.0953332 loss)
I1005 21:06:32.432701 16183 solver.cpp:590] Iteration 8700, lr = 0.01
I1005 21:06:34.923935 16183 solver.cpp:243] Iteration 8800, loss = 0.0981477
I1005 21:06:34.923966 16183 solver.cpp:259]     Train net output #0: error_blob = 0.0981477 (* 1 = 0.0981477 loss)
I1005 21:06:34.923974 16183 solver.cpp:590] Iteration 8800, lr = 0.01
I1005 21:06:37.399540 16183 solver.cpp:243] Iteration 8900, loss = 0.0992767
I1005 21:06:37.399569 16183 solver.cpp:259]     Train net output #0: error_blob = 0.0992767 (* 1 = 0.0992767 loss)
I1005 21:06:37.399574 16183 solver.cpp:590] Iteration 8900, lr = 0.01
I1005 21:06:39.876215 16183 solver.cpp:347] Iteration 9000, Testing net (#0)
I1005 21:06:40.164772 16183 solver.cpp:415]     Test net output #0: error_blob = 0.101269 (* 1 = 0.101269 loss)
I1005 21:06:40.165386 16183 solver.cpp:243] Iteration 9000, loss = 0.0939516
I1005 21:06:40.165403 16183 solver.cpp:259]     Train net output #0: error_blob = 0.0939516 (* 1 = 0.0939516 loss)
I1005 21:06:40.165410 16183 solver.cpp:590] Iteration 9000, lr = 0.01
I1005 21:06:41.501180 16183 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:06:42.596405 16183 solver.cpp:243] Iteration 9100, loss = 0.0951273
I1005 21:06:42.596437 16183 solver.cpp:259]     Train net output #0: error_blob = 0.0951273 (* 1 = 0.0951273 loss)
I1005 21:06:42.596444 16183 solver.cpp:590] Iteration 9100, lr = 0.01
I1005 21:06:45.086277 16183 solver.cpp:243] Iteration 9200, loss = 0.0982078
I1005 21:06:45.086308 16183 solver.cpp:259]     Train net output #0: error_blob = 0.0982078 (* 1 = 0.0982078 loss)
I1005 21:06:45.086315 16183 solver.cpp:590] Iteration 9200, lr = 0.01
I1005 21:06:47.582916 16183 solver.cpp:243] Iteration 9300, loss = 0.0991082
I1005 21:06:47.582945 16183 solver.cpp:259]     Train net output #0: error_blob = 0.0991082 (* 1 = 0.0991082 loss)
I1005 21:06:47.582952 16183 solver.cpp:590] Iteration 9300, lr = 0.01
I1005 21:06:50.048817 16183 solver.cpp:243] Iteration 9400, loss = 0.0937548
I1005 21:06:50.049796 16183 solver.cpp:259]     Train net output #0: error_blob = 0.0937548 (* 1 = 0.0937548 loss)
I1005 21:06:50.049805 16183 solver.cpp:590] Iteration 9400, lr = 0.01
I1005 21:06:52.544625 16183 solver.cpp:243] Iteration 9500, loss = 0.0947321
I1005 21:06:52.544656 16183 solver.cpp:259]     Train net output #0: error_blob = 0.0947321 (* 1 = 0.0947321 loss)
I1005 21:06:52.544661 16183 solver.cpp:590] Iteration 9500, lr = 0.01
I1005 21:06:55.031147 16183 solver.cpp:243] Iteration 9600, loss = 0.0978751
I1005 21:06:55.031188 16183 solver.cpp:259]     Train net output #0: error_blob = 0.0978751 (* 1 = 0.0978751 loss)
I1005 21:06:55.031193 16183 solver.cpp:590] Iteration 9600, lr = 0.01
I1005 21:06:57.548313 16183 solver.cpp:243] Iteration 9700, loss = 0.098622
I1005 21:06:57.548346 16183 solver.cpp:259]     Train net output #0: error_blob = 0.098622 (* 1 = 0.098622 loss)
I1005 21:06:57.548351 16183 solver.cpp:590] Iteration 9700, lr = 0.01
I1005 21:07:00.055685 16183 solver.cpp:243] Iteration 9800, loss = 0.0940506
I1005 21:07:00.055714 16183 solver.cpp:259]     Train net output #0: error_blob = 0.0940506 (* 1 = 0.0940506 loss)
I1005 21:07:00.055719 16183 solver.cpp:590] Iteration 9800, lr = 0.01
I1005 21:07:02.533982 16183 solver.cpp:243] Iteration 9900, loss = 0.0946833
I1005 21:07:02.534011 16183 solver.cpp:259]     Train net output #0: error_blob = 0.0946833 (* 1 = 0.0946833 loss)
I1005 21:07:02.534016 16183 solver.cpp:590] Iteration 9900, lr = 0.01
I1005 21:07:04.999344 16183 solver.cpp:468] Snapshotting to binary proto file _iter_10000.caffemodel
I1005 21:07:05.000182 16183 solver.cpp:753] Snapshotting solver state to binary proto file _iter_10000.solverstate
I1005 21:07:05.023715 16183 solver.cpp:327] Iteration 10000, loss = 0.0979305
I1005 21:07:05.023741 16183 solver.cpp:347] Iteration 10000, Testing net (#0)
I1005 21:07:05.193120 16183 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:07:05.302134 16183 solver.cpp:415]     Test net output #0: error_blob = 0.10056 (* 1 = 0.10056 loss)
I1005 21:07:05.302155 16183 solver.cpp:332] Optimization Done.
I1005 21:07:05.302158 16183 caffe.cpp:215] Optimization Done.
I1005 21:07:05.370076 16192 caffe.cpp:184] Using GPUs 0
I1005 21:07:05.934010 16192 solver.cpp:54] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "fixed"
momentum: 0.9
solver_mode: GPU
device_id: 0
net: "large_batch/model0_part5.prototxt"
I1005 21:07:05.934044 16192 solver.cpp:97] Creating training net from net file: large_batch/model0_part5.prototxt
I1005 21:07:05.934204 16192 net.cpp:339] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_layer
I1005 21:07:05.934244 16192 net.cpp:50] Initializing net from parameters: 
name: "large_batch/model0_part5.prototxt"
state {
  phase: TRAIN
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TRAIN
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.part5.train"
    batch_size: 20000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1005 21:07:05.934295 16192 layer_factory.hpp:76] Creating layer data_layer
I1005 21:07:05.946905 16192 net.cpp:110] Creating Layer data_layer
I1005 21:07:05.946928 16192 net.cpp:433] data_layer -> data_blob
I1005 21:07:05.946965 16192 net.cpp:433] data_layer -> label_blob
I1005 21:07:05.947548 16196 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.part5.train
I1005 21:07:06.634958 16192 data_layer.cpp:45] output data size: 20000,61,1,1
I1005 21:07:06.639891 16192 net.cpp:155] Setting up data_layer
I1005 21:07:06.639926 16192 net.cpp:163] Top shape: 20000 61 1 1 (1220000)
I1005 21:07:06.639941 16192 net.cpp:163] Top shape: 20000 (20000)
I1005 21:07:06.639950 16192 layer_factory.hpp:76] Creating layer hidden_sum_layer
I1005 21:07:06.639963 16192 net.cpp:110] Creating Layer hidden_sum_layer
I1005 21:07:06.639968 16192 net.cpp:477] hidden_sum_layer <- data_blob
I1005 21:07:06.639981 16192 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I1005 21:07:06.640328 16192 net.cpp:155] Setting up hidden_sum_layer
I1005 21:07:06.640336 16192 net.cpp:163] Top shape: 20000 10 (200000)
I1005 21:07:06.640362 16192 layer_factory.hpp:76] Creating layer hidden_act_layer
I1005 21:07:06.640372 16192 net.cpp:110] Creating Layer hidden_act_layer
I1005 21:07:06.640377 16192 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I1005 21:07:06.640382 16192 net.cpp:433] hidden_act_layer -> hidden_act_blob
I1005 21:07:09.866264 16192 net.cpp:155] Setting up hidden_act_layer
I1005 21:07:09.866286 16192 net.cpp:163] Top shape: 20000 10 (200000)
I1005 21:07:09.866297 16192 layer_factory.hpp:76] Creating layer output_sum_layer
I1005 21:07:09.866320 16192 net.cpp:110] Creating Layer output_sum_layer
I1005 21:07:09.866325 16192 net.cpp:477] output_sum_layer <- hidden_act_blob
I1005 21:07:09.866333 16192 net.cpp:433] output_sum_layer -> output_sum_blob
I1005 21:07:09.866418 16192 net.cpp:155] Setting up output_sum_layer
I1005 21:07:09.866425 16192 net.cpp:163] Top shape: 20000 1 (20000)
I1005 21:07:09.866436 16192 layer_factory.hpp:76] Creating layer output_act_layer
I1005 21:07:09.866442 16192 net.cpp:110] Creating Layer output_act_layer
I1005 21:07:09.866446 16192 net.cpp:477] output_act_layer <- output_sum_blob
I1005 21:07:09.866451 16192 net.cpp:433] output_act_layer -> output_act_blob
I1005 21:07:09.866511 16192 net.cpp:155] Setting up output_act_layer
I1005 21:07:09.866531 16192 net.cpp:163] Top shape: 20000 1 (20000)
I1005 21:07:09.866535 16192 layer_factory.hpp:76] Creating layer error_layer
I1005 21:07:09.866544 16192 net.cpp:110] Creating Layer error_layer
I1005 21:07:09.866547 16192 net.cpp:477] error_layer <- output_act_blob
I1005 21:07:09.866551 16192 net.cpp:477] error_layer <- label_blob
I1005 21:07:09.866557 16192 net.cpp:433] error_layer -> error_blob
I1005 21:07:09.866591 16192 net.cpp:155] Setting up error_layer
I1005 21:07:09.866596 16192 net.cpp:163] Top shape: (1)
I1005 21:07:09.866600 16192 net.cpp:168]     with loss weight 1
I1005 21:07:09.866619 16192 net.cpp:236] error_layer needs backward computation.
I1005 21:07:09.866624 16192 net.cpp:236] output_act_layer needs backward computation.
I1005 21:07:09.866627 16192 net.cpp:236] output_sum_layer needs backward computation.
I1005 21:07:09.866631 16192 net.cpp:236] hidden_act_layer needs backward computation.
I1005 21:07:09.866634 16192 net.cpp:236] hidden_sum_layer needs backward computation.
I1005 21:07:09.866638 16192 net.cpp:240] data_layer does not need backward computation.
I1005 21:07:09.866641 16192 net.cpp:283] This network produces output error_blob
I1005 21:07:09.866649 16192 net.cpp:297] Network initialization done.
I1005 21:07:09.866652 16192 net.cpp:298] Memory required for data: 6720004
I1005 21:07:09.866777 16192 solver.cpp:187] Creating test net (#0) specified by net file: large_batch/model0_part5.prototxt
I1005 21:07:09.866794 16192 net.cpp:339] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_layer
I1005 21:07:09.866830 16192 net.cpp:50] Initializing net from parameters: 
name: "large_batch/model0_part5.prototxt"
state {
  phase: TEST
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TEST
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.part5.test"
    batch_size: 2000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1005 21:07:09.866860 16192 layer_factory.hpp:76] Creating layer data_layer
I1005 21:07:09.868093 16192 net.cpp:110] Creating Layer data_layer
I1005 21:07:09.868110 16192 net.cpp:433] data_layer -> data_blob
I1005 21:07:09.868118 16192 net.cpp:433] data_layer -> label_blob
I1005 21:07:09.868677 16198 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.part5.test
I1005 21:07:09.868754 16192 data_layer.cpp:45] output data size: 2000,61,1,1
I1005 21:07:09.870225 16192 net.cpp:155] Setting up data_layer
I1005 21:07:09.870240 16192 net.cpp:163] Top shape: 2000 61 1 1 (122000)
I1005 21:07:09.870247 16192 net.cpp:163] Top shape: 2000 (2000)
I1005 21:07:09.870254 16192 layer_factory.hpp:76] Creating layer hidden_sum_layer
I1005 21:07:09.870265 16192 net.cpp:110] Creating Layer hidden_sum_layer
I1005 21:07:09.870270 16192 net.cpp:477] hidden_sum_layer <- data_blob
I1005 21:07:09.870276 16192 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I1005 21:07:09.870385 16192 net.cpp:155] Setting up hidden_sum_layer
I1005 21:07:09.870391 16192 net.cpp:163] Top shape: 2000 10 (20000)
I1005 21:07:09.870403 16192 layer_factory.hpp:76] Creating layer hidden_act_layer
I1005 21:07:09.870410 16192 net.cpp:110] Creating Layer hidden_act_layer
I1005 21:07:09.870414 16192 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I1005 21:07:09.870432 16192 net.cpp:433] hidden_act_layer -> hidden_act_blob
I1005 21:07:09.870628 16192 net.cpp:155] Setting up hidden_act_layer
I1005 21:07:09.870636 16192 net.cpp:163] Top shape: 2000 10 (20000)
I1005 21:07:09.870640 16192 layer_factory.hpp:76] Creating layer output_sum_layer
I1005 21:07:09.870647 16192 net.cpp:110] Creating Layer output_sum_layer
I1005 21:07:09.870651 16192 net.cpp:477] output_sum_layer <- hidden_act_blob
I1005 21:07:09.870657 16192 net.cpp:433] output_sum_layer -> output_sum_blob
I1005 21:07:09.870723 16192 net.cpp:155] Setting up output_sum_layer
I1005 21:07:09.870728 16192 net.cpp:163] Top shape: 2000 1 (2000)
I1005 21:07:09.870738 16192 layer_factory.hpp:76] Creating layer output_act_layer
I1005 21:07:09.870743 16192 net.cpp:110] Creating Layer output_act_layer
I1005 21:07:09.870748 16192 net.cpp:477] output_act_layer <- output_sum_blob
I1005 21:07:09.870754 16192 net.cpp:433] output_act_layer -> output_act_blob
I1005 21:07:09.870807 16192 net.cpp:155] Setting up output_act_layer
I1005 21:07:09.870817 16192 net.cpp:163] Top shape: 2000 1 (2000)
I1005 21:07:09.870821 16192 layer_factory.hpp:76] Creating layer error_layer
I1005 21:07:09.870827 16192 net.cpp:110] Creating Layer error_layer
I1005 21:07:09.870831 16192 net.cpp:477] error_layer <- output_act_blob
I1005 21:07:09.870836 16192 net.cpp:477] error_layer <- label_blob
I1005 21:07:09.870841 16192 net.cpp:433] error_layer -> error_blob
I1005 21:07:09.870867 16192 net.cpp:155] Setting up error_layer
I1005 21:07:09.870872 16192 net.cpp:163] Top shape: (1)
I1005 21:07:09.870874 16192 net.cpp:168]     with loss weight 1
I1005 21:07:09.870887 16192 net.cpp:236] error_layer needs backward computation.
I1005 21:07:09.870893 16192 net.cpp:236] output_act_layer needs backward computation.
I1005 21:07:09.870895 16192 net.cpp:236] output_sum_layer needs backward computation.
I1005 21:07:09.870899 16192 net.cpp:236] hidden_act_layer needs backward computation.
I1005 21:07:09.870903 16192 net.cpp:236] hidden_sum_layer needs backward computation.
I1005 21:07:09.870906 16192 net.cpp:240] data_layer does not need backward computation.
I1005 21:07:09.870909 16192 net.cpp:283] This network produces output error_blob
I1005 21:07:09.870916 16192 net.cpp:297] Network initialization done.
I1005 21:07:09.870919 16192 net.cpp:298] Memory required for data: 672004
I1005 21:07:09.870944 16192 solver.cpp:66] Solver scaffolding done.
I1005 21:07:09.871039 16192 caffe.cpp:212] Starting Optimization
I1005 21:07:09.871047 16192 solver.cpp:294] Solving large_batch/model0_part5.prototxt
I1005 21:07:09.871050 16192 solver.cpp:295] Learning Rate Policy: fixed
I1005 21:07:09.871284 16192 solver.cpp:347] Iteration 0, Testing net (#0)
I1005 21:07:09.871341 16192 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:07:10.160742 16192 solver.cpp:415]     Test net output #0: error_blob = 0.125463 (* 1 = 0.125463 loss)
I1005 21:07:10.162144 16192 solver.cpp:243] Iteration 0, loss = 0.125363
I1005 21:07:10.162186 16192 solver.cpp:259]     Train net output #0: error_blob = 0.125363 (* 1 = 0.125363 loss)
I1005 21:07:10.162202 16192 solver.cpp:590] Iteration 0, lr = 0.01
I1005 21:07:12.644549 16192 solver.cpp:243] Iteration 100, loss = 0.115921
I1005 21:07:12.644595 16192 solver.cpp:259]     Train net output #0: error_blob = 0.115921 (* 1 = 0.115921 loss)
I1005 21:07:12.644603 16192 solver.cpp:590] Iteration 100, lr = 0.01
I1005 21:07:15.166093 16192 solver.cpp:243] Iteration 200, loss = 0.113274
I1005 21:07:15.166141 16192 solver.cpp:259]     Train net output #0: error_blob = 0.113274 (* 1 = 0.113274 loss)
I1005 21:07:15.166148 16192 solver.cpp:590] Iteration 200, lr = 0.01
I1005 21:07:17.662039 16192 solver.cpp:243] Iteration 300, loss = 0.112001
I1005 21:07:17.662086 16192 solver.cpp:259]     Train net output #0: error_blob = 0.112001 (* 1 = 0.112001 loss)
I1005 21:07:17.662092 16192 solver.cpp:590] Iteration 300, lr = 0.01
I1005 21:07:20.156383 16192 solver.cpp:243] Iteration 400, loss = 0.11137
I1005 21:07:20.156460 16192 solver.cpp:259]     Train net output #0: error_blob = 0.11137 (* 1 = 0.11137 loss)
I1005 21:07:20.156467 16192 solver.cpp:590] Iteration 400, lr = 0.01
I1005 21:07:22.645252 16192 solver.cpp:243] Iteration 500, loss = 0.107584
I1005 21:07:22.645282 16192 solver.cpp:259]     Train net output #0: error_blob = 0.107584 (* 1 = 0.107584 loss)
I1005 21:07:22.645288 16192 solver.cpp:590] Iteration 500, lr = 0.01
I1005 21:07:25.141505 16192 solver.cpp:243] Iteration 600, loss = 0.108483
I1005 21:07:25.141552 16192 solver.cpp:259]     Train net output #0: error_blob = 0.108483 (* 1 = 0.108483 loss)
I1005 21:07:25.141561 16192 solver.cpp:590] Iteration 600, lr = 0.01
I1005 21:07:27.643261 16192 solver.cpp:243] Iteration 700, loss = 0.107424
I1005 21:07:27.643292 16192 solver.cpp:259]     Train net output #0: error_blob = 0.107424 (* 1 = 0.107424 loss)
I1005 21:07:27.643297 16192 solver.cpp:590] Iteration 700, lr = 0.01
I1005 21:07:30.124850 16192 solver.cpp:243] Iteration 800, loss = 0.106675
I1005 21:07:30.124889 16192 solver.cpp:259]     Train net output #0: error_blob = 0.106675 (* 1 = 0.106675 loss)
I1005 21:07:30.124897 16192 solver.cpp:590] Iteration 800, lr = 0.01
I1005 21:07:32.635553 16192 solver.cpp:243] Iteration 900, loss = 0.105125
I1005 21:07:32.635601 16192 solver.cpp:259]     Train net output #0: error_blob = 0.105125 (* 1 = 0.105125 loss)
I1005 21:07:32.635608 16192 solver.cpp:590] Iteration 900, lr = 0.01
I1005 21:07:32.684392 16192 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:07:35.080958 16192 solver.cpp:347] Iteration 1000, Testing net (#0)
I1005 21:07:35.387068 16192 solver.cpp:415]     Test net output #0: error_blob = 0.104203 (* 1 = 0.104203 loss)
I1005 21:07:35.387893 16192 solver.cpp:243] Iteration 1000, loss = 0.106468
I1005 21:07:35.387912 16192 solver.cpp:259]     Train net output #0: error_blob = 0.106468 (* 1 = 0.106468 loss)
I1005 21:07:35.387920 16192 solver.cpp:590] Iteration 1000, lr = 0.01
I1005 21:07:37.836871 16192 solver.cpp:243] Iteration 1100, loss = 0.106959
I1005 21:07:37.836910 16192 solver.cpp:259]     Train net output #0: error_blob = 0.106959 (* 1 = 0.106959 loss)
I1005 21:07:37.836918 16192 solver.cpp:590] Iteration 1100, lr = 0.01
I1005 21:07:40.270511 16192 solver.cpp:243] Iteration 1200, loss = 0.104606
I1005 21:07:40.270550 16192 solver.cpp:259]     Train net output #0: error_blob = 0.104606 (* 1 = 0.104606 loss)
I1005 21:07:40.270557 16192 solver.cpp:590] Iteration 1200, lr = 0.01
I1005 21:07:42.778127 16192 solver.cpp:243] Iteration 1300, loss = 0.102974
I1005 21:07:42.778163 16192 solver.cpp:259]     Train net output #0: error_blob = 0.102974 (* 1 = 0.102974 loss)
I1005 21:07:42.778172 16192 solver.cpp:590] Iteration 1300, lr = 0.01
I1005 21:07:45.266217 16192 solver.cpp:243] Iteration 1400, loss = 0.105516
I1005 21:07:45.266249 16192 solver.cpp:259]     Train net output #0: error_blob = 0.105516 (* 1 = 0.105516 loss)
I1005 21:07:45.266254 16192 solver.cpp:590] Iteration 1400, lr = 0.01
I1005 21:07:47.741473 16192 solver.cpp:243] Iteration 1500, loss = 0.106907
I1005 21:07:47.741504 16192 solver.cpp:259]     Train net output #0: error_blob = 0.106907 (* 1 = 0.106907 loss)
I1005 21:07:47.741509 16192 solver.cpp:590] Iteration 1500, lr = 0.01
I1005 21:07:50.199221 16192 solver.cpp:243] Iteration 1600, loss = 0.102124
I1005 21:07:50.199260 16192 solver.cpp:259]     Train net output #0: error_blob = 0.102124 (* 1 = 0.102124 loss)
I1005 21:07:50.199268 16192 solver.cpp:590] Iteration 1600, lr = 0.01
I1005 21:07:52.641782 16192 solver.cpp:243] Iteration 1700, loss = 0.103931
I1005 21:07:52.641813 16192 solver.cpp:259]     Train net output #0: error_blob = 0.103931 (* 1 = 0.103931 loss)
I1005 21:07:52.641819 16192 solver.cpp:590] Iteration 1700, lr = 0.01
I1005 21:07:55.139072 16192 solver.cpp:243] Iteration 1800, loss = 0.105699
I1005 21:07:55.139104 16192 solver.cpp:259]     Train net output #0: error_blob = 0.105699 (* 1 = 0.105699 loss)
I1005 21:07:55.139109 16192 solver.cpp:590] Iteration 1800, lr = 0.01
I1005 21:07:55.343477 16192 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:07:57.633388 16192 solver.cpp:243] Iteration 1900, loss = 0.105435
I1005 21:07:57.633416 16192 solver.cpp:259]     Train net output #0: error_blob = 0.105435 (* 1 = 0.105435 loss)
I1005 21:07:57.633422 16192 solver.cpp:590] Iteration 1900, lr = 0.01
I1005 21:08:00.086630 16192 solver.cpp:347] Iteration 2000, Testing net (#0)
I1005 21:08:00.362632 16192 solver.cpp:415]     Test net output #0: error_blob = 0.0999087 (* 1 = 0.0999087 loss)
I1005 21:08:00.363237 16192 solver.cpp:243] Iteration 2000, loss = 0.100686
I1005 21:08:00.363251 16192 solver.cpp:259]     Train net output #0: error_blob = 0.100686 (* 1 = 0.100686 loss)
I1005 21:08:00.363256 16192 solver.cpp:590] Iteration 2000, lr = 0.01
I1005 21:08:02.856658 16192 solver.cpp:243] Iteration 2100, loss = 0.102476
I1005 21:08:02.856688 16192 solver.cpp:259]     Train net output #0: error_blob = 0.102476 (* 1 = 0.102476 loss)
I1005 21:08:02.856694 16192 solver.cpp:590] Iteration 2100, lr = 0.01
I1005 21:08:05.359966 16192 solver.cpp:243] Iteration 2200, loss = 0.103264
I1005 21:08:05.360009 16192 solver.cpp:259]     Train net output #0: error_blob = 0.103264 (* 1 = 0.103264 loss)
I1005 21:08:05.360014 16192 solver.cpp:590] Iteration 2200, lr = 0.01
I1005 21:08:07.854044 16192 solver.cpp:243] Iteration 2300, loss = 0.102858
I1005 21:08:07.854154 16192 solver.cpp:259]     Train net output #0: error_blob = 0.102858 (* 1 = 0.102858 loss)
I1005 21:08:07.854162 16192 solver.cpp:590] Iteration 2300, lr = 0.01
I1005 21:08:10.378990 16192 solver.cpp:243] Iteration 2400, loss = 0.100748
I1005 21:08:10.379034 16192 solver.cpp:259]     Train net output #0: error_blob = 0.100748 (* 1 = 0.100748 loss)
I1005 21:08:10.379039 16192 solver.cpp:590] Iteration 2400, lr = 0.01
I1005 21:08:12.892647 16192 solver.cpp:243] Iteration 2500, loss = 0.102447
I1005 21:08:12.892688 16192 solver.cpp:259]     Train net output #0: error_blob = 0.102447 (* 1 = 0.102447 loss)
I1005 21:08:12.892695 16192 solver.cpp:590] Iteration 2500, lr = 0.01
I1005 21:08:15.387025 16192 solver.cpp:243] Iteration 2600, loss = 0.103849
I1005 21:08:15.387056 16192 solver.cpp:259]     Train net output #0: error_blob = 0.103849 (* 1 = 0.103849 loss)
I1005 21:08:15.387063 16192 solver.cpp:590] Iteration 2600, lr = 0.01
I1005 21:08:17.875433 16192 solver.cpp:243] Iteration 2700, loss = 0.101481
I1005 21:08:17.875466 16192 solver.cpp:259]     Train net output #0: error_blob = 0.101481 (* 1 = 0.101481 loss)
I1005 21:08:17.875471 16192 solver.cpp:590] Iteration 2700, lr = 0.01
I1005 21:08:18.230839 16192 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:08:20.343786 16192 solver.cpp:243] Iteration 2800, loss = 0.099459
I1005 21:08:20.343819 16192 solver.cpp:259]     Train net output #0: error_blob = 0.099459 (* 1 = 0.099459 loss)
I1005 21:08:20.343827 16192 solver.cpp:590] Iteration 2800, lr = 0.01
I1005 21:08:22.784952 16192 solver.cpp:243] Iteration 2900, loss = 0.102703
I1005 21:08:22.784983 16192 solver.cpp:259]     Train net output #0: error_blob = 0.102703 (* 1 = 0.102703 loss)
I1005 21:08:22.784988 16192 solver.cpp:590] Iteration 2900, lr = 0.01
I1005 21:08:25.213363 16192 solver.cpp:347] Iteration 3000, Testing net (#0)
I1005 21:08:25.542197 16192 solver.cpp:415]     Test net output #0: error_blob = 0.0977214 (* 1 = 0.0977214 loss)
I1005 21:08:25.542821 16192 solver.cpp:243] Iteration 3000, loss = 0.104808
I1005 21:08:25.542834 16192 solver.cpp:259]     Train net output #0: error_blob = 0.104808 (* 1 = 0.104808 loss)
I1005 21:08:25.542839 16192 solver.cpp:590] Iteration 3000, lr = 0.01
I1005 21:08:28.069623 16192 solver.cpp:243] Iteration 3100, loss = 0.0997527
I1005 21:08:28.069655 16192 solver.cpp:259]     Train net output #0: error_blob = 0.0997527 (* 1 = 0.0997527 loss)
I1005 21:08:28.069660 16192 solver.cpp:590] Iteration 3100, lr = 0.01
I1005 21:08:30.545483 16192 solver.cpp:243] Iteration 3200, loss = 0.100634
I1005 21:08:30.545526 16192 solver.cpp:259]     Train net output #0: error_blob = 0.100634 (* 1 = 0.100634 loss)
I1005 21:08:30.545532 16192 solver.cpp:590] Iteration 3200, lr = 0.01
I1005 21:08:33.079035 16192 solver.cpp:243] Iteration 3300, loss = 0.103263
I1005 21:08:33.079076 16192 solver.cpp:259]     Train net output #0: error_blob = 0.103263 (* 1 = 0.103263 loss)
I1005 21:08:33.079082 16192 solver.cpp:590] Iteration 3300, lr = 0.01
I1005 21:08:35.589850 16192 solver.cpp:243] Iteration 3400, loss = 0.103505
I1005 21:08:35.589884 16192 solver.cpp:259]     Train net output #0: error_blob = 0.103505 (* 1 = 0.103505 loss)
I1005 21:08:35.589890 16192 solver.cpp:590] Iteration 3400, lr = 0.01
I1005 21:08:38.061055 16192 solver.cpp:243] Iteration 3500, loss = 0.098382
I1005 21:08:38.062122 16192 solver.cpp:259]     Train net output #0: error_blob = 0.098382 (* 1 = 0.098382 loss)
I1005 21:08:38.062131 16192 solver.cpp:590] Iteration 3500, lr = 0.01
I1005 21:08:40.598235 16192 solver.cpp:243] Iteration 3600, loss = 0.0998764
I1005 21:08:40.598266 16192 solver.cpp:259]     Train net output #0: error_blob = 0.0998764 (* 1 = 0.0998764 loss)
I1005 21:08:40.598273 16192 solver.cpp:590] Iteration 3600, lr = 0.01
I1005 21:08:41.096163 16192 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:08:43.095916 16192 solver.cpp:243] Iteration 3700, loss = 0.101454
I1005 21:08:43.095947 16192 solver.cpp:259]     Train net output #0: error_blob = 0.101454 (* 1 = 0.101454 loss)
I1005 21:08:43.095952 16192 solver.cpp:590] Iteration 3700, lr = 0.01
I1005 21:08:45.583545 16192 solver.cpp:243] Iteration 3800, loss = 0.101356
I1005 21:08:45.583577 16192 solver.cpp:259]     Train net output #0: error_blob = 0.101356 (* 1 = 0.101356 loss)
I1005 21:08:45.583585 16192 solver.cpp:590] Iteration 3800, lr = 0.01
I1005 21:08:48.065237 16192 solver.cpp:243] Iteration 3900, loss = 0.0986509
I1005 21:08:48.065270 16192 solver.cpp:259]     Train net output #0: error_blob = 0.0986509 (* 1 = 0.0986509 loss)
I1005 21:08:48.065279 16192 solver.cpp:590] Iteration 3900, lr = 0.01
I1005 21:08:50.529362 16192 solver.cpp:347] Iteration 4000, Testing net (#0)
I1005 21:08:50.816965 16192 solver.cpp:415]     Test net output #0: error_blob = 0.0962458 (* 1 = 0.0962458 loss)
I1005 21:08:50.817664 16192 solver.cpp:243] Iteration 4000, loss = 0.100044
I1005 21:08:50.817684 16192 solver.cpp:259]     Train net output #0: error_blob = 0.100044 (* 1 = 0.100044 loss)
I1005 21:08:50.817692 16192 solver.cpp:590] Iteration 4000, lr = 0.01
I1005 21:08:53.269568 16192 solver.cpp:243] Iteration 4100, loss = 0.102313
I1005 21:08:53.269598 16192 solver.cpp:259]     Train net output #0: error_blob = 0.102313 (* 1 = 0.102313 loss)
I1005 21:08:53.269605 16192 solver.cpp:590] Iteration 4100, lr = 0.01
I1005 21:08:55.766171 16192 solver.cpp:243] Iteration 4200, loss = 0.100095
I1005 21:08:55.766201 16192 solver.cpp:259]     Train net output #0: error_blob = 0.100095 (* 1 = 0.100095 loss)
I1005 21:08:55.766206 16192 solver.cpp:590] Iteration 4200, lr = 0.01
I1005 21:08:58.249215 16192 solver.cpp:243] Iteration 4300, loss = 0.0972977
I1005 21:08:58.249256 16192 solver.cpp:259]     Train net output #0: error_blob = 0.0972977 (* 1 = 0.0972977 loss)
I1005 21:08:58.249263 16192 solver.cpp:590] Iteration 4300, lr = 0.01
I1005 21:09:00.723083 16192 solver.cpp:243] Iteration 4400, loss = 0.101029
I1005 21:09:00.723114 16192 solver.cpp:259]     Train net output #0: error_blob = 0.101029 (* 1 = 0.101029 loss)
I1005 21:09:00.723120 16192 solver.cpp:590] Iteration 4400, lr = 0.01
I1005 21:09:03.205842 16192 solver.cpp:243] Iteration 4500, loss = 0.103555
I1005 21:09:03.205884 16192 solver.cpp:259]     Train net output #0: error_blob = 0.103555 (* 1 = 0.103555 loss)
I1005 21:09:03.205890 16192 solver.cpp:590] Iteration 4500, lr = 0.01
I1005 21:09:03.839247 16192 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:09:05.690740 16192 solver.cpp:243] Iteration 4600, loss = 0.098407
I1005 21:09:05.690771 16192 solver.cpp:259]     Train net output #0: error_blob = 0.098407 (* 1 = 0.098407 loss)
I1005 21:09:05.690776 16192 solver.cpp:590] Iteration 4600, lr = 0.01
I1005 21:09:08.162194 16192 solver.cpp:243] Iteration 4700, loss = 0.0985958
I1005 21:09:08.163231 16192 solver.cpp:259]     Train net output #0: error_blob = 0.0985958 (* 1 = 0.0985958 loss)
I1005 21:09:08.163244 16192 solver.cpp:590] Iteration 4700, lr = 0.01
I1005 21:09:10.672130 16192 solver.cpp:243] Iteration 4800, loss = 0.101586
I1005 21:09:10.672173 16192 solver.cpp:259]     Train net output #0: error_blob = 0.101586 (* 1 = 0.101586 loss)
I1005 21:09:10.672178 16192 solver.cpp:590] Iteration 4800, lr = 0.01
I1005 21:09:13.205811 16192 solver.cpp:243] Iteration 4900, loss = 0.1023
I1005 21:09:13.205842 16192 solver.cpp:259]     Train net output #0: error_blob = 0.1023 (* 1 = 0.1023 loss)
I1005 21:09:13.205847 16192 solver.cpp:590] Iteration 4900, lr = 0.01
I1005 21:09:15.700122 16192 solver.cpp:347] Iteration 5000, Testing net (#0)
I1005 21:09:15.983417 16192 solver.cpp:415]     Test net output #0: error_blob = 0.0955245 (* 1 = 0.0955245 loss)
I1005 21:09:15.984061 16192 solver.cpp:243] Iteration 5000, loss = 0.0968561
I1005 21:09:15.984077 16192 solver.cpp:259]     Train net output #0: error_blob = 0.0968561 (* 1 = 0.0968561 loss)
I1005 21:09:15.984083 16192 solver.cpp:590] Iteration 5000, lr = 0.01
I1005 21:09:18.516463 16192 solver.cpp:243] Iteration 5100, loss = 0.0980744
I1005 21:09:18.516513 16192 solver.cpp:259]     Train net output #0: error_blob = 0.0980744 (* 1 = 0.0980744 loss)
I1005 21:09:18.516525 16192 solver.cpp:590] Iteration 5100, lr = 0.01
I1005 21:09:21.013764 16192 solver.cpp:243] Iteration 5200, loss = 0.10013
I1005 21:09:21.013798 16192 solver.cpp:259]     Train net output #0: error_blob = 0.10013 (* 1 = 0.10013 loss)
I1005 21:09:21.013805 16192 solver.cpp:590] Iteration 5200, lr = 0.01
I1005 21:09:23.525317 16192 solver.cpp:243] Iteration 5300, loss = 0.100405
I1005 21:09:23.525348 16192 solver.cpp:259]     Train net output #0: error_blob = 0.100405 (* 1 = 0.100405 loss)
I1005 21:09:23.525353 16192 solver.cpp:590] Iteration 5300, lr = 0.01
I1005 21:09:26.000156 16192 solver.cpp:243] Iteration 5400, loss = 0.0970434
I1005 21:09:26.000198 16192 solver.cpp:259]     Train net output #0: error_blob = 0.0970434 (* 1 = 0.0970434 loss)
I1005 21:09:26.000205 16192 solver.cpp:590] Iteration 5400, lr = 0.01
I1005 21:09:26.788715 16192 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:09:28.494048 16192 solver.cpp:243] Iteration 5500, loss = 0.0983704
I1005 21:09:28.494081 16192 solver.cpp:259]     Train net output #0: error_blob = 0.0983704 (* 1 = 0.0983704 loss)
I1005 21:09:28.494087 16192 solver.cpp:590] Iteration 5500, lr = 0.01
I1005 21:09:31.012789 16192 solver.cpp:243] Iteration 5600, loss = 0.101166
I1005 21:09:31.012820 16192 solver.cpp:259]     Train net output #0: error_blob = 0.101166 (* 1 = 0.101166 loss)
I1005 21:09:31.012825 16192 solver.cpp:590] Iteration 5600, lr = 0.01
I1005 21:09:33.550277 16192 solver.cpp:243] Iteration 5700, loss = 0.0991314
I1005 21:09:33.550309 16192 solver.cpp:259]     Train net output #0: error_blob = 0.0991314 (* 1 = 0.0991314 loss)
I1005 21:09:33.550318 16192 solver.cpp:590] Iteration 5700, lr = 0.01
I1005 21:09:36.070576 16192 solver.cpp:243] Iteration 5800, loss = 0.0958868
I1005 21:09:36.070610 16192 solver.cpp:259]     Train net output #0: error_blob = 0.0958868 (* 1 = 0.0958868 loss)
I1005 21:09:36.070616 16192 solver.cpp:590] Iteration 5800, lr = 0.01
I1005 21:09:38.593430 16192 solver.cpp:243] Iteration 5900, loss = 0.0998404
I1005 21:09:38.593572 16192 solver.cpp:259]     Train net output #0: error_blob = 0.0998404 (* 1 = 0.0998404 loss)
I1005 21:09:38.593580 16192 solver.cpp:590] Iteration 5900, lr = 0.01
I1005 21:09:41.089896 16192 solver.cpp:347] Iteration 6000, Testing net (#0)
I1005 21:09:41.388535 16192 solver.cpp:415]     Test net output #0: error_blob = 0.0949384 (* 1 = 0.0949384 loss)
I1005 21:09:41.389142 16192 solver.cpp:243] Iteration 6000, loss = 0.102528
I1005 21:09:41.389155 16192 solver.cpp:259]     Train net output #0: error_blob = 0.102528 (* 1 = 0.102528 loss)
I1005 21:09:41.389160 16192 solver.cpp:590] Iteration 6000, lr = 0.01
I1005 21:09:43.855618 16192 solver.cpp:243] Iteration 6100, loss = 0.0973401
I1005 21:09:43.855648 16192 solver.cpp:259]     Train net output #0: error_blob = 0.0973401 (* 1 = 0.0973401 loss)
I1005 21:09:43.855654 16192 solver.cpp:590] Iteration 6100, lr = 0.01
I1005 21:09:46.383159 16192 solver.cpp:243] Iteration 6200, loss = 0.0971214
I1005 21:09:46.383191 16192 solver.cpp:259]     Train net output #0: error_blob = 0.0971214 (* 1 = 0.0971214 loss)
I1005 21:09:46.383196 16192 solver.cpp:590] Iteration 6200, lr = 0.01
I1005 21:09:48.899760 16192 solver.cpp:243] Iteration 6300, loss = 0.100297
I1005 21:09:48.899791 16192 solver.cpp:259]     Train net output #0: error_blob = 0.100297 (* 1 = 0.100297 loss)
I1005 21:09:48.899797 16192 solver.cpp:590] Iteration 6300, lr = 0.01
I1005 21:09:49.832089 16192 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:09:51.384023 16192 solver.cpp:243] Iteration 6400, loss = 0.101178
I1005 21:09:51.384053 16192 solver.cpp:259]     Train net output #0: error_blob = 0.101178 (* 1 = 0.101178 loss)
I1005 21:09:51.384058 16192 solver.cpp:590] Iteration 6400, lr = 0.01
I1005 21:09:53.910189 16192 solver.cpp:243] Iteration 6500, loss = 0.0957132
I1005 21:09:53.910220 16192 solver.cpp:259]     Train net output #0: error_blob = 0.0957132 (* 1 = 0.0957132 loss)
I1005 21:09:53.910225 16192 solver.cpp:590] Iteration 6500, lr = 0.01
I1005 21:09:56.409137 16192 solver.cpp:243] Iteration 6600, loss = 0.0967979
I1005 21:09:56.409168 16192 solver.cpp:259]     Train net output #0: error_blob = 0.0967979 (* 1 = 0.0967979 loss)
I1005 21:09:56.409173 16192 solver.cpp:590] Iteration 6600, lr = 0.01
I1005 21:09:58.904422 16192 solver.cpp:243] Iteration 6700, loss = 0.0990095
I1005 21:09:58.904453 16192 solver.cpp:259]     Train net output #0: error_blob = 0.0990095 (* 1 = 0.0990095 loss)
I1005 21:09:58.904458 16192 solver.cpp:590] Iteration 6700, lr = 0.01
I1005 21:10:01.397457 16192 solver.cpp:243] Iteration 6800, loss = 0.099641
I1005 21:10:01.397490 16192 solver.cpp:259]     Train net output #0: error_blob = 0.099641 (* 1 = 0.099641 loss)
I1005 21:10:01.397497 16192 solver.cpp:590] Iteration 6800, lr = 0.01
I1005 21:10:03.877580 16192 solver.cpp:243] Iteration 6900, loss = 0.0959413
I1005 21:10:03.877609 16192 solver.cpp:259]     Train net output #0: error_blob = 0.0959413 (* 1 = 0.0959413 loss)
I1005 21:10:03.877614 16192 solver.cpp:590] Iteration 6900, lr = 0.01
I1005 21:10:06.363920 16192 solver.cpp:347] Iteration 7000, Testing net (#0)
I1005 21:10:06.638723 16192 solver.cpp:415]     Test net output #0: error_blob = 0.0943411 (* 1 = 0.0943411 loss)
I1005 21:10:06.639359 16192 solver.cpp:243] Iteration 7000, loss = 0.0970724
I1005 21:10:06.639376 16192 solver.cpp:259]     Train net output #0: error_blob = 0.0970724 (* 1 = 0.0970724 loss)
I1005 21:10:06.639382 16192 solver.cpp:590] Iteration 7000, lr = 0.01
I1005 21:10:09.096161 16192 solver.cpp:243] Iteration 7100, loss = 0.100201
I1005 21:10:09.096276 16192 solver.cpp:259]     Train net output #0: error_blob = 0.100201 (* 1 = 0.100201 loss)
I1005 21:10:09.096295 16192 solver.cpp:590] Iteration 7100, lr = 0.01
I1005 21:10:11.610281 16192 solver.cpp:243] Iteration 7200, loss = 0.0983474
I1005 21:10:11.610319 16192 solver.cpp:259]     Train net output #0: error_blob = 0.0983474 (* 1 = 0.0983474 loss)
I1005 21:10:11.610327 16192 solver.cpp:590] Iteration 7200, lr = 0.01
I1005 21:10:12.706287 16192 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:10:14.136227 16192 solver.cpp:243] Iteration 7300, loss = 0.0948435
I1005 21:10:14.136260 16192 solver.cpp:259]     Train net output #0: error_blob = 0.0948435 (* 1 = 0.0948435 loss)
I1005 21:10:14.136267 16192 solver.cpp:590] Iteration 7300, lr = 0.01
I1005 21:10:16.648175 16192 solver.cpp:243] Iteration 7400, loss = 0.0989522
I1005 21:10:16.648206 16192 solver.cpp:259]     Train net output #0: error_blob = 0.0989522 (* 1 = 0.0989522 loss)
I1005 21:10:16.648213 16192 solver.cpp:590] Iteration 7400, lr = 0.01
I1005 21:10:19.132380 16192 solver.cpp:243] Iteration 7500, loss = 0.101601
I1005 21:10:19.132419 16192 solver.cpp:259]     Train net output #0: error_blob = 0.101601 (* 1 = 0.101601 loss)
I1005 21:10:19.132428 16192 solver.cpp:590] Iteration 7500, lr = 0.01
I1005 21:10:21.601632 16192 solver.cpp:243] Iteration 7600, loss = 0.0964515
I1005 21:10:21.601663 16192 solver.cpp:259]     Train net output #0: error_blob = 0.0964515 (* 1 = 0.0964515 loss)
I1005 21:10:21.601668 16192 solver.cpp:590] Iteration 7600, lr = 0.01
I1005 21:10:24.128417 16192 solver.cpp:243] Iteration 7700, loss = 0.0960337
I1005 21:10:24.128454 16192 solver.cpp:259]     Train net output #0: error_blob = 0.0960337 (* 1 = 0.0960337 loss)
I1005 21:10:24.128461 16192 solver.cpp:590] Iteration 7700, lr = 0.01
I1005 21:10:26.688889 16192 solver.cpp:243] Iteration 7800, loss = 0.0993021
I1005 21:10:26.688928 16192 solver.cpp:259]     Train net output #0: error_blob = 0.0993021 (* 1 = 0.0993021 loss)
I1005 21:10:26.688935 16192 solver.cpp:590] Iteration 7800, lr = 0.01
I1005 21:10:29.221501 16192 solver.cpp:243] Iteration 7900, loss = 0.100233
I1005 21:10:29.221539 16192 solver.cpp:259]     Train net output #0: error_blob = 0.100233 (* 1 = 0.100233 loss)
I1005 21:10:29.221547 16192 solver.cpp:590] Iteration 7900, lr = 0.01
I1005 21:10:31.738188 16192 solver.cpp:347] Iteration 8000, Testing net (#0)
I1005 21:10:32.017026 16192 solver.cpp:415]     Test net output #0: error_blob = 0.094181 (* 1 = 0.094181 loss)
I1005 21:10:32.017695 16192 solver.cpp:243] Iteration 8000, loss = 0.0947863
I1005 21:10:32.017714 16192 solver.cpp:259]     Train net output #0: error_blob = 0.0947863 (* 1 = 0.0947863 loss)
I1005 21:10:32.017725 16192 solver.cpp:590] Iteration 8000, lr = 0.01
I1005 21:10:34.525157 16192 solver.cpp:243] Iteration 8100, loss = 0.0957203
I1005 21:10:34.525197 16192 solver.cpp:259]     Train net output #0: error_blob = 0.0957203 (* 1 = 0.0957203 loss)
I1005 21:10:34.525203 16192 solver.cpp:590] Iteration 8100, lr = 0.01
I1005 21:10:35.787225 16192 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:10:37.027850 16192 solver.cpp:243] Iteration 8200, loss = 0.0981198
I1005 21:10:37.027891 16192 solver.cpp:259]     Train net output #0: error_blob = 0.0981198 (* 1 = 0.0981198 loss)
I1005 21:10:37.027899 16192 solver.cpp:590] Iteration 8200, lr = 0.01
I1005 21:10:39.526060 16192 solver.cpp:243] Iteration 8300, loss = 0.0990025
I1005 21:10:39.526234 16192 solver.cpp:259]     Train net output #0: error_blob = 0.0990025 (* 1 = 0.0990025 loss)
I1005 21:10:39.526255 16192 solver.cpp:590] Iteration 8300, lr = 0.01
I1005 21:10:42.002885 16192 solver.cpp:243] Iteration 8400, loss = 0.0950068
I1005 21:10:42.002928 16192 solver.cpp:259]     Train net output #0: error_blob = 0.0950068 (* 1 = 0.0950068 loss)
I1005 21:10:42.002933 16192 solver.cpp:590] Iteration 8400, lr = 0.01
I1005 21:10:44.569623 16192 solver.cpp:243] Iteration 8500, loss = 0.0961666
I1005 21:10:44.569654 16192 solver.cpp:259]     Train net output #0: error_blob = 0.0961666 (* 1 = 0.0961666 loss)
I1005 21:10:44.569659 16192 solver.cpp:590] Iteration 8500, lr = 0.01
I1005 21:10:47.086395 16192 solver.cpp:243] Iteration 8600, loss = 0.099407
I1005 21:10:47.086427 16192 solver.cpp:259]     Train net output #0: error_blob = 0.099407 (* 1 = 0.099407 loss)
I1005 21:10:47.086433 16192 solver.cpp:590] Iteration 8600, lr = 0.01
I1005 21:10:49.639299 16192 solver.cpp:243] Iteration 8700, loss = 0.0977492
I1005 21:10:49.639349 16192 solver.cpp:259]     Train net output #0: error_blob = 0.0977492 (* 1 = 0.0977492 loss)
I1005 21:10:49.639358 16192 solver.cpp:590] Iteration 8700, lr = 0.01
I1005 21:10:52.134574 16192 solver.cpp:243] Iteration 8800, loss = 0.0940274
I1005 21:10:52.134604 16192 solver.cpp:259]     Train net output #0: error_blob = 0.0940274 (* 1 = 0.0940274 loss)
I1005 21:10:52.134609 16192 solver.cpp:590] Iteration 8800, lr = 0.01
I1005 21:10:54.659804 16192 solver.cpp:243] Iteration 8900, loss = 0.0983184
I1005 21:10:54.659852 16192 solver.cpp:259]     Train net output #0: error_blob = 0.0983184 (* 1 = 0.0983184 loss)
I1005 21:10:54.659859 16192 solver.cpp:590] Iteration 8900, lr = 0.01
I1005 21:10:57.125063 16192 solver.cpp:347] Iteration 9000, Testing net (#0)
I1005 21:10:57.403084 16192 solver.cpp:415]     Test net output #0: error_blob = 0.0939015 (* 1 = 0.0939015 loss)
I1005 21:10:57.403779 16192 solver.cpp:243] Iteration 9000, loss = 0.100708
I1005 21:10:57.403798 16192 solver.cpp:259]     Train net output #0: error_blob = 0.100708 (* 1 = 0.100708 loss)
I1005 21:10:57.403806 16192 solver.cpp:590] Iteration 9000, lr = 0.01
I1005 21:10:58.769345 16192 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:10:59.854396 16192 solver.cpp:243] Iteration 9100, loss = 0.0957625
I1005 21:10:59.854428 16192 solver.cpp:259]     Train net output #0: error_blob = 0.0957625 (* 1 = 0.0957625 loss)
I1005 21:10:59.854432 16192 solver.cpp:590] Iteration 9100, lr = 0.01
I1005 21:11:02.334080 16192 solver.cpp:243] Iteration 9200, loss = 0.0950727
I1005 21:11:02.334121 16192 solver.cpp:259]     Train net output #0: error_blob = 0.0950727 (* 1 = 0.0950727 loss)
I1005 21:11:02.334128 16192 solver.cpp:590] Iteration 9200, lr = 0.01
I1005 21:11:04.861315 16192 solver.cpp:243] Iteration 9300, loss = 0.0985082
I1005 21:11:04.861346 16192 solver.cpp:259]     Train net output #0: error_blob = 0.0985082 (* 1 = 0.0985082 loss)
I1005 21:11:04.861352 16192 solver.cpp:590] Iteration 9300, lr = 0.01
I1005 21:11:07.386615 16192 solver.cpp:243] Iteration 9400, loss = 0.0993936
I1005 21:11:07.386656 16192 solver.cpp:259]     Train net output #0: error_blob = 0.0993936 (* 1 = 0.0993936 loss)
I1005 21:11:07.386662 16192 solver.cpp:590] Iteration 9400, lr = 0.01
I1005 21:11:09.905119 16192 solver.cpp:243] Iteration 9500, loss = 0.0940616
I1005 21:11:09.906469 16192 solver.cpp:259]     Train net output #0: error_blob = 0.0940616 (* 1 = 0.0940616 loss)
I1005 21:11:09.906491 16192 solver.cpp:590] Iteration 9500, lr = 0.01
I1005 21:11:12.440196 16192 solver.cpp:243] Iteration 9600, loss = 0.0948204
I1005 21:11:12.440232 16192 solver.cpp:259]     Train net output #0: error_blob = 0.0948204 (* 1 = 0.0948204 loss)
I1005 21:11:12.440238 16192 solver.cpp:590] Iteration 9600, lr = 0.01
I1005 21:11:14.944128 16192 solver.cpp:243] Iteration 9700, loss = 0.0975142
I1005 21:11:14.944166 16192 solver.cpp:259]     Train net output #0: error_blob = 0.0975142 (* 1 = 0.0975142 loss)
I1005 21:11:14.944172 16192 solver.cpp:590] Iteration 9700, lr = 0.01
I1005 21:11:17.463341 16192 solver.cpp:243] Iteration 9800, loss = 0.0984655
I1005 21:11:17.463389 16192 solver.cpp:259]     Train net output #0: error_blob = 0.0984655 (* 1 = 0.0984655 loss)
I1005 21:11:17.463397 16192 solver.cpp:590] Iteration 9800, lr = 0.01
I1005 21:11:19.971616 16192 solver.cpp:243] Iteration 9900, loss = 0.0942545
I1005 21:11:19.971647 16192 solver.cpp:259]     Train net output #0: error_blob = 0.0942545 (* 1 = 0.0942545 loss)
I1005 21:11:19.971652 16192 solver.cpp:590] Iteration 9900, lr = 0.01
I1005 21:11:22.438263 16192 solver.cpp:468] Snapshotting to binary proto file _iter_10000.caffemodel
I1005 21:11:22.439151 16192 solver.cpp:753] Snapshotting solver state to binary proto file _iter_10000.solverstate
I1005 21:11:22.462733 16192 solver.cpp:327] Iteration 10000, loss = 0.0953567
I1005 21:11:22.462769 16192 solver.cpp:347] Iteration 10000, Testing net (#0)
I1005 21:11:22.632108 16192 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:11:22.741564 16192 solver.cpp:415]     Test net output #0: error_blob = 0.0935296 (* 1 = 0.0935296 loss)
I1005 21:11:22.741596 16192 solver.cpp:332] Optimization Done.
I1005 21:11:22.741601 16192 caffe.cpp:215] Optimization Done.
I1005 21:11:22.804936 16213 caffe.cpp:184] Using GPUs 0
I1005 21:11:23.366499 16213 solver.cpp:54] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "fixed"
momentum: 0.9
solver_mode: GPU
device_id: 0
net: "large_batch/model0_part3.prototxt"
I1005 21:11:23.366531 16213 solver.cpp:97] Creating training net from net file: large_batch/model0_part3.prototxt
I1005 21:11:23.366698 16213 net.cpp:339] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_layer
I1005 21:11:23.366744 16213 net.cpp:50] Initializing net from parameters: 
name: "large_batch/model0_part3.prototxt"
state {
  phase: TRAIN
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TRAIN
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.part3.train"
    batch_size: 20000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1005 21:11:23.366818 16213 layer_factory.hpp:76] Creating layer data_layer
I1005 21:11:23.379539 16213 net.cpp:110] Creating Layer data_layer
I1005 21:11:23.379567 16213 net.cpp:433] data_layer -> data_blob
I1005 21:11:23.379604 16213 net.cpp:433] data_layer -> label_blob
I1005 21:11:23.380204 16217 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.part3.train
I1005 21:11:24.064409 16213 data_layer.cpp:45] output data size: 20000,61,1,1
I1005 21:11:24.069516 16213 net.cpp:155] Setting up data_layer
I1005 21:11:24.069557 16213 net.cpp:163] Top shape: 20000 61 1 1 (1220000)
I1005 21:11:24.069561 16213 net.cpp:163] Top shape: 20000 (20000)
I1005 21:11:24.069566 16213 layer_factory.hpp:76] Creating layer hidden_sum_layer
I1005 21:11:24.069588 16213 net.cpp:110] Creating Layer hidden_sum_layer
I1005 21:11:24.069591 16213 net.cpp:477] hidden_sum_layer <- data_blob
I1005 21:11:24.069600 16213 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I1005 21:11:24.069978 16213 net.cpp:155] Setting up hidden_sum_layer
I1005 21:11:24.069985 16213 net.cpp:163] Top shape: 20000 10 (200000)
I1005 21:11:24.070008 16213 layer_factory.hpp:76] Creating layer hidden_act_layer
I1005 21:11:24.070025 16213 net.cpp:110] Creating Layer hidden_act_layer
I1005 21:11:24.070027 16213 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I1005 21:11:24.070030 16213 net.cpp:433] hidden_act_layer -> hidden_act_blob
I1005 21:11:27.302677 16213 net.cpp:155] Setting up hidden_act_layer
I1005 21:11:27.302709 16213 net.cpp:163] Top shape: 20000 10 (200000)
I1005 21:11:27.302714 16213 layer_factory.hpp:76] Creating layer output_sum_layer
I1005 21:11:27.302724 16213 net.cpp:110] Creating Layer output_sum_layer
I1005 21:11:27.302727 16213 net.cpp:477] output_sum_layer <- hidden_act_blob
I1005 21:11:27.302732 16213 net.cpp:433] output_sum_layer -> output_sum_blob
I1005 21:11:27.302820 16213 net.cpp:155] Setting up output_sum_layer
I1005 21:11:27.302825 16213 net.cpp:163] Top shape: 20000 1 (20000)
I1005 21:11:27.302842 16213 layer_factory.hpp:76] Creating layer output_act_layer
I1005 21:11:27.302847 16213 net.cpp:110] Creating Layer output_act_layer
I1005 21:11:27.302850 16213 net.cpp:477] output_act_layer <- output_sum_blob
I1005 21:11:27.302853 16213 net.cpp:433] output_act_layer -> output_act_blob
I1005 21:11:27.302916 16213 net.cpp:155] Setting up output_act_layer
I1005 21:11:27.302932 16213 net.cpp:163] Top shape: 20000 1 (20000)
I1005 21:11:27.302944 16213 layer_factory.hpp:76] Creating layer error_layer
I1005 21:11:27.302949 16213 net.cpp:110] Creating Layer error_layer
I1005 21:11:27.302953 16213 net.cpp:477] error_layer <- output_act_blob
I1005 21:11:27.302954 16213 net.cpp:477] error_layer <- label_blob
I1005 21:11:27.302958 16213 net.cpp:433] error_layer -> error_blob
I1005 21:11:27.302981 16213 net.cpp:155] Setting up error_layer
I1005 21:11:27.302985 16213 net.cpp:163] Top shape: (1)
I1005 21:11:27.302996 16213 net.cpp:168]     with loss weight 1
I1005 21:11:27.303022 16213 net.cpp:236] error_layer needs backward computation.
I1005 21:11:27.303025 16213 net.cpp:236] output_act_layer needs backward computation.
I1005 21:11:27.303026 16213 net.cpp:236] output_sum_layer needs backward computation.
I1005 21:11:27.303028 16213 net.cpp:236] hidden_act_layer needs backward computation.
I1005 21:11:27.303030 16213 net.cpp:236] hidden_sum_layer needs backward computation.
I1005 21:11:27.303032 16213 net.cpp:240] data_layer does not need backward computation.
I1005 21:11:27.303035 16213 net.cpp:283] This network produces output error_blob
I1005 21:11:27.303040 16213 net.cpp:297] Network initialization done.
I1005 21:11:27.303041 16213 net.cpp:298] Memory required for data: 6720004
I1005 21:11:27.303171 16213 solver.cpp:187] Creating test net (#0) specified by net file: large_batch/model0_part3.prototxt
I1005 21:11:27.303194 16213 net.cpp:339] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_layer
I1005 21:11:27.303233 16213 net.cpp:50] Initializing net from parameters: 
name: "large_batch/model0_part3.prototxt"
state {
  phase: TEST
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TEST
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.part3.test"
    batch_size: 2000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1005 21:11:27.303264 16213 layer_factory.hpp:76] Creating layer data_layer
I1005 21:11:27.304533 16213 net.cpp:110] Creating Layer data_layer
I1005 21:11:27.304549 16213 net.cpp:433] data_layer -> data_blob
I1005 21:11:27.304554 16213 net.cpp:433] data_layer -> label_blob
I1005 21:11:27.305110 16219 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.part3.test
I1005 21:11:27.305176 16213 data_layer.cpp:45] output data size: 2000,61,1,1
I1005 21:11:27.306542 16213 net.cpp:155] Setting up data_layer
I1005 21:11:27.306553 16213 net.cpp:163] Top shape: 2000 61 1 1 (122000)
I1005 21:11:27.306556 16213 net.cpp:163] Top shape: 2000 (2000)
I1005 21:11:27.306560 16213 layer_factory.hpp:76] Creating layer hidden_sum_layer
I1005 21:11:27.306566 16213 net.cpp:110] Creating Layer hidden_sum_layer
I1005 21:11:27.306568 16213 net.cpp:477] hidden_sum_layer <- data_blob
I1005 21:11:27.306572 16213 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I1005 21:11:27.306701 16213 net.cpp:155] Setting up hidden_sum_layer
I1005 21:11:27.306706 16213 net.cpp:163] Top shape: 2000 10 (20000)
I1005 21:11:27.306713 16213 layer_factory.hpp:76] Creating layer hidden_act_layer
I1005 21:11:27.306718 16213 net.cpp:110] Creating Layer hidden_act_layer
I1005 21:11:27.306720 16213 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I1005 21:11:27.306735 16213 net.cpp:433] hidden_act_layer -> hidden_act_blob
I1005 21:11:27.306893 16213 net.cpp:155] Setting up hidden_act_layer
I1005 21:11:27.306900 16213 net.cpp:163] Top shape: 2000 10 (20000)
I1005 21:11:27.306903 16213 layer_factory.hpp:76] Creating layer output_sum_layer
I1005 21:11:27.306907 16213 net.cpp:110] Creating Layer output_sum_layer
I1005 21:11:27.306910 16213 net.cpp:477] output_sum_layer <- hidden_act_blob
I1005 21:11:27.306912 16213 net.cpp:433] output_sum_layer -> output_sum_blob
I1005 21:11:27.306972 16213 net.cpp:155] Setting up output_sum_layer
I1005 21:11:27.306978 16213 net.cpp:163] Top shape: 2000 1 (2000)
I1005 21:11:27.306983 16213 layer_factory.hpp:76] Creating layer output_act_layer
I1005 21:11:27.306988 16213 net.cpp:110] Creating Layer output_act_layer
I1005 21:11:27.306989 16213 net.cpp:477] output_act_layer <- output_sum_blob
I1005 21:11:27.306993 16213 net.cpp:433] output_act_layer -> output_act_blob
I1005 21:11:27.307046 16213 net.cpp:155] Setting up output_act_layer
I1005 21:11:27.307051 16213 net.cpp:163] Top shape: 2000 1 (2000)
I1005 21:11:27.307054 16213 layer_factory.hpp:76] Creating layer error_layer
I1005 21:11:27.307057 16213 net.cpp:110] Creating Layer error_layer
I1005 21:11:27.307060 16213 net.cpp:477] error_layer <- output_act_blob
I1005 21:11:27.307062 16213 net.cpp:477] error_layer <- label_blob
I1005 21:11:27.307065 16213 net.cpp:433] error_layer -> error_blob
I1005 21:11:27.307087 16213 net.cpp:155] Setting up error_layer
I1005 21:11:27.307091 16213 net.cpp:163] Top shape: (1)
I1005 21:11:27.307093 16213 net.cpp:168]     with loss weight 1
I1005 21:11:27.307101 16213 net.cpp:236] error_layer needs backward computation.
I1005 21:11:27.307103 16213 net.cpp:236] output_act_layer needs backward computation.
I1005 21:11:27.307106 16213 net.cpp:236] output_sum_layer needs backward computation.
I1005 21:11:27.307107 16213 net.cpp:236] hidden_act_layer needs backward computation.
I1005 21:11:27.307109 16213 net.cpp:236] hidden_sum_layer needs backward computation.
I1005 21:11:27.307111 16213 net.cpp:240] data_layer does not need backward computation.
I1005 21:11:27.307113 16213 net.cpp:283] This network produces output error_blob
I1005 21:11:27.307118 16213 net.cpp:297] Network initialization done.
I1005 21:11:27.307121 16213 net.cpp:298] Memory required for data: 672004
I1005 21:11:27.307138 16213 solver.cpp:66] Solver scaffolding done.
I1005 21:11:27.307231 16213 caffe.cpp:212] Starting Optimization
I1005 21:11:27.307238 16213 solver.cpp:294] Solving large_batch/model0_part3.prototxt
I1005 21:11:27.307240 16213 solver.cpp:295] Learning Rate Policy: fixed
I1005 21:11:27.307380 16213 solver.cpp:347] Iteration 0, Testing net (#0)
I1005 21:11:27.307431 16213 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:11:27.588672 16213 solver.cpp:415]     Test net output #0: error_blob = 0.133444 (* 1 = 0.133444 loss)
I1005 21:11:27.590068 16213 solver.cpp:243] Iteration 0, loss = 0.134143
I1005 21:11:27.590108 16213 solver.cpp:259]     Train net output #0: error_blob = 0.134143 (* 1 = 0.134143 loss)
I1005 21:11:27.590122 16213 solver.cpp:590] Iteration 0, lr = 0.01
I1005 21:11:30.133432 16213 solver.cpp:243] Iteration 100, loss = 0.11999
I1005 21:11:30.133474 16213 solver.cpp:259]     Train net output #0: error_blob = 0.11999 (* 1 = 0.11999 loss)
I1005 21:11:30.133479 16213 solver.cpp:590] Iteration 100, lr = 0.01
I1005 21:11:32.679792 16213 solver.cpp:243] Iteration 200, loss = 0.114199
I1005 21:11:32.679838 16213 solver.cpp:259]     Train net output #0: error_blob = 0.114199 (* 1 = 0.114199 loss)
I1005 21:11:32.679847 16213 solver.cpp:590] Iteration 200, lr = 0.01
I1005 21:11:35.230132 16213 solver.cpp:243] Iteration 300, loss = 0.112776
I1005 21:11:35.230178 16213 solver.cpp:259]     Train net output #0: error_blob = 0.112776 (* 1 = 0.112776 loss)
I1005 21:11:35.230186 16213 solver.cpp:590] Iteration 300, lr = 0.01
I1005 21:11:37.796476 16213 solver.cpp:243] Iteration 400, loss = 0.111718
I1005 21:11:37.796525 16213 solver.cpp:259]     Train net output #0: error_blob = 0.111718 (* 1 = 0.111718 loss)
I1005 21:11:37.798094 16213 solver.cpp:590] Iteration 400, lr = 0.01
I1005 21:11:40.361277 16213 solver.cpp:243] Iteration 500, loss = 0.10924
I1005 21:11:40.361311 16213 solver.cpp:259]     Train net output #0: error_blob = 0.10924 (* 1 = 0.10924 loss)
I1005 21:11:40.361317 16213 solver.cpp:590] Iteration 500, lr = 0.01
I1005 21:11:42.930932 16213 solver.cpp:243] Iteration 600, loss = 0.111071
I1005 21:11:42.930971 16213 solver.cpp:259]     Train net output #0: error_blob = 0.111071 (* 1 = 0.111071 loss)
I1005 21:11:42.930979 16213 solver.cpp:590] Iteration 600, lr = 0.01
I1005 21:11:45.451481 16213 solver.cpp:243] Iteration 700, loss = 0.110477
I1005 21:11:45.451529 16213 solver.cpp:259]     Train net output #0: error_blob = 0.110477 (* 1 = 0.110477 loss)
I1005 21:11:45.451536 16213 solver.cpp:590] Iteration 700, lr = 0.01
I1005 21:11:47.980221 16213 solver.cpp:243] Iteration 800, loss = 0.105282
I1005 21:11:47.980267 16213 solver.cpp:259]     Train net output #0: error_blob = 0.105282 (* 1 = 0.105282 loss)
I1005 21:11:47.980275 16213 solver.cpp:590] Iteration 800, lr = 0.01
I1005 21:11:50.508363 16213 solver.cpp:243] Iteration 900, loss = 0.107008
I1005 21:11:50.508394 16213 solver.cpp:259]     Train net output #0: error_blob = 0.107008 (* 1 = 0.107008 loss)
I1005 21:11:50.508399 16213 solver.cpp:590] Iteration 900, lr = 0.01
I1005 21:11:50.559830 16213 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:11:52.972332 16213 solver.cpp:347] Iteration 1000, Testing net (#0)
I1005 21:11:53.264533 16213 solver.cpp:415]     Test net output #0: error_blob = 0.0960115 (* 1 = 0.0960115 loss)
I1005 21:11:53.265171 16213 solver.cpp:243] Iteration 1000, loss = 0.107936
I1005 21:11:53.265180 16213 solver.cpp:259]     Train net output #0: error_blob = 0.107936 (* 1 = 0.107936 loss)
I1005 21:11:53.265195 16213 solver.cpp:590] Iteration 1000, lr = 0.01
I1005 21:11:55.724784 16213 solver.cpp:243] Iteration 1100, loss = 0.105412
I1005 21:11:55.724814 16213 solver.cpp:259]     Train net output #0: error_blob = 0.105412 (* 1 = 0.105412 loss)
I1005 21:11:55.724819 16213 solver.cpp:590] Iteration 1100, lr = 0.01
I1005 21:11:58.223757 16213 solver.cpp:243] Iteration 1200, loss = 0.103503
I1005 21:11:58.223798 16213 solver.cpp:259]     Train net output #0: error_blob = 0.103503 (* 1 = 0.103503 loss)
I1005 21:11:58.223805 16213 solver.cpp:590] Iteration 1200, lr = 0.01
I1005 21:12:00.731999 16213 solver.cpp:243] Iteration 1300, loss = 0.107693
I1005 21:12:00.732039 16213 solver.cpp:259]     Train net output #0: error_blob = 0.107693 (* 1 = 0.107693 loss)
I1005 21:12:00.732045 16213 solver.cpp:590] Iteration 1300, lr = 0.01
I1005 21:12:03.265287 16213 solver.cpp:243] Iteration 1400, loss = 0.105617
I1005 21:12:03.265316 16213 solver.cpp:259]     Train net output #0: error_blob = 0.105617 (* 1 = 0.105617 loss)
I1005 21:12:03.265321 16213 solver.cpp:590] Iteration 1400, lr = 0.01
I1005 21:12:05.786099 16213 solver.cpp:243] Iteration 1500, loss = 0.101829
I1005 21:12:05.786131 16213 solver.cpp:259]     Train net output #0: error_blob = 0.101829 (* 1 = 0.101829 loss)
I1005 21:12:05.786139 16213 solver.cpp:590] Iteration 1500, lr = 0.01
I1005 21:12:08.320436 16213 solver.cpp:243] Iteration 1600, loss = 0.105753
I1005 21:12:08.320477 16213 solver.cpp:259]     Train net output #0: error_blob = 0.105753 (* 1 = 0.105753 loss)
I1005 21:12:08.320482 16213 solver.cpp:590] Iteration 1600, lr = 0.01
I1005 21:12:10.824457 16213 solver.cpp:243] Iteration 1700, loss = 0.10685
I1005 21:12:10.824497 16213 solver.cpp:259]     Train net output #0: error_blob = 0.10685 (* 1 = 0.10685 loss)
I1005 21:12:10.824502 16213 solver.cpp:590] Iteration 1700, lr = 0.01
I1005 21:12:13.325712 16213 solver.cpp:243] Iteration 1800, loss = 0.102686
I1005 21:12:13.325753 16213 solver.cpp:259]     Train net output #0: error_blob = 0.102686 (* 1 = 0.102686 loss)
I1005 21:12:13.325758 16213 solver.cpp:590] Iteration 1800, lr = 0.01
I1005 21:12:13.524724 16213 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:12:15.838701 16213 solver.cpp:243] Iteration 1900, loss = 0.102145
I1005 21:12:15.838732 16213 solver.cpp:259]     Train net output #0: error_blob = 0.102145 (* 1 = 0.102145 loss)
I1005 21:12:15.838737 16213 solver.cpp:590] Iteration 1900, lr = 0.01
I1005 21:12:18.355132 16213 solver.cpp:347] Iteration 2000, Testing net (#0)
I1005 21:12:18.652904 16213 solver.cpp:415]     Test net output #0: error_blob = 0.0935456 (* 1 = 0.0935456 loss)
I1005 21:12:18.653602 16213 solver.cpp:243] Iteration 2000, loss = 0.105442
I1005 21:12:18.653617 16213 solver.cpp:259]     Train net output #0: error_blob = 0.105442 (* 1 = 0.105442 loss)
I1005 21:12:18.653625 16213 solver.cpp:590] Iteration 2000, lr = 0.01
I1005 21:12:21.127058 16213 solver.cpp:243] Iteration 2100, loss = 0.104368
I1005 21:12:21.127089 16213 solver.cpp:259]     Train net output #0: error_blob = 0.104368 (* 1 = 0.104368 loss)
I1005 21:12:21.127094 16213 solver.cpp:590] Iteration 2100, lr = 0.01
I1005 21:12:23.667680 16213 solver.cpp:243] Iteration 2200, loss = 0.100157
I1005 21:12:23.667845 16213 solver.cpp:259]     Train net output #0: error_blob = 0.100157 (* 1 = 0.100157 loss)
I1005 21:12:23.667851 16213 solver.cpp:590] Iteration 2200, lr = 0.01
I1005 21:12:26.220960 16213 solver.cpp:243] Iteration 2300, loss = 0.104671
I1005 21:12:26.220993 16213 solver.cpp:259]     Train net output #0: error_blob = 0.104671 (* 1 = 0.104671 loss)
I1005 21:12:26.220999 16213 solver.cpp:590] Iteration 2300, lr = 0.01
I1005 21:12:28.752449 16213 solver.cpp:243] Iteration 2400, loss = 0.106488
I1005 21:12:28.752480 16213 solver.cpp:259]     Train net output #0: error_blob = 0.106488 (* 1 = 0.106488 loss)
I1005 21:12:28.752495 16213 solver.cpp:590] Iteration 2400, lr = 0.01
I1005 21:12:31.269752 16213 solver.cpp:243] Iteration 2500, loss = 0.10024
I1005 21:12:31.269781 16213 solver.cpp:259]     Train net output #0: error_blob = 0.10024 (* 1 = 0.10024 loss)
I1005 21:12:31.269786 16213 solver.cpp:590] Iteration 2500, lr = 0.01
I1005 21:12:33.781863 16213 solver.cpp:243] Iteration 2600, loss = 0.101648
I1005 21:12:33.781893 16213 solver.cpp:259]     Train net output #0: error_blob = 0.101648 (* 1 = 0.101648 loss)
I1005 21:12:33.781898 16213 solver.cpp:590] Iteration 2600, lr = 0.01
I1005 21:12:36.309408 16213 solver.cpp:243] Iteration 2700, loss = 0.103717
I1005 21:12:36.309439 16213 solver.cpp:259]     Train net output #0: error_blob = 0.103717 (* 1 = 0.103717 loss)
I1005 21:12:36.309445 16213 solver.cpp:590] Iteration 2700, lr = 0.01
I1005 21:12:36.666275 16213 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:12:38.865111 16213 solver.cpp:243] Iteration 2800, loss = 0.102683
I1005 21:12:38.865144 16213 solver.cpp:259]     Train net output #0: error_blob = 0.102683 (* 1 = 0.102683 loss)
I1005 21:12:38.865152 16213 solver.cpp:590] Iteration 2800, lr = 0.01
I1005 21:12:41.417227 16213 solver.cpp:243] Iteration 2900, loss = 0.0998498
I1005 21:12:41.417260 16213 solver.cpp:259]     Train net output #0: error_blob = 0.0998498 (* 1 = 0.0998498 loss)
I1005 21:12:41.417268 16213 solver.cpp:590] Iteration 2900, lr = 0.01
I1005 21:12:43.952282 16213 solver.cpp:347] Iteration 3000, Testing net (#0)
I1005 21:12:44.234642 16213 solver.cpp:415]     Test net output #0: error_blob = 0.0925299 (* 1 = 0.0925299 loss)
I1005 21:12:44.235241 16213 solver.cpp:243] Iteration 3000, loss = 0.105823
I1005 21:12:44.235255 16213 solver.cpp:259]     Train net output #0: error_blob = 0.105823 (* 1 = 0.105823 loss)
I1005 21:12:44.235260 16213 solver.cpp:590] Iteration 3000, lr = 0.01
I1005 21:12:46.745457 16213 solver.cpp:243] Iteration 3100, loss = 0.103922
I1005 21:12:46.745487 16213 solver.cpp:259]     Train net output #0: error_blob = 0.103922 (* 1 = 0.103922 loss)
I1005 21:12:46.745492 16213 solver.cpp:590] Iteration 3100, lr = 0.01
I1005 21:12:49.235525 16213 solver.cpp:243] Iteration 3200, loss = 0.099679
I1005 21:12:49.235564 16213 solver.cpp:259]     Train net output #0: error_blob = 0.099679 (* 1 = 0.099679 loss)
I1005 21:12:49.235569 16213 solver.cpp:590] Iteration 3200, lr = 0.01
I1005 21:12:51.772354 16213 solver.cpp:243] Iteration 3300, loss = 0.101177
I1005 21:12:51.772387 16213 solver.cpp:259]     Train net output #0: error_blob = 0.101177 (* 1 = 0.101177 loss)
I1005 21:12:51.772392 16213 solver.cpp:590] Iteration 3300, lr = 0.01
I1005 21:12:54.295673 16213 solver.cpp:243] Iteration 3400, loss = 0.105233
I1005 21:12:54.295786 16213 solver.cpp:259]     Train net output #0: error_blob = 0.105233 (* 1 = 0.105233 loss)
I1005 21:12:54.295794 16213 solver.cpp:590] Iteration 3400, lr = 0.01
I1005 21:12:56.841361 16213 solver.cpp:243] Iteration 3500, loss = 0.10088
I1005 21:12:56.841402 16213 solver.cpp:259]     Train net output #0: error_blob = 0.10088 (* 1 = 0.10088 loss)
I1005 21:12:56.841408 16213 solver.cpp:590] Iteration 3500, lr = 0.01
I1005 21:12:59.386414 16213 solver.cpp:243] Iteration 3600, loss = 0.0994682
I1005 21:12:59.386445 16213 solver.cpp:259]     Train net output #0: error_blob = 0.0994682 (* 1 = 0.0994682 loss)
I1005 21:12:59.386451 16213 solver.cpp:590] Iteration 3600, lr = 0.01
I1005 21:12:59.881494 16213 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:13:01.903436 16213 solver.cpp:243] Iteration 3700, loss = 0.104396
I1005 21:13:01.903465 16213 solver.cpp:259]     Train net output #0: error_blob = 0.104396 (* 1 = 0.104396 loss)
I1005 21:13:01.903472 16213 solver.cpp:590] Iteration 3700, lr = 0.01
I1005 21:13:04.470561 16213 solver.cpp:243] Iteration 3800, loss = 0.103246
I1005 21:13:04.470594 16213 solver.cpp:259]     Train net output #0: error_blob = 0.103246 (* 1 = 0.103246 loss)
I1005 21:13:04.470602 16213 solver.cpp:590] Iteration 3800, lr = 0.01
I1005 21:13:07.020582 16213 solver.cpp:243] Iteration 3900, loss = 0.0986234
I1005 21:13:07.020613 16213 solver.cpp:259]     Train net output #0: error_blob = 0.0986234 (* 1 = 0.0986234 loss)
I1005 21:13:07.020622 16213 solver.cpp:590] Iteration 3900, lr = 0.01
I1005 21:13:09.509912 16213 solver.cpp:347] Iteration 4000, Testing net (#0)
I1005 21:13:09.862316 16213 solver.cpp:415]     Test net output #0: error_blob = 0.0916077 (* 1 = 0.0916077 loss)
I1005 21:13:09.862915 16213 solver.cpp:243] Iteration 4000, loss = 0.100755
I1005 21:13:09.862926 16213 solver.cpp:259]     Train net output #0: error_blob = 0.100755 (* 1 = 0.100755 loss)
I1005 21:13:09.862929 16213 solver.cpp:590] Iteration 4000, lr = 0.01
I1005 21:13:12.337138 16213 solver.cpp:243] Iteration 4100, loss = 0.104642
I1005 21:13:12.337182 16213 solver.cpp:259]     Train net output #0: error_blob = 0.104642 (* 1 = 0.104642 loss)
I1005 21:13:12.337187 16213 solver.cpp:590] Iteration 4100, lr = 0.01
I1005 21:13:14.845276 16213 solver.cpp:243] Iteration 4200, loss = 0.0987014
I1005 21:13:14.845305 16213 solver.cpp:259]     Train net output #0: error_blob = 0.0987014 (* 1 = 0.0987014 loss)
I1005 21:13:14.845310 16213 solver.cpp:590] Iteration 4200, lr = 0.01
I1005 21:13:17.385392 16213 solver.cpp:243] Iteration 4300, loss = 0.0989074
I1005 21:13:17.385432 16213 solver.cpp:259]     Train net output #0: error_blob = 0.0989074 (* 1 = 0.0989074 loss)
I1005 21:13:17.385439 16213 solver.cpp:590] Iteration 4300, lr = 0.01
I1005 21:13:19.956934 16213 solver.cpp:243] Iteration 4400, loss = 0.102115
I1005 21:13:19.956967 16213 solver.cpp:259]     Train net output #0: error_blob = 0.102115 (* 1 = 0.102115 loss)
I1005 21:13:19.956976 16213 solver.cpp:590] Iteration 4400, lr = 0.01
I1005 21:13:22.498950 16213 solver.cpp:243] Iteration 4500, loss = 0.10199
I1005 21:13:22.498999 16213 solver.cpp:259]     Train net output #0: error_blob = 0.10199 (* 1 = 0.10199 loss)
I1005 21:13:22.499011 16213 solver.cpp:590] Iteration 4500, lr = 0.01
I1005 21:13:23.172327 16213 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:13:25.041820 16213 solver.cpp:243] Iteration 4600, loss = 0.0966586
I1005 21:13:25.041918 16213 solver.cpp:259]     Train net output #0: error_blob = 0.0966586 (* 1 = 0.0966586 loss)
I1005 21:13:25.041928 16213 solver.cpp:590] Iteration 4600, lr = 0.01
I1005 21:13:27.587044 16213 solver.cpp:243] Iteration 4700, loss = 0.101326
I1005 21:13:27.587074 16213 solver.cpp:259]     Train net output #0: error_blob = 0.101326 (* 1 = 0.101326 loss)
I1005 21:13:27.587080 16213 solver.cpp:590] Iteration 4700, lr = 0.01
I1005 21:13:30.106626 16213 solver.cpp:243] Iteration 4800, loss = 0.102391
I1005 21:13:30.106655 16213 solver.cpp:259]     Train net output #0: error_blob = 0.102391 (* 1 = 0.102391 loss)
I1005 21:13:30.106660 16213 solver.cpp:590] Iteration 4800, lr = 0.01
I1005 21:13:32.560585 16213 solver.cpp:243] Iteration 4900, loss = 0.0977386
I1005 21:13:32.560614 16213 solver.cpp:259]     Train net output #0: error_blob = 0.0977386 (* 1 = 0.0977386 loss)
I1005 21:13:32.560619 16213 solver.cpp:590] Iteration 4900, lr = 0.01
I1005 21:13:35.088069 16213 solver.cpp:347] Iteration 5000, Testing net (#0)
I1005 21:13:35.364426 16213 solver.cpp:415]     Test net output #0: error_blob = 0.0909359 (* 1 = 0.0909359 loss)
I1005 21:13:35.365100 16213 solver.cpp:243] Iteration 5000, loss = 0.098278
I1005 21:13:35.365136 16213 solver.cpp:259]     Train net output #0: error_blob = 0.098278 (* 1 = 0.098278 loss)
I1005 21:13:35.365147 16213 solver.cpp:590] Iteration 5000, lr = 0.01
I1005 21:13:37.878355 16213 solver.cpp:243] Iteration 5100, loss = 0.103325
I1005 21:13:37.878387 16213 solver.cpp:259]     Train net output #0: error_blob = 0.103325 (* 1 = 0.103325 loss)
I1005 21:13:37.878394 16213 solver.cpp:590] Iteration 5100, lr = 0.01
I1005 21:13:40.392853 16213 solver.cpp:243] Iteration 5200, loss = 0.100579
I1005 21:13:40.392884 16213 solver.cpp:259]     Train net output #0: error_blob = 0.100579 (* 1 = 0.100579 loss)
I1005 21:13:40.392889 16213 solver.cpp:590] Iteration 5200, lr = 0.01
I1005 21:13:42.966929 16213 solver.cpp:243] Iteration 5300, loss = 0.0974127
I1005 21:13:42.966964 16213 solver.cpp:259]     Train net output #0: error_blob = 0.0974127 (* 1 = 0.0974127 loss)
I1005 21:13:42.966969 16213 solver.cpp:590] Iteration 5300, lr = 0.01
I1005 21:13:45.513984 16213 solver.cpp:243] Iteration 5400, loss = 0.102178
I1005 21:13:45.514015 16213 solver.cpp:259]     Train net output #0: error_blob = 0.102178 (* 1 = 0.102178 loss)
I1005 21:13:45.514022 16213 solver.cpp:590] Iteration 5400, lr = 0.01
I1005 21:13:46.328865 16213 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:13:48.032519 16213 solver.cpp:243] Iteration 5500, loss = 0.10302
I1005 21:13:48.032549 16213 solver.cpp:259]     Train net output #0: error_blob = 0.10302 (* 1 = 0.10302 loss)
I1005 21:13:48.032555 16213 solver.cpp:590] Iteration 5500, lr = 0.01
I1005 21:13:50.498158 16213 solver.cpp:243] Iteration 5600, loss = 0.0980404
I1005 21:13:50.498189 16213 solver.cpp:259]     Train net output #0: error_blob = 0.0980404 (* 1 = 0.0980404 loss)
I1005 21:13:50.498193 16213 solver.cpp:590] Iteration 5600, lr = 0.01
I1005 21:13:52.983732 16213 solver.cpp:243] Iteration 5700, loss = 0.0987414
I1005 21:13:52.983762 16213 solver.cpp:259]     Train net output #0: error_blob = 0.0987414 (* 1 = 0.0987414 loss)
I1005 21:13:52.983767 16213 solver.cpp:590] Iteration 5700, lr = 0.01
I1005 21:13:55.469590 16213 solver.cpp:243] Iteration 5800, loss = 0.102946
I1005 21:13:55.470578 16213 solver.cpp:259]     Train net output #0: error_blob = 0.102946 (* 1 = 0.102946 loss)
I1005 21:13:55.470585 16213 solver.cpp:590] Iteration 5800, lr = 0.01
I1005 21:13:57.998960 16213 solver.cpp:243] Iteration 5900, loss = 0.0981614
I1005 21:13:57.998989 16213 solver.cpp:259]     Train net output #0: error_blob = 0.0981614 (* 1 = 0.0981614 loss)
I1005 21:13:57.998994 16213 solver.cpp:590] Iteration 5900, lr = 0.01
I1005 21:14:00.491469 16213 solver.cpp:347] Iteration 6000, Testing net (#0)
I1005 21:14:00.768380 16213 solver.cpp:415]     Test net output #0: error_blob = 0.0900553 (* 1 = 0.0900553 loss)
I1005 21:14:00.768986 16213 solver.cpp:243] Iteration 6000, loss = 0.0963215
I1005 21:14:00.769000 16213 solver.cpp:259]     Train net output #0: error_blob = 0.0963215 (* 1 = 0.0963215 loss)
I1005 21:14:00.769006 16213 solver.cpp:590] Iteration 6000, lr = 0.01
I1005 21:14:03.255545 16213 solver.cpp:243] Iteration 6100, loss = 0.100387
I1005 21:14:03.255578 16213 solver.cpp:259]     Train net output #0: error_blob = 0.100387 (* 1 = 0.100387 loss)
I1005 21:14:03.255584 16213 solver.cpp:590] Iteration 6100, lr = 0.01
I1005 21:14:05.742439 16213 solver.cpp:243] Iteration 6200, loss = 0.103032
I1005 21:14:05.742471 16213 solver.cpp:259]     Train net output #0: error_blob = 0.103032 (* 1 = 0.103032 loss)
I1005 21:14:05.742480 16213 solver.cpp:590] Iteration 6200, lr = 0.01
I1005 21:14:08.284811 16213 solver.cpp:243] Iteration 6300, loss = 0.0968216
I1005 21:14:08.284842 16213 solver.cpp:259]     Train net output #0: error_blob = 0.0968216 (* 1 = 0.0968216 loss)
I1005 21:14:08.284848 16213 solver.cpp:590] Iteration 6300, lr = 0.01
I1005 21:14:09.244410 16213 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:14:10.820281 16213 solver.cpp:243] Iteration 6400, loss = 0.100706
I1005 21:14:10.820312 16213 solver.cpp:259]     Train net output #0: error_blob = 0.100706 (* 1 = 0.100706 loss)
I1005 21:14:10.820317 16213 solver.cpp:590] Iteration 6400, lr = 0.01
I1005 21:14:13.323029 16213 solver.cpp:243] Iteration 6500, loss = 0.103432
I1005 21:14:13.323061 16213 solver.cpp:259]     Train net output #0: error_blob = 0.103432 (* 1 = 0.103432 loss)
I1005 21:14:13.323066 16213 solver.cpp:590] Iteration 6500, lr = 0.01
I1005 21:14:15.824200 16213 solver.cpp:243] Iteration 6600, loss = 0.0960889
I1005 21:14:15.824230 16213 solver.cpp:259]     Train net output #0: error_blob = 0.0960889 (* 1 = 0.0960889 loss)
I1005 21:14:15.824235 16213 solver.cpp:590] Iteration 6600, lr = 0.01
I1005 21:14:18.361397 16213 solver.cpp:243] Iteration 6700, loss = 0.0970064
I1005 21:14:18.361428 16213 solver.cpp:259]     Train net output #0: error_blob = 0.0970064 (* 1 = 0.0970064 loss)
I1005 21:14:18.361433 16213 solver.cpp:590] Iteration 6700, lr = 0.01
I1005 21:14:20.913096 16213 solver.cpp:243] Iteration 6800, loss = 0.101294
I1005 21:14:20.913126 16213 solver.cpp:259]     Train net output #0: error_blob = 0.101294 (* 1 = 0.101294 loss)
I1005 21:14:20.913132 16213 solver.cpp:590] Iteration 6800, lr = 0.01
I1005 21:14:23.490283 16213 solver.cpp:243] Iteration 6900, loss = 0.0994144
I1005 21:14:23.490310 16213 solver.cpp:259]     Train net output #0: error_blob = 0.0994144 (* 1 = 0.0994144 loss)
I1005 21:14:23.490315 16213 solver.cpp:590] Iteration 6900, lr = 0.01
I1005 21:14:25.960508 16213 solver.cpp:347] Iteration 7000, Testing net (#0)
I1005 21:14:26.272274 16213 solver.cpp:415]     Test net output #0: error_blob = 0.08928 (* 1 = 0.08928 loss)
I1005 21:14:26.272905 16213 solver.cpp:243] Iteration 7000, loss = 0.0963428
I1005 21:14:26.272917 16213 solver.cpp:259]     Train net output #0: error_blob = 0.0963428 (* 1 = 0.0963428 loss)
I1005 21:14:26.272922 16213 solver.cpp:590] Iteration 7000, lr = 0.01
I1005 21:14:28.776223 16213 solver.cpp:243] Iteration 7100, loss = 0.100789
I1005 21:14:28.776257 16213 solver.cpp:259]     Train net output #0: error_blob = 0.100789 (* 1 = 0.100789 loss)
I1005 21:14:28.776265 16213 solver.cpp:590] Iteration 7100, lr = 0.01
I1005 21:14:31.335189 16213 solver.cpp:243] Iteration 7200, loss = 0.101919
I1005 21:14:31.335222 16213 solver.cpp:259]     Train net output #0: error_blob = 0.101919 (* 1 = 0.101919 loss)
I1005 21:14:31.335228 16213 solver.cpp:590] Iteration 7200, lr = 0.01
I1005 21:14:32.404973 16213 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:14:33.835348 16213 solver.cpp:243] Iteration 7300, loss = 0.0953426
I1005 21:14:33.835377 16213 solver.cpp:259]     Train net output #0: error_blob = 0.0953426 (* 1 = 0.0953426 loss)
I1005 21:14:33.835382 16213 solver.cpp:590] Iteration 7300, lr = 0.01
I1005 21:14:36.400702 16213 solver.cpp:243] Iteration 7400, loss = 0.0973007
I1005 21:14:36.400732 16213 solver.cpp:259]     Train net output #0: error_blob = 0.0973007 (* 1 = 0.0973007 loss)
I1005 21:14:36.400738 16213 solver.cpp:590] Iteration 7400, lr = 0.01
I1005 21:14:38.927974 16213 solver.cpp:243] Iteration 7500, loss = 0.103096
I1005 21:14:38.928006 16213 solver.cpp:259]     Train net output #0: error_blob = 0.103096 (* 1 = 0.103096 loss)
I1005 21:14:38.928011 16213 solver.cpp:590] Iteration 7500, lr = 0.01
I1005 21:14:41.436816 16213 solver.cpp:243] Iteration 7600, loss = 0.0968105
I1005 21:14:41.436846 16213 solver.cpp:259]     Train net output #0: error_blob = 0.0968105 (* 1 = 0.0968105 loss)
I1005 21:14:41.436851 16213 solver.cpp:590] Iteration 7600, lr = 0.01
I1005 21:14:43.985709 16213 solver.cpp:243] Iteration 7700, loss = 0.0946188
I1005 21:14:43.985749 16213 solver.cpp:259]     Train net output #0: error_blob = 0.0946188 (* 1 = 0.0946188 loss)
I1005 21:14:43.985754 16213 solver.cpp:590] Iteration 7700, lr = 0.01
I1005 21:14:46.509456 16213 solver.cpp:243] Iteration 7800, loss = 0.0991249
I1005 21:14:46.509486 16213 solver.cpp:259]     Train net output #0: error_blob = 0.0991249 (* 1 = 0.0991249 loss)
I1005 21:14:46.509491 16213 solver.cpp:590] Iteration 7800, lr = 0.01
I1005 21:14:49.086360 16213 solver.cpp:243] Iteration 7900, loss = 0.10128
I1005 21:14:49.086390 16213 solver.cpp:259]     Train net output #0: error_blob = 0.10128 (* 1 = 0.10128 loss)
I1005 21:14:49.086395 16213 solver.cpp:590] Iteration 7900, lr = 0.01
I1005 21:14:51.611709 16213 solver.cpp:347] Iteration 8000, Testing net (#0)
I1005 21:14:51.910569 16213 solver.cpp:415]     Test net output #0: error_blob = 0.0887587 (* 1 = 0.0887587 loss)
I1005 21:14:51.911176 16213 solver.cpp:243] Iteration 8000, loss = 0.095136
I1005 21:14:51.911190 16213 solver.cpp:259]     Train net output #0: error_blob = 0.095136 (* 1 = 0.095136 loss)
I1005 21:14:51.911236 16213 solver.cpp:590] Iteration 8000, lr = 0.01
I1005 21:14:54.397222 16213 solver.cpp:243] Iteration 8100, loss = 0.098527
I1005 21:14:54.397253 16213 solver.cpp:259]     Train net output #0: error_blob = 0.098527 (* 1 = 0.098527 loss)
I1005 21:14:54.397258 16213 solver.cpp:590] Iteration 8100, lr = 0.01
I1005 21:14:55.643906 16213 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:14:56.922760 16213 solver.cpp:243] Iteration 8200, loss = 0.102029
I1005 21:14:56.922868 16213 solver.cpp:259]     Train net output #0: error_blob = 0.102029 (* 1 = 0.102029 loss)
I1005 21:14:56.922874 16213 solver.cpp:590] Iteration 8200, lr = 0.01
I1005 21:14:59.455629 16213 solver.cpp:243] Iteration 8300, loss = 0.0941379
I1005 21:14:59.455659 16213 solver.cpp:259]     Train net output #0: error_blob = 0.0941379 (* 1 = 0.0941379 loss)
I1005 21:14:59.455665 16213 solver.cpp:590] Iteration 8300, lr = 0.01
I1005 21:15:01.949581 16213 solver.cpp:243] Iteration 8400, loss = 0.0956993
I1005 21:15:01.949623 16213 solver.cpp:259]     Train net output #0: error_blob = 0.0956993 (* 1 = 0.0956993 loss)
I1005 21:15:01.949630 16213 solver.cpp:590] Iteration 8400, lr = 0.01
I1005 21:15:04.493271 16213 solver.cpp:243] Iteration 8500, loss = 0.0993001
I1005 21:15:04.493311 16213 solver.cpp:259]     Train net output #0: error_blob = 0.0993001 (* 1 = 0.0993001 loss)
I1005 21:15:04.493317 16213 solver.cpp:590] Iteration 8500, lr = 0.01
I1005 21:15:07.052736 16213 solver.cpp:243] Iteration 8600, loss = 0.0993769
I1005 21:15:07.052767 16213 solver.cpp:259]     Train net output #0: error_blob = 0.0993769 (* 1 = 0.0993769 loss)
I1005 21:15:07.052774 16213 solver.cpp:590] Iteration 8600, lr = 0.01
I1005 21:15:09.564615 16213 solver.cpp:243] Iteration 8700, loss = 0.0945135
I1005 21:15:09.564649 16213 solver.cpp:259]     Train net output #0: error_blob = 0.0945135 (* 1 = 0.0945135 loss)
I1005 21:15:09.564657 16213 solver.cpp:590] Iteration 8700, lr = 0.01
I1005 21:15:12.059248 16213 solver.cpp:243] Iteration 8800, loss = 0.100668
I1005 21:15:12.059279 16213 solver.cpp:259]     Train net output #0: error_blob = 0.100668 (* 1 = 0.100668 loss)
I1005 21:15:12.059284 16213 solver.cpp:590] Iteration 8800, lr = 0.01
I1005 21:15:14.545191 16213 solver.cpp:243] Iteration 8900, loss = 0.100343
I1005 21:15:14.545222 16213 solver.cpp:259]     Train net output #0: error_blob = 0.100343 (* 1 = 0.100343 loss)
I1005 21:15:14.545227 16213 solver.cpp:590] Iteration 8900, lr = 0.01
I1005 21:15:17.036054 16213 solver.cpp:347] Iteration 9000, Testing net (#0)
I1005 21:15:17.331640 16213 solver.cpp:415]     Test net output #0: error_blob = 0.0882497 (* 1 = 0.0882497 loss)
I1005 21:15:17.332250 16213 solver.cpp:243] Iteration 9000, loss = 0.0945009
I1005 21:15:17.332262 16213 solver.cpp:259]     Train net output #0: error_blob = 0.0945009 (* 1 = 0.0945009 loss)
I1005 21:15:17.332267 16213 solver.cpp:590] Iteration 9000, lr = 0.01
I1005 21:15:18.708220 16213 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:15:19.820847 16213 solver.cpp:243] Iteration 9100, loss = 0.0960781
I1005 21:15:19.820876 16213 solver.cpp:259]     Train net output #0: error_blob = 0.0960781 (* 1 = 0.0960781 loss)
I1005 21:15:19.820883 16213 solver.cpp:590] Iteration 9100, lr = 0.01
I1005 21:15:22.382868 16213 solver.cpp:243] Iteration 9200, loss = 0.101148
I1005 21:15:22.382905 16213 solver.cpp:259]     Train net output #0: error_blob = 0.101148 (* 1 = 0.101148 loss)
I1005 21:15:22.382910 16213 solver.cpp:590] Iteration 9200, lr = 0.01
I1005 21:15:24.897773 16213 solver.cpp:243] Iteration 9300, loss = 0.0977648
I1005 21:15:24.897804 16213 solver.cpp:259]     Train net output #0: error_blob = 0.0977648 (* 1 = 0.0977648 loss)
I1005 21:15:24.897809 16213 solver.cpp:590] Iteration 9300, lr = 0.01
I1005 21:15:27.416421 16213 solver.cpp:243] Iteration 9400, loss = 0.094534
I1005 21:15:27.417328 16213 solver.cpp:259]     Train net output #0: error_blob = 0.094534 (* 1 = 0.094534 loss)
I1005 21:15:27.417337 16213 solver.cpp:590] Iteration 9400, lr = 0.01
I1005 21:15:29.956058 16213 solver.cpp:243] Iteration 9500, loss = 0.100631
I1005 21:15:29.956097 16213 solver.cpp:259]     Train net output #0: error_blob = 0.100631 (* 1 = 0.100631 loss)
I1005 21:15:29.956104 16213 solver.cpp:590] Iteration 9500, lr = 0.01
I1005 21:15:32.480723 16213 solver.cpp:243] Iteration 9600, loss = 0.100325
I1005 21:15:32.480761 16213 solver.cpp:259]     Train net output #0: error_blob = 0.100325 (* 1 = 0.100325 loss)
I1005 21:15:32.480767 16213 solver.cpp:590] Iteration 9600, lr = 0.01
I1005 21:15:34.970569 16213 solver.cpp:243] Iteration 9700, loss = 0.0943029
I1005 21:15:34.970612 16213 solver.cpp:259]     Train net output #0: error_blob = 0.0943029 (* 1 = 0.0943029 loss)
I1005 21:15:34.970618 16213 solver.cpp:590] Iteration 9700, lr = 0.01
I1005 21:15:37.437089 16213 solver.cpp:243] Iteration 9800, loss = 0.0969444
I1005 21:15:37.437129 16213 solver.cpp:259]     Train net output #0: error_blob = 0.0969444 (* 1 = 0.0969444 loss)
I1005 21:15:37.437134 16213 solver.cpp:590] Iteration 9800, lr = 0.01
I1005 21:15:39.921676 16213 solver.cpp:243] Iteration 9900, loss = 0.102506
I1005 21:15:39.921706 16213 solver.cpp:259]     Train net output #0: error_blob = 0.102506 (* 1 = 0.102506 loss)
I1005 21:15:39.921710 16213 solver.cpp:590] Iteration 9900, lr = 0.01
I1005 21:15:42.388818 16213 solver.cpp:468] Snapshotting to binary proto file _iter_10000.caffemodel
I1005 21:15:42.390574 16213 solver.cpp:753] Snapshotting solver state to binary proto file _iter_10000.solverstate
I1005 21:15:42.414225 16213 solver.cpp:327] Iteration 10000, loss = 0.0958824
I1005 21:15:42.414261 16213 solver.cpp:347] Iteration 10000, Testing net (#0)
I1005 21:15:42.586066 16213 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:15:42.697756 16213 solver.cpp:415]     Test net output #0: error_blob = 0.0878567 (* 1 = 0.0878567 loss)
I1005 21:15:42.697774 16213 solver.cpp:332] Optimization Done.
I1005 21:15:42.697777 16213 caffe.cpp:215] Optimization Done.
I1005 21:15:42.759474 16228 caffe.cpp:184] Using GPUs 0
I1005 21:15:43.320106 16228 solver.cpp:54] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "fixed"
momentum: 0.9
solver_mode: GPU
device_id: 0
net: "large_batch/model0_part6.prototxt"
I1005 21:15:43.320140 16228 solver.cpp:97] Creating training net from net file: large_batch/model0_part6.prototxt
I1005 21:15:43.320302 16228 net.cpp:339] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_layer
I1005 21:15:43.320345 16228 net.cpp:50] Initializing net from parameters: 
name: "large_batch/model0_part6.prototxt"
state {
  phase: TRAIN
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TRAIN
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.part6.train"
    batch_size: 20000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1005 21:15:43.320396 16228 layer_factory.hpp:76] Creating layer data_layer
I1005 21:15:43.333712 16228 net.cpp:110] Creating Layer data_layer
I1005 21:15:43.333734 16228 net.cpp:433] data_layer -> data_blob
I1005 21:15:43.333770 16228 net.cpp:433] data_layer -> label_blob
I1005 21:15:43.334372 16232 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.part6.train
I1005 21:15:44.016049 16228 data_layer.cpp:45] output data size: 20000,61,1,1
I1005 21:15:44.020987 16228 net.cpp:155] Setting up data_layer
I1005 21:15:44.021021 16228 net.cpp:163] Top shape: 20000 61 1 1 (1220000)
I1005 21:15:44.021037 16228 net.cpp:163] Top shape: 20000 (20000)
I1005 21:15:44.021045 16228 layer_factory.hpp:76] Creating layer hidden_sum_layer
I1005 21:15:44.021060 16228 net.cpp:110] Creating Layer hidden_sum_layer
I1005 21:15:44.021070 16228 net.cpp:477] hidden_sum_layer <- data_blob
I1005 21:15:44.021083 16228 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I1005 21:15:44.021430 16228 net.cpp:155] Setting up hidden_sum_layer
I1005 21:15:44.021438 16228 net.cpp:163] Top shape: 20000 10 (200000)
I1005 21:15:44.021464 16228 layer_factory.hpp:76] Creating layer hidden_act_layer
I1005 21:15:44.021477 16228 net.cpp:110] Creating Layer hidden_act_layer
I1005 21:15:44.021482 16228 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I1005 21:15:44.021487 16228 net.cpp:433] hidden_act_layer -> hidden_act_blob
I1005 21:15:47.236225 16228 net.cpp:155] Setting up hidden_act_layer
I1005 21:15:47.236249 16228 net.cpp:163] Top shape: 20000 10 (200000)
I1005 21:15:47.236255 16228 layer_factory.hpp:76] Creating layer output_sum_layer
I1005 21:15:47.236277 16228 net.cpp:110] Creating Layer output_sum_layer
I1005 21:15:47.236282 16228 net.cpp:477] output_sum_layer <- hidden_act_blob
I1005 21:15:47.236289 16228 net.cpp:433] output_sum_layer -> output_sum_blob
I1005 21:15:47.236387 16228 net.cpp:155] Setting up output_sum_layer
I1005 21:15:47.236393 16228 net.cpp:163] Top shape: 20000 1 (20000)
I1005 21:15:47.236413 16228 layer_factory.hpp:76] Creating layer output_act_layer
I1005 21:15:47.236421 16228 net.cpp:110] Creating Layer output_act_layer
I1005 21:15:47.236425 16228 net.cpp:477] output_act_layer <- output_sum_blob
I1005 21:15:47.236430 16228 net.cpp:433] output_act_layer -> output_act_blob
I1005 21:15:47.236513 16228 net.cpp:155] Setting up output_act_layer
I1005 21:15:47.236531 16228 net.cpp:163] Top shape: 20000 1 (20000)
I1005 21:15:47.236538 16228 layer_factory.hpp:76] Creating layer error_layer
I1005 21:15:47.236546 16228 net.cpp:110] Creating Layer error_layer
I1005 21:15:47.236554 16228 net.cpp:477] error_layer <- output_act_blob
I1005 21:15:47.236560 16228 net.cpp:477] error_layer <- label_blob
I1005 21:15:47.236567 16228 net.cpp:433] error_layer -> error_blob
I1005 21:15:47.236599 16228 net.cpp:155] Setting up error_layer
I1005 21:15:47.236605 16228 net.cpp:163] Top shape: (1)
I1005 21:15:47.236608 16228 net.cpp:168]     with loss weight 1
I1005 21:15:47.236629 16228 net.cpp:236] error_layer needs backward computation.
I1005 21:15:47.236634 16228 net.cpp:236] output_act_layer needs backward computation.
I1005 21:15:47.236639 16228 net.cpp:236] output_sum_layer needs backward computation.
I1005 21:15:47.236644 16228 net.cpp:236] hidden_act_layer needs backward computation.
I1005 21:15:47.236647 16228 net.cpp:236] hidden_sum_layer needs backward computation.
I1005 21:15:47.236651 16228 net.cpp:240] data_layer does not need backward computation.
I1005 21:15:47.236654 16228 net.cpp:283] This network produces output error_blob
I1005 21:15:47.236662 16228 net.cpp:297] Network initialization done.
I1005 21:15:47.236666 16228 net.cpp:298] Memory required for data: 6720004
I1005 21:15:47.236799 16228 solver.cpp:187] Creating test net (#0) specified by net file: large_batch/model0_part6.prototxt
I1005 21:15:47.236816 16228 net.cpp:339] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_layer
I1005 21:15:47.236855 16228 net.cpp:50] Initializing net from parameters: 
name: "large_batch/model0_part6.prototxt"
state {
  phase: TEST
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TEST
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.part6.test"
    batch_size: 2000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1005 21:15:47.236886 16228 layer_factory.hpp:76] Creating layer data_layer
I1005 21:15:47.238226 16228 net.cpp:110] Creating Layer data_layer
I1005 21:15:47.238234 16228 net.cpp:433] data_layer -> data_blob
I1005 21:15:47.238241 16228 net.cpp:433] data_layer -> label_blob
I1005 21:15:47.238776 16234 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.part6.test
I1005 21:15:47.238842 16228 data_layer.cpp:45] output data size: 2000,61,1,1
I1005 21:15:47.240314 16228 net.cpp:155] Setting up data_layer
I1005 21:15:47.240330 16228 net.cpp:163] Top shape: 2000 61 1 1 (122000)
I1005 21:15:47.240335 16228 net.cpp:163] Top shape: 2000 (2000)
I1005 21:15:47.240341 16228 layer_factory.hpp:76] Creating layer hidden_sum_layer
I1005 21:15:47.240352 16228 net.cpp:110] Creating Layer hidden_sum_layer
I1005 21:15:47.240356 16228 net.cpp:477] hidden_sum_layer <- data_blob
I1005 21:15:47.240365 16228 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I1005 21:15:47.240474 16228 net.cpp:155] Setting up hidden_sum_layer
I1005 21:15:47.240483 16228 net.cpp:163] Top shape: 2000 10 (20000)
I1005 21:15:47.240511 16228 layer_factory.hpp:76] Creating layer hidden_act_layer
I1005 21:15:47.240521 16228 net.cpp:110] Creating Layer hidden_act_layer
I1005 21:15:47.240526 16228 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I1005 21:15:47.240543 16228 net.cpp:433] hidden_act_layer -> hidden_act_blob
I1005 21:15:47.240726 16228 net.cpp:155] Setting up hidden_act_layer
I1005 21:15:47.240734 16228 net.cpp:163] Top shape: 2000 10 (20000)
I1005 21:15:47.240739 16228 layer_factory.hpp:76] Creating layer output_sum_layer
I1005 21:15:47.240746 16228 net.cpp:110] Creating Layer output_sum_layer
I1005 21:15:47.240749 16228 net.cpp:477] output_sum_layer <- hidden_act_blob
I1005 21:15:47.240756 16228 net.cpp:433] output_sum_layer -> output_sum_blob
I1005 21:15:47.240823 16228 net.cpp:155] Setting up output_sum_layer
I1005 21:15:47.240830 16228 net.cpp:163] Top shape: 2000 1 (2000)
I1005 21:15:47.240839 16228 layer_factory.hpp:76] Creating layer output_act_layer
I1005 21:15:47.240845 16228 net.cpp:110] Creating Layer output_act_layer
I1005 21:15:47.240850 16228 net.cpp:477] output_act_layer <- output_sum_blob
I1005 21:15:47.240857 16228 net.cpp:433] output_act_layer -> output_act_blob
I1005 21:15:47.240911 16228 net.cpp:155] Setting up output_act_layer
I1005 21:15:47.240917 16228 net.cpp:163] Top shape: 2000 1 (2000)
I1005 21:15:47.240921 16228 layer_factory.hpp:76] Creating layer error_layer
I1005 21:15:47.240926 16228 net.cpp:110] Creating Layer error_layer
I1005 21:15:47.240932 16228 net.cpp:477] error_layer <- output_act_blob
I1005 21:15:47.240937 16228 net.cpp:477] error_layer <- label_blob
I1005 21:15:47.240943 16228 net.cpp:433] error_layer -> error_blob
I1005 21:15:47.240968 16228 net.cpp:155] Setting up error_layer
I1005 21:15:47.240973 16228 net.cpp:163] Top shape: (1)
I1005 21:15:47.240978 16228 net.cpp:168]     with loss weight 1
I1005 21:15:47.240990 16228 net.cpp:236] error_layer needs backward computation.
I1005 21:15:47.240996 16228 net.cpp:236] output_act_layer needs backward computation.
I1005 21:15:47.240999 16228 net.cpp:236] output_sum_layer needs backward computation.
I1005 21:15:47.241003 16228 net.cpp:236] hidden_act_layer needs backward computation.
I1005 21:15:47.241008 16228 net.cpp:236] hidden_sum_layer needs backward computation.
I1005 21:15:47.241013 16228 net.cpp:240] data_layer does not need backward computation.
I1005 21:15:47.241015 16228 net.cpp:283] This network produces output error_blob
I1005 21:15:47.241022 16228 net.cpp:297] Network initialization done.
I1005 21:15:47.241026 16228 net.cpp:298] Memory required for data: 672004
I1005 21:15:47.241050 16228 solver.cpp:66] Solver scaffolding done.
I1005 21:15:47.241150 16228 caffe.cpp:212] Starting Optimization
I1005 21:15:47.241158 16228 solver.cpp:294] Solving large_batch/model0_part6.prototxt
I1005 21:15:47.241161 16228 solver.cpp:295] Learning Rate Policy: fixed
I1005 21:15:47.241322 16228 solver.cpp:347] Iteration 0, Testing net (#0)
I1005 21:15:47.241417 16228 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:15:47.514792 16228 solver.cpp:415]     Test net output #0: error_blob = 0.139928 (* 1 = 0.139928 loss)
I1005 21:15:47.516068 16228 solver.cpp:243] Iteration 0, loss = 0.13293
I1005 21:15:47.516083 16228 solver.cpp:259]     Train net output #0: error_blob = 0.13293 (* 1 = 0.13293 loss)
I1005 21:15:47.516095 16228 solver.cpp:590] Iteration 0, lr = 0.01
I1005 21:15:49.971707 16228 solver.cpp:243] Iteration 100, loss = 0.117754
I1005 21:15:49.971740 16228 solver.cpp:259]     Train net output #0: error_blob = 0.117754 (* 1 = 0.117754 loss)
I1005 21:15:49.971746 16228 solver.cpp:590] Iteration 100, lr = 0.01
I1005 21:15:52.459362 16228 solver.cpp:243] Iteration 200, loss = 0.11393
I1005 21:15:52.459399 16228 solver.cpp:259]     Train net output #0: error_blob = 0.11393 (* 1 = 0.11393 loss)
I1005 21:15:52.459408 16228 solver.cpp:590] Iteration 200, lr = 0.01
I1005 21:15:54.915019 16228 solver.cpp:243] Iteration 300, loss = 0.11444
I1005 21:15:54.915056 16228 solver.cpp:259]     Train net output #0: error_blob = 0.11444 (* 1 = 0.11444 loss)
I1005 21:15:54.915065 16228 solver.cpp:590] Iteration 300, lr = 0.01
I1005 21:15:57.401020 16228 solver.cpp:243] Iteration 400, loss = 0.113543
I1005 21:15:57.401062 16228 solver.cpp:259]     Train net output #0: error_blob = 0.113543 (* 1 = 0.113543 loss)
I1005 21:15:57.401089 16228 solver.cpp:590] Iteration 400, lr = 0.01
I1005 21:15:59.860618 16228 solver.cpp:243] Iteration 500, loss = 0.11153
I1005 21:15:59.860658 16228 solver.cpp:259]     Train net output #0: error_blob = 0.11153 (* 1 = 0.11153 loss)
I1005 21:15:59.860666 16228 solver.cpp:590] Iteration 500, lr = 0.01
I1005 21:16:02.329231 16228 solver.cpp:243] Iteration 600, loss = 0.108347
I1005 21:16:02.329259 16228 solver.cpp:259]     Train net output #0: error_blob = 0.108347 (* 1 = 0.108347 loss)
I1005 21:16:02.329264 16228 solver.cpp:590] Iteration 600, lr = 0.01
I1005 21:16:04.773020 16228 solver.cpp:243] Iteration 700, loss = 0.109338
I1005 21:16:04.773067 16228 solver.cpp:259]     Train net output #0: error_blob = 0.109338 (* 1 = 0.109338 loss)
I1005 21:16:04.773074 16228 solver.cpp:590] Iteration 700, lr = 0.01
I1005 21:16:07.245954 16228 solver.cpp:243] Iteration 800, loss = 0.109647
I1005 21:16:07.245981 16228 solver.cpp:259]     Train net output #0: error_blob = 0.109647 (* 1 = 0.109647 loss)
I1005 21:16:07.245986 16228 solver.cpp:590] Iteration 800, lr = 0.01
I1005 21:16:09.705137 16228 solver.cpp:243] Iteration 900, loss = 0.108995
I1005 21:16:09.705178 16228 solver.cpp:259]     Train net output #0: error_blob = 0.108995 (* 1 = 0.108995 loss)
I1005 21:16:09.705184 16228 solver.cpp:590] Iteration 900, lr = 0.01
I1005 21:16:09.753342 16228 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:16:12.133923 16228 solver.cpp:347] Iteration 1000, Testing net (#0)
I1005 21:16:12.467820 16228 solver.cpp:415]     Test net output #0: error_blob = 0.111115 (* 1 = 0.111115 loss)
I1005 21:16:12.468497 16228 solver.cpp:243] Iteration 1000, loss = 0.105149
I1005 21:16:12.468513 16228 solver.cpp:259]     Train net output #0: error_blob = 0.105149 (* 1 = 0.105149 loss)
I1005 21:16:12.468523 16228 solver.cpp:590] Iteration 1000, lr = 0.01
I1005 21:16:14.890708 16228 solver.cpp:243] Iteration 1100, loss = 0.105946
I1005 21:16:14.890775 16228 solver.cpp:259]     Train net output #0: error_blob = 0.105946 (* 1 = 0.105946 loss)
I1005 21:16:14.890784 16228 solver.cpp:590] Iteration 1100, lr = 0.01
I1005 21:16:17.320212 16228 solver.cpp:243] Iteration 1200, loss = 0.10834
I1005 21:16:17.320250 16228 solver.cpp:259]     Train net output #0: error_blob = 0.10834 (* 1 = 0.10834 loss)
I1005 21:16:17.320258 16228 solver.cpp:590] Iteration 1200, lr = 0.01
I1005 21:16:19.785516 16228 solver.cpp:243] Iteration 1300, loss = 0.108257
I1005 21:16:19.785544 16228 solver.cpp:259]     Train net output #0: error_blob = 0.108257 (* 1 = 0.108257 loss)
I1005 21:16:19.785549 16228 solver.cpp:590] Iteration 1300, lr = 0.01
I1005 21:16:22.239660 16228 solver.cpp:243] Iteration 1400, loss = 0.103052
I1005 21:16:22.239701 16228 solver.cpp:259]     Train net output #0: error_blob = 0.103052 (* 1 = 0.103052 loss)
I1005 21:16:22.239707 16228 solver.cpp:590] Iteration 1400, lr = 0.01
I1005 21:16:24.725653 16228 solver.cpp:243] Iteration 1500, loss = 0.102644
I1005 21:16:24.725698 16228 solver.cpp:259]     Train net output #0: error_blob = 0.102644 (* 1 = 0.102644 loss)
I1005 21:16:24.725706 16228 solver.cpp:590] Iteration 1500, lr = 0.01
I1005 21:16:27.215690 16228 solver.cpp:243] Iteration 1600, loss = 0.10595
I1005 21:16:27.215728 16228 solver.cpp:259]     Train net output #0: error_blob = 0.10595 (* 1 = 0.10595 loss)
I1005 21:16:27.215734 16228 solver.cpp:590] Iteration 1600, lr = 0.01
I1005 21:16:29.681056 16228 solver.cpp:243] Iteration 1700, loss = 0.105929
I1005 21:16:29.681102 16228 solver.cpp:259]     Train net output #0: error_blob = 0.105929 (* 1 = 0.105929 loss)
I1005 21:16:29.681109 16228 solver.cpp:590] Iteration 1700, lr = 0.01
I1005 21:16:32.157410 16228 solver.cpp:243] Iteration 1800, loss = 0.102632
I1005 21:16:32.157459 16228 solver.cpp:259]     Train net output #0: error_blob = 0.102632 (* 1 = 0.102632 loss)
I1005 21:16:32.157467 16228 solver.cpp:590] Iteration 1800, lr = 0.01
I1005 21:16:32.350422 16228 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:16:34.624389 16228 solver.cpp:243] Iteration 1900, loss = 0.100749
I1005 21:16:34.624430 16228 solver.cpp:259]     Train net output #0: error_blob = 0.100749 (* 1 = 0.100749 loss)
I1005 21:16:34.624436 16228 solver.cpp:590] Iteration 1900, lr = 0.01
I1005 21:16:37.043084 16228 solver.cpp:347] Iteration 2000, Testing net (#0)
I1005 21:16:37.323493 16228 solver.cpp:415]     Test net output #0: error_blob = 0.106761 (* 1 = 0.106761 loss)
I1005 21:16:37.324148 16228 solver.cpp:243] Iteration 2000, loss = 0.103446
I1005 21:16:37.324183 16228 solver.cpp:259]     Train net output #0: error_blob = 0.103446 (* 1 = 0.103446 loss)
I1005 21:16:37.324194 16228 solver.cpp:590] Iteration 2000, lr = 0.01
I1005 21:16:39.766432 16228 solver.cpp:243] Iteration 2100, loss = 0.106708
I1005 21:16:39.766461 16228 solver.cpp:259]     Train net output #0: error_blob = 0.106708 (* 1 = 0.106708 loss)
I1005 21:16:39.766466 16228 solver.cpp:590] Iteration 2100, lr = 0.01
I1005 21:16:42.241377 16228 solver.cpp:243] Iteration 2200, loss = 0.103554
I1005 21:16:42.241415 16228 solver.cpp:259]     Train net output #0: error_blob = 0.103554 (* 1 = 0.103554 loss)
I1005 21:16:42.241422 16228 solver.cpp:590] Iteration 2200, lr = 0.01
I1005 21:16:44.696715 16228 solver.cpp:243] Iteration 2300, loss = 0.0993914
I1005 21:16:44.696746 16228 solver.cpp:259]     Train net output #0: error_blob = 0.0993914 (* 1 = 0.0993914 loss)
I1005 21:16:44.696751 16228 solver.cpp:590] Iteration 2300, lr = 0.01
I1005 21:16:47.154775 16228 solver.cpp:243] Iteration 2400, loss = 0.101007
I1005 21:16:47.154940 16228 solver.cpp:259]     Train net output #0: error_blob = 0.101007 (* 1 = 0.101007 loss)
I1005 21:16:47.154949 16228 solver.cpp:590] Iteration 2400, lr = 0.01
I1005 21:16:49.640661 16228 solver.cpp:243] Iteration 2500, loss = 0.102983
I1005 21:16:49.640697 16228 solver.cpp:259]     Train net output #0: error_blob = 0.102983 (* 1 = 0.102983 loss)
I1005 21:16:49.640704 16228 solver.cpp:590] Iteration 2500, lr = 0.01
I1005 21:16:52.126657 16228 solver.cpp:243] Iteration 2600, loss = 0.103695
I1005 21:16:52.126691 16228 solver.cpp:259]     Train net output #0: error_blob = 0.103695 (* 1 = 0.103695 loss)
I1005 21:16:52.126699 16228 solver.cpp:590] Iteration 2600, lr = 0.01
I1005 21:16:54.607622 16228 solver.cpp:243] Iteration 2700, loss = 0.0991306
I1005 21:16:54.607658 16228 solver.cpp:259]     Train net output #0: error_blob = 0.0991306 (* 1 = 0.0991306 loss)
I1005 21:16:54.607664 16228 solver.cpp:590] Iteration 2700, lr = 0.01
I1005 21:16:54.952976 16228 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:16:57.121991 16228 solver.cpp:243] Iteration 2800, loss = 0.0992652
I1005 21:16:57.122028 16228 solver.cpp:259]     Train net output #0: error_blob = 0.0992652 (* 1 = 0.0992652 loss)
I1005 21:16:57.122037 16228 solver.cpp:590] Iteration 2800, lr = 0.01
I1005 21:16:59.557126 16228 solver.cpp:243] Iteration 2900, loss = 0.104181
I1005 21:16:59.557164 16228 solver.cpp:259]     Train net output #0: error_blob = 0.104181 (* 1 = 0.104181 loss)
I1005 21:16:59.557171 16228 solver.cpp:590] Iteration 2900, lr = 0.01
I1005 21:17:02.009668 16228 solver.cpp:347] Iteration 3000, Testing net (#0)
I1005 21:17:02.292067 16228 solver.cpp:415]     Test net output #0: error_blob = 0.104637 (* 1 = 0.104637 loss)
I1005 21:17:02.292745 16228 solver.cpp:243] Iteration 3000, loss = 0.10357
I1005 21:17:02.292760 16228 solver.cpp:259]     Train net output #0: error_blob = 0.10357 (* 1 = 0.10357 loss)
I1005 21:17:02.292767 16228 solver.cpp:590] Iteration 3000, lr = 0.01
I1005 21:17:04.727411 16228 solver.cpp:243] Iteration 3100, loss = 0.0988283
I1005 21:17:04.727459 16228 solver.cpp:259]     Train net output #0: error_blob = 0.0988283 (* 1 = 0.0988283 loss)
I1005 21:17:04.727468 16228 solver.cpp:590] Iteration 3100, lr = 0.01
I1005 21:17:07.228662 16228 solver.cpp:243] Iteration 3200, loss = 0.0986397
I1005 21:17:07.228693 16228 solver.cpp:259]     Train net output #0: error_blob = 0.0986397 (* 1 = 0.0986397 loss)
I1005 21:17:07.228698 16228 solver.cpp:590] Iteration 3200, lr = 0.01
I1005 21:17:09.703567 16228 solver.cpp:243] Iteration 3300, loss = 0.103088
I1005 21:17:09.703608 16228 solver.cpp:259]     Train net output #0: error_blob = 0.103088 (* 1 = 0.103088 loss)
I1005 21:17:09.703613 16228 solver.cpp:590] Iteration 3300, lr = 0.01
I1005 21:17:12.170423 16228 solver.cpp:243] Iteration 3400, loss = 0.103178
I1005 21:17:12.170459 16228 solver.cpp:259]     Train net output #0: error_blob = 0.103178 (* 1 = 0.103178 loss)
I1005 21:17:12.170467 16228 solver.cpp:590] Iteration 3400, lr = 0.01
I1005 21:17:14.634655 16228 solver.cpp:243] Iteration 3500, loss = 0.0996171
I1005 21:17:14.634701 16228 solver.cpp:259]     Train net output #0: error_blob = 0.0996171 (* 1 = 0.0996171 loss)
I1005 21:17:14.634708 16228 solver.cpp:590] Iteration 3500, lr = 0.01
I1005 21:17:17.098559 16228 solver.cpp:243] Iteration 3600, loss = 0.0963288
I1005 21:17:17.098604 16228 solver.cpp:259]     Train net output #0: error_blob = 0.0963288 (* 1 = 0.0963288 loss)
I1005 21:17:17.098611 16228 solver.cpp:590] Iteration 3600, lr = 0.01
I1005 21:17:17.593823 16228 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:17:19.556038 16228 solver.cpp:243] Iteration 3700, loss = 0.0996068
I1005 21:17:19.556071 16228 solver.cpp:259]     Train net output #0: error_blob = 0.0996068 (* 1 = 0.0996068 loss)
I1005 21:17:19.556076 16228 solver.cpp:590] Iteration 3700, lr = 0.01
I1005 21:17:22.038589 16228 solver.cpp:243] Iteration 3800, loss = 0.104136
I1005 21:17:22.038626 16228 solver.cpp:259]     Train net output #0: error_blob = 0.104136 (* 1 = 0.104136 loss)
I1005 21:17:22.038635 16228 solver.cpp:590] Iteration 3800, lr = 0.01
I1005 21:17:24.514470 16228 solver.cpp:243] Iteration 3900, loss = 0.101735
I1005 21:17:24.514511 16228 solver.cpp:259]     Train net output #0: error_blob = 0.101735 (* 1 = 0.101735 loss)
I1005 21:17:24.514516 16228 solver.cpp:590] Iteration 3900, lr = 0.01
I1005 21:17:26.983175 16228 solver.cpp:347] Iteration 4000, Testing net (#0)
I1005 21:17:27.261904 16228 solver.cpp:415]     Test net output #0: error_blob = 0.103674 (* 1 = 0.103674 loss)
I1005 21:17:27.262619 16228 solver.cpp:243] Iteration 4000, loss = 0.0966944
I1005 21:17:27.262635 16228 solver.cpp:259]     Train net output #0: error_blob = 0.0966944 (* 1 = 0.0966944 loss)
I1005 21:17:27.262641 16228 solver.cpp:590] Iteration 4000, lr = 0.01
I1005 21:17:29.682581 16228 solver.cpp:243] Iteration 4100, loss = 0.0979669
I1005 21:17:29.682615 16228 solver.cpp:259]     Train net output #0: error_blob = 0.0979669 (* 1 = 0.0979669 loss)
I1005 21:17:29.682621 16228 solver.cpp:590] Iteration 4100, lr = 0.01
I1005 21:17:32.140353 16228 solver.cpp:243] Iteration 4200, loss = 0.101041
I1005 21:17:32.140384 16228 solver.cpp:259]     Train net output #0: error_blob = 0.101041 (* 1 = 0.101041 loss)
I1005 21:17:32.140389 16228 solver.cpp:590] Iteration 4200, lr = 0.01
I1005 21:17:34.593940 16228 solver.cpp:243] Iteration 4300, loss = 0.102239
I1005 21:17:34.593971 16228 solver.cpp:259]     Train net output #0: error_blob = 0.102239 (* 1 = 0.102239 loss)
I1005 21:17:34.593976 16228 solver.cpp:590] Iteration 4300, lr = 0.01
I1005 21:17:37.041363 16228 solver.cpp:243] Iteration 4400, loss = 0.0964876
I1005 21:17:37.041396 16228 solver.cpp:259]     Train net output #0: error_blob = 0.0964876 (* 1 = 0.0964876 loss)
I1005 21:17:37.041404 16228 solver.cpp:590] Iteration 4400, lr = 0.01
I1005 21:17:39.503233 16228 solver.cpp:243] Iteration 4500, loss = 0.0964362
I1005 21:17:39.503264 16228 solver.cpp:259]     Train net output #0: error_blob = 0.0964362 (* 1 = 0.0964362 loss)
I1005 21:17:39.503269 16228 solver.cpp:590] Iteration 4500, lr = 0.01
I1005 21:17:40.142897 16228 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:17:41.949870 16228 solver.cpp:243] Iteration 4600, loss = 0.101786
I1005 21:17:41.949901 16228 solver.cpp:259]     Train net output #0: error_blob = 0.101786 (* 1 = 0.101786 loss)
I1005 21:17:41.949906 16228 solver.cpp:590] Iteration 4600, lr = 0.01
I1005 21:17:44.401418 16228 solver.cpp:243] Iteration 4700, loss = 0.102391
I1005 21:17:44.401450 16228 solver.cpp:259]     Train net output #0: error_blob = 0.102391 (* 1 = 0.102391 loss)
I1005 21:17:44.401455 16228 solver.cpp:590] Iteration 4700, lr = 0.01
I1005 21:17:46.838340 16228 solver.cpp:243] Iteration 4800, loss = 0.0968195
I1005 21:17:46.838382 16228 solver.cpp:259]     Train net output #0: error_blob = 0.0968195 (* 1 = 0.0968195 loss)
I1005 21:17:46.838387 16228 solver.cpp:590] Iteration 4800, lr = 0.01
I1005 21:17:49.277101 16228 solver.cpp:243] Iteration 4900, loss = 0.0969047
I1005 21:17:49.277230 16228 solver.cpp:259]     Train net output #0: error_blob = 0.0969047 (* 1 = 0.0969047 loss)
I1005 21:17:49.277248 16228 solver.cpp:590] Iteration 4900, lr = 0.01
I1005 21:17:51.695858 16228 solver.cpp:347] Iteration 5000, Testing net (#0)
I1005 21:17:51.966338 16228 solver.cpp:415]     Test net output #0: error_blob = 0.103189 (* 1 = 0.103189 loss)
I1005 21:17:51.966948 16228 solver.cpp:243] Iteration 5000, loss = 0.102308
I1005 21:17:51.966958 16228 solver.cpp:259]     Train net output #0: error_blob = 0.102308 (* 1 = 0.102308 loss)
I1005 21:17:51.966963 16228 solver.cpp:590] Iteration 5000, lr = 0.01
I1005 21:17:54.347528 16228 solver.cpp:243] Iteration 5100, loss = 0.102769
I1005 21:17:54.347569 16228 solver.cpp:259]     Train net output #0: error_blob = 0.102769 (* 1 = 0.102769 loss)
I1005 21:17:54.347574 16228 solver.cpp:590] Iteration 5100, lr = 0.01
I1005 21:17:56.787020 16228 solver.cpp:243] Iteration 5200, loss = 0.0977902
I1005 21:17:56.787052 16228 solver.cpp:259]     Train net output #0: error_blob = 0.0977902 (* 1 = 0.0977902 loss)
I1005 21:17:56.787057 16228 solver.cpp:590] Iteration 5200, lr = 0.01
I1005 21:17:59.238047 16228 solver.cpp:243] Iteration 5300, loss = 0.0948679
I1005 21:17:59.238090 16228 solver.cpp:259]     Train net output #0: error_blob = 0.0948679 (* 1 = 0.0948679 loss)
I1005 21:17:59.238095 16228 solver.cpp:590] Iteration 5300, lr = 0.01
I1005 21:18:01.696311 16228 solver.cpp:243] Iteration 5400, loss = 0.0983774
I1005 21:18:01.696352 16228 solver.cpp:259]     Train net output #0: error_blob = 0.0983774 (* 1 = 0.0983774 loss)
I1005 21:18:01.696357 16228 solver.cpp:590] Iteration 5400, lr = 0.01
I1005 21:18:02.466660 16228 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:18:04.150089 16228 solver.cpp:243] Iteration 5500, loss = 0.10326
I1005 21:18:04.150120 16228 solver.cpp:259]     Train net output #0: error_blob = 0.10326 (* 1 = 0.10326 loss)
I1005 21:18:04.150125 16228 solver.cpp:590] Iteration 5500, lr = 0.01
I1005 21:18:06.579934 16228 solver.cpp:243] Iteration 5600, loss = 0.100192
I1005 21:18:06.579965 16228 solver.cpp:259]     Train net output #0: error_blob = 0.100192 (* 1 = 0.100192 loss)
I1005 21:18:06.579970 16228 solver.cpp:590] Iteration 5600, lr = 0.01
I1005 21:18:09.008262 16228 solver.cpp:243] Iteration 5700, loss = 0.0945923
I1005 21:18:09.008306 16228 solver.cpp:259]     Train net output #0: error_blob = 0.0945923 (* 1 = 0.0945923 loss)
I1005 21:18:09.008311 16228 solver.cpp:590] Iteration 5700, lr = 0.01
I1005 21:18:11.453974 16228 solver.cpp:243] Iteration 5800, loss = 0.0970004
I1005 21:18:11.454005 16228 solver.cpp:259]     Train net output #0: error_blob = 0.0970004 (* 1 = 0.0970004 loss)
I1005 21:18:11.454011 16228 solver.cpp:590] Iteration 5800, lr = 0.01
I1005 21:18:13.915665 16228 solver.cpp:243] Iteration 5900, loss = 0.100196
I1005 21:18:13.915699 16228 solver.cpp:259]     Train net output #0: error_blob = 0.100196 (* 1 = 0.100196 loss)
I1005 21:18:13.915706 16228 solver.cpp:590] Iteration 5900, lr = 0.01
I1005 21:18:16.335155 16228 solver.cpp:347] Iteration 6000, Testing net (#0)
I1005 21:18:16.618443 16228 solver.cpp:415]     Test net output #0: error_blob = 0.102626 (* 1 = 0.102626 loss)
I1005 21:18:16.619051 16228 solver.cpp:243] Iteration 6000, loss = 0.100545
I1005 21:18:16.619062 16228 solver.cpp:259]     Train net output #0: error_blob = 0.100545 (* 1 = 0.100545 loss)
I1005 21:18:16.619066 16228 solver.cpp:590] Iteration 6000, lr = 0.01
I1005 21:18:19.023540 16228 solver.cpp:243] Iteration 6100, loss = 0.0940525
I1005 21:18:19.023571 16228 solver.cpp:259]     Train net output #0: error_blob = 0.0940525 (* 1 = 0.0940525 loss)
I1005 21:18:19.023576 16228 solver.cpp:590] Iteration 6100, lr = 0.01
I1005 21:18:21.472388 16228 solver.cpp:243] Iteration 6200, loss = 0.0945048
I1005 21:18:21.472506 16228 solver.cpp:259]     Train net output #0: error_blob = 0.0945048 (* 1 = 0.0945048 loss)
I1005 21:18:21.472515 16228 solver.cpp:590] Iteration 6200, lr = 0.01
I1005 21:18:23.960921 16228 solver.cpp:243] Iteration 6300, loss = 0.100674
I1005 21:18:23.960952 16228 solver.cpp:259]     Train net output #0: error_blob = 0.100674 (* 1 = 0.100674 loss)
I1005 21:18:23.960957 16228 solver.cpp:590] Iteration 6300, lr = 0.01
I1005 21:18:24.906750 16228 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:18:26.439218 16228 solver.cpp:243] Iteration 6400, loss = 0.101174
I1005 21:18:26.439260 16228 solver.cpp:259]     Train net output #0: error_blob = 0.101174 (* 1 = 0.101174 loss)
I1005 21:18:26.439265 16228 solver.cpp:590] Iteration 6400, lr = 0.01
I1005 21:18:28.905977 16228 solver.cpp:243] Iteration 6500, loss = 0.0938646
I1005 21:18:28.906010 16228 solver.cpp:259]     Train net output #0: error_blob = 0.0938646 (* 1 = 0.0938646 loss)
I1005 21:18:28.906015 16228 solver.cpp:590] Iteration 6500, lr = 0.01
I1005 21:18:31.330065 16228 solver.cpp:243] Iteration 6600, loss = 0.0953036
I1005 21:18:31.330106 16228 solver.cpp:259]     Train net output #0: error_blob = 0.0953036 (* 1 = 0.0953036 loss)
I1005 21:18:31.330111 16228 solver.cpp:590] Iteration 6600, lr = 0.01
I1005 21:18:33.798614 16228 solver.cpp:243] Iteration 6700, loss = 0.100669
I1005 21:18:33.798646 16228 solver.cpp:259]     Train net output #0: error_blob = 0.100669 (* 1 = 0.100669 loss)
I1005 21:18:33.798650 16228 solver.cpp:590] Iteration 6700, lr = 0.01
I1005 21:18:36.222574 16228 solver.cpp:243] Iteration 6800, loss = 0.10259
I1005 21:18:36.222605 16228 solver.cpp:259]     Train net output #0: error_blob = 0.10259 (* 1 = 0.10259 loss)
I1005 21:18:36.222610 16228 solver.cpp:590] Iteration 6800, lr = 0.01
I1005 21:18:38.655725 16228 solver.cpp:243] Iteration 6900, loss = 0.0965293
I1005 21:18:38.655756 16228 solver.cpp:259]     Train net output #0: error_blob = 0.0965293 (* 1 = 0.0965293 loss)
I1005 21:18:38.655762 16228 solver.cpp:590] Iteration 6900, lr = 0.01
I1005 21:18:41.079838 16228 solver.cpp:347] Iteration 7000, Testing net (#0)
I1005 21:18:41.423209 16228 solver.cpp:415]     Test net output #0: error_blob = 0.10215 (* 1 = 0.10215 loss)
I1005 21:18:41.423874 16228 solver.cpp:243] Iteration 7000, loss = 0.0939735
I1005 21:18:41.423888 16228 solver.cpp:259]     Train net output #0: error_blob = 0.0939735 (* 1 = 0.0939735 loss)
I1005 21:18:41.423894 16228 solver.cpp:590] Iteration 7000, lr = 0.01
I1005 21:18:43.847069 16228 solver.cpp:243] Iteration 7100, loss = 0.0972977
I1005 21:18:43.847102 16228 solver.cpp:259]     Train net output #0: error_blob = 0.0972977 (* 1 = 0.0972977 loss)
I1005 21:18:43.847110 16228 solver.cpp:590] Iteration 7100, lr = 0.01
I1005 21:18:46.318709 16228 solver.cpp:243] Iteration 7200, loss = 0.102171
I1005 21:18:46.318742 16228 solver.cpp:259]     Train net output #0: error_blob = 0.102171 (* 1 = 0.102171 loss)
I1005 21:18:46.318747 16228 solver.cpp:590] Iteration 7200, lr = 0.01
I1005 21:18:47.396021 16228 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:18:48.747469 16228 solver.cpp:243] Iteration 7300, loss = 0.0988108
I1005 21:18:48.747503 16228 solver.cpp:259]     Train net output #0: error_blob = 0.0988108 (* 1 = 0.0988108 loss)
I1005 21:18:48.747509 16228 solver.cpp:590] Iteration 7300, lr = 0.01
I1005 21:18:51.183604 16228 solver.cpp:243] Iteration 7400, loss = 0.0931817
I1005 21:18:51.183639 16228 solver.cpp:259]     Train net output #0: error_blob = 0.0931817 (* 1 = 0.0931817 loss)
I1005 21:18:51.183645 16228 solver.cpp:590] Iteration 7400, lr = 0.01
I1005 21:18:53.607655 16228 solver.cpp:243] Iteration 7500, loss = 0.0957166
I1005 21:18:53.607771 16228 solver.cpp:259]     Train net output #0: error_blob = 0.0957166 (* 1 = 0.0957166 loss)
I1005 21:18:53.607776 16228 solver.cpp:590] Iteration 7500, lr = 0.01
I1005 21:18:56.054669 16228 solver.cpp:243] Iteration 7600, loss = 0.0993478
I1005 21:18:56.054699 16228 solver.cpp:259]     Train net output #0: error_blob = 0.0993478 (* 1 = 0.0993478 loss)
I1005 21:18:56.054705 16228 solver.cpp:590] Iteration 7600, lr = 0.01
I1005 21:18:58.502537 16228 solver.cpp:243] Iteration 7700, loss = 0.100121
I1005 21:18:58.502568 16228 solver.cpp:259]     Train net output #0: error_blob = 0.100121 (* 1 = 0.100121 loss)
I1005 21:18:58.502573 16228 solver.cpp:590] Iteration 7700, lr = 0.01
I1005 21:19:00.936790 16228 solver.cpp:243] Iteration 7800, loss = 0.0927672
I1005 21:19:00.936821 16228 solver.cpp:259]     Train net output #0: error_blob = 0.0927672 (* 1 = 0.0927672 loss)
I1005 21:19:00.936826 16228 solver.cpp:590] Iteration 7800, lr = 0.01
I1005 21:19:03.400583 16228 solver.cpp:243] Iteration 7900, loss = 0.09365
I1005 21:19:03.400612 16228 solver.cpp:259]     Train net output #0: error_blob = 0.09365 (* 1 = 0.09365 loss)
I1005 21:19:03.400617 16228 solver.cpp:590] Iteration 7900, lr = 0.01
I1005 21:19:05.815129 16228 solver.cpp:347] Iteration 8000, Testing net (#0)
I1005 21:19:06.087368 16228 solver.cpp:415]     Test net output #0: error_blob = 0.101745 (* 1 = 0.101745 loss)
I1005 21:19:06.087972 16228 solver.cpp:243] Iteration 8000, loss = 0.098829
I1005 21:19:06.087983 16228 solver.cpp:259]     Train net output #0: error_blob = 0.098829 (* 1 = 0.098829 loss)
I1005 21:19:06.087987 16228 solver.cpp:590] Iteration 8000, lr = 0.01
I1005 21:19:08.487360 16228 solver.cpp:243] Iteration 8100, loss = 0.100416
I1005 21:19:08.487393 16228 solver.cpp:259]     Train net output #0: error_blob = 0.100416 (* 1 = 0.100416 loss)
I1005 21:19:08.487401 16228 solver.cpp:590] Iteration 8100, lr = 0.01
I1005 21:19:09.719018 16228 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:19:10.959290 16228 solver.cpp:243] Iteration 8200, loss = 0.0928109
I1005 21:19:10.959331 16228 solver.cpp:259]     Train net output #0: error_blob = 0.0928109 (* 1 = 0.0928109 loss)
I1005 21:19:10.959336 16228 solver.cpp:590] Iteration 8200, lr = 0.01
I1005 21:19:13.387312 16228 solver.cpp:243] Iteration 8300, loss = 0.0932392
I1005 21:19:13.387344 16228 solver.cpp:259]     Train net output #0: error_blob = 0.0932392 (* 1 = 0.0932392 loss)
I1005 21:19:13.387349 16228 solver.cpp:590] Iteration 8300, lr = 0.01
I1005 21:19:15.837561 16228 solver.cpp:243] Iteration 8400, loss = 0.0987561
I1005 21:19:15.837592 16228 solver.cpp:259]     Train net output #0: error_blob = 0.0987561 (* 1 = 0.0987561 loss)
I1005 21:19:15.837597 16228 solver.cpp:590] Iteration 8400, lr = 0.01
I1005 21:19:18.299262 16228 solver.cpp:243] Iteration 8500, loss = 0.100571
I1005 21:19:18.299290 16228 solver.cpp:259]     Train net output #0: error_blob = 0.100571 (* 1 = 0.100571 loss)
I1005 21:19:18.299295 16228 solver.cpp:590] Iteration 8500, lr = 0.01
I1005 21:19:20.752136 16228 solver.cpp:243] Iteration 8600, loss = 0.0954476
I1005 21:19:20.752167 16228 solver.cpp:259]     Train net output #0: error_blob = 0.0954476 (* 1 = 0.0954476 loss)
I1005 21:19:20.752172 16228 solver.cpp:590] Iteration 8600, lr = 0.01
I1005 21:19:23.197705 16228 solver.cpp:243] Iteration 8700, loss = 0.0923371
I1005 21:19:23.197743 16228 solver.cpp:259]     Train net output #0: error_blob = 0.0923371 (* 1 = 0.0923371 loss)
I1005 21:19:23.197749 16228 solver.cpp:590] Iteration 8700, lr = 0.01
I1005 21:19:25.629276 16228 solver.cpp:243] Iteration 8800, loss = 0.0969903
I1005 21:19:25.629343 16228 solver.cpp:259]     Train net output #0: error_blob = 0.0969903 (* 1 = 0.0969903 loss)
I1005 21:19:25.629349 16228 solver.cpp:590] Iteration 8800, lr = 0.01
I1005 21:19:28.031949 16228 solver.cpp:243] Iteration 8900, loss = 0.101201
I1005 21:19:28.031987 16228 solver.cpp:259]     Train net output #0: error_blob = 0.101201 (* 1 = 0.101201 loss)
I1005 21:19:28.031993 16228 solver.cpp:590] Iteration 8900, lr = 0.01
I1005 21:19:30.425521 16228 solver.cpp:347] Iteration 9000, Testing net (#0)
I1005 21:19:30.704380 16228 solver.cpp:415]     Test net output #0: error_blob = 0.101311 (* 1 = 0.101311 loss)
I1005 21:19:30.704988 16228 solver.cpp:243] Iteration 9000, loss = 0.0977229
I1005 21:19:30.705003 16228 solver.cpp:259]     Train net output #0: error_blob = 0.0977229 (* 1 = 0.0977229 loss)
I1005 21:19:30.705008 16228 solver.cpp:590] Iteration 9000, lr = 0.01
I1005 21:19:32.081748 16228 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:19:33.150475 16228 solver.cpp:243] Iteration 9100, loss = 0.0925179
I1005 21:19:33.150506 16228 solver.cpp:259]     Train net output #0: error_blob = 0.0925179 (* 1 = 0.0925179 loss)
I1005 21:19:33.150511 16228 solver.cpp:590] Iteration 9100, lr = 0.01
I1005 21:19:35.622699 16228 solver.cpp:243] Iteration 9200, loss = 0.0946099
I1005 21:19:35.622730 16228 solver.cpp:259]     Train net output #0: error_blob = 0.0946099 (* 1 = 0.0946099 loss)
I1005 21:19:35.622737 16228 solver.cpp:590] Iteration 9200, lr = 0.01
I1005 21:19:38.081133 16228 solver.cpp:243] Iteration 9300, loss = 0.099259
I1005 21:19:38.081164 16228 solver.cpp:259]     Train net output #0: error_blob = 0.099259 (* 1 = 0.099259 loss)
I1005 21:19:38.081171 16228 solver.cpp:590] Iteration 9300, lr = 0.01
I1005 21:19:40.529919 16228 solver.cpp:243] Iteration 9400, loss = 0.0994725
I1005 21:19:40.529953 16228 solver.cpp:259]     Train net output #0: error_blob = 0.0994725 (* 1 = 0.0994725 loss)
I1005 21:19:40.529961 16228 solver.cpp:590] Iteration 9400, lr = 0.01
I1005 21:19:42.994894 16228 solver.cpp:243] Iteration 9500, loss = 0.0926331
I1005 21:19:42.994925 16228 solver.cpp:259]     Train net output #0: error_blob = 0.0926331 (* 1 = 0.0926331 loss)
I1005 21:19:42.994930 16228 solver.cpp:590] Iteration 9500, lr = 0.01
I1005 21:19:45.449162 16228 solver.cpp:243] Iteration 9600, loss = 0.0928878
I1005 21:19:45.449204 16228 solver.cpp:259]     Train net output #0: error_blob = 0.0928878 (* 1 = 0.0928878 loss)
I1005 21:19:45.449209 16228 solver.cpp:590] Iteration 9600, lr = 0.01
I1005 21:19:47.901546 16228 solver.cpp:243] Iteration 9700, loss = 0.0970984
I1005 21:19:47.901587 16228 solver.cpp:259]     Train net output #0: error_blob = 0.0970984 (* 1 = 0.0970984 loss)
I1005 21:19:47.901592 16228 solver.cpp:590] Iteration 9700, lr = 0.01
I1005 21:19:50.356798 16228 solver.cpp:243] Iteration 9800, loss = 0.0997536
I1005 21:19:50.356829 16228 solver.cpp:259]     Train net output #0: error_blob = 0.0997536 (* 1 = 0.0997536 loss)
I1005 21:19:50.356834 16228 solver.cpp:590] Iteration 9800, lr = 0.01
I1005 21:19:52.811895 16228 solver.cpp:243] Iteration 9900, loss = 0.0931289
I1005 21:19:52.811926 16228 solver.cpp:259]     Train net output #0: error_blob = 0.0931289 (* 1 = 0.0931289 loss)
I1005 21:19:52.811931 16228 solver.cpp:590] Iteration 9900, lr = 0.01
I1005 21:19:55.258201 16228 solver.cpp:468] Snapshotting to binary proto file _iter_10000.caffemodel
I1005 21:19:55.259021 16228 solver.cpp:753] Snapshotting solver state to binary proto file _iter_10000.solverstate
I1005 21:19:55.282603 16228 solver.cpp:327] Iteration 10000, loss = 0.0920403
I1005 21:19:55.282630 16228 solver.cpp:347] Iteration 10000, Testing net (#0)
I1005 21:19:55.488469 16228 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:19:55.597976 16228 solver.cpp:415]     Test net output #0: error_blob = 0.100862 (* 1 = 0.100862 loss)
I1005 21:19:55.597995 16228 solver.cpp:332] Optimization Done.
I1005 21:19:55.597998 16228 caffe.cpp:215] Optimization Done.
I1005 21:19:55.669592 16240 caffe.cpp:184] Using GPUs 0
I1005 21:19:56.233191 16240 solver.cpp:54] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "fixed"
momentum: 0.9
solver_mode: GPU
device_id: 0
net: "large_batch/model0_part2.prototxt"
I1005 21:19:56.233222 16240 solver.cpp:97] Creating training net from net file: large_batch/model0_part2.prototxt
I1005 21:19:56.233408 16240 net.cpp:339] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_layer
I1005 21:19:56.233455 16240 net.cpp:50] Initializing net from parameters: 
name: "large_batch/model0_part2.prototxt"
state {
  phase: TRAIN
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TRAIN
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.part2.train"
    batch_size: 20000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1005 21:19:56.233531 16240 layer_factory.hpp:76] Creating layer data_layer
I1005 21:19:56.247059 16240 net.cpp:110] Creating Layer data_layer
I1005 21:19:56.247088 16240 net.cpp:433] data_layer -> data_blob
I1005 21:19:56.247120 16240 net.cpp:433] data_layer -> label_blob
I1005 21:19:56.247717 16244 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.part2.train
I1005 21:19:56.935717 16240 data_layer.cpp:45] output data size: 20000,61,1,1
I1005 21:19:56.940667 16240 net.cpp:155] Setting up data_layer
I1005 21:19:56.940708 16240 net.cpp:163] Top shape: 20000 61 1 1 (1220000)
I1005 21:19:56.940712 16240 net.cpp:163] Top shape: 20000 (20000)
I1005 21:19:56.940718 16240 layer_factory.hpp:76] Creating layer hidden_sum_layer
I1005 21:19:56.940740 16240 net.cpp:110] Creating Layer hidden_sum_layer
I1005 21:19:56.940743 16240 net.cpp:477] hidden_sum_layer <- data_blob
I1005 21:19:56.940752 16240 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I1005 21:19:56.941128 16240 net.cpp:155] Setting up hidden_sum_layer
I1005 21:19:56.941135 16240 net.cpp:163] Top shape: 20000 10 (200000)
I1005 21:19:56.941157 16240 layer_factory.hpp:76] Creating layer hidden_act_layer
I1005 21:19:56.941174 16240 net.cpp:110] Creating Layer hidden_act_layer
I1005 21:19:56.941176 16240 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I1005 21:19:56.941179 16240 net.cpp:433] hidden_act_layer -> hidden_act_blob
I1005 21:20:00.194226 16240 net.cpp:155] Setting up hidden_act_layer
I1005 21:20:00.194262 16240 net.cpp:163] Top shape: 20000 10 (200000)
I1005 21:20:00.194268 16240 layer_factory.hpp:76] Creating layer output_sum_layer
I1005 21:20:00.194281 16240 net.cpp:110] Creating Layer output_sum_layer
I1005 21:20:00.194285 16240 net.cpp:477] output_sum_layer <- hidden_act_blob
I1005 21:20:00.194303 16240 net.cpp:433] output_sum_layer -> output_sum_blob
I1005 21:20:00.194417 16240 net.cpp:155] Setting up output_sum_layer
I1005 21:20:00.194422 16240 net.cpp:163] Top shape: 20000 1 (20000)
I1005 21:20:00.194439 16240 layer_factory.hpp:76] Creating layer output_act_layer
I1005 21:20:00.194445 16240 net.cpp:110] Creating Layer output_act_layer
I1005 21:20:00.194447 16240 net.cpp:477] output_act_layer <- output_sum_blob
I1005 21:20:00.194449 16240 net.cpp:433] output_act_layer -> output_act_blob
I1005 21:20:00.194533 16240 net.cpp:155] Setting up output_act_layer
I1005 21:20:00.194555 16240 net.cpp:163] Top shape: 20000 1 (20000)
I1005 21:20:00.194567 16240 layer_factory.hpp:76] Creating layer error_layer
I1005 21:20:00.194573 16240 net.cpp:110] Creating Layer error_layer
I1005 21:20:00.194576 16240 net.cpp:477] error_layer <- output_act_blob
I1005 21:20:00.194577 16240 net.cpp:477] error_layer <- label_blob
I1005 21:20:00.194591 16240 net.cpp:433] error_layer -> error_blob
I1005 21:20:00.195022 16240 net.cpp:155] Setting up error_layer
I1005 21:20:00.195026 16240 net.cpp:163] Top shape: (1)
I1005 21:20:00.195029 16240 net.cpp:168]     with loss weight 1
I1005 21:20:00.195044 16240 net.cpp:236] error_layer needs backward computation.
I1005 21:20:00.195046 16240 net.cpp:236] output_act_layer needs backward computation.
I1005 21:20:00.195049 16240 net.cpp:236] output_sum_layer needs backward computation.
I1005 21:20:00.195050 16240 net.cpp:236] hidden_act_layer needs backward computation.
I1005 21:20:00.195052 16240 net.cpp:236] hidden_sum_layer needs backward computation.
I1005 21:20:00.195055 16240 net.cpp:240] data_layer does not need backward computation.
I1005 21:20:00.195057 16240 net.cpp:283] This network produces output error_blob
I1005 21:20:00.195062 16240 net.cpp:297] Network initialization done.
I1005 21:20:00.195066 16240 net.cpp:298] Memory required for data: 6720004
I1005 21:20:00.195193 16240 solver.cpp:187] Creating test net (#0) specified by net file: large_batch/model0_part2.prototxt
I1005 21:20:00.195204 16240 net.cpp:339] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_layer
I1005 21:20:00.195236 16240 net.cpp:50] Initializing net from parameters: 
name: "large_batch/model0_part2.prototxt"
state {
  phase: TEST
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  include {
    phase: TEST
  }
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.part2.test"
    batch_size: 2000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1005 21:20:00.195257 16240 layer_factory.hpp:76] Creating layer data_layer
I1005 21:20:00.196528 16240 net.cpp:110] Creating Layer data_layer
I1005 21:20:00.196547 16240 net.cpp:433] data_layer -> data_blob
I1005 21:20:00.196550 16240 net.cpp:433] data_layer -> label_blob
I1005 21:20:00.197113 16246 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.part2.test
I1005 21:20:00.197192 16240 data_layer.cpp:45] output data size: 2000,61,1,1
I1005 21:20:00.198565 16240 net.cpp:155] Setting up data_layer
I1005 21:20:00.198576 16240 net.cpp:163] Top shape: 2000 61 1 1 (122000)
I1005 21:20:00.198580 16240 net.cpp:163] Top shape: 2000 (2000)
I1005 21:20:00.198583 16240 layer_factory.hpp:76] Creating layer hidden_sum_layer
I1005 21:20:00.198593 16240 net.cpp:110] Creating Layer hidden_sum_layer
I1005 21:20:00.198597 16240 net.cpp:477] hidden_sum_layer <- data_blob
I1005 21:20:00.198603 16240 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I1005 21:20:00.198732 16240 net.cpp:155] Setting up hidden_sum_layer
I1005 21:20:00.198739 16240 net.cpp:163] Top shape: 2000 10 (20000)
I1005 21:20:00.198746 16240 layer_factory.hpp:76] Creating layer hidden_act_layer
I1005 21:20:00.198753 16240 net.cpp:110] Creating Layer hidden_act_layer
I1005 21:20:00.198756 16240 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I1005 21:20:00.198776 16240 net.cpp:433] hidden_act_layer -> hidden_act_blob
I1005 21:20:00.198953 16240 net.cpp:155] Setting up hidden_act_layer
I1005 21:20:00.198961 16240 net.cpp:163] Top shape: 2000 10 (20000)
I1005 21:20:00.198963 16240 layer_factory.hpp:76] Creating layer output_sum_layer
I1005 21:20:00.198969 16240 net.cpp:110] Creating Layer output_sum_layer
I1005 21:20:00.198972 16240 net.cpp:477] output_sum_layer <- hidden_act_blob
I1005 21:20:00.198978 16240 net.cpp:433] output_sum_layer -> output_sum_blob
I1005 21:20:00.199048 16240 net.cpp:155] Setting up output_sum_layer
I1005 21:20:00.199054 16240 net.cpp:163] Top shape: 2000 1 (2000)
I1005 21:20:00.199060 16240 layer_factory.hpp:76] Creating layer output_act_layer
I1005 21:20:00.199066 16240 net.cpp:110] Creating Layer output_act_layer
I1005 21:20:00.199071 16240 net.cpp:477] output_act_layer <- output_sum_blob
I1005 21:20:00.199076 16240 net.cpp:433] output_act_layer -> output_act_blob
I1005 21:20:00.199133 16240 net.cpp:155] Setting up output_act_layer
I1005 21:20:00.199139 16240 net.cpp:163] Top shape: 2000 1 (2000)
I1005 21:20:00.199141 16240 layer_factory.hpp:76] Creating layer error_layer
I1005 21:20:00.199146 16240 net.cpp:110] Creating Layer error_layer
I1005 21:20:00.199151 16240 net.cpp:477] error_layer <- output_act_blob
I1005 21:20:00.199154 16240 net.cpp:477] error_layer <- label_blob
I1005 21:20:00.199159 16240 net.cpp:433] error_layer -> error_blob
I1005 21:20:00.199188 16240 net.cpp:155] Setting up error_layer
I1005 21:20:00.199193 16240 net.cpp:163] Top shape: (1)
I1005 21:20:00.199194 16240 net.cpp:168]     with loss weight 1
I1005 21:20:00.199203 16240 net.cpp:236] error_layer needs backward computation.
I1005 21:20:00.199208 16240 net.cpp:236] output_act_layer needs backward computation.
I1005 21:20:00.199211 16240 net.cpp:236] output_sum_layer needs backward computation.
I1005 21:20:00.199215 16240 net.cpp:236] hidden_act_layer needs backward computation.
I1005 21:20:00.199218 16240 net.cpp:236] hidden_sum_layer needs backward computation.
I1005 21:20:00.199223 16240 net.cpp:240] data_layer does not need backward computation.
I1005 21:20:00.199225 16240 net.cpp:283] This network produces output error_blob
I1005 21:20:00.199232 16240 net.cpp:297] Network initialization done.
I1005 21:20:00.199236 16240 net.cpp:298] Memory required for data: 672004
I1005 21:20:00.199261 16240 solver.cpp:66] Solver scaffolding done.
I1005 21:20:00.199359 16240 caffe.cpp:212] Starting Optimization
I1005 21:20:00.199367 16240 solver.cpp:294] Solving large_batch/model0_part2.prototxt
I1005 21:20:00.199368 16240 solver.cpp:295] Learning Rate Policy: fixed
I1005 21:20:00.199550 16240 solver.cpp:347] Iteration 0, Testing net (#0)
I1005 21:20:00.199645 16240 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:20:00.472059 16240 solver.cpp:415]     Test net output #0: error_blob = 0.139404 (* 1 = 0.139404 loss)
I1005 21:20:00.473392 16240 solver.cpp:243] Iteration 0, loss = 0.137922
I1005 21:20:00.473405 16240 solver.cpp:259]     Train net output #0: error_blob = 0.137922 (* 1 = 0.137922 loss)
I1005 21:20:00.473415 16240 solver.cpp:590] Iteration 0, lr = 0.01
I1005 21:20:02.973943 16240 solver.cpp:243] Iteration 100, loss = 0.118464
I1005 21:20:02.973985 16240 solver.cpp:259]     Train net output #0: error_blob = 0.118464 (* 1 = 0.118464 loss)
I1005 21:20:02.973991 16240 solver.cpp:590] Iteration 100, lr = 0.01
I1005 21:20:05.467758 16240 solver.cpp:243] Iteration 200, loss = 0.11377
I1005 21:20:05.467800 16240 solver.cpp:259]     Train net output #0: error_blob = 0.11377 (* 1 = 0.11377 loss)
I1005 21:20:05.467805 16240 solver.cpp:590] Iteration 200, lr = 0.01
I1005 21:20:07.971914 16240 solver.cpp:243] Iteration 300, loss = 0.112452
I1005 21:20:07.971952 16240 solver.cpp:259]     Train net output #0: error_blob = 0.112452 (* 1 = 0.112452 loss)
I1005 21:20:07.971959 16240 solver.cpp:590] Iteration 300, lr = 0.01
I1005 21:20:10.493844 16240 solver.cpp:243] Iteration 400, loss = 0.10886
I1005 21:20:10.493885 16240 solver.cpp:259]     Train net output #0: error_blob = 0.10886 (* 1 = 0.10886 loss)
I1005 21:20:10.493916 16240 solver.cpp:590] Iteration 400, lr = 0.01
I1005 21:20:13.004238 16240 solver.cpp:243] Iteration 500, loss = 0.11106
I1005 21:20:13.004268 16240 solver.cpp:259]     Train net output #0: error_blob = 0.11106 (* 1 = 0.11106 loss)
I1005 21:20:13.004273 16240 solver.cpp:590] Iteration 500, lr = 0.01
I1005 21:20:15.499475 16240 solver.cpp:243] Iteration 600, loss = 0.107097
I1005 21:20:15.499516 16240 solver.cpp:259]     Train net output #0: error_blob = 0.107097 (* 1 = 0.107097 loss)
I1005 21:20:15.499522 16240 solver.cpp:590] Iteration 600, lr = 0.01
I1005 21:20:17.996348 16240 solver.cpp:243] Iteration 700, loss = 0.109331
I1005 21:20:17.996381 16240 solver.cpp:259]     Train net output #0: error_blob = 0.109331 (* 1 = 0.109331 loss)
I1005 21:20:17.996387 16240 solver.cpp:590] Iteration 700, lr = 0.01
I1005 21:20:20.543476 16240 solver.cpp:243] Iteration 800, loss = 0.108612
I1005 21:20:20.543515 16240 solver.cpp:259]     Train net output #0: error_blob = 0.108612 (* 1 = 0.108612 loss)
I1005 21:20:20.543534 16240 solver.cpp:590] Iteration 800, lr = 0.01
I1005 21:20:23.087620 16240 solver.cpp:243] Iteration 900, loss = 0.104966
I1005 21:20:23.087671 16240 solver.cpp:259]     Train net output #0: error_blob = 0.104966 (* 1 = 0.104966 loss)
I1005 21:20:23.087679 16240 solver.cpp:590] Iteration 900, lr = 0.01
I1005 21:20:23.138698 16240 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:20:25.590314 16240 solver.cpp:347] Iteration 1000, Testing net (#0)
I1005 21:20:25.886559 16240 solver.cpp:415]     Test net output #0: error_blob = 0.104782 (* 1 = 0.104782 loss)
I1005 21:20:25.887255 16240 solver.cpp:243] Iteration 1000, loss = 0.107529
I1005 21:20:25.887269 16240 solver.cpp:259]     Train net output #0: error_blob = 0.107529 (* 1 = 0.107529 loss)
I1005 21:20:25.887275 16240 solver.cpp:590] Iteration 1000, lr = 0.01
I1005 21:20:28.481014 16240 solver.cpp:243] Iteration 1100, loss = 0.103504
I1005 21:20:28.481046 16240 solver.cpp:259]     Train net output #0: error_blob = 0.103504 (* 1 = 0.103504 loss)
I1005 21:20:28.481055 16240 solver.cpp:590] Iteration 1100, lr = 0.01
I1005 21:20:31.040523 16240 solver.cpp:243] Iteration 1200, loss = 0.105847
I1005 21:20:31.040555 16240 solver.cpp:259]     Train net output #0: error_blob = 0.105847 (* 1 = 0.105847 loss)
I1005 21:20:31.040560 16240 solver.cpp:590] Iteration 1200, lr = 0.01
I1005 21:20:33.574895 16240 solver.cpp:243] Iteration 1300, loss = 0.106361
I1005 21:20:33.574934 16240 solver.cpp:259]     Train net output #0: error_blob = 0.106361 (* 1 = 0.106361 loss)
I1005 21:20:33.574944 16240 solver.cpp:590] Iteration 1300, lr = 0.01
I1005 21:20:36.105883 16240 solver.cpp:243] Iteration 1400, loss = 0.102491
I1005 21:20:36.105917 16240 solver.cpp:259]     Train net output #0: error_blob = 0.102491 (* 1 = 0.102491 loss)
I1005 21:20:36.105922 16240 solver.cpp:590] Iteration 1400, lr = 0.01
I1005 21:20:38.630480 16240 solver.cpp:243] Iteration 1500, loss = 0.103975
I1005 21:20:38.630517 16240 solver.cpp:259]     Train net output #0: error_blob = 0.103975 (* 1 = 0.103975 loss)
I1005 21:20:38.630525 16240 solver.cpp:590] Iteration 1500, lr = 0.01
I1005 21:20:41.177012 16240 solver.cpp:243] Iteration 1600, loss = 0.102951
I1005 21:20:41.177059 16240 solver.cpp:259]     Train net output #0: error_blob = 0.102951 (* 1 = 0.102951 loss)
I1005 21:20:41.177067 16240 solver.cpp:590] Iteration 1600, lr = 0.01
I1005 21:20:43.697962 16240 solver.cpp:243] Iteration 1700, loss = 0.1033
I1005 21:20:43.697993 16240 solver.cpp:259]     Train net output #0: error_blob = 0.1033 (* 1 = 0.1033 loss)
I1005 21:20:43.697999 16240 solver.cpp:590] Iteration 1700, lr = 0.01
I1005 21:20:46.185701 16240 solver.cpp:243] Iteration 1800, loss = 0.105677
I1005 21:20:46.185751 16240 solver.cpp:259]     Train net output #0: error_blob = 0.105677 (* 1 = 0.105677 loss)
I1005 21:20:46.185760 16240 solver.cpp:590] Iteration 1800, lr = 0.01
I1005 21:20:46.387027 16240 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:20:48.683455 16240 solver.cpp:243] Iteration 1900, loss = 0.101067
I1005 21:20:48.683487 16240 solver.cpp:259]     Train net output #0: error_blob = 0.101067 (* 1 = 0.101067 loss)
I1005 21:20:48.683493 16240 solver.cpp:590] Iteration 1900, lr = 0.01
I1005 21:20:51.165045 16240 solver.cpp:347] Iteration 2000, Testing net (#0)
I1005 21:20:51.450249 16240 solver.cpp:415]     Test net output #0: error_blob = 0.102535 (* 1 = 0.102535 loss)
I1005 21:20:51.450954 16240 solver.cpp:243] Iteration 2000, loss = 0.104501
I1005 21:20:51.450999 16240 solver.cpp:259]     Train net output #0: error_blob = 0.104501 (* 1 = 0.104501 loss)
I1005 21:20:51.451006 16240 solver.cpp:590] Iteration 2000, lr = 0.01
I1005 21:20:53.920781 16240 solver.cpp:243] Iteration 2100, loss = 0.101391
I1005 21:20:53.920824 16240 solver.cpp:259]     Train net output #0: error_blob = 0.101391 (* 1 = 0.101391 loss)
I1005 21:20:53.920830 16240 solver.cpp:590] Iteration 2100, lr = 0.01
I1005 21:20:56.430279 16240 solver.cpp:243] Iteration 2200, loss = 0.101882
I1005 21:20:56.431335 16240 solver.cpp:259]     Train net output #0: error_blob = 0.101882 (* 1 = 0.101882 loss)
I1005 21:20:56.431346 16240 solver.cpp:590] Iteration 2200, lr = 0.01
I1005 21:20:58.968785 16240 solver.cpp:243] Iteration 2300, loss = 0.10473
I1005 21:20:58.968822 16240 solver.cpp:259]     Train net output #0: error_blob = 0.10473 (* 1 = 0.10473 loss)
I1005 21:20:58.968829 16240 solver.cpp:590] Iteration 2300, lr = 0.01
I1005 21:21:01.486982 16240 solver.cpp:243] Iteration 2400, loss = 0.100187
I1005 21:21:01.487030 16240 solver.cpp:259]     Train net output #0: error_blob = 0.100187 (* 1 = 0.100187 loss)
I1005 21:21:01.487040 16240 solver.cpp:590] Iteration 2400, lr = 0.01
I1005 21:21:03.993676 16240 solver.cpp:243] Iteration 2500, loss = 0.103563
I1005 21:21:03.993710 16240 solver.cpp:259]     Train net output #0: error_blob = 0.103563 (* 1 = 0.103563 loss)
I1005 21:21:03.993716 16240 solver.cpp:590] Iteration 2500, lr = 0.01
I1005 21:21:06.525682 16240 solver.cpp:243] Iteration 2600, loss = 0.101512
I1005 21:21:06.525722 16240 solver.cpp:259]     Train net output #0: error_blob = 0.101512 (* 1 = 0.101512 loss)
I1005 21:21:06.525730 16240 solver.cpp:590] Iteration 2600, lr = 0.01
I1005 21:21:09.031054 16240 solver.cpp:243] Iteration 2700, loss = 0.0996404
I1005 21:21:09.031093 16240 solver.cpp:259]     Train net output #0: error_blob = 0.0996404 (* 1 = 0.0996404 loss)
I1005 21:21:09.031105 16240 solver.cpp:590] Iteration 2700, lr = 0.01
I1005 21:21:09.372149 16240 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:21:11.522675 16240 solver.cpp:243] Iteration 2800, loss = 0.103896
I1005 21:21:11.522712 16240 solver.cpp:259]     Train net output #0: error_blob = 0.103896 (* 1 = 0.103896 loss)
I1005 21:21:11.522719 16240 solver.cpp:590] Iteration 2800, lr = 0.01
I1005 21:21:14.068614 16240 solver.cpp:243] Iteration 2900, loss = 0.0980239
I1005 21:21:14.068646 16240 solver.cpp:259]     Train net output #0: error_blob = 0.0980239 (* 1 = 0.0980239 loss)
I1005 21:21:14.068652 16240 solver.cpp:590] Iteration 2900, lr = 0.01
I1005 21:21:16.575808 16240 solver.cpp:347] Iteration 3000, Testing net (#0)
I1005 21:21:16.908442 16240 solver.cpp:415]     Test net output #0: error_blob = 0.101748 (* 1 = 0.101748 loss)
I1005 21:21:16.909106 16240 solver.cpp:243] Iteration 3000, loss = 0.103876
I1005 21:21:16.909121 16240 solver.cpp:259]     Train net output #0: error_blob = 0.103876 (* 1 = 0.103876 loss)
I1005 21:21:16.909157 16240 solver.cpp:590] Iteration 3000, lr = 0.01
I1005 21:21:19.375599 16240 solver.cpp:243] Iteration 3100, loss = 0.101643
I1005 21:21:19.375636 16240 solver.cpp:259]     Train net output #0: error_blob = 0.101643 (* 1 = 0.101643 loss)
I1005 21:21:19.375644 16240 solver.cpp:590] Iteration 3100, lr = 0.01
I1005 21:21:21.907703 16240 solver.cpp:243] Iteration 3200, loss = 0.0994939
I1005 21:21:21.907737 16240 solver.cpp:259]     Train net output #0: error_blob = 0.0994939 (* 1 = 0.0994939 loss)
I1005 21:21:21.907743 16240 solver.cpp:590] Iteration 3200, lr = 0.01
I1005 21:21:24.422402 16240 solver.cpp:243] Iteration 3300, loss = 0.104273
I1005 21:21:24.422441 16240 solver.cpp:259]     Train net output #0: error_blob = 0.104273 (* 1 = 0.104273 loss)
I1005 21:21:24.422451 16240 solver.cpp:590] Iteration 3300, lr = 0.01
I1005 21:21:26.947751 16240 solver.cpp:243] Iteration 3400, loss = 0.0973652
I1005 21:21:26.947859 16240 solver.cpp:259]     Train net output #0: error_blob = 0.0973652 (* 1 = 0.0973652 loss)
I1005 21:21:26.947867 16240 solver.cpp:590] Iteration 3400, lr = 0.01
I1005 21:21:29.483217 16240 solver.cpp:243] Iteration 3500, loss = 0.102048
I1005 21:21:29.483259 16240 solver.cpp:259]     Train net output #0: error_blob = 0.102048 (* 1 = 0.102048 loss)
I1005 21:21:29.483268 16240 solver.cpp:590] Iteration 3500, lr = 0.01
I1005 21:21:31.997771 16240 solver.cpp:243] Iteration 3600, loss = 0.102969
I1005 21:21:31.997810 16240 solver.cpp:259]     Train net output #0: error_blob = 0.102969 (* 1 = 0.102969 loss)
I1005 21:21:31.997817 16240 solver.cpp:590] Iteration 3600, lr = 0.01
I1005 21:21:32.508379 16240 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:21:34.509274 16240 solver.cpp:243] Iteration 3700, loss = 0.0987339
I1005 21:21:34.509313 16240 solver.cpp:259]     Train net output #0: error_blob = 0.0987339 (* 1 = 0.0987339 loss)
I1005 21:21:34.509322 16240 solver.cpp:590] Iteration 3700, lr = 0.01
I1005 21:21:37.023006 16240 solver.cpp:243] Iteration 3800, loss = 0.102424
I1005 21:21:37.023046 16240 solver.cpp:259]     Train net output #0: error_blob = 0.102424 (* 1 = 0.102424 loss)
I1005 21:21:37.023053 16240 solver.cpp:590] Iteration 3800, lr = 0.01
I1005 21:21:39.547327 16240 solver.cpp:243] Iteration 3900, loss = 0.0976779
I1005 21:21:39.547360 16240 solver.cpp:259]     Train net output #0: error_blob = 0.0976779 (* 1 = 0.0976779 loss)
I1005 21:21:39.547365 16240 solver.cpp:590] Iteration 3900, lr = 0.01
I1005 21:21:42.039980 16240 solver.cpp:347] Iteration 4000, Testing net (#0)
I1005 21:21:42.320732 16240 solver.cpp:415]     Test net output #0: error_blob = 0.101171 (* 1 = 0.101171 loss)
I1005 21:21:42.321398 16240 solver.cpp:243] Iteration 4000, loss = 0.101441
I1005 21:21:42.321411 16240 solver.cpp:259]     Train net output #0: error_blob = 0.101441 (* 1 = 0.101441 loss)
I1005 21:21:42.321418 16240 solver.cpp:590] Iteration 4000, lr = 0.01
I1005 21:21:44.800542 16240 solver.cpp:243] Iteration 4100, loss = 0.102483
I1005 21:21:44.800582 16240 solver.cpp:259]     Train net output #0: error_blob = 0.102483 (* 1 = 0.102483 loss)
I1005 21:21:44.800590 16240 solver.cpp:590] Iteration 4100, lr = 0.01
I1005 21:21:47.330725 16240 solver.cpp:243] Iteration 4200, loss = 0.09864
I1005 21:21:47.330757 16240 solver.cpp:259]     Train net output #0: error_blob = 0.09864 (* 1 = 0.09864 loss)
I1005 21:21:47.330762 16240 solver.cpp:590] Iteration 4200, lr = 0.01
I1005 21:21:49.859066 16240 solver.cpp:243] Iteration 4300, loss = 0.101664
I1005 21:21:49.859099 16240 solver.cpp:259]     Train net output #0: error_blob = 0.101664 (* 1 = 0.101664 loss)
I1005 21:21:49.859104 16240 solver.cpp:590] Iteration 4300, lr = 0.01
I1005 21:21:52.366534 16240 solver.cpp:243] Iteration 4400, loss = 0.0975628
I1005 21:21:52.366575 16240 solver.cpp:259]     Train net output #0: error_blob = 0.0975628 (* 1 = 0.0975628 loss)
I1005 21:21:52.366582 16240 solver.cpp:590] Iteration 4400, lr = 0.01
I1005 21:21:54.893827 16240 solver.cpp:243] Iteration 4500, loss = 0.0990798
I1005 21:21:54.893860 16240 solver.cpp:259]     Train net output #0: error_blob = 0.0990798 (* 1 = 0.0990798 loss)
I1005 21:21:54.893865 16240 solver.cpp:590] Iteration 4500, lr = 0.01
I1005 21:21:55.556705 16240 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:21:57.432430 16240 solver.cpp:243] Iteration 4600, loss = 0.102494
I1005 21:21:57.432503 16240 solver.cpp:259]     Train net output #0: error_blob = 0.102494 (* 1 = 0.102494 loss)
I1005 21:21:57.432510 16240 solver.cpp:590] Iteration 4600, lr = 0.01
I1005 21:21:59.924156 16240 solver.cpp:243] Iteration 4700, loss = 0.0978381
I1005 21:21:59.924188 16240 solver.cpp:259]     Train net output #0: error_blob = 0.0978381 (* 1 = 0.0978381 loss)
I1005 21:21:59.924193 16240 solver.cpp:590] Iteration 4700, lr = 0.01
I1005 21:22:02.453603 16240 solver.cpp:243] Iteration 4800, loss = 0.0994901
I1005 21:22:02.453640 16240 solver.cpp:259]     Train net output #0: error_blob = 0.0994901 (* 1 = 0.0994901 loss)
I1005 21:22:02.453649 16240 solver.cpp:590] Iteration 4800, lr = 0.01
I1005 21:22:04.996248 16240 solver.cpp:243] Iteration 4900, loss = 0.0978458
I1005 21:22:04.996296 16240 solver.cpp:259]     Train net output #0: error_blob = 0.0978458 (* 1 = 0.0978458 loss)
I1005 21:22:04.996307 16240 solver.cpp:590] Iteration 4900, lr = 0.01
I1005 21:22:07.499666 16240 solver.cpp:347] Iteration 5000, Testing net (#0)
I1005 21:22:07.775049 16240 solver.cpp:415]     Test net output #0: error_blob = 0.100343 (* 1 = 0.100343 loss)
I1005 21:22:07.775696 16240 solver.cpp:243] Iteration 5000, loss = 0.0986751
I1005 21:22:07.775719 16240 solver.cpp:259]     Train net output #0: error_blob = 0.0986751 (* 1 = 0.0986751 loss)
I1005 21:22:07.775727 16240 solver.cpp:590] Iteration 5000, lr = 0.01
I1005 21:22:10.260818 16240 solver.cpp:243] Iteration 5100, loss = 0.101945
I1005 21:22:10.260851 16240 solver.cpp:259]     Train net output #0: error_blob = 0.101945 (* 1 = 0.101945 loss)
I1005 21:22:10.260859 16240 solver.cpp:590] Iteration 5100, lr = 0.01
I1005 21:22:12.759711 16240 solver.cpp:243] Iteration 5200, loss = 0.0969673
I1005 21:22:12.759753 16240 solver.cpp:259]     Train net output #0: error_blob = 0.0969673 (* 1 = 0.0969673 loss)
I1005 21:22:12.759758 16240 solver.cpp:590] Iteration 5200, lr = 0.01
I1005 21:22:15.267866 16240 solver.cpp:243] Iteration 5300, loss = 0.101498
I1005 21:22:15.267915 16240 solver.cpp:259]     Train net output #0: error_blob = 0.101498 (* 1 = 0.101498 loss)
I1005 21:22:15.267923 16240 solver.cpp:590] Iteration 5300, lr = 0.01
I1005 21:22:17.794034 16240 solver.cpp:243] Iteration 5400, loss = 0.0983952
I1005 21:22:17.794081 16240 solver.cpp:259]     Train net output #0: error_blob = 0.0983952 (* 1 = 0.0983952 loss)
I1005 21:22:17.794090 16240 solver.cpp:590] Iteration 5400, lr = 0.01
I1005 21:22:18.609710 16240 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:22:20.333083 16240 solver.cpp:243] Iteration 5500, loss = 0.0973366
I1005 21:22:20.333133 16240 solver.cpp:259]     Train net output #0: error_blob = 0.0973366 (* 1 = 0.0973366 loss)
I1005 21:22:20.333142 16240 solver.cpp:590] Iteration 5500, lr = 0.01
I1005 21:22:22.852725 16240 solver.cpp:243] Iteration 5600, loss = 0.101844
I1005 21:22:22.852766 16240 solver.cpp:259]     Train net output #0: error_blob = 0.101844 (* 1 = 0.101844 loss)
I1005 21:22:22.852771 16240 solver.cpp:590] Iteration 5600, lr = 0.01
I1005 21:22:25.367727 16240 solver.cpp:243] Iteration 5700, loss = 0.0965176
I1005 21:22:25.367760 16240 solver.cpp:259]     Train net output #0: error_blob = 0.0965176 (* 1 = 0.0965176 loss)
I1005 21:22:25.367766 16240 solver.cpp:590] Iteration 5700, lr = 0.01
I1005 21:22:27.920076 16240 solver.cpp:243] Iteration 5800, loss = 0.101039
I1005 21:22:27.921159 16240 solver.cpp:259]     Train net output #0: error_blob = 0.101039 (* 1 = 0.101039 loss)
I1005 21:22:27.921165 16240 solver.cpp:590] Iteration 5800, lr = 0.01
I1005 21:22:30.428653 16240 solver.cpp:243] Iteration 5900, loss = 0.0990649
I1005 21:22:30.428692 16240 solver.cpp:259]     Train net output #0: error_blob = 0.0990649 (* 1 = 0.0990649 loss)
I1005 21:22:30.428701 16240 solver.cpp:590] Iteration 5900, lr = 0.01
I1005 21:22:32.907191 16240 solver.cpp:347] Iteration 6000, Testing net (#0)
I1005 21:22:33.194155 16240 solver.cpp:415]     Test net output #0: error_blob = 0.0996879 (* 1 = 0.0996879 loss)
I1005 21:22:33.194828 16240 solver.cpp:243] Iteration 6000, loss = 0.0955193
I1005 21:22:33.194844 16240 solver.cpp:259]     Train net output #0: error_blob = 0.0955193 (* 1 = 0.0955193 loss)
I1005 21:22:33.194852 16240 solver.cpp:590] Iteration 6000, lr = 0.01
I1005 21:22:35.664088 16240 solver.cpp:243] Iteration 6100, loss = 0.100861
I1005 21:22:35.664125 16240 solver.cpp:259]     Train net output #0: error_blob = 0.100861 (* 1 = 0.100861 loss)
I1005 21:22:35.664132 16240 solver.cpp:590] Iteration 6100, lr = 0.01
I1005 21:22:38.157591 16240 solver.cpp:243] Iteration 6200, loss = 0.094248
I1005 21:22:38.157631 16240 solver.cpp:259]     Train net output #0: error_blob = 0.094248 (* 1 = 0.094248 loss)
I1005 21:22:38.157639 16240 solver.cpp:590] Iteration 6200, lr = 0.01
I1005 21:22:40.694279 16240 solver.cpp:243] Iteration 6300, loss = 0.102078
I1005 21:22:40.694313 16240 solver.cpp:259]     Train net output #0: error_blob = 0.102078 (* 1 = 0.102078 loss)
I1005 21:22:40.694319 16240 solver.cpp:590] Iteration 6300, lr = 0.01
I1005 21:22:41.649405 16240 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:22:43.213488 16240 solver.cpp:243] Iteration 6400, loss = 0.0997054
I1005 21:22:43.213521 16240 solver.cpp:259]     Train net output #0: error_blob = 0.0997054 (* 1 = 0.0997054 loss)
I1005 21:22:43.213526 16240 solver.cpp:590] Iteration 6400, lr = 0.01
I1005 21:22:45.752398 16240 solver.cpp:243] Iteration 6500, loss = 0.0948082
I1005 21:22:45.752439 16240 solver.cpp:259]     Train net output #0: error_blob = 0.0948082 (* 1 = 0.0948082 loss)
I1005 21:22:45.752444 16240 solver.cpp:590] Iteration 6500, lr = 0.01
I1005 21:22:48.227195 16240 solver.cpp:243] Iteration 6600, loss = 0.101738
I1005 21:22:48.227243 16240 solver.cpp:259]     Train net output #0: error_blob = 0.101738 (* 1 = 0.101738 loss)
I1005 21:22:48.227253 16240 solver.cpp:590] Iteration 6600, lr = 0.01
I1005 21:22:50.734772 16240 solver.cpp:243] Iteration 6700, loss = 0.0951326
I1005 21:22:50.734817 16240 solver.cpp:259]     Train net output #0: error_blob = 0.0951326 (* 1 = 0.0951326 loss)
I1005 21:22:50.734822 16240 solver.cpp:590] Iteration 6700, lr = 0.01
I1005 21:22:53.228586 16240 solver.cpp:243] Iteration 6800, loss = 0.0994022
I1005 21:22:53.228626 16240 solver.cpp:259]     Train net output #0: error_blob = 0.0994022 (* 1 = 0.0994022 loss)
I1005 21:22:53.228632 16240 solver.cpp:590] Iteration 6800, lr = 0.01
I1005 21:22:55.734473 16240 solver.cpp:243] Iteration 6900, loss = 0.100839
I1005 21:22:55.734514 16240 solver.cpp:259]     Train net output #0: error_blob = 0.100839 (* 1 = 0.100839 loss)
I1005 21:22:55.734524 16240 solver.cpp:590] Iteration 6900, lr = 0.01
I1005 21:22:58.215612 16240 solver.cpp:347] Iteration 7000, Testing net (#0)
I1005 21:22:58.600361 16240 solver.cpp:415]     Test net output #0: error_blob = 0.0993311 (* 1 = 0.0993311 loss)
I1005 21:22:58.601061 16240 solver.cpp:243] Iteration 7000, loss = 0.0959848
I1005 21:22:58.601083 16240 solver.cpp:259]     Train net output #0: error_blob = 0.0959848 (* 1 = 0.0959848 loss)
I1005 21:22:58.601089 16240 solver.cpp:590] Iteration 7000, lr = 0.01
I1005 21:23:01.072685 16240 solver.cpp:243] Iteration 7100, loss = 0.100246
I1005 21:23:01.072721 16240 solver.cpp:259]     Train net output #0: error_blob = 0.100246 (* 1 = 0.100246 loss)
I1005 21:23:01.072731 16240 solver.cpp:590] Iteration 7100, lr = 0.01
I1005 21:23:03.609007 16240 solver.cpp:243] Iteration 7200, loss = 0.0933778
I1005 21:23:03.609052 16240 solver.cpp:259]     Train net output #0: error_blob = 0.0933778 (* 1 = 0.0933778 loss)
I1005 21:23:03.609061 16240 solver.cpp:590] Iteration 7200, lr = 0.01
I1005 21:23:04.705574 16240 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:23:06.132627 16240 solver.cpp:243] Iteration 7300, loss = 0.0982352
I1005 21:23:06.132663 16240 solver.cpp:259]     Train net output #0: error_blob = 0.0982352 (* 1 = 0.0982352 loss)
I1005 21:23:06.132671 16240 solver.cpp:590] Iteration 7300, lr = 0.01
I1005 21:23:08.642925 16240 solver.cpp:243] Iteration 7400, loss = 0.101171
I1005 21:23:08.642971 16240 solver.cpp:259]     Train net output #0: error_blob = 0.101171 (* 1 = 0.101171 loss)
I1005 21:23:08.642978 16240 solver.cpp:590] Iteration 7400, lr = 0.01
I1005 21:23:11.142304 16240 solver.cpp:243] Iteration 7500, loss = 0.0947485
I1005 21:23:11.142348 16240 solver.cpp:259]     Train net output #0: error_blob = 0.0947485 (* 1 = 0.0947485 loss)
I1005 21:23:11.142354 16240 solver.cpp:590] Iteration 7500, lr = 0.01
I1005 21:23:13.626355 16240 solver.cpp:243] Iteration 7600, loss = 0.0985493
I1005 21:23:13.626389 16240 solver.cpp:259]     Train net output #0: error_blob = 0.0985493 (* 1 = 0.0985493 loss)
I1005 21:23:13.626395 16240 solver.cpp:590] Iteration 7600, lr = 0.01
I1005 21:23:16.165323 16240 solver.cpp:243] Iteration 7700, loss = 0.0951177
I1005 21:23:16.165365 16240 solver.cpp:259]     Train net output #0: error_blob = 0.0951177 (* 1 = 0.0951177 loss)
I1005 21:23:16.165372 16240 solver.cpp:590] Iteration 7700, lr = 0.01
I1005 21:23:18.680773 16240 solver.cpp:243] Iteration 7800, loss = 0.0959317
I1005 21:23:18.680804 16240 solver.cpp:259]     Train net output #0: error_blob = 0.0959317 (* 1 = 0.0959317 loss)
I1005 21:23:18.680809 16240 solver.cpp:590] Iteration 7800, lr = 0.01
I1005 21:23:21.222409 16240 solver.cpp:243] Iteration 7900, loss = 0.100562
I1005 21:23:21.222451 16240 solver.cpp:259]     Train net output #0: error_blob = 0.100562 (* 1 = 0.100562 loss)
I1005 21:23:21.222457 16240 solver.cpp:590] Iteration 7900, lr = 0.01
I1005 21:23:23.703919 16240 solver.cpp:347] Iteration 8000, Testing net (#0)
I1005 21:23:24.010205 16240 solver.cpp:415]     Test net output #0: error_blob = 0.0989351 (* 1 = 0.0989351 loss)
I1005 21:23:24.010802 16240 solver.cpp:243] Iteration 8000, loss = 0.0942457
I1005 21:23:24.010814 16240 solver.cpp:259]     Train net output #0: error_blob = 0.0942457 (* 1 = 0.0942457 loss)
I1005 21:23:24.010818 16240 solver.cpp:590] Iteration 8000, lr = 0.01
I1005 21:23:26.507985 16240 solver.cpp:243] Iteration 8100, loss = 0.0979735
I1005 21:23:26.508016 16240 solver.cpp:259]     Train net output #0: error_blob = 0.0979735 (* 1 = 0.0979735 loss)
I1005 21:23:26.508021 16240 solver.cpp:590] Iteration 8100, lr = 0.01
I1005 21:23:27.747998 16240 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:23:28.990429 16240 solver.cpp:243] Iteration 8200, loss = 0.0961023
I1005 21:23:28.990583 16240 solver.cpp:259]     Train net output #0: error_blob = 0.0961023 (* 1 = 0.0961023 loss)
I1005 21:23:28.990603 16240 solver.cpp:590] Iteration 8200, lr = 0.01
I1005 21:23:31.502856 16240 solver.cpp:243] Iteration 8300, loss = 0.0950787
I1005 21:23:31.502894 16240 solver.cpp:259]     Train net output #0: error_blob = 0.0950787 (* 1 = 0.0950787 loss)
I1005 21:23:31.502902 16240 solver.cpp:590] Iteration 8300, lr = 0.01
I1005 21:23:34.044369 16240 solver.cpp:243] Iteration 8400, loss = 0.100833
I1005 21:23:34.044411 16240 solver.cpp:259]     Train net output #0: error_blob = 0.100833 (* 1 = 0.100833 loss)
I1005 21:23:34.044417 16240 solver.cpp:590] Iteration 8400, lr = 0.01
I1005 21:23:36.565295 16240 solver.cpp:243] Iteration 8500, loss = 0.0938416
I1005 21:23:36.565335 16240 solver.cpp:259]     Train net output #0: error_blob = 0.0938416 (* 1 = 0.0938416 loss)
I1005 21:23:36.565342 16240 solver.cpp:590] Iteration 8500, lr = 0.01
I1005 21:23:39.099236 16240 solver.cpp:243] Iteration 8600, loss = 0.0997969
I1005 21:23:39.099285 16240 solver.cpp:259]     Train net output #0: error_blob = 0.0997969 (* 1 = 0.0997969 loss)
I1005 21:23:39.099293 16240 solver.cpp:590] Iteration 8600, lr = 0.01
I1005 21:23:41.609208 16240 solver.cpp:243] Iteration 8700, loss = 0.0973958
I1005 21:23:41.609248 16240 solver.cpp:259]     Train net output #0: error_blob = 0.0973958 (* 1 = 0.0973958 loss)
I1005 21:23:41.609258 16240 solver.cpp:590] Iteration 8700, lr = 0.01
I1005 21:23:44.129633 16240 solver.cpp:243] Iteration 8800, loss = 0.0937247
I1005 21:23:44.129667 16240 solver.cpp:259]     Train net output #0: error_blob = 0.0937247 (* 1 = 0.0937247 loss)
I1005 21:23:44.129672 16240 solver.cpp:590] Iteration 8800, lr = 0.01
I1005 21:23:46.642457 16240 solver.cpp:243] Iteration 8900, loss = 0.101181
I1005 21:23:46.642496 16240 solver.cpp:259]     Train net output #0: error_blob = 0.101181 (* 1 = 0.101181 loss)
I1005 21:23:46.642503 16240 solver.cpp:590] Iteration 8900, lr = 0.01
I1005 21:23:49.149916 16240 solver.cpp:347] Iteration 9000, Testing net (#0)
I1005 21:23:49.497030 16240 solver.cpp:415]     Test net output #0: error_blob = 0.0989065 (* 1 = 0.0989065 loss)
I1005 21:23:49.497699 16240 solver.cpp:243] Iteration 9000, loss = 0.0935083
I1005 21:23:49.497716 16240 solver.cpp:259]     Train net output #0: error_blob = 0.0935083 (* 1 = 0.0935083 loss)
I1005 21:23:49.497726 16240 solver.cpp:590] Iteration 9000, lr = 0.01
I1005 21:23:50.884665 16240 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:23:51.999171 16240 solver.cpp:243] Iteration 9100, loss = 0.098984
I1005 21:23:51.999212 16240 solver.cpp:259]     Train net output #0: error_blob = 0.098984 (* 1 = 0.098984 loss)
I1005 21:23:51.999220 16240 solver.cpp:590] Iteration 9100, lr = 0.01
I1005 21:23:54.533398 16240 solver.cpp:243] Iteration 9200, loss = 0.098049
I1005 21:23:54.533432 16240 solver.cpp:259]     Train net output #0: error_blob = 0.098049 (* 1 = 0.098049 loss)
I1005 21:23:54.533437 16240 solver.cpp:590] Iteration 9200, lr = 0.01
I1005 21:23:57.032920 16240 solver.cpp:243] Iteration 9300, loss = 0.0938812
I1005 21:23:57.032963 16240 solver.cpp:259]     Train net output #0: error_blob = 0.0938812 (* 1 = 0.0938812 loss)
I1005 21:23:57.032968 16240 solver.cpp:590] Iteration 9300, lr = 0.01
I1005 21:23:59.529721 16240 solver.cpp:243] Iteration 9400, loss = 0.100109
I1005 21:23:59.529824 16240 solver.cpp:259]     Train net output #0: error_blob = 0.100109 (* 1 = 0.100109 loss)
I1005 21:23:59.529829 16240 solver.cpp:590] Iteration 9400, lr = 0.01
I1005 21:24:02.012905 16240 solver.cpp:243] Iteration 9500, loss = 0.0919954
I1005 21:24:02.012944 16240 solver.cpp:259]     Train net output #0: error_blob = 0.0919954 (* 1 = 0.0919954 loss)
I1005 21:24:02.012953 16240 solver.cpp:590] Iteration 9500, lr = 0.01
I1005 21:24:04.547188 16240 solver.cpp:243] Iteration 9600, loss = 0.0993649
I1005 21:24:04.547225 16240 solver.cpp:259]     Train net output #0: error_blob = 0.0993649 (* 1 = 0.0993649 loss)
I1005 21:24:04.547232 16240 solver.cpp:590] Iteration 9600, lr = 0.01
I1005 21:24:07.059715 16240 solver.cpp:243] Iteration 9700, loss = 0.0994309
I1005 21:24:07.059762 16240 solver.cpp:259]     Train net output #0: error_blob = 0.0994309 (* 1 = 0.0994309 loss)
I1005 21:24:07.059769 16240 solver.cpp:590] Iteration 9700, lr = 0.01
I1005 21:24:09.566417 16240 solver.cpp:243] Iteration 9800, loss = 0.0926809
I1005 21:24:09.566450 16240 solver.cpp:259]     Train net output #0: error_blob = 0.0926809 (* 1 = 0.0926809 loss)
I1005 21:24:09.566455 16240 solver.cpp:590] Iteration 9800, lr = 0.01
I1005 21:24:12.088719 16240 solver.cpp:243] Iteration 9900, loss = 0.100148
I1005 21:24:12.088757 16240 solver.cpp:259]     Train net output #0: error_blob = 0.100148 (* 1 = 0.100148 loss)
I1005 21:24:12.088763 16240 solver.cpp:590] Iteration 9900, lr = 0.01
I1005 21:24:14.599874 16240 solver.cpp:468] Snapshotting to binary proto file _iter_10000.caffemodel
I1005 21:24:14.600759 16240 solver.cpp:753] Snapshotting solver state to binary proto file _iter_10000.solverstate
I1005 21:24:14.624634 16240 solver.cpp:327] Iteration 10000, loss = 0.0931144
I1005 21:24:14.624666 16240 solver.cpp:347] Iteration 10000, Testing net (#0)
I1005 21:24:14.794674 16240 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 21:24:14.901473 16240 solver.cpp:415]     Test net output #0: error_blob = 0.0988045 (* 1 = 0.0988045 loss)
I1005 21:24:14.901490 16240 solver.cpp:332] Optimization Done.
I1005 21:24:14.901494 16240 caffe.cpp:215] Optimization Done.
