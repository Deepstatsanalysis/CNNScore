I1005 15:24:34.955488 14642 caffe.cpp:184] Using GPUs 0
I1005 15:24:35.531776 14642 solver.cpp:54] Initializing solver from parameters: 
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "fixed"
momentum: 0.9
solver_mode: GPU
device_id: 0
net: "basic/model0_full.prototxt"
I1005 15:24:35.531806 14642 solver.cpp:97] Creating training net from net file: basic/model0_full.prototxt
I1005 15:24:35.531986 14642 net.cpp:50] Initializing net from parameters: 
name: "basic/model0_full.prototxt"
state {
  phase: TRAIN
}
layer {
  name: "data_layer"
  type: "Data"
  top: "data_blob"
  top: "label_blob"
  data_param {
    source: "lmdb/SCOREDATA.vina.balanced.full"
    batch_size: 20000
    backend: LMDB
    prefetch: 8
  }
}
layer {
  name: "hidden_sum_layer"
  type: "InnerProduct"
  bottom: "data_blob"
  top: "hidden_sum_blob"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "hidden_act_layer"
  type: "Sigmoid"
  bottom: "hidden_sum_blob"
  top: "hidden_act_blob"
}
layer {
  name: "output_sum_layer"
  type: "InnerProduct"
  bottom: "hidden_act_blob"
  top: "output_sum_blob"
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "output_act_layer"
  type: "Sigmoid"
  bottom: "output_sum_blob"
  top: "output_act_blob"
}
layer {
  name: "error_layer"
  type: "EuclideanLoss"
  bottom: "output_act_blob"
  bottom: "label_blob"
  top: "error_blob"
}
I1005 15:24:35.532026 14642 layer_factory.hpp:76] Creating layer data_layer
I1005 15:24:35.545665 14642 net.cpp:110] Creating Layer data_layer
I1005 15:24:35.545686 14642 net.cpp:433] data_layer -> data_blob
I1005 15:24:35.545717 14642 net.cpp:433] data_layer -> label_blob
I1005 15:24:35.546305 14646 db_lmdb.cpp:23] Opened lmdb lmdb/SCOREDATA.vina.balanced.full
I1005 15:24:36.228137 14642 data_layer.cpp:45] output data size: 20000,61,1,1
I1005 15:24:36.233103 14642 net.cpp:155] Setting up data_layer
I1005 15:24:36.233134 14642 net.cpp:163] Top shape: 20000 61 1 1 (1220000)
I1005 15:24:36.233139 14642 net.cpp:163] Top shape: 20000 (20000)
I1005 15:24:36.233155 14642 layer_factory.hpp:76] Creating layer hidden_sum_layer
I1005 15:24:36.233166 14642 net.cpp:110] Creating Layer hidden_sum_layer
I1005 15:24:36.233170 14642 net.cpp:477] hidden_sum_layer <- data_blob
I1005 15:24:36.233180 14642 net.cpp:433] hidden_sum_layer -> hidden_sum_blob
I1005 15:24:36.233566 14642 net.cpp:155] Setting up hidden_sum_layer
I1005 15:24:36.233573 14642 net.cpp:163] Top shape: 20000 10 (200000)
I1005 15:24:36.233585 14642 layer_factory.hpp:76] Creating layer hidden_act_layer
I1005 15:24:36.233603 14642 net.cpp:110] Creating Layer hidden_act_layer
I1005 15:24:36.233604 14642 net.cpp:477] hidden_act_layer <- hidden_sum_blob
I1005 15:24:36.233608 14642 net.cpp:433] hidden_act_layer -> hidden_act_blob
I1005 15:24:39.439874 14642 net.cpp:155] Setting up hidden_act_layer
I1005 15:24:39.439898 14642 net.cpp:163] Top shape: 20000 10 (200000)
I1005 15:24:39.439901 14642 layer_factory.hpp:76] Creating layer output_sum_layer
I1005 15:24:39.439911 14642 net.cpp:110] Creating Layer output_sum_layer
I1005 15:24:39.439915 14642 net.cpp:477] output_sum_layer <- hidden_act_blob
I1005 15:24:39.439921 14642 net.cpp:433] output_sum_layer -> output_sum_blob
I1005 15:24:39.440016 14642 net.cpp:155] Setting up output_sum_layer
I1005 15:24:39.440021 14642 net.cpp:163] Top shape: 20000 1 (20000)
I1005 15:24:39.440028 14642 layer_factory.hpp:76] Creating layer output_act_layer
I1005 15:24:39.440033 14642 net.cpp:110] Creating Layer output_act_layer
I1005 15:24:39.440035 14642 net.cpp:477] output_act_layer <- output_sum_blob
I1005 15:24:39.440039 14642 net.cpp:433] output_act_layer -> output_act_blob
I1005 15:24:39.440102 14642 net.cpp:155] Setting up output_act_layer
I1005 15:24:39.440107 14642 net.cpp:163] Top shape: 20000 1 (20000)
I1005 15:24:39.440110 14642 layer_factory.hpp:76] Creating layer error_layer
I1005 15:24:39.440115 14642 net.cpp:110] Creating Layer error_layer
I1005 15:24:39.440117 14642 net.cpp:477] error_layer <- output_act_blob
I1005 15:24:39.440135 14642 net.cpp:477] error_layer <- label_blob
I1005 15:24:39.440140 14642 net.cpp:433] error_layer -> error_blob
I1005 15:24:39.440168 14642 net.cpp:155] Setting up error_layer
I1005 15:24:39.440173 14642 net.cpp:163] Top shape: (1)
I1005 15:24:39.440176 14642 net.cpp:168]     with loss weight 1
I1005 15:24:39.440191 14642 net.cpp:236] error_layer needs backward computation.
I1005 15:24:39.440193 14642 net.cpp:236] output_act_layer needs backward computation.
I1005 15:24:39.440196 14642 net.cpp:236] output_sum_layer needs backward computation.
I1005 15:24:39.440198 14642 net.cpp:236] hidden_act_layer needs backward computation.
I1005 15:24:39.440201 14642 net.cpp:236] hidden_sum_layer needs backward computation.
I1005 15:24:39.440203 14642 net.cpp:240] data_layer does not need backward computation.
I1005 15:24:39.440206 14642 net.cpp:283] This network produces output error_blob
I1005 15:24:39.440210 14642 net.cpp:297] Network initialization done.
I1005 15:24:39.440212 14642 net.cpp:298] Memory required for data: 6720004
I1005 15:24:39.440232 14642 solver.cpp:66] Solver scaffolding done.
I1005 15:24:39.440326 14642 caffe.cpp:212] Starting Optimization
I1005 15:24:39.440332 14642 solver.cpp:294] Solving basic/model0_full.prototxt
I1005 15:24:39.440335 14642 solver.cpp:295] Learning Rate Policy: fixed
I1005 15:24:39.441721 14642 solver.cpp:243] Iteration 0, loss = 0.155972
I1005 15:24:39.441735 14642 solver.cpp:259]     Train net output #0: error_blob = 0.155972 (* 1 = 0.155972 loss)
I1005 15:24:39.441751 14642 solver.cpp:590] Iteration 0, lr = 0.01
I1005 15:24:39.442812 14642 blocking_queue.cpp:50] Data layer prefetch queue empty
I1005 15:24:41.915398 14642 solver.cpp:243] Iteration 100, loss = 0.125003
I1005 15:24:41.915429 14642 solver.cpp:259]     Train net output #0: error_blob = 0.125003 (* 1 = 0.125003 loss)
I1005 15:24:41.915436 14642 solver.cpp:590] Iteration 100, lr = 0.01
I1005 15:24:44.373358 14642 solver.cpp:243] Iteration 200, loss = 0.125007
I1005 15:24:44.373389 14642 solver.cpp:259]     Train net output #0: error_blob = 0.125007 (* 1 = 0.125007 loss)
I1005 15:24:44.373394 14642 solver.cpp:590] Iteration 200, lr = 0.01
I1005 15:24:46.845424 14642 solver.cpp:243] Iteration 300, loss = 0.125007
I1005 15:24:46.845464 14642 solver.cpp:259]     Train net output #0: error_blob = 0.125007 (* 1 = 0.125007 loss)
I1005 15:24:46.845470 14642 solver.cpp:590] Iteration 300, lr = 0.01
I1005 15:24:49.326489 14642 solver.cpp:243] Iteration 400, loss = 0.125003
I1005 15:24:49.326529 14642 solver.cpp:259]     Train net output #0: error_blob = 0.125003 (* 1 = 0.125003 loss)
I1005 15:24:49.326534 14642 solver.cpp:590] Iteration 400, lr = 0.01
I1005 15:24:51.837658 14642 solver.cpp:243] Iteration 500, loss = 0.125
I1005 15:24:51.837689 14642 solver.cpp:259]     Train net output #0: error_blob = 0.125 (* 1 = 0.125 loss)
I1005 15:24:51.837694 14642 solver.cpp:590] Iteration 500, lr = 0.01
I1005 15:24:54.343147 14642 solver.cpp:243] Iteration 600, loss = 0.125
I1005 15:24:54.343178 14642 solver.cpp:259]     Train net output #0: error_blob = 0.125 (* 1 = 0.125 loss)
I1005 15:24:54.343184 14642 solver.cpp:590] Iteration 600, lr = 0.01
I1005 15:24:56.829452 14642 solver.cpp:243] Iteration 700, loss = 0.125001
I1005 15:24:56.829481 14642 solver.cpp:259]     Train net output #0: error_blob = 0.125001 (* 1 = 0.125001 loss)
I1005 15:24:56.829486 14642 solver.cpp:590] Iteration 700, lr = 0.01
I1005 15:24:59.308218 14642 solver.cpp:243] Iteration 800, loss = 0.125
I1005 15:24:59.308248 14642 solver.cpp:259]     Train net output #0: error_blob = 0.125 (* 1 = 0.125 loss)
I1005 15:24:59.308253 14642 solver.cpp:590] Iteration 800, lr = 0.01
I1005 15:25:01.803067 14642 solver.cpp:243] Iteration 900, loss = 0.125
I1005 15:25:01.803097 14642 solver.cpp:259]     Train net output #0: error_blob = 0.125 (* 1 = 0.125 loss)
I1005 15:25:01.803102 14642 solver.cpp:590] Iteration 900, lr = 0.01
